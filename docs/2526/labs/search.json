[
  {
    "objectID": "1_01_slr.html",
    "href": "1_01_slr.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nBe able to specify a simple linear model\n\nUnderstand what fitted values and residuals are\n\nBe able to interpret the coefficients of a fitted model\n\n\nBe up to date with lectures\n\nHave watched course intro video in Week 0 folder, and completed associated tasks\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nsjPlot\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not directly copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_01_slr.html#descriptive-statistics-visualisations",
    "href": "1_01_slr.html#descriptive-statistics-visualisations",
    "title": "Simple Linear Regression",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 1\n\n\nVisualise and describe the marginal distributions of wellbeing scores and social interactions.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples of marginal distribution visualisations, see the data visualisation &gt; marginal distributions - examples flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nWellbeing (WEMWBS) Scores\nSocial Interactions\n\n\n\n\n\nVisualisation of Distribution\nDescriptive (Summary) Statistics\n\n\n\n\nggplot(data = mwdata, aes(x = wellbeing)) +\n  geom_density() +\n  labs(x = \"Wellbeing (WEMWBS) Scores\", \n       y = \"Probability density\")\n\n\n\nFigure 1: Distribution of Wellbeing (WEMWBS) Scores\n\n\n\nInitial observations from plot:\n\nThe distribution of wellbeing scores was unimodal\nMost of the wellbeing scores were between approximately 30 and 45\nThe lowest wellbeing in the sample was approximately 22 and the highest approximately 59. This suggested there was a fair high degree of variation in the data\nScores were within the range of possible values\n\n\n\n\nmwdata |&gt;\n  summarize(\n    M = mean(wellbeing), \n    SD = sd(wellbeing)\n    ) |&gt;\n    kable(caption = \"Wellbeing Descriptive Statistics\", align = \"c\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Wellbeing Descriptive Statistics\n\nM\nSD\n\n\n36.3\n5.39\n\n\n\n\n\n\n\nFollowing the exploration above, we can describe the wellbeing variable as follows:\n\n\n\n\n\n\nThe marginal distribution of scores on the WEMWBS was unimodal with a mean of approximately 36.3. There was variation in WEMWBS scores (SD = 5.39)\n\n\n\n\n\n\n\n\n\n\nVisualisation of Distribution\nDescriptive (Summary) Statistics\n\n\n\n\nggplot(data = mwdata, aes(x = social_int)) +\n  geom_density() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Probability density\")\n\n\n\nFigure 2: Distribution of Number of Social Interactions\n\n\n\nInitial observations from plot:\n\nThe distribution of social interactions was unimodal\nMost of the participants had between 8 and 15 social interactions per week\nThe fewest social interactions per week was approximately 3, and the highest approximately 24. This suggested there was a fair high degree of variation in the data\n\n\n\n\nmwdata |&gt; \n  summarize(\n    M = mean(social_int), \n    SD = sd(social_int)\n    ) |&gt;\n    kable(caption = \"Social Interactions Descriptive Statistics\", align = \"c\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 2: Social Interactions Descriptive Statistics\n\nM\nSD\n\n\n12.06\n4.02\n\n\n\n\n\n\n\nFollowing the exploration above, we can describe the social interactions variable as follows:\n\n\n\n\n\n\nThe marginal distribution of numbers of social interactions per week was unimodal with a mean of approximately 12.06. There was variation in numbers of social interactions (SD = 4.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nCreate a scatterplot of wellbeing score and social interactions before calculating the correlation between them.\nMaking reference to both the plot and correlation coefficient, describe the association between wellbeing and social interactions among participants in the Edinburgh & Lothians sample.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples of bivariate associations visualisations, see the data visualisation &gt; bivariate associations - examples flashcard.\nTo review how to calculate the correlation coefficient and for examples, see the correlation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nScatterplot\nCorrelation\n\n\n\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Wellbeing (WEMWBS) Scores\")\n\n\n\nFigure 3: Association between Wellbeing and Social Interactions\n\n\n\n\n\nTo comment on the strength of the linear association we compute the correlation coefficient in either of the following ways:\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\n# correlation matrix of the two columns of interest - (check with columns we need, in this case 3 & 5)\nround(cor(mwdata[,c(3,5)]), digits = 2)\n\n           social_int wellbeing\nsocial_int       1.00      0.24\nwellbeing        0.24      1.00\n\n\n\n\n\n# select only the columns we want by name, and pass this to cor()\nmwdata |&gt; \n  select(social_int, wellbeing) |&gt;\n  cor() |&gt;\n    round(digits = 2)\n\n           social_int wellbeing\nsocial_int       1.00      0.24\nwellbeing        0.24      1.00\n\n\n\n\n\nAnd we can see that via either method, the correlation is \\[\nr_{\\text({Social~Interactions,~~ Wellbeing})} = .24\n\\] \n\n\n\n\n\n\nThere was a weak, positive, linear association between the weekly number of social interactions and WEMWBS scores for the participants in the sample (\\(r\\) = .24). More social interactions were associated, on average, with higher wellbeing scores."
  },
  {
    "objectID": "1_01_slr.html#model-fitting-interpretation",
    "href": "1_01_slr.html#model-fitting-interpretation",
    "title": "Simple Linear Regression",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 3\n\n\nFirst, write the equation of the fitted line.\nNext, using the lm() function, fit a simple linear model to predict wellbeing (DV) by social interactions (IV), naming the output mdl.\nLastly, update your equation of the fitted line to include the estimated coefficients.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; simple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nFor how to format and write your model in RMarkdown, see the LaTeX symbols and equations flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nFirst, lets specify the fitted model, which can be written either as:\n\n\nOption A\nOption B\n\n\n\n\\[\n\\widehat{\\text{Wellbeing}} = \\hat \\beta_0 + \\hat \\beta_1 \\cdot \\text{Social Interactions}\n\\]\n\n\n\\[\n\\widehat{\\text{Wellbeing}} = \\hat \\beta_0 \\cdot 1 + \\hat \\beta_1 \\cdot \\text{Social Interactions}\n\\]\n\n\n\nTo fit the model in R, as the variables are in the mwdata dataframe, we would write:\n\n\nOption A\nOption B\n\n\n\n\nmdl &lt;- lm(wellbeing ~ social_int, data = mwdata)\nmdl\n\n\nCall:\nlm(formula = wellbeing ~ social_int, data = mwdata)\n\nCoefficients:\n(Intercept)   social_int  \n    32.4077       0.3222  \n\n\n\n\n\nmdl &lt;- lm(wellbeing ~ 1 + social_int, data = mwdata)\nmdl\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nCoefficients:\n(Intercept)   social_int  \n    32.4077       0.3222  \n\n\n\n\n\nNote that by calling the name of the fitted model, mdl, you can see the estimated regression coefficients \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\). We can add these values to the fitted line:\n\\[\n\\widehat{\\text{Wellbeing}} = 32.41 + 0.32 \\cdot \\text{Social Interactions} \\\\\n\\]\n\n\n\n\n\nQuestion 4\n\n\nExplore the following equivalent ways to obtain the estimated regression coefficients — that is, \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\) — from the fitted model:\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret estimated regression coefficients, see the general - extracting information &gt; model coefficients &gt; estimates flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nThe estimated parameters returned by the below methods are all equivalent. However, summary() returns more information.\n\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\nSimply invoke the name of the fitted model:\n\nmdl\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nCoefficients:\n(Intercept)   social_int  \n    32.4077       0.3222  \n\n\n\n\n\nmdl$coefficients\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n\n\n\n\ncoef(mdl)\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n\n\n\n\ncoefficients(mdl)\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n\n\n\nLook under the “Estimate” column:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 32.40771    1.17532  27.573  &lt; 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n\n\n\n\n\n\n\n\n\n\nThe estimated intercept is \\(\\hat \\beta_0 = 32.41\\) and the estimated slope is \\(\\hat \\beta_1 = 0.32\\).\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nExplore the following equivalent ways to obtain the estimated standard deviation of the errors — that is, \\(\\hat \\sigma\\) — from the fitted model mdl:\n\nsigma(mdl)\nsummary(mdl)\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret the estimated standard deviation of the errors, see the general - extracting information &gt; \\(\\sigma\\) flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nThe estimated standard deviation of the errors can be equivalently obtained by the below methods. However, summary() returns more information.\n\n\nsigma(mdl)\nsummary(mdl)\n\n\n\n\nsigma(mdl)\n\n[1] 5.246982\n\n\n\n\nLook at the “Residual standard error” entry of the summary(mdl) output:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 32.40771    1.17532  27.573  &lt; 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe term “Residual standard error” is a misnomer, as the help page for sigma says (check ?sigma). However, it’s hard to get rid of this bad name as it has been used in too many books showing R output. For more information, check the simple & multiple regression models - extracting information flashcard flashcard.\n\n\n\n\n\n\n\n\n\n\n\nThe estimated standard deviation of the errors is \\(\\hat \\sigma = 5.25\\).\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nInterpret the estimated intercept, slope, and standard deviation of the errors in the context of the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret estimated intercept, slope, and standard deviation of the errors coefficients, see the general - extracting information &gt; model coefficients flashcards.\nFor an example of intercept and slope interpretation in the context of simple linear regression, review the simple linear regression models &gt; example flashcards for a reminder on how to specify models, as well as an example.\nTo interpret the estimated standard deviation of the errors we can use the fact that about 95% of values from a normal distribution fall within two standard deviations of the center.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nIntercept\nSlope\nStandard deviation of the errors\n\n\n\nThe estimated wellbeing score associated with zero weekly social interactions is 32.41.\n\n\nThe estimated increase in wellbeing associated with one additional weekly social interaction is 0.32.\n\n\nFor any particular number of weekly social interactions, participants’ wellbeing scores should be distributed above and below the regression line with standard deviation estimated to be \\(\\hat \\sigma = 5.25\\). Since \\(2 \\hat \\sigma = 10.49\\), we expect most (about 95%) of the participants’ wellbeing scores to be within about 11 points from the regression line.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nPlot the data and the fitted regression line. To do so:\n\nExtract the estimated regression coefficients e.g., via betas &lt;- coef(mdl)\n\nExtract the first entry of betas (i.e., the intercept) via betas[1]\n\nExtract the second entry of betas (i.e., the slope) via betas[2]\n\nProvide the intercept and slope to the ggplot() function using geom_abline()\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nExtracting values\nThe function coef(mdl) returns a vector (a sequence of numbers all of the same type). To get the first element of the sequence you append [1], and [2] for the second.\nPlotting\nIn your ggplot(), you will need to specify geom_abline(). This might help get you started:\n\n geom_abline(intercept = intercept estimate, slope = slope estimate) \n\n\nFor further ggplot() guidance, see the how to visualise data flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nFirst extract the values required:\n\n#store the coefficients from the model in an object named betas\nbetas &lt;- coef(mdl)\n\n#examine object named betas\nbetas\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n#We can see that the intercept is the first value, and slope the second.\n\n#store the intercept estimate from betas object (beta 1, first element in list) in an object named int (short for intercept)\nint &lt;- betas[1]\n\n#store the slope estimate from betas object (beta 2, second element in list) in an object named slp (short for slope)\nslp &lt;- betas[2]\n\nWe can then plot the model as follows:\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = int, slope = slp, color = 'blue') + \n  labs(x = \"Social Interactions (Number per Week)\", y = \"Wellbeing (WEMWBS) Scores\")"
  },
  {
    "objectID": "1_01_slr.html#predicted-values-residuals",
    "href": "1_01_slr.html#predicted-values-residuals",
    "title": "Simple Linear Regression",
    "section": "Predicted Values & Residuals",
    "text": "Predicted Values & Residuals\n\nQuestion 8\n\n\nUse predict(mdl) to compute the fitted values and residuals. Mutate the mwdata dataframe to include the fitted values and residuals as extra columns.\nAssign to the following symbols the corresponding numerical values:\n\n\n\\(y_{3}\\) (response variable for unit \\(i = 3\\) in the sample data)\n\n\\(\\hat y_{3}\\) (fitted value for the third unit)\n\n\\(\\hat \\epsilon_{5}\\) (the residual corresponding to the 5th unit, i.e., \\(y_{5} - \\hat y_{5}\\))\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor a more detailed description and worked example, check the model predicted values & residuals flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nmwdata_fitted &lt;- mwdata |&gt;\n  mutate(\n    wellbeing_hat = predict(mdl),\n    resid = wellbeing - wellbeing_hat\n  )\n\nhead(mwdata_fitted)\n\n# A tibble: 6 × 9\n    age outdoor_time social_int routine wellbeing location steps_k wellbeing_hat\n  &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n1    28           12         13       1        36 rural       21.6          36.6\n2    56            5         15       1        41 rural       12.3          37.2\n3    25           19         11       1        35 rural       49.8          36.0\n4    60           25         15       0        35 rural       NA            37.2\n5    19            9         18       1        32 rural       48.1          38.2\n6    34           18         13       1        34 rural       67.3          36.6\n# ℹ 1 more variable: resid &lt;dbl&gt;\n\n\nBased on the above:\n\n\n\\(y_{3}\\) = 35 (see row 3, column 5)\n\n\\(\\hat y_{3}\\) = 35.95 (see row 3, column 8)\n\n\\(\\hat \\epsilon_{5} = y_{5} - \\hat y_{5}\\) = 32 - 38.21 = -6.21 (see row 5, columns 5 and 8)"
  },
  {
    "objectID": "1_01_slr.html#writing-up-presenting-results",
    "href": "1_01_slr.html#writing-up-presenting-results",
    "title": "Simple Linear Regression",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\ntab_model(mdl,\n          dv.labels = \"Wellbeing (WEMWBS) Scores\",\n          pred.labels = c(\"social_int\" = \"Social Interactions (Number per Week)\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\nTable 3: Regression Table for Wellbeing Model\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS) Scores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n32.41\n30.09 – 34.73\n&lt;0.001\n\n\nSocial Interactions\n(Number per Week)\n0.32\n0.14 – 0.50\n0.001\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.058 / 0.053\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nDescribe the design of the study (see Study Overview codebook), and the analyses that you undertook. Interpret your results in the context of the research question and report your model results in full.\nMake reference to your descriptive plots and/or statistics and regression table.\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nThe mwdata dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants’ wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\nTo visualise the marginal distributions of wellbeing and social interactions, density plots were used. To understand the strength of association between the two variables, the correlation coefficient was estimated. To investigate whether the number of weekly social interactions influences wellbeing (WEMWBS) scores, the following simple linear regression model was used:\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions}\n\\]\nFrom Figure 1 and Figure 2, we can see that both wellbeing \\((M = 36.3, SD = 5.39)\\) and social interactions \\((M = 12.06, SD = 4.02)\\) followed unimodal distributions. There was a weak, positive, linear association between WEMWBS scores and the weekly number of social interactions for the participants in the sample \\((r = .24)\\).\nFull regression results are displayed in Table 3. There was a significant association between wellbeing scores and social interactions \\((\\beta = 0.32, SE = 0.09, p &lt; .001)\\). The estimated wellbeing score with no social interactions per week was 32.41. Each additional social interaction was associated with a 0.32 point increase in wellbeing scores."
  },
  {
    "objectID": "1_01_slr_elm.html",
    "href": "1_01_slr_elm.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nBe able to specify a simple linear model\n\nUnderstand what fitted values and residuals are\n\nBe able to interpret the coefficients of a fitted model\n\n\nBe up to date with lectures\n\nHave watched course intro video in Week 0 folder, and completed associated tasks\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nsjPlot\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not directly copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_01_slr_elm.html#descriptive-statistics-visualisations",
    "href": "1_01_slr_elm.html#descriptive-statistics-visualisations",
    "title": "Simple Linear Regression",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 1\n\n\nVisualise and describe the marginal distributions of wellbeing scores and social interactions.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples of marginal distribution visualisations, see the data visualisation &gt; marginal distributions - examples flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nWellbeing (WEMWBS) Scores\nSocial Interactions\n\n\n\n\n\nVisualisation of Distribution\nDescriptive (Summary) Statistics\n\n\n\n\nggplot(data = mwdata, aes(x = wellbeing)) +\n  geom_density() +\n  labs(x = \"Wellbeing (WEMWBS) Scores\", \n       y = \"Probability density\")\n\n\n\nFigure 1: Distribution of Wellbeing (WEMWBS) Scores\n\n\n\nInitial observations from plot:\n\nThe distribution of wellbeing scores was unimodal\nMost of the wellbeing scores were between approximately 30 and 45\nThe lowest wellbeing in the sample was approximately 22 and the highest approximately 59. This suggested there was a fair high degree of variation in the data\nScores were within the range of possible values\n\n\n\n\nmwdata |&gt;\n  summarize(\n    M = mean(wellbeing), \n    SD = sd(wellbeing)\n    ) |&gt;\n    kable(caption = \"Wellbeing Descriptive Statistics\", align = \"c\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Wellbeing Descriptive Statistics\n\nM\nSD\n\n\n36.3\n5.39\n\n\n\n\n\n\n\nFollowing the exploration above, we can describe the wellbeing variable as follows:\n\n\n\n\n\n\nThe marginal distribution of scores on the WEMWBS was unimodal with a mean of approximately 36.3. There was variation in WEMWBS scores (SD = 5.39)\n\n\n\n\n\n\n\n\n\n\nVisualisation of Distribution\nDescriptive (Summary) Statistics\n\n\n\n\nggplot(data = mwdata, aes(x = social_int)) +\n  geom_density() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Probability density\")\n\n\n\nFigure 2: Distribution of Number of Social Interactions\n\n\n\nInitial observations from plot:\n\nThe distribution of social interactions was unimodal\nMost of the participants had between 8 and 15 social interactions per week\nThe fewest social interactions per week was approximately 3, and the highest approximately 24. This suggested there was a fair high degree of variation in the data\n\n\n\n\nmwdata |&gt; \n  summarize(\n    M = mean(social_int), \n    SD = sd(social_int)\n    ) |&gt;\n    kable(caption = \"Social Interactions Descriptive Statistics\", align = \"c\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 2: Social Interactions Descriptive Statistics\n\nM\nSD\n\n\n12.06\n4.02\n\n\n\n\n\n\n\nFollowing the exploration above, we can describe the social interactions variable as follows:\n\n\n\n\n\n\nThe marginal distribution of numbers of social interactions per week was unimodal with a mean of approximately 12.06. There was variation in numbers of social interactions (SD = 4.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nCreate a scatterplot of wellbeing score and social interactions before calculating the correlation between them.\nMaking reference to both the plot and correlation coefficient, describe the association between wellbeing and social interactions among participants in the Edinburgh & Lothians sample.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples of bivariate associations visualisations, see the data visualisation &gt; bivariate associations - examples flashcard.\nTo review how to calculate the correlation coefficient and for examples, see the correlation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nScatterplot\nCorrelation\n\n\n\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Wellbeing (WEMWBS) Scores\")\n\n\n\nFigure 3: Association between Wellbeing and Social Interactions\n\n\n\n\n\nTo comment on the strength of the linear association we compute the correlation coefficient in either of the following ways:\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\n# correlation matrix of the two columns of interest - (check with columns we need, in this case 3 & 5)\nround(cor(mwdata[,c(3,5)]), digits = 2)\n\n           social_int wellbeing\nsocial_int       1.00      0.24\nwellbeing        0.24      1.00\n\n\n\n\n\n# select only the columns we want by name, and pass this to cor()\nmwdata |&gt; \n  select(social_int, wellbeing) |&gt;\n  cor() |&gt;\n    round(digits = 2)\n\n           social_int wellbeing\nsocial_int       1.00      0.24\nwellbeing        0.24      1.00\n\n\n\n\n\nAnd we can see that via either method, the correlation is \\[\nr_{\\text({Social~Interactions,~~ Wellbeing})} = .24\n\\] \n\n\n\n\n\n\nThere was a weak, positive, linear association between the weekly number of social interactions and WEMWBS scores for the participants in the sample (\\(r\\) = .24). More social interactions were associated, on average, with higher wellbeing scores."
  },
  {
    "objectID": "1_01_slr_elm.html#model-fitting-interpretation",
    "href": "1_01_slr_elm.html#model-fitting-interpretation",
    "title": "Simple Linear Regression",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 3\n\n\nFirst, write the equation of the fitted line.\nNext, using the lm() function, fit a simple linear model to predict wellbeing (DV) by social interactions (IV), naming the output mdl.\nLastly, update your equation of the fitted line to include the estimated coefficients.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; simple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nFor how to format and write your model in RMarkdown, see the LaTeX symbols and equations flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nFirst, lets specify the fitted model, which can be written either as:\n\n\nOption A\nOption B\n\n\n\n\\[\n\\widehat{\\text{Wellbeing}} = \\hat \\beta_0 + \\hat \\beta_1 \\cdot \\text{Social Interactions}\n\\]\n\n\n\\[\n\\widehat{\\text{Wellbeing}} = \\hat \\beta_0 \\cdot 1 + \\hat \\beta_1 \\cdot \\text{Social Interactions}\n\\]\n\n\n\nTo fit the model in R, as the variables are in the mwdata dataframe, we would write:\n\n\nOption A\nOption B\n\n\n\n\nmdl &lt;- lm(wellbeing ~ social_int, data = mwdata)\nmdl\n\n\nCall:\nlm(formula = wellbeing ~ social_int, data = mwdata)\n\nCoefficients:\n(Intercept)   social_int  \n    32.4077       0.3222  \n\n\n\n\n\nmdl &lt;- lm(wellbeing ~ 1 + social_int, data = mwdata)\nmdl\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nCoefficients:\n(Intercept)   social_int  \n    32.4077       0.3222  \n\n\n\n\n\nNote that by calling the name of the fitted model, mdl, you can see the estimated regression coefficients \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\). We can add these values to the fitted line:\n\\[\n\\widehat{\\text{Wellbeing}} = 32.41 + 0.32 \\cdot \\text{Social Interactions} \\\\\n\\]\n\n\n\n\n\nQuestion 4\n\n\nExplore the following equivalent ways to obtain the estimated regression coefficients — that is, \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\) — from the fitted model:\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret estimated regression coefficients, see the general - extracting information &gt; model coefficients &gt; estimates flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nThe estimated parameters returned by the below methods are all equivalent. However, summary() returns more information.\n\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\nSimply invoke the name of the fitted model:\n\nmdl\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nCoefficients:\n(Intercept)   social_int  \n    32.4077       0.3222  \n\n\n\n\n\nmdl$coefficients\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n\n\n\n\ncoef(mdl)\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n\n\n\n\ncoefficients(mdl)\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n\n\n\nLook under the “Estimate” column:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 32.40771    1.17532  27.573  &lt; 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n\n\n\n\n\n\n\n\n\n\nThe estimated intercept is \\(\\hat \\beta_0 = 32.41\\) and the estimated slope is \\(\\hat \\beta_1 = 0.32\\).\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nExplore the following equivalent ways to obtain the estimated standard deviation of the errors — that is, \\(\\hat \\sigma\\) — from the fitted model mdl:\n\nsigma(mdl)\nsummary(mdl)\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret the estimated standard deviation of the errors, see the general - extracting information &gt; \\(\\sigma\\) flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nThe estimated standard deviation of the errors can be equivalently obtained by the below methods. However, summary() returns more information.\n\n\nsigma(mdl)\nsummary(mdl)\n\n\n\n\nsigma(mdl)\n\n[1] 5.246982\n\n\n\n\nLook at the “Residual standard error” entry of the summary(mdl) output:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 32.40771    1.17532  27.573  &lt; 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe term “Residual standard error” is a misnomer, as the help page for sigma says (check ?sigma). However, it’s hard to get rid of this bad name as it has been used in too many books showing R output. For more information, check the simple & multiple regression models - extracting information flashcard flashcard.\n\n\n\n\n\n\n\n\n\n\n\nThe estimated standard deviation of the errors is \\(\\hat \\sigma = 5.25\\).\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nInterpret the estimated intercept, slope, and standard deviation of the errors in the context of the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret estimated intercept, slope, and standard deviation of the errors coefficients, see the general - extracting information &gt; model coefficients flashcards.\nFor an example of intercept and slope interpretation in the context of simple linear regression, review the simple linear regression models &gt; example flashcards for a reminder on how to specify models, as well as an example.\nTo interpret the estimated standard deviation of the errors we can use the fact that about 95% of values from a normal distribution fall within two standard deviations of the center.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nIntercept\nSlope\nStandard deviation of the errors\n\n\n\nThe estimated wellbeing score associated with zero weekly social interactions is 32.41.\n\n\nThe estimated increase in wellbeing associated with one additional weekly social interaction is 0.32.\n\n\nFor any particular number of weekly social interactions, participants’ wellbeing scores should be distributed above and below the regression line with standard deviation estimated to be \\(\\hat \\sigma = 5.25\\). Since \\(2 \\hat \\sigma = 10.49\\), we expect most (about 95%) of the participants’ wellbeing scores to be within about 11 points from the regression line.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nPlot the data and the fitted regression line. To do so:\n\nExtract the estimated regression coefficients e.g., via betas &lt;- coef(mdl)\n\nExtract the first entry of betas (i.e., the intercept) via betas[1]\n\nExtract the second entry of betas (i.e., the slope) via betas[2]\n\nProvide the intercept and slope to the ggplot() function using geom_abline()\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nExtracting values\nThe function coef(mdl) returns a vector (a sequence of numbers all of the same type). To get the first element of the sequence you append [1], and [2] for the second.\nPlotting\nIn your ggplot(), you will need to specify geom_abline(). This might help get you started:\n\n geom_abline(intercept = intercept estimate, slope = slope estimate) \n\n\nFor further ggplot() guidance, see the how to visualise data flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nFirst extract the values required:\n\n#store the coefficients from the model in an object named betas\nbetas &lt;- coef(mdl)\n\n#examine object named betas\nbetas\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n#We can see that the intercept is the first value, and slope the second.\n\n#store the intercept estimate from betas object (beta 1, first element in list) in an object named int (short for intercept)\nint &lt;- betas[1]\n\n#store the slope estimate from betas object (beta 2, second element in list) in an object named slp (short for slope)\nslp &lt;- betas[2]\n\nWe can then plot the model as follows:\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = int, slope = slp, color = 'blue') + \n  labs(x = \"Social Interactions (Number per Week)\", y = \"Wellbeing (WEMWBS) Scores\")"
  },
  {
    "objectID": "1_01_slr_elm.html#predicted-values-residuals",
    "href": "1_01_slr_elm.html#predicted-values-residuals",
    "title": "Simple Linear Regression",
    "section": "Predicted Values & Residuals",
    "text": "Predicted Values & Residuals\n\nQuestion 8\n\n\nUse predict(mdl) to compute the fitted values and residuals. Mutate the mwdata dataframe to include the fitted values and residuals as extra columns.\nAssign to the following symbols the corresponding numerical values:\n\n\n\\(y_{3}\\) (response variable for unit \\(i = 3\\) in the sample data)\n\n\\(\\hat y_{3}\\) (fitted value for the third unit)\n\n\\(\\hat \\epsilon_{5}\\) (the residual corresponding to the 5th unit, i.e., \\(y_{5} - \\hat y_{5}\\))\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor a more detailed description and worked example, check the model predicted values & residuals flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nmwdata_fitted &lt;- mwdata |&gt;\n  mutate(\n    wellbeing_hat = predict(mdl),\n    resid = wellbeing - wellbeing_hat\n  )\n\nhead(mwdata_fitted)\n\n# A tibble: 6 × 9\n    age outdoor_time social_int routine wellbeing location steps_k wellbeing_hat\n  &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n1    28           12         13       1        36 rural       21.6          36.6\n2    56            5         15       1        41 rural       12.3          37.2\n3    25           19         11       1        35 rural       49.8          36.0\n4    60           25         15       0        35 rural       NA            37.2\n5    19            9         18       1        32 rural       48.1          38.2\n6    34           18         13       1        34 rural       67.3          36.6\n# ℹ 1 more variable: resid &lt;dbl&gt;\n\n\nBased on the above:\n\n\n\\(y_{3}\\) = 35 (see row 3, column 5)\n\n\\(\\hat y_{3}\\) = 35.95 (see row 3, column 8)\n\n\\(\\hat \\epsilon_{5} = y_{5} - \\hat y_{5}\\) = 32 - 38.21 = -6.21 (see row 5, columns 5 and 8)"
  },
  {
    "objectID": "1_01_slr_elm.html#writing-up-presenting-results",
    "href": "1_01_slr_elm.html#writing-up-presenting-results",
    "title": "Simple Linear Regression",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\ntab_model(mdl,\n          dv.labels = \"Wellbeing (WEMWBS) Scores\",\n          pred.labels = c(\"social_int\" = \"Social Interactions (Number per Week)\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\nTable 3: Regression Table for Wellbeing Model\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS) Scores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n32.41\n30.09 – 34.73\n&lt;0.001\n\n\nSocial Interactions\n(Number per Week)\n0.32\n0.14 – 0.50\n0.001\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.058 / 0.053\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nDescribe the design of the study (see Study Overview codebook), and the analyses that you undertook. Interpret your results in the context of the research question and report your model results in full.\nMake reference to your descriptive plots and/or statistics and regression table.\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nThe mwdata dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants’ wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\nTo visualise the marginal distributions of wellbeing and social interactions, density plots were used. To understand the strength of association between the two variables, the correlation coefficient was estimated. To investigate whether the number of weekly social interactions influences wellbeing (WEMWBS) scores, the following simple linear regression model was used:\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions}\n\\]\nFrom Figure 1 and Figure 2, we can see that both wellbeing \\((M = 36.3, SD = 5.39)\\) and social interactions \\((M = 12.06, SD = 4.02)\\) followed unimodal distributions. There was a weak, positive, linear association between WEMWBS scores and the weekly number of social interactions for the participants in the sample \\((r = .24)\\).\nFull regression results are displayed in Table 3. There was a significant association between wellbeing scores and social interactions \\((\\beta = 0.32, SE = 0.09, p &lt; .001)\\). The estimated wellbeing score with no social interactions per week was 32.41. Each additional social interaction was associated with a 0.32 point increase in wellbeing scores."
  },
  {
    "objectID": "1_02_mlr.html",
    "href": "1_02_mlr.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nExtend the ideas of single linear regression to consider regression models with two or more predictors\nUnderstand and interpret the coefficients in multiple linear regression models\n\n\nBe up to date with lectures\nHave completed Week 1 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_02_mlr.html#study-analysis-plan-overview",
    "href": "1_02_mlr.html#study-analysis-plan-overview",
    "title": "Multiple Linear Regression",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nProvide a brief overview of the study design and data, before detailing your analysis strategy to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study (you might be able to re-use some of the content you wrote for Lab 1 Q10 here)\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook. The statistical models flaschards, specifically the multiple linear regression models flashcards may also be useful to refer to.\n\n\n\n\n\n\n\n Solution \n\n\nThe mwdata dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants’ wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\nDensity plots and boxplots will be used to visualise the marginal distributions of wellbeing, social interactions, and outdoor time. To understand the strength of association among the variables, we will estimate the the correlation coefficients. To address the research question of whether there is an association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions, we are going to fit the following multiple linear regression model:\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\).\nOur hypotheses are:\n\\(H_0: \\beta_2 = 0\\): There is no association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions\n\\(H_1: \\beta_2 \\neq 0\\): There is an association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions"
  },
  {
    "objectID": "1_02_mlr.html#descriptive-statistics-visualisations",
    "href": "1_02_mlr.html#descriptive-statistics-visualisations",
    "title": "Multiple Linear Regression",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 2\n\n\nAlongside descriptive statistics, visualize the marginal distributions of the wellbeing, outdoor_time, and social_int variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables and data visualisation &gt; marginal distributions - examples flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nWe can present our summary statistics for wellbeing, outdoor time, and social interactions as a well formatted table using kable():\n\nmwdata |&gt; \n  select(wellbeing, outdoor_time, social_int) |&gt;\n    describe() |&gt;\n    kable(caption = \"Wellbeing, Social Interactions, and Outdoor Time Descriptive Statistics\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Wellbeing, Social Interactions, and Outdoor Time Descriptive Statistics\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nwellbeing\n1\n200\n36.30\n5.39\n35\n36.07\n4.45\n22\n59\n37\n0.58\n0.92\n0.38\n\n\noutdoor_time\n2\n200\n18.25\n7.10\n18\n18.14\n7.41\n1\n35\n34\n0.06\n-0.62\n0.50\n\n\nsocial_int\n3\n200\n12.06\n4.02\n12\n11.96\n4.45\n3\n24\n21\n0.21\n-0.40\n0.28\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe marginal distribution of scores on the WEMWBS was unimodal with a mean of approximately 36.3. There was variation in WEMWBS scores (SD = 5.39)\n\nThe marginal distribution of weekly hours spent outdoors was unimodal with a mean of approximately 18.25. There was variation in weekly hours spent outdoors (SD = 7.1)\nThe marginal distribution of numbers of social interactions per week was unimodal with a mean of approximately 12.06. There was variation in numbers of social interactions (SD = 4.02)\n\n\n\n\n\n\nYou should be familiar now with how to visualise a marginal distribution:\n\nwellbeing_plot &lt;- \n  ggplot(data = mwdata, aes(x = wellbeing)) +\n  geom_density() +\n  labs(x = \"Score on WEMWBS (range 14-70)\", y = \"Density\")\n\noutdoortime_plot &lt;- \n  ggplot(data = mwdata, aes(x = outdoor_time)) +\n  geom_density() +\n  labs(x = \"Time spent outdoors per week (hours)\", y = \"Density\")\n\nsocial_plot &lt;- \n  ggplot(data = mwdata, aes(x = social_int)) +\n  geom_density() +\n  labs(x = \"Number of social interactions per week\", y = \"Density\")\n\n# arrange plots vertically \nwellbeing_plot / outdoortime_plot / social_plot\n\n\n\nFigure 1: Marginal distribution plots of wellbeing sores, weekly hours spent outdoors, and social interactions\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nProduce plots of the associations between the outcome variable (wellbeing) and each of the explanatory variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview how to visually explore bivariate associations via the data explortation flashcards.\nFor specifically visualising associations between variables, see the visual exploration &gt; bivariate associations - examples.\n\n\n\n\n\n\n\n Solution \n\n\n\nwellbeing_outdoor &lt;- \n  ggplot(data = mwdata, aes(x = outdoor_time, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Time spent outdoors \\nper week (hours)\", y = \"Wellbeing score (WEMWBS)\")\n\nwellbeing_social &lt;- \n  ggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Number of social interactions \\nper week\", y = \"Wellbeing score (WEMWBS)\")\n\n# place plots adjacent to one another\nwellbeing_outdoor | wellbeing_social\n\n\n\nFigure 2: Scatterplots displaying the relationships between scores on the WEMWBS and a) weekly outdoor time (hours), and b) weekly number of social interactions\n\n\n\nBoth scatterplots indicated weak, positive, and linear associations both between wellbeing and outdoor time, and between wellbeing and the number of weekly social interactions.\n\n\n\n\n\nQuestion 4\n\n\nProduce a correlation matrix of the variables which are to be used in the analysis, and write a short paragraph describing the associations.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate the correlation coefficient and for examples, see the correlation flashcards. Remember to interpret in the context of the research question.\n\n\n\n\n\n\n\n Solution \n\n\nWe can either index the dataframe or select the variables of interest:\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\n# correlation matrix of the three columns of interest (check which columns we need - in this case, 2,3, and 5)\nround(cor(mwdata[,c(5,3,2)]), digits = 2)\n\n             wellbeing social_int outdoor_time\nwellbeing         1.00       0.24         0.25\nsocial_int        0.24       1.00        -0.04\noutdoor_time      0.25      -0.04         1.00\n\n\n\n\n\n# select only the columns we want by variable name, and pass this to cor()\nmwdata |&gt; \n  select(wellbeing, social_int, outdoor_time) |&gt;\n  cor() |&gt;\n  round(digits = 2)\n\n             wellbeing social_int outdoor_time\nwellbeing         1.00       0.24         0.25\nsocial_int        0.24       1.00        -0.04\noutdoor_time      0.25      -0.04         1.00\n\n\n\n\n\n\n\n\n\n\n\n\nThere was a weak, positive, linear association between WEMWBS scores and weekly outdoor time for the participants in the sample (\\(r\\) = .25). Higher number of hours spent outdoors each week was associated, on average, with higher wellbeing scores\n\nThere was a weak, positive, linear association between WEMWBS scores and the weekly number of social interactions for the participants in the sample (\\(r\\) = .24). More social interactions were associated, on average, with higher wellbeing scores\nThere was a negligible negative correlation between weekly outdoor time and the weekly number of social interactions (\\(r\\) = -.04)"
  },
  {
    "objectID": "1_02_mlr.html#model-fitting-interpretation",
    "href": "1_02_mlr.html#model-fitting-interpretation",
    "title": "Multiple Linear Regression",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nRecall the model specified in Q1, and:\n\nState the parameters of the model. How do we denote parameter estimates?\n\nFit the linear model in using lm(), assigning the output to an object called mdl1.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nFor how to format and write your model in RMarkdown, see the LaTeX symbols and equations flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nA model for the association between \\(x_1\\) = weekly numbers of social interactions, \\(x_2\\) = weekly outdoor time, and \\(y\\) = scores on the WEMWBS can be given by: \\[\ny_i = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\epsilon_i \\\\ \\quad \\\\\n\\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\nIn the model specified above,\n\n\n\\(\\mu_{y|x_1, x_2} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\\) represents the systematic part of the model giving the mean of \\(y\\) at each combination of values of \\(x_1\\) and \\(x_2\\);\n\n\\(\\epsilon\\) represents the error (deviation) from that mean, and the errors are independent from one another.\n\nThe parameters of our model are:\n\n\n\\(\\beta_0\\) (The intercept)\n\n\n\\(\\beta_1\\) (The slope across values of \\(x_1\\))\n\n\n\\(\\beta_2\\) (The slope across values of \\(x_2\\))\n\n\n\\(\\sigma\\) (The standard deviation of the errors)\n\nWhen we estimate these parameters from the available data, we have a fitted model (recall that the h\\(\\hat{\\textrm{a}}\\)ts are used to distinguish our estimates from the true unknown parameters):\n\\[\n\\widehat{\\text{Wellbeing}} = \\hat\\beta_0 + \\hat\\beta_1 \\cdot \\text{Social Interactions} + \\hat\\beta_2 \\cdot \\text{Outdoor Time}\n\\]\nAnd we have residuals \\(\\hat \\epsilon = y - \\hat y\\) which are the deviations from the observed values and our model-predicted responses.\nFitting the model in R:\n\nmdl1 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\n\n\n\n\n\n\nQuestion 6\n\n\nUsing any of:\n\nmdl1\nmdl1$coefficients\ncoef(mdl1)\ncoefficients(mdl1)\nsummary(mdl1)\n\nWrite out the estimated parameter values of:\n\n\n\\(\\hat \\beta_0\\), the estimated average wellbeing score associated with zero hours of outdoor time and zero social interactions per week\n\n\n\\(\\hat \\beta_1\\), the estimated increase in average wellbeing score associated with an additional social interaction per week (an increase of one), holding weekly outdoor time constant\n\n\n\\(\\hat \\beta_2\\), the estimated increase in average wellbeing score associated with one hour increase in weekly outdoor time, holding the number of social interactions constant\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret estimated regression coefficients, see the general - extracting information &gt; model coefficients &gt; estimates flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nmdl1\nmdl1$coefficients\ncoef(mdl1)\ncoefficients(mdl1)\nsummary(mdl1)\n\n\n\n\nmdl1\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nCoefficients:\n (Intercept)    social_int  outdoor_time  \n     28.6202        0.3349        0.1991  \n\n\n\n\n\nmdl1$coefficients\n\n (Intercept)   social_int outdoor_time \n  28.6201808    0.3348821    0.1990943 \n\n\n\n\n\ncoef(mdl1)\n\n (Intercept)   social_int outdoor_time \n  28.6201808    0.3348821    0.1990943 \n\n\n\n\n\ncoefficients(mdl1)\n\n (Intercept)   social_int outdoor_time \n  28.6201808    0.3348821    0.1990943 \n\n\n\n\nLook under the “Estimate” column:\n\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n\n\n\\(\\hat \\beta_0\\) = 28.62\n\n\n\\(\\hat \\beta_1\\) = 0.33\n\n\n\\(\\hat \\beta_2\\) = 0.2\n\n\n\n\n\n\nQuestion 7\n\n\nWithin what distance from the model predicted values (the regression line) would we expect 95% of WEMWBS wellbeing scores to be?\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret the estimated standard deviation of the errors, see the general - extracting information &gt; \\(\\sigma\\) flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nsigma(mdl1)\nsummary(mdl1)\n\n\n\n\nsigma(mdl1)\n\n[1] 5.065003\n\n\n\n\nLook at the “Residual standard error” entry of the summary(mdl) output:\n\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\nThe estimated standard deviation of the errors is \\(\\hat \\sigma\\) = 5.07. We would expect 95% of wellbeing scores to be within about 10.13 (\\(2 \\hat \\sigma\\)) from the model fit.\n\n\n\n\n\nQuestion 8\n\n\nBased on the model, predict the wellbeing scores for the following individuals who were not included in the original sample:\n\nLeah: Social Interactions = 25; Outdoor Time = 3\nSean: Social Interactions = 19; Outdoor Time = 36\nMike: Social Interactions = 15; Outdoor Time = 20\nDonna: Social Interactions = 7; Outdoor Time = 1\n\nWho has the highest predicted wellbeing score, and who has the lowest?\n\n\n\n\n\n\nHint\n\n\n\n\n\nIt might be helpful to review the model predicted values & residuals &gt; predicted values &gt; model predicted values for other (unobserved) data flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nFirst we need to pass the data into R:\n\nwellbeing_query &lt;- tibble(social_int = c(25, 19, 15, 7),\n                          outdoor_time = c(3, 36, 20, 1))\n\nAnd next use predict() to get their estimated wellbeing scores:\n\npredict(mdl1, newdata = wellbeing_query)\n\n       1        2        3        4 \n37.58952 42.15034 37.62530 31.16345 \n\n\nSean has the highest predicted wellbeing score (42.15), and Donna the lowest (31.16)."
  },
  {
    "objectID": "1_02_mlr.html#writing-up-presenting-results",
    "href": "1_02_mlr.html#writing-up-presenting-results",
    "title": "Multiple Linear Regression",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\ntab_model(mdl1,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"social_int\" = \"Social Interactions (number per week)\",\n                          \"outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\nTable 2: Regression Table for Wellbeing Model\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n28.62\n25.69 – 31.55\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n0.33\n0.16 – 0.51\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n0.20\n0.10 – 0.30\n&lt;0.001\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.126 / 0.118\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question.\nMake reference to the regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake sure to include a decision in relation to your null hypothesis - based on the evidence, should you reject or fail to reject the null?\n\n\n\n\n\n\n\n Solution \n\n\nFrom Figure 1, we can see that wellbeing \\((M = 36.3, SD = 5.39)\\), social interactions \\((M = 12.06, SD = 4.02)\\), and outdoor time \\((M = 18.25, SD = 7.1)\\) followed unimodal distributions. There were weak, positive, linear associations between WEMWBS scores and the weekly number of social interactions \\((r = .24)\\), and between WEMWBS scores and outdoor time \\((r = .25)\\) in the sample.\nA multiple regression model was used to determine if there was an association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions. As presented in Table 2, outdoor time was significantly associated with wellbeing scores \\((\\beta = 0.20, SE = 0.05, p &lt; .001)\\) after controlling for the number of weekly social interactions. Results suggested that, holding constant social interactions, for every additional hour spent outdoors each week, wellbeing scores increased by 0.20 points. Therefore, we should reject the null hypothesis since \\(p &lt; .05\\)."
  },
  {
    "objectID": "1_02_mlr_sycamore.html",
    "href": "1_02_mlr_sycamore.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nExtend the ideas of single linear regression to consider regression models with two or more predictors\nUnderstand and interpret the coefficients in multiple linear regression models\n\n\nBe up to date with lectures\nHave completed Week 1 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_02_mlr_sycamore.html#study-analysis-plan-overview",
    "href": "1_02_mlr_sycamore.html#study-analysis-plan-overview",
    "title": "Multiple Linear Regression",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nProvide a brief overview of the study design and data, before detailing your analysis strategy to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study (you might be able to re-use some of the content you wrote for Lab 1 Q10 here)\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook. The statistical models flaschards, specifically the multiple linear regression models flashcards may also be useful to refer to.\n\n\n\n\n\n\n\n Solution \n\n\nThe mwdata dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants’ wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\nDensity plots and boxplots will be used to visualise the marginal distributions of wellbeing, social interactions, and outdoor time. To understand the strength of association among the variables, we will estimate the the correlation coefficients. To address the research question of whether there is an association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions, we are going to fit the following multiple linear regression model:\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\).\nOur hypotheses are:\n\\(H_0: \\beta_2 = 0\\): There is no association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions\n\\(H_1: \\beta_2 \\neq 0\\): There is an association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions"
  },
  {
    "objectID": "1_02_mlr_sycamore.html#descriptive-statistics-visualisations",
    "href": "1_02_mlr_sycamore.html#descriptive-statistics-visualisations",
    "title": "Multiple Linear Regression",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 2\n\n\nAlongside descriptive statistics, visualize the marginal distributions of the wellbeing, outdoor_time, and social_int variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables and data visualisation &gt; marginal distributions - examples flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nWe can present our summary statistics for wellbeing, outdoor time, and social interactions as a well formatted table using kable():\n\nmwdata |&gt; \n  select(wellbeing, outdoor_time, social_int) |&gt;\n    describe() |&gt;\n    kable(caption = \"Wellbeing, Social Interactions, and Outdoor Time Descriptive Statistics\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Wellbeing, Social Interactions, and Outdoor Time Descriptive Statistics\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nwellbeing\n1\n200\n36.30\n5.39\n35\n36.07\n4.45\n22\n59\n37\n0.58\n0.92\n0.38\n\n\noutdoor_time\n2\n200\n18.25\n7.10\n18\n18.14\n7.41\n1\n35\n34\n0.06\n-0.62\n0.50\n\n\nsocial_int\n3\n200\n12.06\n4.02\n12\n11.96\n4.45\n3\n24\n21\n0.21\n-0.40\n0.28\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe marginal distribution of scores on the WEMWBS was unimodal with a mean of approximately 36.3. There was variation in WEMWBS scores (SD = 5.39)\n\nThe marginal distribution of weekly hours spent outdoors was unimodal with a mean of approximately 18.25. There was variation in weekly hours spent outdoors (SD = 7.1)\nThe marginal distribution of numbers of social interactions per week was unimodal with a mean of approximately 12.06. There was variation in numbers of social interactions (SD = 4.02)\n\n\n\n\n\n\nYou should be familiar now with how to visualise a marginal distribution:\n\nwellbeing_plot &lt;- \n  ggplot(data = mwdata, aes(x = wellbeing)) +\n  geom_density() +\n  labs(x = \"Score on WEMWBS (range 14-70)\", y = \"Density\")\n\noutdoortime_plot &lt;- \n  ggplot(data = mwdata, aes(x = outdoor_time)) +\n  geom_density() +\n  labs(x = \"Time spent outdoors per week (hours)\", y = \"Density\")\n\nsocial_plot &lt;- \n  ggplot(data = mwdata, aes(x = social_int)) +\n  geom_density() +\n  labs(x = \"Number of social interactions per week\", y = \"Density\")\n\n# arrange plots vertically \nwellbeing_plot / outdoortime_plot / social_plot\n\n\n\nFigure 1: Marginal distribution plots of wellbeing sores, weekly hours spent outdoors, and social interactions\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nProduce plots of the associations between the outcome variable (wellbeing) and each of the explanatory variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview how to visually explore bivariate associations via the data explortation flashcards.\nFor specifically visualising associations between variables, see the visual exploration &gt; bivariate associations - examples.\n\n\n\n\n\n\n\n Solution \n\n\n\nwellbeing_outdoor &lt;- \n  ggplot(data = mwdata, aes(x = outdoor_time, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Time spent outdoors \\nper week (hours)\", y = \"Wellbeing score (WEMWBS)\")\n\nwellbeing_social &lt;- \n  ggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Number of social interactions \\nper week\", y = \"Wellbeing score (WEMWBS)\")\n\n# place plots adjacent to one another\nwellbeing_outdoor | wellbeing_social\n\n\n\nFigure 2: Scatterplots displaying the relationships between scores on the WEMWBS and a) weekly outdoor time (hours), and b) weekly number of social interactions\n\n\n\nBoth scatterplots indicated weak, positive, and linear associations both between wellbeing and outdoor time, and between wellbeing and the number of weekly social interactions.\n\n\n\n\n\nQuestion 4\n\n\nProduce a correlation matrix of the variables which are to be used in the analysis, and write a short paragraph describing the associations.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate the correlation coefficient and for examples, see the correlation flashcards. Remember to interpret in the context of the research question.\n\n\n\n\n\n\n\n Solution \n\n\nWe can either index the dataframe or select the variables of interest:\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\n# correlation matrix of the three columns of interest (check which columns we need - in this case, 2,3, and 5)\nround(cor(mwdata[,c(5,3,2)]), digits = 2)\n\n             wellbeing social_int outdoor_time\nwellbeing         1.00       0.24         0.25\nsocial_int        0.24       1.00        -0.04\noutdoor_time      0.25      -0.04         1.00\n\n\n\n\n\n# select only the columns we want by variable name, and pass this to cor()\nmwdata |&gt; \n  select(wellbeing, social_int, outdoor_time) |&gt;\n  cor() |&gt;\n  round(digits = 2)\n\n             wellbeing social_int outdoor_time\nwellbeing         1.00       0.24         0.25\nsocial_int        0.24       1.00        -0.04\noutdoor_time      0.25      -0.04         1.00\n\n\n\n\n\n\n\n\n\n\n\n\nThere was a weak, positive, linear association between WEMWBS scores and weekly outdoor time for the participants in the sample (\\(r\\) = .25). Higher number of hours spent outdoors each week was associated, on average, with higher wellbeing scores\n\nThere was a weak, positive, linear association between WEMWBS scores and the weekly number of social interactions for the participants in the sample (\\(r\\) = .24). More social interactions were associated, on average, with higher wellbeing scores\nThere was a negligible negative correlation between weekly outdoor time and the weekly number of social interactions (\\(r\\) = -.04)"
  },
  {
    "objectID": "1_02_mlr_sycamore.html#model-fitting-interpretation",
    "href": "1_02_mlr_sycamore.html#model-fitting-interpretation",
    "title": "Multiple Linear Regression",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nRecall the model specified in Q1, and:\n\nState the parameters of the model. How do we denote parameter estimates?\n\nFit the linear model in using lm(), assigning the output to an object called mdl1.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nFor how to format and write your model in RMarkdown, see the LaTeX symbols and equations flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nA model for the association between \\(x_1\\) = weekly numbers of social interactions, \\(x_2\\) = weekly outdoor time, and \\(y\\) = scores on the WEMWBS can be given by: \\[\ny_i = \\beta_0 + \\beta_1 x_{1_i} + \\beta_2 x_{2_i} + \\epsilon_i \\\\ \\quad \\\\\n\\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\nIn the model specified above,\n\n\n\\(\\mu_{y|x_1, x_2} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\\) represents the systematic part of the model giving the mean of \\(y\\) at each combination of values of \\(x_1\\) and \\(x_2\\);\n\n\\(\\epsilon\\) represents the error (deviation) from that mean, and the errors are independent from one another.\n\nThe parameters of our model are:\n\n\n\\(\\beta_0\\) (The intercept)\n\n\n\\(\\beta_1\\) (The slope across values of \\(x_1\\))\n\n\n\\(\\beta_2\\) (The slope across values of \\(x_2\\))\n\n\n\\(\\sigma\\) (The standard deviation of the errors)\n\nWhen we estimate these parameters from the available data, we have a fitted model (recall that the h\\(\\hat{\\textrm{a}}\\)ts are used to distinguish our estimates from the true unknown parameters):\n\\[\n\\widehat{\\text{Wellbeing}} = \\hat\\beta_0 + \\hat\\beta_1 \\cdot \\text{Social Interactions} + \\hat\\beta_2 \\cdot \\text{Outdoor Time}\n\\]\nAnd we have residuals \\(\\hat \\epsilon = y - \\hat y\\) which are the deviations from the observed values and our model-predicted responses.\nFitting the model in R:\n\nmdl1 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\n\n\n\n\n\n\nQuestion 6\n\n\nUsing any of:\n\nmdl1\nmdl1$coefficients\ncoef(mdl1)\ncoefficients(mdl1)\nsummary(mdl1)\n\nWrite out the estimated parameter values of:\n\n\n\\(\\hat \\beta_0\\), the estimated average wellbeing score associated with zero hours of outdoor time and zero social interactions per week\n\n\n\\(\\hat \\beta_1\\), the estimated increase in average wellbeing score associated with an additional social interaction per week (an increase of one), holding weekly outdoor time constant\n\n\n\\(\\hat \\beta_2\\), the estimated increase in average wellbeing score associated with one hour increase in weekly outdoor time, holding the number of social interactions constant\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret estimated regression coefficients, see the general - extracting information &gt; model coefficients &gt; estimates flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nmdl1\nmdl1$coefficients\ncoef(mdl1)\ncoefficients(mdl1)\nsummary(mdl1)\n\n\n\n\nmdl1\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nCoefficients:\n (Intercept)    social_int  outdoor_time  \n     28.6202        0.3349        0.1991  \n\n\n\n\n\nmdl1$coefficients\n\n (Intercept)   social_int outdoor_time \n  28.6201808    0.3348821    0.1990943 \n\n\n\n\n\ncoef(mdl1)\n\n (Intercept)   social_int outdoor_time \n  28.6201808    0.3348821    0.1990943 \n\n\n\n\n\ncoefficients(mdl1)\n\n (Intercept)   social_int outdoor_time \n  28.6201808    0.3348821    0.1990943 \n\n\n\n\nLook under the “Estimate” column:\n\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n\n\n\\(\\hat \\beta_0\\) = 28.62\n\n\n\\(\\hat \\beta_1\\) = 0.33\n\n\n\\(\\hat \\beta_2\\) = 0.2\n\n\n\n\n\n\nQuestion 7\n\n\nWithin what distance from the model predicted values (the regression line) would we expect 95% of WEMWBS wellbeing scores to be?\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret the estimated standard deviation of the errors, see the general - extracting information &gt; \\(\\sigma\\) flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nsigma(mdl1)\nsummary(mdl1)\n\n\n\n\nsigma(mdl1)\n\n[1] 5.065003\n\n\n\n\nLook at the “Residual standard error” entry of the summary(mdl) output:\n\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\nThe estimated standard deviation of the errors is \\(\\hat \\sigma\\) = 5.07. We would expect 95% of wellbeing scores to be within about 10.13 (\\(2 \\hat \\sigma\\)) from the model fit.\n\n\n\n\n\nQuestion 8\n\n\nBased on the model, predict the wellbeing scores for the following individuals who were not included in the original sample:\n\nLeah: Social Interactions = 25; Outdoor Time = 3\nSean: Social Interactions = 19; Outdoor Time = 36\nMike: Social Interactions = 15; Outdoor Time = 20\nDonna: Social Interactions = 7; Outdoor Time = 1\n\nWho has the highest predicted wellbeing score, and who has the lowest?\n\n\n\n\n\n\nHint\n\n\n\n\n\nIt might be helpful to review the model predicted values & residuals &gt; predicted values &gt; model predicted values for other (unobserved) data flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nFirst we need to pass the data into R:\n\nwellbeing_query &lt;- tibble(social_int = c(25, 19, 15, 7),\n                          outdoor_time = c(3, 36, 20, 1))\n\nAnd next use predict() to get their estimated wellbeing scores:\n\npredict(mdl1, newdata = wellbeing_query)\n\n       1        2        3        4 \n37.58952 42.15034 37.62530 31.16345 \n\n\nSean has the highest predicted wellbeing score (42.15), and Donna the lowest (31.16)."
  },
  {
    "objectID": "1_02_mlr_sycamore.html#writing-up-presenting-results",
    "href": "1_02_mlr_sycamore.html#writing-up-presenting-results",
    "title": "Multiple Linear Regression",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\ntab_model(mdl1,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"social_int\" = \"Social Interactions (number per week)\",\n                          \"outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\nTable 2: Regression Table for Wellbeing Model\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n28.62\n25.69 – 31.55\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n0.33\n0.16 – 0.51\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n0.20\n0.10 – 0.30\n&lt;0.001\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.126 / 0.118\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question.\nMake reference to the regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake sure to include a decision in relation to your null hypothesis - based on the evidence, should you reject or fail to reject the null?\n\n\n\n\n\n\n\n Solution \n\n\nFrom Figure 1, we can see that wellbeing \\((M = 36.3, SD = 5.39)\\), social interactions \\((M = 12.06, SD = 4.02)\\), and outdoor time \\((M = 18.25, SD = 7.1)\\) followed unimodal distributions. There were weak, positive, linear associations between WEMWBS scores and the weekly number of social interactions \\((r = .24)\\), and between WEMWBS scores and outdoor time \\((r = .25)\\) in the sample.\nA multiple regression model was used to determine if there was an association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions. As presented in Table 2, outdoor time was significantly associated with wellbeing scores \\((\\beta = 0.20, SE = 0.05, p &lt; .001)\\) after controlling for the number of weekly social interactions. Results suggested that, holding constant social interactions, for every additional hour spent outdoors each week, wellbeing scores increased by 0.20 points. Therefore, we should reject the null hypothesis since \\(p &lt; .05\\)."
  },
  {
    "objectID": "1_03_mlr_stz.html",
    "href": "1_03_mlr_stz.html",
    "title": "Multiple Linear Regression & Standardization",
    "section": "",
    "text": "At the end of this lab, you will:\n\nExtend the ideas of single linear regression to consider regression models with two or more predictors\nUnderstand how to interpret significance tests for \\(\\beta\\) coefficients\nUnderstand how to standardize model coefficients and when this is appropriate to do\nUnderstand how to interpret standardized model coefficients in multiple linear regression models\n\n\nBe up to date with lectures\nHave completed Week 1 and Week 2 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npatchwork\nsjPlot\nppcor\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_03_mlr_stz.html#lab-2-recap",
    "href": "1_03_mlr_stz.html#lab-2-recap",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Lab 2 Recap",
    "text": "Lab 2 Recap\n\nQuestion 1\n\n\nFit the following multiple linear regression model, and assign the output to an object called mdl, and examine the summary output.\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nThe summary() function will be useful to examine the model output.\n\n\n\n\n\n\n\n Solution \n\n\n\nmdl &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06"
  },
  {
    "objectID": "1_03_mlr_stz.html#significance-tests-for-beta-coefficients",
    "href": "1_03_mlr_stz.html#significance-tests-for-beta-coefficients",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Significance Tests for \\(\\beta\\) Coefficients",
    "text": "Significance Tests for \\(\\beta\\) Coefficients\n\nQuestion 2\n\n\nTest the hypothesis that the population slope for outdoor time is zero — that is, that there is no linear association between wellbeing and outdoor time (after controlling for the number of social interactions) in the population.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret \\(t\\)-values, see the general - extracting information &gt; model coefficients &gt; t value flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\nWe calculate the test statistic for \\(\\beta_2\\) as:\n\\[\nt = \\frac{\\hat \\beta_2 - 0}{SE(\\hat \\beta_2)} = \\frac{0.19909 - 0}{0.05060} = 3.934585\n\\]\nand compare it with the 5% critical value from a \\(t\\)-distribution with \\(n-3\\) degrees of freedom (since \\(k = 2\\), we have \\(n-2-1\\)), which is:\n\nn &lt;- nrow(mwdata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 1.972079\n\n\nAs \\(|t|\\) (\\(|t|\\) = 3.93) is much larger than \\(t^*\\) (\\(t^*\\) = 1.97), we can reject the null hypothesis as we have strong evidence against it.\nThe \\(p\\)-value, shown below, also confirms this conclusion.\n\n2 * (1 - pt(3.934585, n - 3))\n\n[1] 0.0001154709\n\n\n\n\nPlease note that the same information was already contained in the row corresponding to the variable “outdoor_time” in the output of summary(mdl), which reported the \\(t\\)-statistic under t value and the \\(p\\)-value under Pr(&gt;|t|):\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\nThe result is exactly the same (up to rounding errors) as calculating manually.\nBefore we interpret the results, note that sometimes \\(p\\)-values will be reported to \\(e^X\\). For example, look in the Pr(&gt;|t|) column for “(Intercept)”. The value \\(2e^{-16}\\) simply means \\(2 \\times 10^{-16}\\). This is a very small value (i.e., 0.0000000000000002), hence we would simply report it as &lt;.001 following the APA guidelines.\n\n\n\n\n\n\n\n\n\nWe performed a test against the null hypothesis that outdoor time was not associated with wellbeing scores after controlling for social interactions. A significant association was found between outdoor time (hours per week) and wellbeing (WEMWBS scores) \\(t(197) = 3.94,\\ p &lt; .001\\), two-sided. Thus, we have evidence to reject the null hypothesis.\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nObtain 95% confidence intervals for the regression coefficients, and write a sentence about each one.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret confidence intervals, see the general - extracting information &gt; confidence intervals flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\nIn order to use the qt() function, we first we need to calculate our degrees of freedom:\n\n#calculated as df = n - k - 1\nn &lt;- nrow(mwdata)\nk &lt;- 2\ndf &lt;- n - k -1\ndf\n\n[1] 197\n\n\nWe have 197 degrees of freedom, and so can calculate the confidence intervals as follows:\n\ntibble(\n  b0_LowerCI = round(28.62018 - (qt(0.975, 197) * 1.48786), 3),\n  b0_UpperCI = round(28.62018 + (qt(0.975, 197)* 1.48786), 3),\n  b1_LowerCI = round(0.33488 - (qt(0.975, 197) * 0.08929), 3),\n  b1_UpperCI = round(0.33488 + (qt(0.975, 197)* 0.08929), 3),\n  b2_LowerCI = round(0.19909 - (qt(0.975, 197) * 0.05060), 3),\n  b2_UpperCI = round(0.19909 + (qt(0.975, 197)* 0.05060), 3)\n      )\n\n# A tibble: 1 × 6\n  b0_LowerCI b0_UpperCI b1_LowerCI b1_UpperCI b2_LowerCI b2_UpperCI\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1       25.7       31.6      0.159      0.511      0.099      0.299\n\n\nAlternatively, we could use the tstar value we computed above in Question 2 in place of the qt() function:\n\ntibble(\n  b0_LowerCI = round(28.62018 - (tstar * 1.48786), 3),\n  b0_UpperCI = round(28.62018 + (tstar * 1.48786), 3),\n  b1_LowerCI = round(0.33488 - (tstar  * 0.08929), 3),\n  b1_UpperCI = round(0.33488 + (tstar * 0.08929), 3),\n  b2_LowerCI = round(0.19909 - (tstar * 0.05060), 3),\n  b2_UpperCI = round(0.19909 + (tstar * 0.05060), 3)\n      )\n\n# A tibble: 1 × 6\n  b0_LowerCI b0_UpperCI b1_LowerCI b1_UpperCI b2_LowerCI b2_UpperCI\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1       25.7       31.6      0.159      0.511      0.099      0.299\n\n\n\n\nWe can much more easily obtain the confidence intervals for the regression coefficients using the command confint():\n\nconfint(mdl, level = 0.95)\n\n                   2.5 %     97.5 %\n(Intercept)  25.68600170 31.5543598\nsocial_int    0.15880045  0.5109638\noutdoor_time  0.09931273  0.2988759\n\n\nThe result is exactly the same (up to rounding errors) as calculating manually.\n\n\n\n\n\n\n\n\n\n\nThe average wellbeing score for all those with zero hours of outdoor time and zero social interactions per week was between 25.69 and 31.55.\n\nWhen holding weekly outdoor time constant, each increase of one social interaction per week was associated with a difference in wellbeing scores between 0.16 and 0.51, on average.\n\nWhen holding the number of social interactions per week constant, each one hour increase in weekly outdoor time was associated with a difference in wellbeing scores between 0.1 and 0.3, on average."
  },
  {
    "objectID": "1_03_mlr_stz.html#standardization",
    "href": "1_03_mlr_stz.html#standardization",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Standardization",
    "text": "Standardization\n\nQuestion 4\n\n\nFit two regression models using the standardized response and explanatory variables. For demonstration purposes, fit one model using the manually calculated z-scored variables (assigning the output to an object called mdl_z), and the other using the scale() function (assigning the output to an object called mdl_s).\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the data transformation flashcards, specifically the scaling and standardization flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nz-score\nscale() function\n\n\n\nz-score variables:\n\nmwdata &lt;- mwdata |&gt;\n  mutate(\n    z_wellbeing = (wellbeing - mean(wellbeing)) / sd(wellbeing),\n    z_social_int = (social_int - mean(social_int)) / sd(social_int),\n    z_outdoor_time = (outdoor_time - mean(outdoor_time)) / sd(outdoor_time)\n  )\n\nCheck that they are standardized (standardised variables should have a mean of 0, SD of 1).\n\nmwdata |&gt;\n  summarise(\n    M_z_wellbeing = round(mean(z_wellbeing),2), SD_z_wellbeing = sd(z_wellbeing), \n    M_z_social_int = round(mean(z_social_int),2), SD_z_social_int = sd(z_social_int),\n    M_z_outdoor_time = round(mean(z_outdoor_time),2), SD_z_outdoor_time = sd(z_outdoor_time)\n  )\n\n# A tibble: 1 × 6\n  M_z_wellbeing SD_z_wellbeing M_z_social_int SD_z_social_int M_z_outdoor_time\n          &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;\n1             0              1              0               1                0\n# ℹ 1 more variable: SD_z_outdoor_time &lt;dbl&gt;\n\n\nRun model:\n\nmdl_z &lt;- lm(z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\n\n\n\nmdl_s &lt;- lm(scale(wellbeing) ~ scale(social_int) + scale(outdoor_time), data = mwdata)\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nExamine the estimates from both standardized models - what do you notice?\n\n\n\n\n\n\nHint\n\n\n\n\n\nConsider whether the values the same, or different? What would you expect them to be and why?\nSee the data transofrmation flashcards, specifically the scaling and standardization flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nz-score\nscale() function\n\n\n\n\nsummary(mdl_z)\n\n\nCall:\nlm(formula = z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9231 -0.5806 -0.0781  0.6144  3.4942 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -4.168e-16  6.642e-02   0.000 1.000000    \nz_social_int    2.499e-01  6.663e-02   3.751 0.000232 ***\nz_outdoor_time  2.622e-01  6.663e-02   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9394 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl_z)$coefficients, 4)\n\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)      0.0000     0.0664  0.0000    1e+00\nz_social_int     0.2499     0.0666  3.7506    2e-04\nz_outdoor_time   0.2622     0.0666  3.9349    1e-04\n\n\n\n\n\nsummary(mdl_s)\n\n\nCall:\nlm(formula = scale(wellbeing) ~ scale(social_int) + scale(outdoor_time), \n    data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9231 -0.5806 -0.0781  0.6144  3.4942 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         -4.106e-16  6.642e-02   0.000 1.000000    \nscale(social_int)    2.499e-01  6.663e-02   3.751 0.000232 ***\nscale(outdoor_time)  2.622e-01  6.663e-02   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9394 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl_s)$coefficients, 4)\n\n                    Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)           0.0000     0.0664  0.0000    1e+00\nscale(social_int)     0.2499     0.0666  3.7506    2e-04\nscale(outdoor_time)   0.2622     0.0666  3.9349    1e-04\n\n\n\n\n\nFrom comparing either the summary() or rounded output, we can see that the estimates are the same under both approaches. That means you can use either approach to standardize the variables in your model.\n\n\n\n\n\nQuestion 6\n\n\nExamine the ‘Coefficients’ section of the summary() output from the standardized and unstandardized models - what do you notice? In other words, what is the same / different?\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret estimated regression coefficients, see the general - extracting information &gt; model coefficients &gt; estimates flashcard.\nSee the data transofrmation flashcards, specifically the scaling and standardization flashcards for guidance on how to interpret standardized coefficients.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nUnstandardized\nStandardized\n\n\n\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl)$coefficients, 2)\n\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)     28.62       1.49   19.24        0\nsocial_int       0.33       0.09    3.75        0\noutdoor_time     0.20       0.05    3.93        0\n\n\n\n\n\nsummary(mdl_z)\n\n\nCall:\nlm(formula = z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9231 -0.5806 -0.0781  0.6144  3.4942 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -4.168e-16  6.642e-02   0.000 1.000000    \nz_social_int    2.499e-01  6.663e-02   3.751 0.000232 ***\nz_outdoor_time  2.622e-01  6.663e-02   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9394 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl_z)$coefficients, 2)\n\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)        0.00       0.07    0.00        1\nz_social_int       0.25       0.07    3.75        0\nz_outdoor_time     0.26       0.07    3.93        0\n\n\n\n\n\nSimilarities\n\nThe \\(t\\) and \\(p\\)-values for the two predictor variables in both models are the same. This is because the significance of these values remains the same for the standardized coefficients as for unstandardized coefficients\n\nDifferences\n\nThe estimates and standard errors for the intercept and both predictor variables are different under the unstandardized and standardized models\n\nThe \\(t\\) and \\(p\\)-values are different in each model for the intercept. This is because:\n\nIn the unstandardized model, the intercept is significantly different from 0 (it is 28.62), and hence has a very small \\(p\\)-value (&lt; .001)\n\nIn the standardized model, the intercept is not significantly different from 0 (it is 0!), and hence has a \\(p\\)-value of 1.\n\n\n\nRemember, whether to report standarsized or unstandardized coefficients can depend on a number of factors (e.g., the scales on which you measured the constructs of interest - were they arbitrary or meaningful?; and whether you want to compare estimates).\n\n\n\n\n\nQuestion 7\n\n\nNote this is quite a difficult question (really it could/should be optional), and the exercise is designed to get you to think about how semi-partial correlation coefficients and standardized \\(\\beta\\) coefficients are related.\nHow do these standardized estimates relate to the semi-partial correlation coefficients?\nProduce a visualisation of the association between wellbeing and outdoor time, after accounting for social interactions.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSemi-partial (part) correlation coefficient\nFirstly, think about what semi-partial correlation coefficients and standardized \\(\\beta\\) coefficients represent:\n\nSemi-partial correlation coefficients (which you may also see referred to as part correlations) estimate the unique contribution of each predictor variable to the explained variance in the dependent variable, while controlling for the influence of all other predictors in the model.\n\nStandardized \\(\\beta\\) estimates represent the change in the dependent variable in standard deviation units for a one-standard-deviation change in the predictor variable, whilst holding all other predictors constant.\n\nTo calculate semi-partial (part) correlation coefficients, you will need to use the spcor.test() from the ppcor package.\nRecall that you can look at the estimates from either ‘mdl_s’ or ‘mdl_z’ - they contain the same standardized model estimates.\nPlotting\nTo visualise just one association, you need to specify the terms argument in plot_model(). The type = \"eff\" option is particularly useful when you want to focus on the estimated effects or marginal means of predictor variables whilst holding other predictors constant. Don’t forget you can look up the documentation by typing ?plot_model in the console.\nImportant: Since using plot_model(), we need to use ‘mdl_z’ here not ‘mdl_s’ - it won’t work with a model that’s used the scale() function.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nSemi-partial (part) correlation coefficient\nVisualisation\n\n\n\nFirst, lets recall the estimates from our standardized model (rounding to 2 decimal places):\n\nround(mdl_z$coefficients, 2)\n\n   (Intercept)   z_social_int z_outdoor_time \n          0.00           0.25           0.26 \n\n\nNext, lets calculate the semi-partial correlation coefficients:\n\n#semi-partial (part) correlation between wellbeing & social interactions\nwb_soc &lt;- spcor.test(mwdata$wellbeing, mwdata$social_int, mwdata$outdoor_time,  method=\"pearson\")\n#round correlation coefficient estimate to 2 decimal places\nround(wb_soc$estimate, 2)\n\n[1] 0.25\n\n#semi-partial (part) correlation between wellbeing & outdoor time\nwb_out &lt;- spcor.test(mwdata$wellbeing, mwdata$outdoor_time, mwdata$social_int, method=\"pearson\")\n#round correlation coefficient estimate to 2 decimal places\nround(wb_out$estimate, 2)\n\n[1] 0.26\n\n\nWe can see that the slope estimates from the standardized model are equivalent to the semi-partial (part) correlation coefficients. This makes theoretical sense given that:\nIn our example, we had a multiple regression model with two predictors, so in our case this means that the \\(\\beta^*\\) coefficients quantify the change in the dependent variable when one predictor (i.e., outdoor time) changes by one standard deviation while the other predictor remains constant (i.e., number of weekly social interactions); whilst the semi-partial correlation for a given predictor (i.e., outdoor time) represents the correlation between the dependent variable and that predictor (i.e., wellbeing and outdoor time) while controlling for the other predictor (i.e., number of weekly social interactions). Thus, the standardized estimate (i.e., \\(\\beta^*\\) coefficient) for one predictor in a multiple regression model with two predictors is equivalent to the semi-partial correlation coefficient for that predictor because, in this context, “holding all other predictors constant” refers to the one remaining predictor.\nNote\nIf this seems a bit confusing, try not to worry - it was more a demonstration of the relationship between \\(r\\) and \\(\\beta^*\\) for when you have 2 predictors (since you saw how this worked with 1 predictor in lecture, we thought it would be useful to extend to 2 predictors). Also, this can become pretty messy very quickly when you have a model with 3+ predictors as the associations among variables becomes more complex.\n\n\n\nplot_model(mdl_z, type = \"eff\",\n           terms = c(\"z_outdoor_time\"), \n           show.data = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nPlot the data and the fitted regression line from both the unstandardized and standardized models. To do so, for each model:\n\nExtract the estimated regression coefficients e.g., via betas &lt;- coef(mdl)\n\nExtract the first entry of betas (i.e., the intercept) via betas[1]\n\nExtract the second entry of betas (i.e., the slope) via betas[2]\n\nProvide the intercept and slope to the function\n\nNote down what you observe from the plots - what is the same / different?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is very similar to Lab 1 Q7.\nExtracting values\nThe function coef() returns a vector (a sequence of numbers all of the same type). To get the first element of the sequence you append [1], and [2] for the second.\nPlotting\nIn your ggplot(), you will need to specify geom_abline(). This might help get you started:\n\n geom_abline(intercept = intercept, slope = slope) \n\n\nYou may also want to plot these side by side to more easily compare, so consider using | from patchwork.\nFor further ggplot() guidance, see the how to visualise data flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nFirst extract the values required for both non-standardized and standardized models:\n\n#non-standardized (from 'mdl')\nbetas &lt;- coef(mdl)\nintercept &lt;- betas[1]\nslope &lt;- betas[2]\n\n#standardized (from 'mdl_z')\nbetas_z &lt;- coef(mdl_z)\nintercept_z &lt;- betas_z[1]\nslope_z &lt;- betas_z[2]\n\nWe can plot the models as follows:\n\np1 &lt;- ggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = intercept, slope = slope, color = 'blue') + \n  labs(x = \"Social Interactions \\n(Number per Week)\", y = \"Wellbeing (WEMWBS) Scores\")\n\np2 &lt;- ggplot(data = mwdata, aes(x = z_social_int, y = z_wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = intercept_z, slope = slope_z, color = 'red') + \n  labs(x = \"Social Interactions \\n(Number per Week; z-scored)\", y = \"Wellbeing (WEMWBS) Scores; z-scored\")\n\np1 | p2\n\n\n\n\n\n\n\nSimilarities\n\nThe data points are distributed in the same pattern\n\nThe slope of the line follows the same gradient\n\nDifferences\n\nThe x- and y-axis scales are different for each plot. This is because:\n\nThe unstandardized is in the original units where we interpret the slope as the change in \\(y\\) units for a unit change in \\(x\\)\n\nThe standardized is in SD units where we interpret the slope as the SD change in \\(y\\) for 1 SD change in \\(x\\)"
  },
  {
    "objectID": "1_03_mlr_stz.html#writing-up-presenting-results",
    "href": "1_03_mlr_stz.html#writing-up-presenting-results",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results from the standardized model in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\nSince using tab_model(), We need to use ‘mdl_z’ here not ‘mdl_s’ - it won’t work with a model that’s used the scale() function.\n\n\n\n\n\n\n\n Solution \n\n\n\ntab_model(mdl_z,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"z_social_int\" = \"Social Interactions (number per week)\",\n                          \"z_outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression Results for Wellbeing Model (both DV and IVs z-scored)\")\n\n\n\nTable 1: Regression Results for Wellbeing Model (both DV and IVs z-scored)\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n-0.00\n-0.13 – 0.13\n1.000\n\n\nSocial Interactions\n(number per week)\n0.25\n0.12 – 0.38\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n0.26\n0.13 – 0.39\n&lt;0.001\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.126 / 0.118\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret the results from the standardized model the context of the research question.\nMake reference to the your regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember to inform the reader of the scale of your variables.\n\n\n\n\n\n\n\n Solution \n\n\nA multiple regression model was used to determine if there was an association between well-being and time spent outdoors after taking into account the association between well-being and social interactions. All variables (wellbeing, social interactions, and outdoor time) were \\(z\\)-scored. As presented in Table 1, outdoor time was significantly associated with wellbeing scores \\((\\beta = 0.26, SE = 0.07, p &lt; .001)\\) after controlling for the number of weekly social interactions. Results suggested that, holding constant social interactions, for every standard deviation increase in outdoor time, wellbeing scores increased on average by 0.26 standard deviations. Therefore, we should reject the null hypothesis since \\(p &lt; .05\\)."
  },
  {
    "objectID": "1_03_mlr_stz_spruce.html",
    "href": "1_03_mlr_stz_spruce.html",
    "title": "Multiple Linear Regression & Standardization",
    "section": "",
    "text": "At the end of this lab, you will:\n\nExtend the ideas of single linear regression to consider regression models with two or more predictors\nUnderstand how to interpret significance tests for \\(\\beta\\) coefficients\nUnderstand how to standardize model coefficients and when this is appropriate to do\nUnderstand how to interpret standardized model coefficients in multiple linear regression models\n\n\nBe up to date with lectures\nHave completed Week 1 and Week 2 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npatchwork\nsjPlot\nppcor\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_03_mlr_stz_spruce.html#lab-2-recap",
    "href": "1_03_mlr_stz_spruce.html#lab-2-recap",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Lab 2 Recap",
    "text": "Lab 2 Recap\n\nQuestion 1\n\n\nFit the following multiple linear regression model, and assign the output to an object called mdl, and examine the summary output.\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nThe summary() function will be useful to examine the model output.\n\n\n\n\n\n\n\n Solution \n\n\n\nmdl &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06"
  },
  {
    "objectID": "1_03_mlr_stz_spruce.html#significance-tests-for-beta-coefficients",
    "href": "1_03_mlr_stz_spruce.html#significance-tests-for-beta-coefficients",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Significance Tests for \\(\\beta\\) Coefficients",
    "text": "Significance Tests for \\(\\beta\\) Coefficients\n\nQuestion 2\n\n\nTest the hypothesis that the population slope for outdoor time is zero — that is, that there is no linear association between wellbeing and outdoor time (after controlling for the number of social interactions) in the population.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret \\(t\\)-values, see the general - extracting information &gt; model coefficients &gt; t value flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\nWe calculate the test statistic for \\(\\beta_2\\) as:\n\\[\nt = \\frac{\\hat \\beta_2 - 0}{SE(\\hat \\beta_2)} = \\frac{0.19909 - 0}{0.05060} = 3.934585\n\\]\nand compare it with the 5% critical value from a \\(t\\)-distribution with \\(n-3\\) degrees of freedom (since \\(k = 2\\), we have \\(n-2-1\\)), which is:\n\nn &lt;- nrow(mwdata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 1.972079\n\n\nAs \\(|t|\\) (\\(|t|\\) = 3.93) is much larger than \\(t^*\\) (\\(t^*\\) = 1.97), we can reject the null hypothesis as we have strong evidence against it.\nThe \\(p\\)-value, shown below, also confirms this conclusion.\n\n2 * (1 - pt(3.934585, n - 3))\n\n[1] 0.0001154709\n\n\n\n\nPlease note that the same information was already contained in the row corresponding to the variable “outdoor_time” in the output of summary(mdl), which reported the \\(t\\)-statistic under t value and the \\(p\\)-value under Pr(&gt;|t|):\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\nThe result is exactly the same (up to rounding errors) as calculating manually.\nBefore we interpret the results, note that sometimes \\(p\\)-values will be reported to \\(e^X\\). For example, look in the Pr(&gt;|t|) column for “(Intercept)”. The value \\(2e^{-16}\\) simply means \\(2 \\times 10^{-16}\\). This is a very small value (i.e., 0.0000000000000002), hence we would simply report it as &lt;.001 following the APA guidelines.\n\n\n\n\n\n\n\n\n\nWe performed a test against the null hypothesis that outdoor time was not associated with wellbeing scores after controlling for social interactions. A significant association was found between outdoor time (hours per week) and wellbeing (WEMWBS scores) \\(t(197) = 3.94,\\ p &lt; .001\\), two-sided. Thus, we have evidence to reject the null hypothesis.\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nObtain 95% confidence intervals for the regression coefficients, and write a sentence about each one.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret confidence intervals, see the general - extracting information &gt; confidence intervals flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\nIn order to use the qt() function, we first we need to calculate our degrees of freedom:\n\n#calculated as df = n - k - 1\nn &lt;- nrow(mwdata)\nk &lt;- 2\ndf &lt;- n - k -1\ndf\n\n[1] 197\n\n\nWe have 197 degrees of freedom, and so can calculate the confidence intervals as follows:\n\ntibble(\n  b0_LowerCI = round(28.62018 - (qt(0.975, 197) * 1.48786), 3),\n  b0_UpperCI = round(28.62018 + (qt(0.975, 197)* 1.48786), 3),\n  b1_LowerCI = round(0.33488 - (qt(0.975, 197) * 0.08929), 3),\n  b1_UpperCI = round(0.33488 + (qt(0.975, 197)* 0.08929), 3),\n  b2_LowerCI = round(0.19909 - (qt(0.975, 197) * 0.05060), 3),\n  b2_UpperCI = round(0.19909 + (qt(0.975, 197)* 0.05060), 3)\n      )\n\n# A tibble: 1 × 6\n  b0_LowerCI b0_UpperCI b1_LowerCI b1_UpperCI b2_LowerCI b2_UpperCI\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1       25.7       31.6      0.159      0.511      0.099      0.299\n\n\nAlternatively, we could use the tstar value we computed above in Question 2 in place of the qt() function:\n\ntibble(\n  b0_LowerCI = round(28.62018 - (tstar * 1.48786), 3),\n  b0_UpperCI = round(28.62018 + (tstar * 1.48786), 3),\n  b1_LowerCI = round(0.33488 - (tstar  * 0.08929), 3),\n  b1_UpperCI = round(0.33488 + (tstar * 0.08929), 3),\n  b2_LowerCI = round(0.19909 - (tstar * 0.05060), 3),\n  b2_UpperCI = round(0.19909 + (tstar * 0.05060), 3)\n      )\n\n# A tibble: 1 × 6\n  b0_LowerCI b0_UpperCI b1_LowerCI b1_UpperCI b2_LowerCI b2_UpperCI\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1       25.7       31.6      0.159      0.511      0.099      0.299\n\n\n\n\nWe can much more easily obtain the confidence intervals for the regression coefficients using the command confint():\n\nconfint(mdl, level = 0.95)\n\n                   2.5 %     97.5 %\n(Intercept)  25.68600170 31.5543598\nsocial_int    0.15880045  0.5109638\noutdoor_time  0.09931273  0.2988759\n\n\nThe result is exactly the same (up to rounding errors) as calculating manually.\n\n\n\n\n\n\n\n\n\n\nThe average wellbeing score for all those with zero hours of outdoor time and zero social interactions per week was between 25.69 and 31.55.\n\nWhen holding weekly outdoor time constant, each increase of one social interaction per week was associated with a difference in wellbeing scores between 0.16 and 0.51, on average.\n\nWhen holding the number of social interactions per week constant, each one hour increase in weekly outdoor time was associated with a difference in wellbeing scores between 0.1 and 0.3, on average."
  },
  {
    "objectID": "1_03_mlr_stz_spruce.html#standardization",
    "href": "1_03_mlr_stz_spruce.html#standardization",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Standardization",
    "text": "Standardization\n\nQuestion 4\n\n\nFit two regression models using the standardized response and explanatory variables. For demonstration purposes, fit one model using the manually calculated z-scored variables (assigning the output to an object called mdl_z), and the other using the scale() function (assigning the output to an object called mdl_s).\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the data transformation flashcards, specifically the scaling and standardization flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nz-score\nscale() function\n\n\n\nz-score variables:\n\nmwdata &lt;- mwdata |&gt;\n  mutate(\n    z_wellbeing = (wellbeing - mean(wellbeing)) / sd(wellbeing),\n    z_social_int = (social_int - mean(social_int)) / sd(social_int),\n    z_outdoor_time = (outdoor_time - mean(outdoor_time)) / sd(outdoor_time)\n  )\n\nCheck that they are standardized (standardised variables should have a mean of 0, SD of 1).\n\nmwdata |&gt;\n  summarise(\n    M_z_wellbeing = round(mean(z_wellbeing),2), SD_z_wellbeing = sd(z_wellbeing), \n    M_z_social_int = round(mean(z_social_int),2), SD_z_social_int = sd(z_social_int),\n    M_z_outdoor_time = round(mean(z_outdoor_time),2), SD_z_outdoor_time = sd(z_outdoor_time)\n  )\n\n# A tibble: 1 × 6\n  M_z_wellbeing SD_z_wellbeing M_z_social_int SD_z_social_int M_z_outdoor_time\n          &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;\n1             0              1              0               1                0\n# ℹ 1 more variable: SD_z_outdoor_time &lt;dbl&gt;\n\n\nRun model:\n\nmdl_z &lt;- lm(z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\n\n\n\nmdl_s &lt;- lm(scale(wellbeing) ~ scale(social_int) + scale(outdoor_time), data = mwdata)\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nExamine the estimates from both standardized models - what do you notice?\n\n\n\n\n\n\nHint\n\n\n\n\n\nConsider whether the values the same, or different? What would you expect them to be and why?\nSee the data transofrmation flashcards, specifically the scaling and standardization flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nz-score\nscale() function\n\n\n\n\nsummary(mdl_z)\n\n\nCall:\nlm(formula = z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9231 -0.5806 -0.0781  0.6144  3.4942 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -4.168e-16  6.642e-02   0.000 1.000000    \nz_social_int    2.499e-01  6.663e-02   3.751 0.000232 ***\nz_outdoor_time  2.622e-01  6.663e-02   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9394 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl_z)$coefficients, 4)\n\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)      0.0000     0.0664  0.0000    1e+00\nz_social_int     0.2499     0.0666  3.7506    2e-04\nz_outdoor_time   0.2622     0.0666  3.9349    1e-04\n\n\n\n\n\nsummary(mdl_s)\n\n\nCall:\nlm(formula = scale(wellbeing) ~ scale(social_int) + scale(outdoor_time), \n    data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9231 -0.5806 -0.0781  0.6144  3.4942 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         -4.106e-16  6.642e-02   0.000 1.000000    \nscale(social_int)    2.499e-01  6.663e-02   3.751 0.000232 ***\nscale(outdoor_time)  2.622e-01  6.663e-02   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9394 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl_s)$coefficients, 4)\n\n                    Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)           0.0000     0.0664  0.0000    1e+00\nscale(social_int)     0.2499     0.0666  3.7506    2e-04\nscale(outdoor_time)   0.2622     0.0666  3.9349    1e-04\n\n\n\n\n\nFrom comparing either the summary() or rounded output, we can see that the estimates are the same under both approaches. That means you can use either approach to standardize the variables in your model.\n\n\n\n\n\nQuestion 6\n\n\nExamine the ‘Coefficients’ section of the summary() output from the standardized and unstandardized models - what do you notice? In other words, what is the same / different?\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret estimated regression coefficients, see the general - extracting information &gt; model coefficients &gt; estimates flashcard.\nSee the data transofrmation flashcards, specifically the scaling and standardization flashcards for guidance on how to interpret standardized coefficients.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nUnstandardized\nStandardized\n\n\n\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl)$coefficients, 2)\n\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)     28.62       1.49   19.24        0\nsocial_int       0.33       0.09    3.75        0\noutdoor_time     0.20       0.05    3.93        0\n\n\n\n\n\nsummary(mdl_z)\n\n\nCall:\nlm(formula = z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9231 -0.5806 -0.0781  0.6144  3.4942 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -4.168e-16  6.642e-02   0.000 1.000000    \nz_social_int    2.499e-01  6.663e-02   3.751 0.000232 ***\nz_outdoor_time  2.622e-01  6.663e-02   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9394 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl_z)$coefficients, 2)\n\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)        0.00       0.07    0.00        1\nz_social_int       0.25       0.07    3.75        0\nz_outdoor_time     0.26       0.07    3.93        0\n\n\n\n\n\nSimilarities\n\nThe \\(t\\) and \\(p\\)-values for the two predictor variables in both models are the same. This is because the significance of these values remains the same for the standardized coefficients as for unstandardized coefficients\n\nDifferences\n\nThe estimates and standard errors for the intercept and both predictor variables are different under the unstandardized and standardized models\n\nThe \\(t\\) and \\(p\\)-values are different in each model for the intercept. This is because:\n\nIn the unstandardized model, the intercept is significantly different from 0 (it is 28.62), and hence has a very small \\(p\\)-value (&lt; .001)\n\nIn the standardized model, the intercept is not significantly different from 0 (it is 0!), and hence has a \\(p\\)-value of 1.\n\n\n\nRemember, whether to report standarsized or unstandardized coefficients can depend on a number of factors (e.g., the scales on which you measured the constructs of interest - were they arbitrary or meaningful?; and whether you want to compare estimates).\n\n\n\n\n\nQuestion 7\n\n\nNote this is quite a difficult question (really it could/should be optional), and the exercise is designed to get you to think about how semi-partial correlation coefficients and standardized \\(\\beta\\) coefficients are related.\nHow do these standardized estimates relate to the semi-partial correlation coefficients?\nProduce a visualisation of the association between wellbeing and outdoor time, after accounting for social interactions.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSemi-partial (part) correlation coefficient\nFirstly, think about what semi-partial correlation coefficients and standardized \\(\\beta\\) coefficients represent:\n\nSemi-partial correlation coefficients (which you may also see referred to as part correlations) estimate the unique contribution of each predictor variable to the explained variance in the dependent variable, while controlling for the influence of all other predictors in the model.\n\nStandardized \\(\\beta\\) estimates represent the change in the dependent variable in standard deviation units for a one-standard-deviation change in the predictor variable, whilst holding all other predictors constant.\n\nTo calculate semi-partial (part) correlation coefficients, you will need to use the spcor.test() from the ppcor package.\nRecall that you can look at the estimates from either ‘mdl_s’ or ‘mdl_z’ - they contain the same standardized model estimates.\nPlotting\nTo visualise just one association, you need to specify the terms argument in plot_model(). Don’t forget you can look up the documentation by typing ?plot_model in the console.\nTo visualise just one association, you need to specify the terms argument in plot_model(). The type = \"eff\" option is particularly useful when you want to focus on the estimated effects or marginal means of predictor variables whilst holding other predictors constant. Don’t forget you can look up the documentation by typing ?plot_model in the console.\nImportant: Since using plot_model(), we need to use ‘mdl_z’ here not ‘mdl_s’ - it won’t work with a model that’s used the scale() function.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nSemi-partial (part) correlation coefficient\nVisualisation\n\n\n\nFirst, lets recall the estimates from our standardized model (rounding to 2 decimal places):\n\nround(mdl_z$coefficients, 2)\n\n   (Intercept)   z_social_int z_outdoor_time \n          0.00           0.25           0.26 \n\n\nNext, lets calculate the semi-partial correlation coefficients:\n\n#semi-partial (part) correlation between wellbeing & social interactions\nwb_soc &lt;- spcor.test(mwdata$wellbeing, mwdata$social_int, mwdata$outdoor_time,  method=\"pearson\")\n#round correlation coefficient estimate to 2 decimal places\nround(wb_soc$estimate, 2)\n\n[1] 0.25\n\n#semi-partial (part) correlation between wellbeing & outdoor time\nwb_out &lt;- spcor.test(mwdata$wellbeing, mwdata$outdoor_time, mwdata$social_int, method=\"pearson\")\n#round correlation coefficient estimate to 2 decimal places\nround(wb_out$estimate, 2)\n\n[1] 0.26\n\n\nWe can see that the slope estimates from the standardized model are equivalent to the semi-partial (part) correlation coefficients. This makes theoretical sense given that:\nIn our example, we had a multiple regression model with two predictors, so in our case this means that the \\(\\beta^*\\) coefficients quantify the change in the dependent variable when one predictor (i.e., outdoor time) changes by one standard deviation while the other predictor remains constant (i.e., number of weekly social interactions); whilst the semi-partial correlation for a given predictor (i.e., outdoor time) represents the correlation between the dependent variable and that predictor (i.e., wellbeing and outdoor time) while controlling for the other predictor (i.e., number of weekly social interactions). Thus, the standardized estimate (i.e., \\(\\beta^*\\) coefficient) for one predictor in a multiple regression model with two predictors is equivalent to the semi-partial correlation coefficient for that predictor because, in this context, “holding all other predictors constant” refers to the one remaining predictor.\nNote\nIf this seems a bit confusing, try not to worry - it was more a demonstration of the relationship between \\(r\\) and \\(\\beta^*\\) for when you have 2 predictors (since you saw how this worked with 1 predictor in lecture, we thought it would be useful to extend to 2 predictors). Also, this can become pretty messy very quickly when you have a model with 3+ predictors as the associations among variables becomes more complex.\n\n\n\nplot_model(mdl_z, type = \"eff\",\n           terms = c(\"z_outdoor_time\"), \n           show.data = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nPlot the data and the fitted regression line from both the unstandardized and standardized models. To do so, for each model:\n\nExtract the estimated regression coefficients e.g., via betas &lt;- coef(mdl)\n\nExtract the first entry of betas (i.e., the intercept) via betas[1]\n\nExtract the second entry of betas (i.e., the slope) via betas[2]\n\nProvide the intercept and slope to the function\n\nNote down what you observe from the plots - what is the same / different?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is very similar to Lab 1 Q7.\nExtracting values\nThe function coef() returns a vector (a sequence of numbers all of the same type). To get the first element of the sequence you append [1], and [2] for the second.\nPlotting\nIn your ggplot(), you will need to specify geom_abline(). This might help get you started:\n\n geom_abline(intercept = intercept, slope = slope) \n\n\nYou may also want to plot these side by side to more easily compare, so consider using | from patchwork.\nFor further ggplot() guidance, see the how to visualise data flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nFirst extract the values required for both non-standardized and standardized models:\n\n#non-standardized (from 'mdl')\nbetas &lt;- coef(mdl)\nintercept &lt;- betas[1]\nslope &lt;- betas[2]\n\n#standardized (from 'mdl_z')\nbetas_z &lt;- coef(mdl_z)\nintercept_z &lt;- betas_z[1]\nslope_z &lt;- betas_z[2]\n\nWe can plot the models as follows:\n\np1 &lt;- ggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = intercept, slope = slope, color = 'blue') + \n  labs(x = \"Social Interactions \\n(Number per Week)\", y = \"Wellbeing (WEMWBS) Scores\")\n\np2 &lt;- ggplot(data = mwdata, aes(x = z_social_int, y = z_wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = intercept_z, slope = slope_z, color = 'red') + \n  labs(x = \"Social Interactions \\n(Number per Week; z-scored)\", y = \"Wellbeing (WEMWBS) Scores; z-scored\")\n\np1 | p2\n\n\n\n\n\n\n\nSimilarities\n\nThe data points are distributed in the same pattern\n\nThe slope of the line follows the same gradient\n\nDifferences\n\nThe x- and y-axis scales are different for each plot. This is because:\n\nThe unstandardized is in the original units where we interpret the slope as the change in \\(y\\) units for a unit change in \\(x\\)\n\nThe standardized is in SD units where we interpret the slope as the SD change in \\(y\\) for 1 SD change in \\(x\\)"
  },
  {
    "objectID": "1_03_mlr_stz_spruce.html#writing-up-presenting-results",
    "href": "1_03_mlr_stz_spruce.html#writing-up-presenting-results",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results from the standardized model in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\nSince using tab_model(), We need to use ‘mdl_z’ here not ‘mdl_s’ - it won’t work with a model that’s used the scale() function.\n\n\n\n\n\n\n\n Solution \n\n\n\ntab_model(mdl_z,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"z_social_int\" = \"Social Interactions (number per week)\",\n                          \"z_outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression Results for Wellbeing Model (both DV and IVs z-scored)\")\n\n\n\nTable 1: Regression Results for Wellbeing Model (both DV and IVs z-scored)\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n-0.00\n-0.13 – 0.13\n1.000\n\n\nSocial Interactions\n(number per week)\n0.25\n0.12 – 0.38\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n0.26\n0.13 – 0.39\n&lt;0.001\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.126 / 0.118\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret the results from the standardized model the context of the research question.\nMake reference to the your regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember to inform the reader of the scale of your variables.\n\n\n\n\n\n\n\n Solution \n\n\nA multiple regression model was used to determine if there was an association between well-being and time spent outdoors after taking into account the association between well-being and social interactions. All variables (wellbeing, social interactions, and outdoor time) were \\(z\\)-scored. As presented in Table 1, outdoor time was significantly associated with wellbeing scores \\((\\beta = 0.26, SE = 0.07, p &lt; .001)\\) after controlling for the number of weekly social interactions. Results suggested that, holding constant social interactions, for every standard deviation increase in outdoor time, wellbeing scores increased on average by 0.26 standard deviations. Therefore, we should reject the null hypothesis since \\(p &lt; .05\\)."
  },
  {
    "objectID": "1_04_model_fit_comp.html",
    "href": "1_04_model_fit_comp.html",
    "title": "Model Fit and Comparisons",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to calculate the interpret \\(R^2\\) and \\(\\hat R^2\\) as a measure of model quality.\nUnderstand the calculation and interpretation of the \\(F\\)-test of model utility.\nUnderstand measures of model fit using \\(F\\).\n\nUnderstand the principles of model selection and how to compare models via \\(F\\) tests, \\(AIC\\), and \\(BIC\\).\n\n\nBe up to date with lectures\nHave completed Week 1 and Week 2, and Week 3 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nsjPlot\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_04_model_fit_comp.html#section-i-model-fit",
    "href": "1_04_model_fit_comp.html#section-i-model-fit",
    "title": "Model Fit and Comparisons",
    "section": "Section I: Model Fit",
    "text": "Section I: Model Fit\nIn the first section of this lab, you will focus on the statistics contained within the highlighted sections of the summary() output below. You will be both calculating these by hand and deriving via R before interpreting these values in the context of the research question.\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nFit the following multiple linear regression model, and assign the output to an object called mdl.\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is the same model that you have fitted in the previous couple of weeks.\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nThe summary() function will be useful to examine the model output.\n\n\n\n\n\n\n\n Solution \n\n\n\nmdl &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n\n\nQuestion 2\n\n\nWhat is the proportion of the total variability in wellbeing scores explained by the model?\nYou can calculate this either manually or looking at the R output (or both!).\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret \\(R^2\\) and \\(\\hat R^2\\) values, see the model fit &gt; linear models &gt; R-squared and Adjusted R-squared flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\nIn R we can write:\n\n#Define n & k\nn &lt;- nrow(mwdata)\nk &lt;- 2\n\n#Predicted scores\nwellbeing_fitted &lt;- mwdata |&gt;\n  mutate(\n    wellbeing_pred = predict(mdl),\n    wellbeing_resid = wellbeing - wellbeing_pred)\n\n# Sums of Squares, and R / Adjusted R Squared\nwellbeing_fitted |&gt;\n  summarise(\n    SSModel = sum((wellbeing_pred - mean(wellbeing))^2),\n    SSTotal = sum((wellbeing - mean(wellbeing))^2),\n    SSResid = sum(wellbeing_resid^2)\n  ) |&gt; \n  summarise(\n    RSquared = SSModel / SSTotal,\n    AdjRSquared = 1-((1-(RSquared))*(n-1)/(n-k-1))\n  )\n\n# A tibble: 1 × 2\n  RSquared AdjRSquared\n     &lt;dbl&gt;       &lt;dbl&gt;\n1    0.126       0.118\n\n\nThe output displays the \\(\\hat R^2\\) value in the following column:\nAdjRSquared\n &lt;dbl&gt;\n 0.118\n\n\n\n#look in second bottom row - Multiple R Squared and Adjusted R Squared both reported here\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\nThe output of summary() displays the \\(\\hat R^2\\) value in the following line:\nAdjusted R-squared:  0.1176 \n\n\n\n\n\n\n\n\n\nApproximately 12% of the total variability in wellbeing scores is accounted for by social interactions and outdoor time.\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nWhat do you notice about the unadjusted and adjusted \\(R^2\\) values?\n\n\n\n\n\n\nHint\n\n\n\n\n\nAre they similar or quite different? Why might this be? It might be useful to think about how each is calculated.\nTo review how to calculate, extract, and interpret \\(R^2\\) and \\(\\hat R^2\\) values, see the model fit &gt; linear models &gt; R-squared and Adjusted R-squared flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nThe values of the unadjusted (0.1265) and adjusted \\(R^2\\) (0.1176) values are quite similar. This is because the sample size is quite large \\((n = 200)\\), and the number of predictors \\((k = 2)\\) is small.\n\n\n\n\n\nQuestion 4\n\n\nPerform a model utility test at the 5% significance level and report your results.\nIn other words, conduct an \\(F\\)-test against the null hypothesis that the model is ineffective at predicting wellbeing scores using social interactions and outdoor time.\nYou can conduct this test either manually or looking at the R output (or both!).\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret \\(F-ratio\\) estimates, see the model fit &gt; linear models &gt; F-ratio flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\n\n#df(model) = k \ndf1 &lt;- 2\n\n#df(residual) = n - k - 1\ndf2 &lt;- nrow(mwdata) - 2 - 1\n\nf_star &lt;- qf(0.95, df1, df2)\n\n#check value\nf_star\n\n[1] 3.041753\n\n\n\nmodel_utility &lt;- wellbeing_fitted |&gt;\n  summarise(\n    SSModel = sum((wellbeing_pred - mean(wellbeing))^2),\n    SSResid = sum(wellbeing_resid^2),\n    MSModel = SSModel / df1,\n    MSResid = SSResid / df2,\n    FObs = MSModel / MSResid\n  )\nmodel_utility\n\n# A tibble: 1 × 5\n  SSModel SSResid MSModel MSResid  FObs\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1    732.   5054.    366.    25.7  14.3\n\n\nWe can also compute the p-value:\n\npvalue &lt;- 1 - pf(model_utility$FObs, df1, df2)\npvalue\n\n[1] 1.643779e-06\n\n\nThe value 1.643779e-06 simply means \\(1.6 \\times 10^{-6}\\), so it’s a really small number (i.e., 0.000001643779).\n\n\n\n#look in bottom row\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\nThe relevant row is the following:\n\nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n\n\n\n\n\nWe performed an \\(F\\)-test of model utility at the 5% significance level, where \\(F(2,197) = 14.26, p &lt;.001\\).\nThe large \\(F\\)-statistic and small \\(p\\)-value \\((p &lt;.001)\\) suggested that we have very strong evidence against the null hypothesis.\nIn other words, the data provide strong evidence that the number of social interactions and outdoor time are predictors of wellbeing scores."
  },
  {
    "objectID": "1_04_model_fit_comp.html#section-ii-model-comparisons",
    "href": "1_04_model_fit_comp.html#section-ii-model-comparisons",
    "title": "Model Fit and Comparisons",
    "section": "Section II: Model Comparisons",
    "text": "Section II: Model Comparisons\nIn the second section of this lab, you will focus on model comparison where you will formally test a number of research questions:\n\n\nRQ1: Is the number of weekly social interactions a useful predictor of wellbeing scores?\nRQ2: Does weekly outdoor time explain a significant amount of variance in wellbeing scores over and above the number of weekly social interactions?\n\n\n\n\nQuestion 5\n\n\nFit the below 3 models required to address the 2 research questions stated above. Note down which model(s) will be used to address each research question, and examine the results of each model.\nName the models as follows: “wb_mdl0”, “wb_mdl1”, “wb_mdl2”\n\\[\n\\text{Wellbeing} = \\beta_0  + \\epsilon\n\\]\n\n\\[\n\\text{Wellbeing} = \\beta_0  + \\beta_1 \\cdot \\text{Social Interactions} + \\epsilon\n\\]\n\n\\[\n\\text{Wellbeing} = \\beta_0  + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n\\] \n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nThe summary() function will be useful to examine the model output.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nwb_mdl0\nwb_mdl1\nwb_mdl2\n\n\n\n\n#null/intercept only model\nwb_mdl0 &lt;- lm(wellbeing ~ 1, data = mwdata)\nsummary(wb_mdl0)\n\n\nCall:\nlm(formula = wellbeing ~ 1, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-14.295  -3.295  -1.295   3.705  22.705 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.2950     0.3813   95.19   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.392 on 199 degrees of freedom\n\n\n\n\n\n#model with social interactions\nwb_mdl1 &lt;- lm(wellbeing ~ social_int, data = mwdata)\nsummary(wb_mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 32.40771    1.17532  27.573  &lt; 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n\n\n\n\n#model with social interactions and outdoor time\nwb_mdl2 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nsummary(wb_mdl2)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\nThe models required to address each research question (RQ) are:\n\nRQ1: Models wb_mdl0 and wb_mdl1\nRQ2: Models wb_mdl1 and wb_mdl2\n\n\n\n\n\n\nQuestion 6\n\n\nRQ1: Is the number of weekly social interactions a useful predictor of wellbeing scores?\nCheck that the \\(F\\)-statistic and the \\(p\\)-value are the same from the model comparison as that which are given at the bottom of summary(wb_mdl1).\nProvide the key model results from the two models in a single formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember that the null model tests the null hypothesis that all beta coefficients are zero. By comparing wb_mdl0 to wb_mdl1, we can test whether we should include the IV of ‘social_int’.\nWhen considering what method(s) you can use to compare the models, remember to determine whether the models are nested or non-nested.\nMake sure to present your model comparison results in a well formatted table. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nModel Comparison\nComparing summary() and anova() Outputs\nTable of Model Results\n\n\n\nRun model comparison via anova(), and present results in well formatted table:\n\nanova(wb_mdl0, wb_mdl1) |&gt;\n    kable(caption = \"Model Comparison - wb_mdl0 vs wb_mdl1\", align = \"c\", digits = c(2,2,2,2,2,4)) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Model Comparison - wb_mdl0 vs wb_mdl1\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n199\n5785.6\nNA\nNA\nNA\nNA\n\n\n198\n5451.1\n1\n334.49\n12.15\n6e-04\n\n\n\n\n\n\n\n\n\n\nThe output of anova(wb_mdl0, wb_mdl1) displays the \\(F\\)-statistic and the \\(p\\)-value in the following line:\n  Res.Df    RSS Df Sum of Sq     F    Pr(&gt;F)  \n2    198 5451.1  1    334.49 12.15 0.0006045 ***\nWe can check that the \\(F\\)-statistic and the \\(p\\)-value are the the same as that which is given at the bottom of summary(wb_mdl1):\nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\nThe \\(F\\)-statistic and the \\(p\\)-value from anova(wb_mdl0, wb_mdl1) and summary(wb_mdl1) both match! This is because the \\(F\\)-test from a model with a single predictor (i.e, ‘wb_mdl1’) is really just a comparison against the null model (i.e, ‘wb_mdl0’).\n\n\n\ntab_model(wb_mdl0, wb_mdl1,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"social_int\" = \"Social Interactions (number per week)\"),\n          title = \"Regression Table for Wellbeing Models wb0 and wb1\")\n\n\n\nTable 2: Regression Table for Wellbeing Models wb0 and wb1\n\n\n\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n36.29\n35.54 – 37.05\n&lt;0.001\n32.41\n30.09 – 34.73\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n\n\n\n0.32\n0.14 – 0.50\n0.001\n\n\nObservations\n200\n200\n\n\nR2 / R2 adjusted\n0.000 / 0.000\n0.058 / 0.053\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe number of social interactions was found to explain a significant amount of variance in wellbeing scores \\((F(1 ,198) = 12.15, p&lt;.001)\\). The model with social interactions was significantly better fitting than the intercept-only model, and thus social interactions is a useful predictor of wellbeing scores. Full regression results are presented in Table 2.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nLook at the amount of variation in wellbeing scores explained by models “wb_mdl1” and “wb_mdl2”.\nFrom this, can we answer the second research question of whether weekly outdoor time explains a significant amount of variance in wellbeing scores over and above social interactions?\nProvide justification/rationale for your answer.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to review the \\(R^2\\) and \\(\\hat R^2\\) values.\nConsider whether comparing these numeric values would constitute a statistical comparison.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s look at the amount of variance explained by each model:\n\nsummary(wb_mdl1)$r.squared\n\n[1] 0.0578147\n\nsummary(wb_mdl2)$adj.r.squared\n\n[1] 0.1176021\n\n\nThe model with weekly outdoor time as a predictor explains 12% of the variance, and the model without explains 6%. But, from only looking at the proportion of variance accounted for in each model, we cannot determine which model is statistically a better fit.\nTo answer the question ‘Does including weekly outdoor time as a predictor provide a significantly better fit of the data?’ we need to statistically compare wb_mdl1 to wb_mdl2.\n\n\n\n\n\nQuestion 8\n\n\nDoes weekly outdoor time explain a significant amount of variance in wellbeing scores over and above social interactions?\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo address RQ2, you need to statistically compare “wb_mdl1” and “wb_mdl2”.\nWhen considering what method(s) you can use to compare the models, remember to determine whether the models are nested or non-nested.\nMake sure to present your model comparison results in a well formatted table. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nModel Comparison\nTable of Model Results\n\n\n\nTo statistically compare models, we could use an incremental \\(F\\)-test to compare the models since the models are nested and from the same dataset:\n\nanova(wb_mdl1, wb_mdl2) |&gt;\n    kable(caption = \"Model Comparison - wb_mdl1 vs wb_mdl2\", align = \"c\", digits = c(2,2,2,2,2,4)) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 3: Model Comparison - wb_mdl1 vs wb_mdl2\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n198\n5451.10\nNA\nNA\nNA\nNA\n\n\n197\n5053.89\n1\n397.21\n15.48\n1e-04\n\n\n\n\n\n\n\n\n\n\nPresent results from both models:\n\ntab_model(wb_mdl1, wb_mdl2,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"social_int\" = \"Social Interactions (number per week)\",\n                          \"outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression Table for Wellbeing Models wb1 and wb2\")\n\n\n\nTable 4: Regression Table for Wellbeing Models wb1 and wb2\n\n\n\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n32.41\n30.09 – 34.73\n&lt;0.001\n28.62\n25.69 – 31.55\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n0.32\n0.14 – 0.50\n0.001\n0.33\n0.16 – 0.51\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n\n\n\n0.20\n0.10 – 0.30\n&lt;0.001\n\n\nObservations\n200\n200\n\n\nR2 / R2 adjusted\n0.058 / 0.053\n0.126 / 0.118\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs presented in Table 3, weekly outdoor time was found to explain a significant amount of variance in wellbeing scores over and above weekly social interactions \\((F(1 ,197) = 15.48, p&lt;.001)\\).\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nA fellow researcher has suggested to examine the role of age in wellbeing scores. Based on their recommendation, compare the two following models, each looking at the associations of Wellbeing scores and different predictor variables.\n\\(\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Age} + \\epsilon\\)\n\\(\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Outdoor Time} + \\epsilon\\)\nReport which model you think best fits the data, and justify your answer.\n\n\n\n\n\n\nHint\n\n\n\n\n\nAre the models are nested or non-nested? This will impact what method(s) you can use to compare the models.\nThink about whether you can quantify or use a verbal label to describe the difference in models (i.e., are there any thresholds you can refer to?).\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit models\nwb_socint_age &lt;- lm(wellbeing ~ social_int + age, data = mwdata)\nwb_outdoor &lt;- lm(wellbeing ~ outdoor_time, data = mwdata)\n\n\n#AIC values\nAIC(wb_socint_age, wb_outdoor)\n\n              df      AIC\nwb_socint_age  4 1236.575\nwb_outdoor     3 1233.289\n\n#BIC values\nBIC(wb_socint_age, wb_outdoor)\n\n              df      BIC\nwb_socint_age  4 1249.769\nwb_outdoor     3 1243.184\n\n\n\n\n\n\n\n\nWe used \\(AIC\\) and \\(BIC\\) model selection to distinguish between two possible models describing the association between several personal factors and wellbeing scores. The model with outdoor time included as a single predictor was better fitting \\((AIC = 1233.29)\\) than the alternative model with weekly number of social interactions and age \\((AIC = 1236.58)\\) included. Based on the BIC value of the former model \\((BIC = 1243.18)\\), we concluded that there was strong evidence that it was better fitting than the alternative, latter model \\((BIC = 1249.77)\\).\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nThe code below fits 6 different models based on our mwdata:\n\nmodel1 &lt;- lm(wellbeing ~ social_int, data = mwdata)\nmodel2 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nmodel3 &lt;- lm(wellbeing ~ social_int + age, data = mwdata)\nmodel4 &lt;- lm(wellbeing ~ social_int + outdoor_time + age, data = mwdata)\nmodel5 &lt;- lm(wellbeing ~ social_int + outdoor_time + age + steps_k, data = mwdata)\nmodel6 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = wb_data)\n\nFor each of the below pairs of models, what methods are/are not available for us to use for comparison and why?\n\n\nmodel1 vs model2\n\n\nmodel2 vs model3\n\n\nmodel1 vs model4\n\n\nmodel3 vs model5\n\n\nmodel2 vs model6\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis flowchart might help you to reach your decision.\nYou may need to examine the dataset. It is especially important to check for completeness (e.g., are there any missing values?).\nRemember that not all models can be compared!\n\n\n\n\n\n\n\n Solution \n\n\n\n\nmodel1 vs model2\nmodel2 vs model3\nmodel1 vs model4\nmodel3 vs model5\nmodel2 vs model6\n\n\n\n\nThese models are nested - model2 contains all the variables of model1 and they are fitted on the same dataset.\n\nWe can therefore use an \\(F\\)-test or AIC and BIC.\n\n\n\n\nThese models are not nested, but they are fitted on the same dataset.\n\nWe can therefore use AIC or BIC, but we cannot use an \\(F\\)-test.\n\n\n\n\nThese models are nested - model4 contains all the variables of model1 and they are fitted on the same dataset.\n\nWe can therefore use an \\(F\\)-test or AIC and BIC.\n\n\n\n\nThese models are not nested, and they are not fitted on the same dataset. The “steps_k” variable contains missing values (over 30% of the data is missing for this variable), and so these whole rows are excluded from model5 (but they are included in model3).\nWe cannot compare these models.\n\n\n\n\nThese models are nested, but they are not fitted on the same dataset: model2 uses the ‘mwdata’ dataset, whilst model6 uses the ‘wb_data’ dataset.\nWe cannot compare these models."
  },
  {
    "objectID": "1_04_model_fit_comp_cypress.html",
    "href": "1_04_model_fit_comp_cypress.html",
    "title": "Model Fit and Comparisons",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to calculate the interpret \\(R^2\\) and \\(\\hat R^2\\) as a measure of model quality.\nUnderstand the calculation and interpretation of the \\(F\\)-test of model utility.\nUnderstand measures of model fit using \\(F\\).\n\nUnderstand the principles of model selection and how to compare models via \\(F\\) tests, \\(AIC\\), and \\(BIC\\).\n\n\nBe up to date with lectures\nHave completed Week 1 and Week 2, and Week 3 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nsjPlot\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_04_model_fit_comp_cypress.html#section-i-model-fit",
    "href": "1_04_model_fit_comp_cypress.html#section-i-model-fit",
    "title": "Model Fit and Comparisons",
    "section": "Section I: Model Fit",
    "text": "Section I: Model Fit\nIn the first section of this lab, you will focus on the statistics contained within the highlighted sections of the summary() output below. You will be both calculating these by hand and deriving via R before interpreting these values in the context of the research question.\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nFit the following multiple linear regression model, and assign the output to an object called mdl.\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is the same model that you have fitted in the previous couple of weeks.\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nThe summary() function will be useful to examine the model output.\n\n\n\n\n\n\n\n Solution \n\n\n\nmdl &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n\n\nQuestion 2\n\n\nWhat is the proportion of the total variability in wellbeing scores explained by the model?\nYou can calculate this either manually or looking at the R output (or both!).\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret \\(R^2\\) and \\(\\hat R^2\\) values, see the model fit &gt; linear models &gt; R-squared and Adjusted R-squared flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\nIn R we can write:\n\n#Define n & k\nn &lt;- nrow(mwdata)\nk &lt;- 2\n\n#Predicted scores\nwellbeing_fitted &lt;- mwdata |&gt;\n  mutate(\n    wellbeing_pred = predict(mdl),\n    wellbeing_resid = wellbeing - wellbeing_pred)\n\n# Sums of Squares, and R / Adjusted R Squared\nwellbeing_fitted |&gt;\n  summarise(\n    SSModel = sum((wellbeing_pred - mean(wellbeing))^2),\n    SSTotal = sum((wellbeing - mean(wellbeing))^2),\n    SSResid = sum(wellbeing_resid^2)\n  ) |&gt; \n  summarise(\n    RSquared = SSModel / SSTotal,\n    AdjRSquared = 1-((1-(RSquared))*(n-1)/(n-k-1))\n  )\n\n# A tibble: 1 × 2\n  RSquared AdjRSquared\n     &lt;dbl&gt;       &lt;dbl&gt;\n1    0.126       0.118\n\n\nThe output displays the \\(\\hat R^2\\) value in the following column:\nAdjRSquared\n &lt;dbl&gt;\n 0.118\n\n\n\n#look in second bottom row - Multiple R Squared and Adjusted R Squared both reported here\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\nThe output of summary() displays the \\(\\hat R^2\\) value in the following line:\nAdjusted R-squared:  0.1176 \n\n\n\n\n\n\n\n\n\nApproximately 12% of the total variability in wellbeing scores is accounted for by social interactions and outdoor time.\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nWhat do you notice about the unadjusted and adjusted \\(R^2\\) values?\n\n\n\n\n\n\nHint\n\n\n\n\n\nAre they similar or quite different? Why might this be? It might be useful to think about how each is calculated.\nTo review how to calculate, extract, and interpret \\(R^2\\) and \\(\\hat R^2\\) values, see the model fit &gt; linear models &gt; R-squared and Adjusted R-squared flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nThe values of the unadjusted (0.1265) and adjusted \\(R^2\\) (0.1176) values are quite similar. This is because the sample size is quite large \\((n = 200)\\), and the number of predictors \\((k = 2)\\) is small.\n\n\n\n\n\nQuestion 4\n\n\nPerform a model utility test at the 5% significance level and report your results.\nIn other words, conduct an \\(F\\)-test against the null hypothesis that the model is ineffective at predicting wellbeing scores using social interactions and outdoor time.\nYou can conduct this test either manually or looking at the R output (or both!).\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate, extract, and interpret \\(F-ratio\\) estimates, see the model fit &gt; linear models &gt; F-ratio flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\n\n#df(model) = k \ndf1 &lt;- 2\n\n#df(residual) = n - k - 1\ndf2 &lt;- nrow(mwdata) - 2 - 1\n\nf_star &lt;- qf(0.95, df1, df2)\n\n#check value\nf_star\n\n[1] 3.041753\n\n\n\nmodel_utility &lt;- wellbeing_fitted |&gt;\n  summarise(\n    SSModel = sum((wellbeing_pred - mean(wellbeing))^2),\n    SSResid = sum(wellbeing_resid^2),\n    MSModel = SSModel / df1,\n    MSResid = SSResid / df2,\n    FObs = MSModel / MSResid\n  )\nmodel_utility\n\n# A tibble: 1 × 5\n  SSModel SSResid MSModel MSResid  FObs\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1    732.   5054.    366.    25.7  14.3\n\n\nWe can also compute the p-value:\n\npvalue &lt;- 1 - pf(model_utility$FObs, df1, df2)\npvalue\n\n[1] 1.643779e-06\n\n\nThe value 1.643779e-06 simply means \\(1.6 \\times 10^{-6}\\), so it’s a really small number (i.e., 0.000001643779).\n\n\n\n#look in bottom row\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\nThe relevant row is the following:\n\nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n\n\n\n\n\nWe performed an \\(F\\)-test of model utility at the 5% significance level, where \\(F(2,197) = 14.26, p &lt;.001\\).\nThe large \\(F\\)-statistic and small \\(p\\)-value \\((p &lt;.001)\\) suggested that we have very strong evidence against the null hypothesis.\nIn other words, the data provide strong evidence that the number of social interactions and outdoor time are predictors of wellbeing scores."
  },
  {
    "objectID": "1_04_model_fit_comp_cypress.html#section-ii-model-comparisons",
    "href": "1_04_model_fit_comp_cypress.html#section-ii-model-comparisons",
    "title": "Model Fit and Comparisons",
    "section": "Section II: Model Comparisons",
    "text": "Section II: Model Comparisons\nIn the second section of this lab, you will focus on model comparison where you will formally test a number of research questions:\n\n\nRQ1: Is the number of weekly social interactions a useful predictor of wellbeing scores?\nRQ2: Does weekly outdoor time explain a significant amount of variance in wellbeing scores over and above the number of weekly social interactions?\n\n\n\n\nQuestion 5\n\n\nFit the below 3 models required to address the 2 research questions stated above. Note down which model(s) will be used to address each research question, and examine the results of each model.\nName the models as follows: “wb_mdl0”, “wb_mdl1”, “wb_mdl2”\n\\[\n\\text{Wellbeing} = \\beta_0  + \\epsilon\n\\]\n\n\\[\n\\text{Wellbeing} = \\beta_0  + \\beta_1 \\cdot \\text{Social Interactions} + \\epsilon\n\\]\n\n\\[\n\\text{Wellbeing} = \\beta_0  + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n\\] \n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nThe summary() function will be useful to examine the model output.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nwb_mdl0\nwb_mdl1\nwb_mdl2\n\n\n\n\n#null/intercept only model\nwb_mdl0 &lt;- lm(wellbeing ~ 1, data = mwdata)\nsummary(wb_mdl0)\n\n\nCall:\nlm(formula = wellbeing ~ 1, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-14.295  -3.295  -1.295   3.705  22.705 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.2950     0.3813   95.19   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.392 on 199 degrees of freedom\n\n\n\n\n\n#model with social interactions\nwb_mdl1 &lt;- lm(wellbeing ~ social_int, data = mwdata)\nsummary(wb_mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 32.40771    1.17532  27.573  &lt; 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n\n\n\n\n#model with social interactions and outdoor time\nwb_mdl2 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nsummary(wb_mdl2)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\nThe models required to address each research question (RQ) are:\n\nRQ1: Models wb_mdl0 and wb_mdl1\nRQ2: Models wb_mdl1 and wb_mdl2\n\n\n\n\n\n\nQuestion 6\n\n\nRQ1: Is the number of weekly social interactions a useful predictor of wellbeing scores?\nCheck that the \\(F\\)-statistic and the \\(p\\)-value are the same from the model comparison as that which are given at the bottom of summary(wb_mdl1).\nProvide the key model results from the two models in a single formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember that the null model tests the null hypothesis that all beta coefficients are zero. By comparing wb_mdl0 to wb_mdl1, we can test whether we should include the IV of ‘social_int’.\nWhen considering what method(s) you can use to compare the models, remember to determine whether the models are nested or non-nested.\nMake sure to present your model comparison results in a well formatted table. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nModel Comparison\nComparing summary() and anova() Outputs\nTable of Model Results\n\n\n\nRun model comparison via anova(), and present results in well formatted table:\n\nanova(wb_mdl0, wb_mdl1) |&gt;\n    kable(caption = \"Model Comparison - wb_mdl0 vs wb_mdl1\", align = \"c\", digits = c(2,2,2,2,2,4)) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Model Comparison - wb_mdl0 vs wb_mdl1\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n199\n5785.6\nNA\nNA\nNA\nNA\n\n\n198\n5451.1\n1\n334.49\n12.15\n6e-04\n\n\n\n\n\n\n\n\n\n\nThe output of anova(wb_mdl0, wb_mdl1) displays the \\(F\\)-statistic and the \\(p\\)-value in the following line:\n  Res.Df    RSS Df Sum of Sq     F    Pr(&gt;F)  \n2    198 5451.1  1    334.49 12.15 0.0006045 ***\nWe can check that the \\(F\\)-statistic and the \\(p\\)-value are the the same as that which is given at the bottom of summary(wb_mdl1):\nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\nThe \\(F\\)-statistic and the \\(p\\)-value from anova(wb_mdl0, wb_mdl1) and summary(wb_mdl1) both match! This is because the \\(F\\)-test from a model with a single predictor (i.e, ‘wb_mdl1’) is really just a comparison against the null model (i.e, ‘wb_mdl0’).\n\n\n\ntab_model(wb_mdl0, wb_mdl1,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"social_int\" = \"Social Interactions (number per week)\"),\n          title = \"Regression Table for Wellbeing Models wb0 and wb1\")\n\n\n\nTable 2: Regression Table for Wellbeing Models wb0 and wb1\n\n\n\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n36.29\n35.54 – 37.05\n&lt;0.001\n32.41\n30.09 – 34.73\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n\n\n\n0.32\n0.14 – 0.50\n0.001\n\n\nObservations\n200\n200\n\n\nR2 / R2 adjusted\n0.000 / 0.000\n0.058 / 0.053\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe number of social interactions was found to explain a significant amount of variance in wellbeing scores \\((F(1 ,198) = 12.15, p&lt;.001)\\). The model with social interactions was significantly better fitting than the intercept-only model, and thus social interactions is a useful predictor of wellbeing scores. Full regression results are presented in Table 2.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nLook at the amount of variation in wellbeing scores explained by models “wb_mdl1” and “wb_mdl2”.\nFrom this, can we answer the second research question of whether weekly outdoor time explains a significant amount of variance in wellbeing scores over and above social interactions?\nProvide justification/rationale for your answer.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to review the \\(R^2\\) and \\(\\hat R^2\\) values.\nConsider whether comparing these numeric values would constitute a statistical comparison.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s look at the amount of variance explained by each model:\n\nsummary(wb_mdl1)$r.squared\n\n[1] 0.0578147\n\nsummary(wb_mdl2)$adj.r.squared\n\n[1] 0.1176021\n\n\nThe model with weekly outdoor time as a predictor explains 12% of the variance, and the model without explains 6%. But, from only looking at the proportion of variance accounted for in each model, we cannot determine which model is statistically a better fit.\nTo answer the question ‘Does including weekly outdoor time as a predictor provide a significantly better fit of the data?’ we need to statistically compare wb_mdl1 to wb_mdl2.\n\n\n\n\n\nQuestion 8\n\n\nDoes weekly outdoor time explain a significant amount of variance in wellbeing scores over and above social interactions?\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo address RQ2, you need to statistically compare “wb_mdl1” and “wb_mdl2”.\nWhen considering what method(s) you can use to compare the models, remember to determine whether the models are nested or non-nested.\nMake sure to present your model comparison results in a well formatted table. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nModel Comparison\nTable of Model Results\n\n\n\nTo statistically compare models, we could use an incremental \\(F\\)-test to compare the models since the models are nested and from the same dataset:\n\nanova(wb_mdl1, wb_mdl2) |&gt;\n    kable(caption = \"Model Comparison - wb_mdl1 vs wb_mdl2\", align = \"c\", digits = c(2,2,2,2,2,4)) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 3: Model Comparison - wb_mdl1 vs wb_mdl2\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n198\n5451.10\nNA\nNA\nNA\nNA\n\n\n197\n5053.89\n1\n397.21\n15.48\n1e-04\n\n\n\n\n\n\n\n\n\n\nPresent results from both models:\n\ntab_model(wb_mdl1, wb_mdl2,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"social_int\" = \"Social Interactions (number per week)\",\n                          \"outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression Table for Wellbeing Models wb1 and wb2\")\n\n\n\nTable 4: Regression Table for Wellbeing Models wb1 and wb2\n\n\n\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n32.41\n30.09 – 34.73\n&lt;0.001\n28.62\n25.69 – 31.55\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n0.32\n0.14 – 0.50\n0.001\n0.33\n0.16 – 0.51\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n\n\n\n0.20\n0.10 – 0.30\n&lt;0.001\n\n\nObservations\n200\n200\n\n\nR2 / R2 adjusted\n0.058 / 0.053\n0.126 / 0.118\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs presented in Table 3, weekly outdoor time was found to explain a significant amount of variance in wellbeing scores over and above weekly social interactions \\((F(1 ,197) = 15.48, p&lt;.001)\\).\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nA fellow researcher has suggested to examine the role of age in wellbeing scores. Based on their recommendation, compare the two following models, each looking at the associations of Wellbeing scores and different predictor variables.\n\\(\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Age} + \\epsilon\\)\n\\(\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Outdoor Time} + \\epsilon\\)\nReport which model you think best fits the data, and justify your answer.\n\n\n\n\n\n\nHint\n\n\n\n\n\nAre the models are nested or non-nested? This will impact what method(s) you can use to compare the models.\nThink about whether you can quantify or use a verbal label to describe the difference in models (i.e., are there any thresholds you can refer to?).\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit models\nwb_socint_age &lt;- lm(wellbeing ~ social_int + age, data = mwdata)\nwb_outdoor &lt;- lm(wellbeing ~ outdoor_time, data = mwdata)\n\n\n#AIC values\nAIC(wb_socint_age, wb_outdoor)\n\n              df      AIC\nwb_socint_age  4 1236.575\nwb_outdoor     3 1233.289\n\n#BIC values\nBIC(wb_socint_age, wb_outdoor)\n\n              df      BIC\nwb_socint_age  4 1249.769\nwb_outdoor     3 1243.184\n\n\n\n\n\n\n\n\nWe used \\(AIC\\) and \\(BIC\\) model selection to distinguish between two possible models describing the association between several personal factors and wellbeing scores. The model with outdoor time included as a single predictor was better fitting \\((AIC = 1233.29)\\) than the alternative model with weekly number of social interactions and age \\((AIC = 1236.58)\\) included. Based on the BIC value of the former model \\((BIC = 1243.18)\\), we concluded that there was strong evidence that it was better fitting than the alternative, latter model \\((BIC = 1249.77)\\).\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nThe code below fits 6 different models based on our mwdata:\n\nmodel1 &lt;- lm(wellbeing ~ social_int, data = mwdata)\nmodel2 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nmodel3 &lt;- lm(wellbeing ~ social_int + age, data = mwdata)\nmodel4 &lt;- lm(wellbeing ~ social_int + outdoor_time + age, data = mwdata)\nmodel5 &lt;- lm(wellbeing ~ social_int + outdoor_time + age + steps_k, data = mwdata)\nmodel6 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = wb_data)\n\nFor each of the below pairs of models, what methods are/are not available for us to use for comparison and why?\n\n\nmodel1 vs model2\n\n\nmodel2 vs model3\n\n\nmodel1 vs model4\n\n\nmodel3 vs model5\n\n\nmodel2 vs model6\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis flowchart might help you to reach your decision.\nYou may need to examine the dataset. It is especially important to check for completeness (e.g., are there any missing values?).\nRemember that not all models can be compared!\n\n\n\n\n\n\n\n Solution \n\n\n\n\nmodel1 vs model2\nmodel2 vs model3\nmodel1 vs model4\nmodel3 vs model5\nmodel2 vs model6\n\n\n\n\nThese models are nested - model2 contains all the variables of model1 and they are fitted on the same dataset.\n\nWe can therefore use an \\(F\\)-test or AIC and BIC.\n\n\n\n\nThese models are not nested, but they are fitted on the same dataset.\n\nWe can therefore use AIC or BIC, but we cannot use an \\(F\\)-test.\n\n\n\n\nThese models are nested - model4 contains all the variables of model1 and they are fitted on the same dataset.\n\nWe can therefore use an \\(F\\)-test or AIC and BIC.\n\n\n\n\nThese models are not nested, and they are not fitted on the same dataset. The “steps_k” variable contains missing values (over 30% of the data is missing for this variable), and so these whole rows are excluded from model5 (but they are included in model3).\nWe cannot compare these models.\n\n\n\n\nThese models are nested, but they are not fitted on the same dataset: model2 uses the ‘mwdata’ dataset, whilst model6 uses the ‘wb_data’ dataset.\nWe cannot compare these models."
  },
  {
    "objectID": "1_05_writeup_recap1.html",
    "href": "1_05_writeup_recap1.html",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to write-up and provide interpretation of linear models with single and multiple predictors.\n\n\nBe up to date with lectures\nHave completed Labs 1 - 4\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/FOMOdataset.csv"
  },
  {
    "objectID": "1_05_writeup_recap1.html#study-overview",
    "href": "1_05_writeup_recap1.html#study-overview",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Aim\nExplore the associations among Fear of Missing Out (FoMO), age, social media networks, and the Big Five personality traits.\nResearch Questions\n\nRQ1: Does age predict FoMO?\nRQ2: Does the number of Instagram followers explain a significant amount of variance in FoMO over and above age?\nRQ3: Does personality predict FoMO?\n\n\n\n FoMO data codebook.\n\n\nDescription\nThe data used for this write-up exercise are simulated, drawing on recent work on Fear of Missing Out (FoMO), socio-demographic factors, and the Big Five personality traits. The simulated data are based on the findings of this work, and acted to expand upon the methods and results reported in the following paper:\nRozgonjuk, D., Sindermann, C., Elhai, J. D., & Montag, C. (2021). Individual differences in Fear of Missing Out (FoMO): Age, gender, and the Big Five personality trait domains, facets, and items. Personality and Individual Differences, 171, 110546. https://doi.org/10.1016/j.paid.2020.110546\nIn the current study, participants were invited to an online study investigating the associations among FoMO, socio-demographic factors, and personality. The final sample comprised 3370 people. Participants completed a FOMO scale and a personality inventory. The 10-item FOMO scale measured the extent of experiencing apprehension regarding missing out on interesting events of others on a 5-point scale (1 = “not at all true of me” to 5 = “extremely true of me”), producing a possible range of scores between 10 and 50. The Big Five Inventory (BFI) is a 45-item personality assessment questionnaire (note that only 44 items were used to match the study above) that uses a five-point response scale (1 = “very inapplicable” to 5 = “very applicable”). The BFI consists of five domains: Neuroticism (8 items; possible range of scores 8-40), Extraversion (8 items; possible range of scores 8-40), Openness to Experience (10 items; possible range of scores 10-50), Agreeableness (9 items; possible range of scores 9-45), and Conscientiousness (9 items; possible range of scores 9-45). We extended the aforementioned study to include an extra socio-demographic variable - a measure of popularity on social media based on the number of followers. Unlike the original study, we do not have measures of gender, education level, or specific country of residence.\nData Dictionary\nThe data in FOMOdataset.csv contain eight attributes collected from a simulated sample of \\(n=3370\\) hypothetical individuals across the UK, and include:\n\n\n\n\n\n\n\nVariable\n      Description\n    \n\n\nFOMO\nFoMO Score (as measured by the 10-item FoMO scale)\n\n\nAge\nAge (in years)\n\n\nN\nScore on personality items assessing Neuroticism from the Big Five Inventory (BFI)\n\n\nE\nScore on personality items assessing Extraversion from the Big Five Inventory (BFI)\n\n\nO\nScore on personality items assessing Openness from the Big Five Inventory (BFI)\n\n\nA\nScore on personality items assessing Agreeableness from the Big Five Inventory (BFI)\n\n\nC\nScore on personality items assessing Conscientiousness from the Big Five Inventory (BFI)\n\n\nTotalFollowers\nTotal Number of Instagram Followers\n\n\n\n\n\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\nFOMO\n      Age\n      N\n      E\n      O\n      A\n      C\n      TotalFollowers\n    \n\n\n28\n38\n26\n30\n32\n27\n38\n98\n\n\n26\n30\n23\n27\n33\n32\n30\n192\n\n\n23\n33\n14\n30\n36\n27\n24\n177\n\n\n18\n44\n26\n21\n37\n28\n34\n119\n\n\n19\n43\n32\n21\n41\n35\n40\n278\n\n\n24\n43\n22\n25\n31\n30\n24\n184\n\n\n\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the FOMO dataset into R, assigning it to an object named fomo\n\n\n\n\n\n\n Solution \n\n\n\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(sjPlot)\nlibrary(kableExtra)\nlibrary(psych)\n\n#Reading in fomo data and storing in object named 'fomo'\nfomo &lt;- read_csv(\"https://uoepsy.github.io/data/FOMOdataset.csv\")\n\n#check first six rows\nhead(fomo)\n\n# A tibble: 6 × 8\n   FOMO   Age     N     E     O     A     C TotalFollowers\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n1    28    38    26    30    32    27    38             98\n2    26    30    23    27    33    32    30            192\n3    23    33    14    30    36    27    24            177\n4    18    44    26    21    37    28    34            119\n5    19    43    32    21    41    35    40            278\n6    24    43    22    25    31    30    24            184\n\n\n\n\n\n\nProvided Analysis Code\nBelow you will find the code required to conduct the analysis to address the research questions. This should look similar (in most areas) to what you worked through in lecture.\n\n Provided Analysis Code"
  },
  {
    "objectID": "1_05_writeup_recap1.html#data-management",
    "href": "1_05_writeup_recap1.html#data-management",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "Data Management",
    "text": "Data Management\n\nlibrary(tidyverse) # for all things!\nlibrary(psych) # good for descriptive stats\nlibrary(patchwork) # grouping plots together\nlibrary(kableExtra) # useful for creating nice tables\nlibrary(sjPlot) #regression tables & plots\n\nfomo &lt;- read_csv(\"https://uoepsy.github.io/data/FOMOdataset.csv\")\n\n# standardise FoMO & personality scores for RQ3\nfomo &lt;- \n  fomo |&gt; \n    mutate(\n      FOMOz = (FOMO-mean(FOMO))/sd(FOMO),\n      Oz = (O-mean(O))/sd(O),\n      Cz = (C-mean(C))/sd(C),\n      Ez = (E-mean(E))/sd(E),\n      Az = (A-mean(A))/sd(A),      \n      Nz = (N-mean(N))/sd(N))\n#alternatively, you could do FOMOz = scale(FOMO, center = TRUE, scale = TRUE)"
  },
  {
    "objectID": "1_05_writeup_recap1.html#overall",
    "href": "1_05_writeup_recap1.html#overall",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "Overall",
    "text": "Overall\n\n#######\n#Descriptive Stats\n#######\n\n\n# the describe() function is from the psych package, and kable() from kableExtra which is used to make a nice table where the values are rounded to 2 decimal places using digits = 2. \n# We are first renaming our variables to give more appropriate / informative names.\n#Next we are selecting columns 2, 3, 4, 8, and 9 from the describe output (n, mean, sd, min, max)\n\nfomo |&gt; \n    select(FOMO, Age, TotalFollowers, N, E, O, C, A) |&gt;\n    rename(\"Fear of Missing Out\" = FOMO, \"Age (in years)\" = Age, \"Number of Instagram Followers\" = TotalFollowers, \"Neuroticism\" = N, \"Extraversion\" = E, \"Openness\" = O, \"Conscientiousness\" = C, \"Agreeableness\" = A) |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;\n        kable(caption = \"FoMO, Socio-Demographic Factors, and Personality Traits Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()   \n\n\nFoMO, Socio-Demographic Factors, and Personality Traits Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nAge (in years)\n3370\n33.61\n10.42\n12\n75\n\n\nNumber of Instagram Followers\n3370\n203.25\n93.42\n1\n594\n\n\nNeuroticism\n3370\n22.92\n5.77\n8\n40\n\n\nExtraversion\n3370\n25.88\n5.94\n8\n40\n\n\nOpenness\n3370\n37.61\n5.80\n14\n50\n\n\nConscientiousness\n3370\n31.04\n5.49\n13\n45\n\n\nAgreeableness\n3370\n30.89\n4.93\n13\n43\n\n\n\n\n#from above, no missing values and scores within range (look at min and max values)\n\n\n# scatterplot matrix, hist, and corr of FoMO, Socio-Demographic Factors, and Personality Traits Descriptive Statistics\npairs.panels(fomo |&gt;\n    select(-FOMOz, -Oz, -Cz, -Ez, -Az, -Nz))"
  },
  {
    "objectID": "1_05_writeup_recap1.html#rq1",
    "href": "1_05_writeup_recap1.html#rq1",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "RQ1",
    "text": "RQ1\n\n#######\n#Descriptive Stats\n#######\n\nfomo |&gt; \n    select(FOMO, Age) |&gt;\n    rename(\"Fear of Missing Out\" = FOMO, \"Age (in years)\" = Age) |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;    \n        kable(caption = \"FoMO and Age Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()    \n\n\nFoMO and Age Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nAge (in years)\n3370\n33.61\n10.42\n12\n75\n\n\n\n\n# scatterplot\np1 &lt;- ggplot(data = fomo, aes(x = Age, y = FOMO)) + \n    geom_point() + \n  geom_smooth(method = 'lm', se = FALSE, colour = 'red', linewidth=2) +\n  labs(x = \"(a) Age (in years)\", y = \"Fear of Missing Out\")\np1\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\nfomo_mdl1 &lt;- lm(FOMO ~ Age, data = fomo)\nsummary(fomo_mdl1)\n\n\nCall:\nlm(formula = FOMO ~ Age, data = fomo)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1028  -4.2129  -0.1602   4.0551  22.2321 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 31.22239    0.35408   88.18   &lt;2e-16 ***\nAge         -0.19617    0.01006  -19.50   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.084 on 3368 degrees of freedom\nMultiple R-squared:  0.1014,    Adjusted R-squared:  0.1011 \nF-statistic: 380.1 on 1 and 3368 DF,  p-value: &lt; 2.2e-16\n\nconfint(fomo_mdl1)\n\n                 2.5 %     97.5 %\n(Intercept) 30.5281496 31.9166293\nAge         -0.2158992 -0.1764425\n\n\n\n#######\n#Table for Results\n#######\n\ntab_model(fomo_mdl1,\n          dv.labels = \"FoMO\",\n          pred.labels = c(\"Age\" = \"Age (in years)\"), \n          title = \"RQ1: Regression Table for FoMO Model\")\n\n\nRQ1: Regression Table for FoMO Model\n\n\n \nFoMO\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n31.22\n30.53 – 31.92\n&lt;0.001\n\n\nAge (in years)\n-0.20\n-0.22 – -0.18\n&lt;0.001\n\n\nObservations\n3370\n\n\nR2 / R2 adjusted\n0.101 / 0.101"
  },
  {
    "objectID": "1_05_writeup_recap1.html#rq2",
    "href": "1_05_writeup_recap1.html#rq2",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "RQ2",
    "text": "RQ2\n\n#######\n#Descriptive Stats\n#######\n\nfomo |&gt; \n    select(FOMO, Age, TotalFollowers) |&gt;\n    rename(\"Fear of Missing Out\" = FOMO, \"Age (in years)\" = Age, \"Number of Instagram Followers\" = TotalFollowers) |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;    \n        kable(caption = \"FoMO and Socio-Demographic Factors Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()    \n\n\nFoMO and Socio-Demographic Factors Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nAge (in years)\n3370\n33.61\n10.42\n12\n75\n\n\nNumber of Instagram Followers\n3370\n203.25\n93.42\n1\n594\n\n\n\n\n# scatterplots\np2 &lt;- ggplot(data = fomo, aes(x = TotalFollowers, y = FOMO)) + \n    geom_point() + \n  geom_smooth(method = 'lm', se = FALSE, colour = 'purple', linewidth=2) +\n  labs(x = \"(b) Total Number of \\nInstagram Followers\", y = \"Fear of Missing Out\")\n\np2\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\nfomo_mdl2 &lt;- lm(FOMO ~ Age + TotalFollowers, data = fomo)\nsummary(fomo_mdl2)\n\n\nCall:\nlm(formula = FOMO ~ Age + TotalFollowers, data = fomo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.273  -4.066  -0.071   3.841  21.705 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    26.521966   0.446021   59.46   &lt;2e-16 ***\nAge            -0.165111   0.009871  -16.73   &lt;2e-16 ***\nTotalFollowers  0.017989   0.001101   16.34   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.857 on 3367 degrees of freedom\nMultiple R-squared:  0.1674,    Adjusted R-squared:  0.1669 \nF-statistic: 338.6 on 2 and 3367 DF,  p-value: &lt; 2.2e-16\n\nconfint(fomo_mdl2)\n\n                     2.5 %      97.5 %\n(Intercept)    25.64746694 27.39646570\nAge            -0.18446526 -0.14575589\nTotalFollowers  0.01583102  0.02014788\n\n\n\n#######\n#Model Comparison\n#######\n\nanova(fomo_mdl1 ,fomo_mdl2) |&gt;\n    kable(caption = \"Model Comparison - fomo_mdl1 vs fomo_mdl2\", align = \"c\", digits = c(2,2,2,2,2,60)) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nModel Comparison - fomo_mdl1 vs fomo_mdl2\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n3368\n124676.4\nNA\nNA\nNA\nNA\n\n\n3367\n115515.0\n1\n9161.44\n267.04\n7.98e-58\n\n\n\n\n\n\n#######\n#Table for Results\n#######\n\ntab_model(fomo_mdl1 ,fomo_mdl2,\n          dv.labels = c(\"FoMO\",\"FoMO\"),\n          pred.labels = c(\"Age\" = \"Age (in years)\",\n                          \"TotalFollowers\" = \"Number of Instagram Followers\"), \n          title = \"RQ2 - Regression Table for FoMO Model\")\n\n\nRQ2 - Regression Table for FoMO Model\n\n\n\n\n\n\n\n\n\n\n\n \nFoMO\nFoMO\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n31.22\n30.53 – 31.92\n&lt;0.001\n26.52\n25.65 – 27.40\n&lt;0.001\n\n\nAge (in years)\n-0.20\n-0.22 – -0.18\n&lt;0.001\n-0.17\n-0.18 – -0.15\n&lt;0.001\n\n\nNumber of Instagram\nFollowers\n\n\n\n0.02\n0.02 – 0.02\n&lt;0.001\n\n\nObservations\n3370\n3370\n\n\nR2 / R2 adjusted\n0.101 / 0.101\n0.167 / 0.167"
  },
  {
    "objectID": "1_05_writeup_recap1.html#rq3",
    "href": "1_05_writeup_recap1.html#rq3",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "RQ3",
    "text": "RQ3\n\n#######\n#Descriptive Stats\n#######\n\nfomo |&gt; \n    select(FOMO, N, E, O, C, A) |&gt;\n    rename(\"Fear of Missing Out\" = FOMO, \"Neuroticism\" = N, \"Extraversion\" = E, \"Openness\" = O, \"Conscientiousness\" = C, \"Agreeableness\" = A) |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;    \n        kable(caption = \"FoMO and Personality Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()  \n\n\nFoMO and Personality Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nNeuroticism\n3370\n22.92\n5.77\n8\n40\n\n\nExtraversion\n3370\n25.88\n5.94\n8\n40\n\n\nOpenness\n3370\n37.61\n5.80\n14\n50\n\n\nConscientiousness\n3370\n31.04\n5.49\n13\n45\n\n\nAgreeableness\n3370\n30.89\n4.93\n13\n43\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\nfomo_mdl3 &lt;- lm(FOMOz ~ Nz + Ez + Oz + Cz + Az, data = fomo)\nsummary(fomo_mdl3)\n\n\nCall:\nlm(formula = FOMOz ~ Nz + Ez + Oz + Cz + Az, data = fomo)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.74061 -0.60648 -0.01036  0.59506  3.13402 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.453e-17  1.527e-02   0.000    1.000    \nNz           4.266e-01  1.643e-02  25.971  &lt; 2e-16 ***\nEz           1.744e-02  1.570e-02   1.111    0.267    \nOz           1.117e-02  1.550e-02   0.721    0.471    \nCz          -3.079e-01  1.596e-02 -19.289  &lt; 2e-16 ***\nAz          -8.508e-02  1.544e-02  -5.511 3.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8865 on 3364 degrees of freedom\nMultiple R-squared:  0.2152,    Adjusted R-squared:  0.2141 \nF-statistic: 184.5 on 5 and 3364 DF,  p-value: &lt; 2.2e-16\n\nconfint(fomo_mdl3)\n\n                  2.5 %      97.5 %\n(Intercept) -0.02994194  0.02994194\nNz           0.39441959  0.45883445\nEz          -0.01334388  0.04823358\nOz          -0.01921470  0.04155523\nCz          -0.33916065 -0.27657348\nAz          -0.11535145 -0.05481487\n\n\n\n#plot model examining significant personality predictors\nN_plot &lt;- plot_model(fomo_mdl3, type = \"eff\",\n           terms = c(\"Nz\"),\n           show.data = TRUE,\n           axis.title = c(\"Neuroticsm \\n(z-scored)\",\"FoMO Score (z-scored)\"),\n           title = \"FoMO & N\")\n\nC_plot &lt;- plot_model(fomo_mdl3, type = \"eff\",\n           terms = c(\"Cz\"),\n           show.data = TRUE,\n           axis.title = c(\"Conscientiousness \\n(z-scored)\",\"FoMO Score (z-scored)\"),\n           title = \"FoMO & C\")\n\nA_plot &lt;- plot_model(fomo_mdl3, type = \"eff\",\n           terms = c(\"Az\"),\n           show.data = TRUE,\n           axis.title = c(\"Agreeableness \\n(z-scored)\",\"FoMO Score (z-scored)\"),\n           title = \"FoMO & A\")\n\nN_plot | C_plot | A_plot\n\n\n\n\n\n\n\n\n#create table for results - RQ3\ntab_model(fomo_mdl3,\n          dv.labels = \"FoMO (Z-Scored)\",\n          pred.labels = c(\"Nz\" = \"Neuroticism (Z-Scored)\",\n                          \"Ez\" = \"Extraversion (Z-Scored)\",\n                          \"Oz\" = \"Openness (Z-Scored)\",\n                          \"Az\" = \"Agreeableness (Z-Scored)\",\n                          \"Cz\" = \"Conscientiousness (Z-Scored)\"),\n          title = \"RQ3 - Regression Table for FoMO Model\")\n\n\nRQ3 - Regression Table for FoMO Model\n\n\n\n\n\n\n\n\n \nFoMO (Z-Scored)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n-0.00\n-0.03 – 0.03\n1.000\n\n\nNeuroticism (Z-Scored)\n0.43\n0.39 – 0.46\n&lt;0.001\n\n\nExtraversion (Z-Scored)\n0.02\n-0.01 – 0.05\n0.267\n\n\nOpenness (Z-Scored)\n0.01\n-0.02 – 0.04\n0.471\n\n\nConscientiousness\n(Z-Scored)\n-0.31\n-0.34 – -0.28\n&lt;0.001\n\n\nAgreeableness (Z-Scored)\n-0.09\n-0.12 – -0.05\n&lt;0.001\n\n\nObservations\n3370\n\n\nR2 / R2 adjusted\n0.215 / 0.214"
  },
  {
    "objectID": "1_05_writeup_recap1_larch.html",
    "href": "1_05_writeup_recap1_larch.html",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to write-up and provide interpretation of linear models with single and multiple predictors.\n\n\nBe up to date with lectures\nHave completed Labs 1 - 4\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/FOMOdataset.csv"
  },
  {
    "objectID": "1_05_writeup_recap1_larch.html#study-overview",
    "href": "1_05_writeup_recap1_larch.html#study-overview",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Aim\nExplore the associations among Fear of Missing Out (FoMO), age, social media networks, and the Big Five personality traits.\nResearch Questions\n\nRQ1: Does age predict FoMO?\nRQ2: Does the number of Instagram followers explain a significant amount of variance in FoMO over and above age?\nRQ3: Does personality predict FoMO?\n\n\n\n FoMO data codebook.\n\n\nDescription\nThe data used for this write-up exercise are simulated, drawing on recent work on Fear of Missing Out (FoMO), socio-demographic factors, and the Big Five personality traits. The simulated data are based on the findings of this work, and acted to expand upon the methods and results reported in the following paper:\nRozgonjuk, D., Sindermann, C., Elhai, J. D., & Montag, C. (2021). Individual differences in Fear of Missing Out (FoMO): Age, gender, and the Big Five personality trait domains, facets, and items. Personality and Individual Differences, 171, 110546. https://doi.org/10.1016/j.paid.2020.110546\nIn the current study, participants were invited to an online study investigating the associations among FoMO, socio-demographic factors, and personality. The final sample comprised 3370 people. Participants completed a FOMO scale and a personality inventory. The 10-item FOMO scale measured the extent of experiencing apprehension regarding missing out on interesting events of others on a 5-point scale (1 = “not at all true of me” to 5 = “extremely true of me”), producing a possible range of scores between 10 and 50. The Big Five Inventory (BFI) is a 45-item personality assessment questionnaire (note that only 44 items were used to match the study above) that uses a five-point response scale (1 = “very inapplicable” to 5 = “very applicable”). The BFI consists of five domains: Neuroticism (8 items; possible range of scores 8-40), Extraversion (8 items; possible range of scores 8-40), Openness to Experience (10 items; possible range of scores 10-50), Agreeableness (9 items; possible range of scores 9-45), and Conscientiousness (9 items; possible range of scores 9-45). We extended the aforementioned study to include an extra socio-demographic variable - a measure of popularity on social media based on the number of followers. Unlike the original study, we do not have measures of gender, education level, or specific country of residence.\nData Dictionary\nThe data in FOMOdataset.csv contain eight attributes collected from a simulated sample of \\(n=3370\\) hypothetical individuals across the UK, and include:\n\n\n\n\n\n\n\nVariable\n      Description\n    \n\n\nFOMO\nFoMO Score (as measured by the 10-item FoMO scale)\n\n\nAge\nAge (in years)\n\n\nN\nScore on personality items assessing Neuroticism from the Big Five Inventory (BFI)\n\n\nE\nScore on personality items assessing Extraversion from the Big Five Inventory (BFI)\n\n\nO\nScore on personality items assessing Openness from the Big Five Inventory (BFI)\n\n\nA\nScore on personality items assessing Agreeableness from the Big Five Inventory (BFI)\n\n\nC\nScore on personality items assessing Conscientiousness from the Big Five Inventory (BFI)\n\n\nTotalFollowers\nTotal Number of Instagram Followers\n\n\n\n\n\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\nFOMO\n      Age\n      N\n      E\n      O\n      A\n      C\n      TotalFollowers\n    \n\n\n28\n38\n26\n30\n32\n27\n38\n98\n\n\n26\n30\n23\n27\n33\n32\n30\n192\n\n\n23\n33\n14\n30\n36\n27\n24\n177\n\n\n18\n44\n26\n21\n37\n28\n34\n119\n\n\n19\n43\n32\n21\n41\n35\n40\n278\n\n\n24\n43\n22\n25\n31\n30\n24\n184\n\n\n\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the FOMO dataset into R, assigning it to an object named fomo\n\n\n\n\n\n\n Solution \n\n\n\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(sjPlot)\nlibrary(kableExtra)\nlibrary(psych)\n\n#Reading in fomo data and storing in object named 'fomo'\nfomo &lt;- read_csv(\"https://uoepsy.github.io/data/FOMOdataset.csv\")\n\n#check first six rows\nhead(fomo)\n\n# A tibble: 6 × 8\n   FOMO   Age     N     E     O     A     C TotalFollowers\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n1    28    38    26    30    32    27    38             98\n2    26    30    23    27    33    32    30            192\n3    23    33    14    30    36    27    24            177\n4    18    44    26    21    37    28    34            119\n5    19    43    32    21    41    35    40            278\n6    24    43    22    25    31    30    24            184\n\n\n\n\n\n\nProvided Analysis Code\nBelow you will find the code required to conduct the analysis to address the research questions. This should look similar (in most areas) to what you worked through in lecture.\n\n Provided Analysis Code"
  },
  {
    "objectID": "1_05_writeup_recap1_larch.html#data-management",
    "href": "1_05_writeup_recap1_larch.html#data-management",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "Data Management",
    "text": "Data Management\n\nlibrary(tidyverse) # for all things!\nlibrary(psych) # good for descriptive stats\nlibrary(patchwork) # grouping plots together\nlibrary(kableExtra) # useful for creating nice tables\nlibrary(sjPlot) #regression tables & plots\n\nfomo &lt;- read_csv(\"https://uoepsy.github.io/data/FOMOdataset.csv\")\n\n# standardise FoMO & personality scores for RQ3\nfomo &lt;- \n  fomo |&gt; \n    mutate(\n      FOMOz = (FOMO-mean(FOMO))/sd(FOMO),\n      Oz = (O-mean(O))/sd(O),\n      Cz = (C-mean(C))/sd(C),\n      Ez = (E-mean(E))/sd(E),\n      Az = (A-mean(A))/sd(A),      \n      Nz = (N-mean(N))/sd(N))\n#alternatively, you could do FOMOz = scale(FOMO, center = TRUE, scale = TRUE)"
  },
  {
    "objectID": "1_05_writeup_recap1_larch.html#overall",
    "href": "1_05_writeup_recap1_larch.html#overall",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "Overall",
    "text": "Overall\n\n#######\n#Descriptive Stats\n#######\n\n\n# the describe() function is from the psych package, and kable() from kableExtra which is used to make a nice table where the values are rounded to 2 decimal places using digits = 2. \n# We are first renaming our variables to give more appropriate / informative names.\n#Next we are selecting columns 2, 3, 4, 8, and 9 from the describe output (n, mean, sd, min, max)\n\nfomo |&gt; \n    select(FOMO, Age, TotalFollowers, N, E, O, C, A) |&gt;\n    rename(\"Fear of Missing Out\" = FOMO, \"Age (in years)\" = Age, \"Number of Instagram Followers\" = TotalFollowers, \"Neuroticism\" = N, \"Extraversion\" = E, \"Openness\" = O, \"Conscientiousness\" = C, \"Agreeableness\" = A) |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;\n        kable(caption = \"FoMO, Socio-Demographic Factors, and Personality Traits Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()   \n\n\nFoMO, Socio-Demographic Factors, and Personality Traits Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nAge (in years)\n3370\n33.61\n10.42\n12\n75\n\n\nNumber of Instagram Followers\n3370\n203.25\n93.42\n1\n594\n\n\nNeuroticism\n3370\n22.92\n5.77\n8\n40\n\n\nExtraversion\n3370\n25.88\n5.94\n8\n40\n\n\nOpenness\n3370\n37.61\n5.80\n14\n50\n\n\nConscientiousness\n3370\n31.04\n5.49\n13\n45\n\n\nAgreeableness\n3370\n30.89\n4.93\n13\n43\n\n\n\n\n#from above, no missing values and scores within range (look at min and max values)\n\n\n# scatterplot matrix, hist, and corr of FoMO, Socio-Demographic Factors, and Personality Traits Descriptive Statistics\npairs.panels(fomo |&gt;\n    select(-FOMOz, -Oz, -Cz, -Ez, -Az, -Nz))"
  },
  {
    "objectID": "1_05_writeup_recap1_larch.html#rq1",
    "href": "1_05_writeup_recap1_larch.html#rq1",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "RQ1",
    "text": "RQ1\n\n#######\n#Descriptive Stats\n#######\n\nfomo |&gt; \n    select(FOMO, Age) |&gt;\n    rename(\"Fear of Missing Out\" = FOMO, \"Age (in years)\" = Age) |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;    \n        kable(caption = \"FoMO and Age Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()    \n\n\nFoMO and Age Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nAge (in years)\n3370\n33.61\n10.42\n12\n75\n\n\n\n\n# scatterplot\np1 &lt;- ggplot(data = fomo, aes(x = Age, y = FOMO)) + \n    geom_point() + \n  geom_smooth(method = 'lm', se = FALSE, colour = 'red', linewidth=2) +\n  labs(x = \"(a) Age (in years)\", y = \"Fear of Missing Out\")\np1\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\nfomo_mdl1 &lt;- lm(FOMO ~ Age, data = fomo)\nsummary(fomo_mdl1)\n\n\nCall:\nlm(formula = FOMO ~ Age, data = fomo)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1028  -4.2129  -0.1602   4.0551  22.2321 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 31.22239    0.35408   88.18   &lt;2e-16 ***\nAge         -0.19617    0.01006  -19.50   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.084 on 3368 degrees of freedom\nMultiple R-squared:  0.1014,    Adjusted R-squared:  0.1011 \nF-statistic: 380.1 on 1 and 3368 DF,  p-value: &lt; 2.2e-16\n\nconfint(fomo_mdl1)\n\n                 2.5 %     97.5 %\n(Intercept) 30.5281496 31.9166293\nAge         -0.2158992 -0.1764425\n\n\n\n#######\n#Table for Results\n#######\n\ntab_model(fomo_mdl1,\n          dv.labels = \"FoMO\",\n          pred.labels = c(\"Age\" = \"Age (in years)\"), \n          title = \"RQ1: Regression Table for FoMO Model\")\n\n\nRQ1: Regression Table for FoMO Model\n\n\n \nFoMO\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n31.22\n30.53 – 31.92\n&lt;0.001\n\n\nAge (in years)\n-0.20\n-0.22 – -0.18\n&lt;0.001\n\n\nObservations\n3370\n\n\nR2 / R2 adjusted\n0.101 / 0.101"
  },
  {
    "objectID": "1_05_writeup_recap1_larch.html#rq2",
    "href": "1_05_writeup_recap1_larch.html#rq2",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "RQ2",
    "text": "RQ2\n\n#######\n#Descriptive Stats\n#######\n\nfomo |&gt; \n    select(FOMO, Age, TotalFollowers) |&gt;\n    rename(\"Fear of Missing Out\" = FOMO, \"Age (in years)\" = Age, \"Number of Instagram Followers\" = TotalFollowers) |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;    \n        kable(caption = \"FoMO and Socio-Demographic Factors Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()    \n\n\nFoMO and Socio-Demographic Factors Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nAge (in years)\n3370\n33.61\n10.42\n12\n75\n\n\nNumber of Instagram Followers\n3370\n203.25\n93.42\n1\n594\n\n\n\n\n# scatterplots\np2 &lt;- ggplot(data = fomo, aes(x = TotalFollowers, y = FOMO)) + \n    geom_point() + \n  geom_smooth(method = 'lm', se = FALSE, colour = 'purple', linewidth=2) +\n  labs(x = \"(b) Total Number of \\nInstagram Followers\", y = \"Fear of Missing Out\")\n\np2\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\nfomo_mdl2 &lt;- lm(FOMO ~ Age + TotalFollowers, data = fomo)\nsummary(fomo_mdl2)\n\n\nCall:\nlm(formula = FOMO ~ Age + TotalFollowers, data = fomo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.273  -4.066  -0.071   3.841  21.705 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    26.521966   0.446021   59.46   &lt;2e-16 ***\nAge            -0.165111   0.009871  -16.73   &lt;2e-16 ***\nTotalFollowers  0.017989   0.001101   16.34   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.857 on 3367 degrees of freedom\nMultiple R-squared:  0.1674,    Adjusted R-squared:  0.1669 \nF-statistic: 338.6 on 2 and 3367 DF,  p-value: &lt; 2.2e-16\n\nconfint(fomo_mdl2)\n\n                     2.5 %      97.5 %\n(Intercept)    25.64746694 27.39646570\nAge            -0.18446526 -0.14575589\nTotalFollowers  0.01583102  0.02014788\n\n\n\n#######\n#Model Comparison\n#######\n\nanova(fomo_mdl1 ,fomo_mdl2) |&gt;\n    kable(caption = \"Model Comparison - fomo_mdl1 vs fomo_mdl2\", align = \"c\", digits = c(2,2,2,2,2,60)) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nModel Comparison - fomo_mdl1 vs fomo_mdl2\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n3368\n124676.4\nNA\nNA\nNA\nNA\n\n\n3367\n115515.0\n1\n9161.44\n267.04\n7.98e-58\n\n\n\n\n\n\n#######\n#Table for Results\n#######\n\ntab_model(fomo_mdl1 ,fomo_mdl2,\n          dv.labels = c(\"FoMO\",\"FoMO\"),\n          pred.labels = c(\"Age\" = \"Age (in years)\",\n                          \"TotalFollowers\" = \"Number of Instagram Followers\"), \n          title = \"RQ2 - Regression Table for FoMO Model\")\n\n\nRQ2 - Regression Table for FoMO Model\n\n\n\n\n\n\n\n\n\n\n\n \nFoMO\nFoMO\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n31.22\n30.53 – 31.92\n&lt;0.001\n26.52\n25.65 – 27.40\n&lt;0.001\n\n\nAge (in years)\n-0.20\n-0.22 – -0.18\n&lt;0.001\n-0.17\n-0.18 – -0.15\n&lt;0.001\n\n\nNumber of Instagram\nFollowers\n\n\n\n0.02\n0.02 – 0.02\n&lt;0.001\n\n\nObservations\n3370\n3370\n\n\nR2 / R2 adjusted\n0.101 / 0.101\n0.167 / 0.167"
  },
  {
    "objectID": "1_05_writeup_recap1_larch.html#rq3",
    "href": "1_05_writeup_recap1_larch.html#rq3",
    "title": "Block 1 Analysis & Write-Up Example",
    "section": "RQ3",
    "text": "RQ3\n\n#######\n#Descriptive Stats\n#######\n\nfomo |&gt; \n    select(FOMO, N, E, O, C, A) |&gt;\n    rename(\"Fear of Missing Out\" = FOMO, \"Neuroticism\" = N, \"Extraversion\" = E, \"Openness\" = O, \"Conscientiousness\" = C, \"Agreeableness\" = A) |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;    \n        kable(caption = \"FoMO and Personality Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()  \n\n\nFoMO and Personality Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nNeuroticism\n3370\n22.92\n5.77\n8\n40\n\n\nExtraversion\n3370\n25.88\n5.94\n8\n40\n\n\nOpenness\n3370\n37.61\n5.80\n14\n50\n\n\nConscientiousness\n3370\n31.04\n5.49\n13\n45\n\n\nAgreeableness\n3370\n30.89\n4.93\n13\n43\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\nfomo_mdl3 &lt;- lm(FOMOz ~ Nz + Ez + Oz + Cz + Az, data = fomo)\nsummary(fomo_mdl3)\n\n\nCall:\nlm(formula = FOMOz ~ Nz + Ez + Oz + Cz + Az, data = fomo)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.74061 -0.60648 -0.01036  0.59506  3.13402 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.453e-17  1.527e-02   0.000    1.000    \nNz           4.266e-01  1.643e-02  25.971  &lt; 2e-16 ***\nEz           1.744e-02  1.570e-02   1.111    0.267    \nOz           1.117e-02  1.550e-02   0.721    0.471    \nCz          -3.079e-01  1.596e-02 -19.289  &lt; 2e-16 ***\nAz          -8.508e-02  1.544e-02  -5.511 3.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8865 on 3364 degrees of freedom\nMultiple R-squared:  0.2152,    Adjusted R-squared:  0.2141 \nF-statistic: 184.5 on 5 and 3364 DF,  p-value: &lt; 2.2e-16\n\nconfint(fomo_mdl3)\n\n                  2.5 %      97.5 %\n(Intercept) -0.02994194  0.02994194\nNz           0.39441959  0.45883445\nEz          -0.01334388  0.04823358\nOz          -0.01921470  0.04155523\nCz          -0.33916065 -0.27657348\nAz          -0.11535145 -0.05481487\n\n\n\n#plot model examining significant personality predictors\nN_plot &lt;- plot_model(fomo_mdl3, type = \"eff\",\n           terms = c(\"Nz\"),\n           show.data = TRUE,\n           axis.title = c(\"Neuroticsm \\n(z-scored)\",\"FoMO Score (z-scored)\"),\n           title = \"FoMO & N\")\n\nC_plot &lt;- plot_model(fomo_mdl3, type = \"eff\",\n           terms = c(\"Cz\"),\n           show.data = TRUE,\n           axis.title = c(\"Conscientiousness \\n(z-scored)\",\"FoMO Score (z-scored)\"),\n           title = \"FoMO & C\")\n\nA_plot &lt;- plot_model(fomo_mdl3, type = \"eff\",\n           terms = c(\"Az\"),\n           show.data = TRUE,\n           axis.title = c(\"Agreeableness \\n(z-scored)\",\"FoMO Score (z-scored)\"),\n           title = \"FoMO & A\")\n\nN_plot | C_plot | A_plot\n\n\n\n\n\n\n\n\n#create table for results - RQ3\ntab_model(fomo_mdl3,\n          dv.labels = \"FoMO (Z-Scored)\",\n          pred.labels = c(\"Nz\" = \"Neuroticism (Z-Scored)\",\n                          \"Ez\" = \"Extraversion (Z-Scored)\",\n                          \"Oz\" = \"Openness (Z-Scored)\",\n                          \"Az\" = \"Agreeableness (Z-Scored)\",\n                          \"Cz\" = \"Conscientiousness (Z-Scored)\"),\n          title = \"RQ3 - Regression Table for FoMO Model\")\n\n\nRQ3 - Regression Table for FoMO Model\n\n\n\n\n\n\n\n\n \nFoMO (Z-Scored)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n-0.00\n-0.03 – 0.03\n1.000\n\n\nNeuroticism (Z-Scored)\n0.43\n0.39 – 0.46\n&lt;0.001\n\n\nExtraversion (Z-Scored)\n0.02\n-0.01 – 0.05\n0.267\n\n\nOpenness (Z-Scored)\n0.01\n-0.02 – 0.04\n0.471\n\n\nConscientiousness\n(Z-Scored)\n-0.31\n-0.34 – -0.28\n&lt;0.001\n\n\nAgreeableness (Z-Scored)\n-0.09\n-0.12 – -0.05\n&lt;0.001\n\n\nObservations\n3370\n\n\nR2 / R2 adjusted\n0.215 / 0.214"
  },
  {
    "objectID": "1_06_dummy.html",
    "href": "1_06_dummy.html",
    "title": "Dummy Coding",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to specify a baseline/reference level for categorical variables\nUnderstand how to specify dummy coding\nInterpret the output from a model using dummy coding\nUnderstand how to specify contrasts to test specific effects\n\n\nBe up to date with lectures\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nemmeans\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/caffeinedrink.csv"
  },
  {
    "objectID": "1_06_dummy.html#study-analysis-plan-overview",
    "href": "1_06_dummy.html#study-analysis-plan-overview",
    "title": "Dummy Coding",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe str() function will return the overall structure of the dataset, this can be quite handy to look at\n\nConvert categorical variables to factors, and if needed, provide better variable names*\nLabel factors appropriately to aid with your model interpretations if required*\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\nAre scores within possible ranges (e.g., if we recorded people’s age, it would be impossible to have someone aged -31!)\n\nReview the numeric outcomes & categorical predictors flashcards, specifically ‘coding variables as factors’.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(caffeine)\n\nspc_tbl_ [40 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ treatment: chr [1:40] \"control\" \"control\" \"control\" \"control\" ...\n $ wpm      : num [1:40] 109 114 113 110 116 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   treatment = col_character(),\n  ..   wpm = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(caffeine)\n\n# A tibble: 6 × 2\n  treatment   wpm\n  &lt;chr&gt;     &lt;dbl&gt;\n1 control    109.\n2 control    114.\n3 control    113.\n4 control    110.\n5 control    116.\n6 control    113.\n\n#check for NAs - there are none - all FALSE\ntable(is.na(caffeine))\n\n\nFALSE \n   80 \n\n\nLet’s start with the ‘treatment’ condition variable. This should be coded as factor (&lt;fctr&gt;), but can see from above it is currently coded as a character (&lt;chr&gt;). Let’s correct this.\n\n#Code treatment as a factor\ncaffeine &lt;- caffeine |&gt;\n  mutate(treatment = as_factor(treatment))\n\nNext, let’s look at the ‘wpm’ variable. Here we want to check for impossible values. Although we don’t know if there is a maximum possible WPM, we do know that we cannot have a negative WPM.\n\n# all looks ok - min and max both positive values\ndescribe(caffeine$wpm)\n\n   vars  n   mean   sd median trimmed  mad    min    max range skew kurtosis\nX1    1 40 113.59 2.92 113.06  113.51 3.62 107.94 120.24  12.3 0.22    -0.84\n     se\nX1 0.46\n\n\n\n\n\n\n\n\nAll participant data was complete (no missing values), with WPM scores within possible ranges. Treatment was coded as a factor with four levels - control (water), coffee, red bull, and mint tea.\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nChoose an appropriate reference level for the Treatment condition, and relevel the variable to reflect your choice.\nUse the contrasts() function to review the contrasts associated with Treatment to ensure that the desired reference level is now being used.\n\n\n\n\n\n\nHint\n\n\n\n\n\nConsider whether there is a level of the Treatment variable that would naturally lend itself to be the reference or baseline level (e.g., in a drug trial with conditions ‘placebo’, ‘low dose’, and ‘high dose’, it would be logical to select placebo as the reference level - the only level without any dose.\nSee the numeric outcomes & categorical predictors flashcards, specifically ‘specifying reference levels’.\n\n\n\n\n\n\n\n Solution \n\n\nThe Treatment factor has a group coded ‘Control (Water)’ which lends itself naturally to be the reference category.\n\n#set 'Control' caffeine treatment condition as our reference group \ncaffeine$treatment &lt;- relevel(caffeine$treatment, \"control\")\n\n#check levels - control should be first in the list\nlevels(caffeine$treatment)\n\n[1] \"control\"  \"coffee\"   \"red_bull\" \"mint_tea\"\n\n#view contrasts - control coded as 0 \ncontrasts(caffeine$treatment)\n\n         coffee red_bull mint_tea\ncontrol       0        0        0\ncoffee        1        0        0\nred_bull      0        1        0\nmint_tea      0        0        1\n\n\n\n\n\n\n\nQuestion 3\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook. The statistical models flashcards, especially the numeric outcomes & categorical predictors flashcards may also be useful to refer to. For a more in-depth overview and example, see the numeric outcomes & categorical predictors &gt; example flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nThe caffeine dataset contained information on 40 hypothetical participants who took part in an experiment examining whether the number of words typed per minute (WPM) differed among caffeine treatment conditions. Using a between-subjects design, the researchers collected information on participants’ WPM (average number of words typed per minute), and which one of four treatment conditions they were randomly assigned to (Control (Water), Coffee, Mint Tea, or Red Bull).\nBoxplots will be used to visualise the associations among WPM and caffeine treatment conditions. To address the research question of whether WPM differs by caffeine treatment condition, we first need to define the dummy variables for Treatment:\n\\[\n\\text{Treatment}_\\text{Coffee} = \\begin{cases}  \n1 & \\text{if Treatment is Coffee} \\\\  \n0 & \\text{otherwise}  \n\\end{cases}  \n\\quad    \n\\]\n\\[\n\\text{Treatment}_\\text{Red Bull} = \\begin{cases}  \n1 & \\text{if Treatment is Red Bull} \\\\  \n0 & \\text{otherwise}  \n\\\\  \n\\end{cases}  \n\\quad  \n\\]\n\\[\n\\text{Treatment}_\\text{Mint Tea} = \\begin{cases}  \n1 & \\text{if Treatment is Mint Tea} \\\\  \n0 & \\text{otherwise}  \n\\end{cases}  \n\\quad  \n\\]\n\\[\n(\\text{Control (Water) is base level})  \n\\]\nBased on the above dummy coding, we are going to fit the following regression model:\n\\[\n\\begin{align}\n\\text{WPM} = \\beta_0 + \\beta_1 \\cdot \\text{Treatment}_\\text{Coffee} \\\\    \n+ \\beta_2 \\cdot \\text{Treatment}_\\text{Red Bull} + \\beta_3 \\cdot \\text{Treatment}_\\text{Mint Tea} + \\epsilon\n\\end{align}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2, 3\\))\nThere are no differences in WPM based on caffeine treatment condition.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2, 3\\))\nThere are differences in WPM based on caffeine treatment condition."
  },
  {
    "objectID": "1_06_dummy.html#descriptive-statistics-visualisations",
    "href": "1_06_dummy.html#descriptive-statistics-visualisations",
    "title": "Dummy Coding",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 4\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study (i.e., comment on any observed differences among treatment groups).\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables and data visualisation &gt; bivariate associations - examples flashcard, paying particular attention to the type of data that you’re working with.\nMake sure to comment on any observed differences among the sample means of the four treatment conditions.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table, grouped by treatment condition:\n\ncaffeine |&gt;\n  group_by(treatment) |&gt;\n  summarise(n = n(), \n            Mean = mean(wpm), \n            SD = sd(wpm),\n            Minimum = min(wpm),\n            Maximum = max(wpm)) |&gt;\n    kable(caption = \"Descriptive Statistics\", digits = 2) |&gt;\n    kable_styling()\n\n\n\nTable 1: Descriptive Statistics\n\ntreatment\nn\nMean\nSD\nMinimum\nMaximum\n\n\n\ncontrol\n10\n112.15\n1.98\n109.43\n116.23\n\n\ncoffee\n10\n114.48\n1.82\n112.07\n117.16\n\n\nred_bull\n10\n116.65\n2.15\n113.00\n120.24\n\n\nmint_tea\n10\n111.09\n2.13\n107.94\n115.82\n\n\n\n\n\n\n\n\n\n\nSince we have a continuous outcome and a categorical predictor - either a boxplot or violin plot would be most appropriate for visualisations:\n\nggplot(data = caffeine, aes(x = treatment, y = wpm, fill = treatment)) +\n  geom_boxplot() +\n  labs(x = 'Treatment Condition', y = 'WPM')\n\n\n\nFigure 1: Association between Treatment Conditions and WPM\n\n\n\n\nggplot(data = caffeine, aes(x = treatment, y = wpm, fill = treatment, colour = treatment)) +\n  geom_violin(alpha = 0.5) +\n  geom_jitter(alpha = 0.5) +\n  theme(legend.position = 'none') +\n  labs(x = 'Treatment Condition', y = 'WPM')\n\n\n\nFigure 2: Association between Treatment Conditions and WPM\n\n\n\n\n\n\n\n\n\n\n\n\nInitial observations:\n\nThose in the Red Bull condition, on average, typed the most WPM, whilst those in the Mint Tea condition the fewest\n\nThe average WPM appears to be lower for those in the non-caffeine conditions (i.e., control - water / mint tea) in comparison to those in the caffeine drinks condition (red bull / coffee)\n\nThe range of WPM appears to be slightly higher in the cold drink conditions (i.e., control - water / mint tea) in comparison to those in the hot drink conditions (red bull / coffee)"
  },
  {
    "objectID": "1_06_dummy.html#model-fitting-interpretation",
    "href": "1_06_dummy.html#model-fitting-interpretation",
    "title": "Dummy Coding",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nFit the specified model, and assign it the name “caf_mdl1”.\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can fit multiple regression models with categorical predictors using the lm() function. For a recap, see the description & model specification flashcards.\nRecall that R computes the dummy variables for us. Thus, each row in the summary() output of the model will correspond to one of the estimated \\(\\beta\\)’s in the equation above. For a more in-depth overview and example, see the numeric outcomes & categorical predictors &gt; example flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit model\ncaf_mdl1 &lt;- lm(wpm ~ treatment, data=caffeine)\n\n\n#check model output\nsummary(caf_mdl1)\n\n\nCall:\nlm(formula = wpm ~ treatment, data = caffeine)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.652 -1.362 -0.151  1.125  4.729 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       112.1460     0.6402 175.179  &lt; 2e-16 ***\ntreatmentcoffee     2.3350     0.9053   2.579   0.0141 *  \ntreatmentred_bull   4.5060     0.9053   4.977 1.61e-05 ***\ntreatmentmint_tea  -1.0550     0.9053  -1.165   0.2516    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.024 on 36 degrees of freedom\nMultiple R-squared:  0.5563,    Adjusted R-squared:  0.5194 \nF-statistic: 15.05 on 3 and 36 DF,  p-value: 1.651e-06\n\n\nLet’s first map our coefficients and estimates:\n\n\n\n\n\n\n\nCoefficient\nEstimate\nRelation between \\(\\beta\\) and \\(\\mu\\)\n\n\n\n\n(Intercept)\n112.1460\n\\(\\beta_0 = \\hat \\mu_1\\)\n\n\ntreatmentcoffee\n2.3350\n\\(\\beta_0 + \\beta_1 = \\hat \\mu_2\\)\n\n\ntreatmentred_bull\n4.5060\n\\(\\beta_0 + \\beta_2 = \\hat \\mu_3\\)\n\n\ntreatmentmint_tea\n-1.0550\n\\(\\beta_0 + \\beta_3 = \\hat \\mu_4\\)\n\n\n\n\n\n\n\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\hat \\beta_0 = \\hat \\mu_1 = 112.15\\). The estimated average WPM for those in the control condition (water) was approximately 112.15.\nThe next estimate corresponds to treatmentcoffee and was \\(\\hat \\beta_1 = 2.34\\). The difference in mean WPM between Control and Coffee was estimated to be \\(2.34\\). Thus, \\(\\hat \\mu_2 = 112.15 + 2.34 = 114.49\\). In other words, people who have had coffee typed approximately 114.49 words, which was 2.34 words per minute more than those who have had water. This difference was statistically significant \\((p = .014)\\).\nThe estimate corresponding to treatmentred_bull was \\(\\hat \\beta_2 = 4.51\\). This was the estimated difference in mean WPM between Control and Red Bull, estimated to be \\(4.51\\). Thus, \\(\\hat \\mu_3 = 112.15 + 4.51 = 116.66\\). In other words, people who had red bull typed approximately 116.66 words, 4.51 words per minute more than those who had water. This difference was statistically significant \\((p &lt; .001)\\).\nThe estimate corresponding to treatmentmint_tea was \\(\\hat \\beta_3 = -1.06\\). This was the estimated difference in mean WPM between Control and Mint Tea, estimated to be \\(-1.06\\). Thus, \\(\\hat \\mu_4 = 112.15 + (-1.06) = 111.09\\). In other words, people who had mint tea typed approximately 111.09 words, 1.06 words per minute less than those who had water. This difference was not statistically significant \\((p = .252)\\)."
  },
  {
    "objectID": "1_06_dummy.html#planned-comparisons-contrasts",
    "href": "1_06_dummy.html#planned-comparisons-contrasts",
    "title": "Dummy Coding",
    "section": "Planned Comparisons / Contrasts",
    "text": "Planned Comparisons / Contrasts\n\nQuestion 6\n\n\nFormally state the two planned comparisons that the researchers were interested in as testable hypotheses.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nRecall that the researchers were also interested in addressing these two questions:\n\nWhether having some kind of caffeine (i.e., red bull or coffee), rather than no caffeine (i.e., control - water or mint tea), resulted in a difference in average WPM\nWhether there was a difference in average WPM between those with hot drinks (i.e., mint tea / coffee) in comparison to those with cold drinks (control - water / red bull)\n\nWe can specify the two hypotheses as follows:\n\n\nCaffeine vs No Caffeine\nHot vs Cold\n\n\n\n\\[\n\\begin{aligned}\n1. \\quad \\text{H}_0 &: \\mu_\\text{No Caffeine} = \\mu_\\text{Caffeine} \\\\\n\\\\\n    \\quad \\text{H}_0 &: \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Mint Tea}) = \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Red Bull}) \\\\  \n\\\\  \n\\\\\n    \\quad \\text{H}_1 &: \\mu_\\text{No Caffeine} \\neq \\mu_\\text{Caffeine} \\\\\n    \\\\\n    \\quad \\text{H}_1 &: \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Mint Tea}) \\neq \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Red Bull}) \\\\\n\\\\\n\\end{aligned}\n\\]\n\n\n\\[\n\\begin{aligned}\n2. \\quad H_0 &: \\mu_\\text{Hot Drink} = \\mu_\\text{Cold Drink} \\\\\n\\\\\n    \\quad H_0 &: \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Mint Tea}) = \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Red Bull}) \\\\  \n\\\\  \n\\\\  \n    \\quad H_1 &: \\mu_\\text{Hot Drink} \\neq \\mu_\\text{Cold Drink} \\\\  \n    \\\\  \n    \\quad H_1 &: \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Mint Tea}) \\neq \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Red Bull})  \\\\   \n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nAfter checking the levels of the factor treatment, use emmeans() to obtain the estimated treatment means and uncertainties for your factor.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nlevels(caffeine$treatment)\n\n[1] \"control\"  \"coffee\"   \"red_bull\" \"mint_tea\"\n\n\nUse the emmeans() to get the estimated means of our groups:\n\ntreatment_mean &lt;- emmeans(caf_mdl1, ~ treatment)\ntreatment_mean\n\n treatment emmean   SE df lower.CL upper.CL\n control      112 0.64 36      111      113\n coffee       114 0.64 36      113      116\n red_bull     117 0.64 36      115      118\n mint_tea     111 0.64 36      110      112\n\nConfidence level used: 0.95 \n\nplot(treatment_mean)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nSpecify the coefficients of the comparisons and run the contrast analysis, obtaining 95% confidence intervals.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\nRemember that ordering matters here - look again at the output of levels(caffeine$treatment) as this will help you when assigning your weights.\n\n\n\n\n\n\n\n Solution \n\n\nAs shown above via levels(), the ordering of the treatment factor is:\n\nControl (no caffeine / cold drink)\nCoffee (caffeine / hot drink)\nRed Bull (caffeine / cold drink)\nMint Tea (no caffeine / hot drink)\n\nFrom this ordering, we can specify our weights - based on the hypothesis, lets assign positive values to the no caffeine and hot drink conditions:\n\ntreatment_comp &lt;- list(\"No Caffeine - Caffeine\" = c(1/2, -1/2, -1/2, 1/2),\n             \"Hot Drink - Cold Drink\" = c(-1/2, 1/2, -1/2, 1/2)\n             )\n\nNow lets run our contrast analysis and get confidence intervals - to do so we use the contrast() function from emmeans():\n\n#run contrast analysis\ntreatment_comp_test &lt;- contrast(treatment_mean, method = treatment_comp)\n\n#examine output\ntreatment_comp_test\n\n contrast               estimate   SE df t.ratio p.value\n No Caffeine - Caffeine    -3.95 0.64 36  -6.167  &lt;.0001\n Hot Drink - Cold Drink    -1.61 0.64 36  -2.520  0.0163\n\n#obtain confidence intervals\nconfint(treatment_comp_test)\n\n contrast               estimate   SE df lower.CL upper.CL\n No Caffeine - Caffeine    -3.95 0.64 36    -5.25   -2.650\n Hot Drink - Cold Drink    -1.61 0.64 36    -2.91   -0.315\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\nQuestion 9\n\n\nInterpret the results of the contrast analysis in the context of the researchers hypotheses.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nHypothesis 1: Caffeine vs No Caffeine\nHypothesis 2: Hot vs Cold\n\n\n\nWe performed a test against \\(H_0: \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Mint Tea}) - \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Red Bull}) = 0\\). At the 5% significance level, there was evidence that the mean WPM for those who were in the no caffeine condition (i.e., water and mint tea) was significantly different from those in a caffeine condition (i.e., coffee and red bull) \\((t(36) = -6.17, p &lt; .001, \\text{two-sided})\\), and this difference was estimated to be -3.95. We are 95% confident that those who consumed no caffeine typed, on average, between 2.7 and 5.3 words less per minute than those who consumed some form of caffeine \\(CI_{95}[-5.25, -2.65]\\).\n\n\nWe performed a test against \\(H_0: \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Mint Tea}) - \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Red Bull}) = 0\\). At the 5% significance level, there was evidence that the average WPM for those in the hot drink condition (coffee and mint tea) significantly differed from those in the cold drink condition (water and red bull) \\((t(36) = -2.52, p = .016, \\text{two-sided})\\), and this difference was estimated to be -1.61. We are 95% confident that those who consumed a hot drink typed, on average, between 0.3 and 2.9 words less per minute than those who consumed a cold drink \\(CI_{95}[-2.91, -0.32]\\)."
  },
  {
    "objectID": "1_06_dummy.html#study-design",
    "href": "1_06_dummy.html#study-design",
    "title": "Dummy Coding",
    "section": "Study Design",
    "text": "Study Design\n\nQuestion 10\n\n\nFor each of the below experiment descriptions, note (1) the design, (2) number of variables of interest, (3) levels of categorical variables, (4) what you think the reference group should be and why.\n\n\nExperiment 1\nExperiment 2\nExperiment 3\n\n\n\nA group of researchers were interested in whether sleep deprivation influenced reaction time. They hypothesised that sleep deprived individuals would have slower reaction times than non-sleep deprived individuals.\nTo test this, they recruited 60 participants who were matched on a number of demographic variables including age and sex. One member of each pair (e.g., female, aged 18) was placed into a different sleep condition - ‘Sleep Deprived’ (4 hours per night) or ‘Non-Sleep Deprived’ (8 hours per night).\n\n\nA group of researchers were interested in replicating an experiment testing the Stroop Effect.\nThey recruited 50 participants who took part in Task A (word colour and meaning are congruent) and Task B (word colour and meaning are incongruent) where they were asked to name the color of the ink instead of reading the word. The order of presentation was counterbalanced across participants. The researchers hypothesised that participants would take significantly more time (‘response time’ measured in seconds) to complete Task B than Task A.\nYou can test yourself here for fun: Stroop Task\n\n\nA group of researchers wanted to test a hypothesised theory according to which patients with amnesia will have a deficit in explicit memory but not implicit memory. Huntingtons patients, on the other hand, will display the opposite: they will have no deficit in explicit memory, but will have a deficit in implicit memory.\nTo test this, researchers designed a study that included two variables: ‘Diagnosis’ (Amnesic, Huntingtons, Control) and ‘Task’ (Grammar, Classification, Recognition) where participants were randomly assigned to a Task condition. The first two tasks (Grammar and Classification) are known to reflect implicit memory processes, whereas the Recognition task is known to reflect explicit memory processes.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nExperiment 1\nExperiment 2\nExperiment 3\n\n\n\n\nDesign = Between-person: Matched pairs\nNumber of variables of interest = 2 - Sleep Condition and Reaction Time\nLevels of variables = Sleep Condition has 2 levels - Sleep Deprived and Non-Sleep Deprived; Reaction Time is a continuous measure, so has no associated levels\nReference Group = Sleep Condition - Non-Sleep Deprived. The non-sleep deprived individuals represent the normal level of functioning, which is the standard state without any experimental manipulation. This makes it a natural reference group to compare against the experimental group (sleep deprived). The hypothesis stated an interest in assessing whether sleep deprived individuals had slower reaction times in comparison to non-sleep deprived. The coefficient associated with the sleep deprived group in the linear model will represent the difference in reaction time due to sleep deprivation. A positive coefficient would indicate slower reaction times for the sleep deprived compared to the non-sleep deprived.\n\n\n\n\nDesign = Within-person: Repeated measures (this is a study design that you will learn more about in DAPR3!)\nNumber of variables of interest = 2 - Task and Response Time\nLevels of variables = Task has 2 levels - A and B; Response Time is a continuous measure, so has no associated levels\nReference Group = Task - A. Task A represents the baseline condition where processing is generally considered more straightforward due to the congruency between word meaning and color. This provides a natural baseline for comparison because there are fewer cognitive conflicts or processing challenges in Task A compared to Task B. The hypothesis specifically predicted that participants will take more time to complete Task B. The coefficient for Task B in the linear model will represent the difference in time it takes to complete Task B relative to Task A. A positive coefficient for Task B would support the hypothesis that Task B requires more time and highlight the cognitive interference noted in the Stroop Effect.\n\n\n\n\nDesign = Between-person: 3×3 factorial design\nNumber of variables of interest = 2 - Diagnosis and Task\nLevels of variables = Diagnosis has 3 levels - Amnesic, Huntingtons, and Control; Task has 3 levels - Grammar, Classification, and Recognition\nReference Groups = Diagnosis - Control; Task - Recognition. Selecting the Control group as the reference for Diagnosis allows for the assessment of memory deficits in both patient groups against the typical functioning of participants without cognitive impairments (i.e., individuals in this group provide a baseline of normal memory function related to both explicit and implicit memory tasks). By using Recognition as the reference for Task, the model can assess how performance on the Grammar and Classification tasks (representing implicit memory) differs from performance in explicit tasks across different groups."
  },
  {
    "objectID": "1_06_dummy_beech.html",
    "href": "1_06_dummy_beech.html",
    "title": "Dummy Coding",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to specify a baseline/reference level for categorical variables\nUnderstand how to specify dummy coding\nInterpret the output from a model using dummy coding\nUnderstand how to specify contrasts to test specific effects\n\n\nBe up to date with lectures\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nemmeans\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/caffeinedrink.csv"
  },
  {
    "objectID": "1_06_dummy_beech.html#study-analysis-plan-overview",
    "href": "1_06_dummy_beech.html#study-analysis-plan-overview",
    "title": "Dummy Coding",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe str() function will return the overall structure of the dataset, this can be quite handy to look at\n\nConvert categorical variables to factors, and if needed, provide better variable names*\nLabel factors appropriately to aid with your model interpretations if required*\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\nAre scores within possible ranges (e.g., if we recorded people’s age, it would be impossible to have someone aged -31!)\n\nReview the numeric outcomes & categorical predictors flashcards, specifically ‘coding variables as factors’.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(caffeine)\n\nspc_tbl_ [40 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ treatment: chr [1:40] \"control\" \"control\" \"control\" \"control\" ...\n $ wpm      : num [1:40] 109 114 113 110 116 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   treatment = col_character(),\n  ..   wpm = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(caffeine)\n\n# A tibble: 6 × 2\n  treatment   wpm\n  &lt;chr&gt;     &lt;dbl&gt;\n1 control    109.\n2 control    114.\n3 control    113.\n4 control    110.\n5 control    116.\n6 control    113.\n\n#check for NAs - there are none - all FALSE\ntable(is.na(caffeine))\n\n\nFALSE \n   80 \n\n\nLet’s start with the ‘treatment’ condition variable. This should be coded as factor (&lt;fctr&gt;), but can see from above it is currently coded as a character (&lt;chr&gt;). Let’s correct this.\n\n#Code treatment as a factor\ncaffeine &lt;- caffeine |&gt;\n  mutate(treatment = as_factor(treatment))\n\nNext, let’s look at the ‘wpm’ variable. Here we want to check for impossible values. Although we don’t know if there is a maximum possible WPM, we do know that we cannot have a negative WPM.\n\n# all looks ok - min and max both positive values\ndescribe(caffeine$wpm)\n\n   vars  n   mean   sd median trimmed  mad    min    max range skew kurtosis\nX1    1 40 113.59 2.92 113.06  113.51 3.62 107.94 120.24  12.3 0.22    -0.84\n     se\nX1 0.46\n\n\n\n\n\n\n\n\nAll participant data was complete (no missing values), with WPM scores within possible ranges. Treatment was coded as a factor with four levels - control (water), coffee, red bull, and mint tea.\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nChoose an appropriate reference level for the Treatment condition, and relevel the variable to reflect your choice.\nUse the contrasts() function to review the contrasts associated with Treatment to ensure that the desired reference level is now being used.\n\n\n\n\n\n\nHint\n\n\n\n\n\nConsider whether there is a level of the Treatment variable that would naturally lend itself to be the reference or baseline level (e.g., in a drug trial with conditions ‘placebo’, ‘low dose’, and ‘high dose’, it would be logical to select placebo as the reference level - the only level without any dose.\nSee the numeric outcomes & categorical predictors flashcards, specifically ‘specifying reference levels’.\n\n\n\n\n\n\n\n Solution \n\n\nThe Treatment factor has a group coded ‘Control (Water)’ which lends itself naturally to be the reference category.\n\n#set 'Control' caffeine treatment condition as our reference group \ncaffeine$treatment &lt;- relevel(caffeine$treatment, \"control\")\n\n#check levels - control should be first in the list\nlevels(caffeine$treatment)\n\n[1] \"control\"  \"coffee\"   \"red_bull\" \"mint_tea\"\n\n#view contrasts - control coded as 0 \ncontrasts(caffeine$treatment)\n\n         coffee red_bull mint_tea\ncontrol       0        0        0\ncoffee        1        0        0\nred_bull      0        1        0\nmint_tea      0        0        1\n\n\n\n\n\n\n\nQuestion 3\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook. The statistical models flashcards, especially the numeric outcomes & categorical predictors flashcards may also be useful to refer to. For a more in-depth overview and example, see the numeric outcomes & categorical predictors &gt; example flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nThe caffeine dataset contained information on 40 hypothetical participants who took part in an experiment examining whether the number of words typed per minute (WPM) differed among caffeine treatment conditions. Using a between-subjects design, the researchers collected information on participants’ WPM (average number of words typed per minute), and which one of four treatment conditions they were randomly assigned to (Control (Water), Coffee, Mint Tea, or Red Bull).\nBoxplots will be used to visualise the associations among WPM and caffeine treatment conditions. To address the research question of whether WPM differs by caffeine treatment condition, we first need to define the dummy variables for Treatment:\n\\[\n\\text{Treatment}_\\text{Coffee} = \\begin{cases}  \n1 & \\text{if Treatment is Coffee} \\\\  \n0 & \\text{otherwise}  \n\\end{cases}  \n\\quad    \n\\]\n\\[\n\\text{Treatment}_\\text{Red Bull} = \\begin{cases}  \n1 & \\text{if Treatment is Red Bull} \\\\  \n0 & \\text{otherwise}  \n\\\\  \n\\end{cases}  \n\\quad  \n\\]\n\\[\n\\text{Treatment}_\\text{Mint Tea} = \\begin{cases}  \n1 & \\text{if Treatment is Mint Tea} \\\\  \n0 & \\text{otherwise}  \n\\end{cases}  \n\\quad  \n\\]\n\\[\n(\\text{Control (Water) is base level})  \n\\]\nBased on the above dummy coding, we are going to fit the following regression model:\n\\[\n\\begin{align}\n\\text{WPM} = \\beta_0 + \\beta_1 \\cdot \\text{Treatment}_\\text{Coffee} \\\\    \n+ \\beta_2 \\cdot \\text{Treatment}_\\text{Red Bull} + \\beta_3 \\cdot \\text{Treatment}_\\text{Mint Tea} + \\epsilon\n\\end{align}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2, 3\\))\nThere are no differences in WPM based on caffeine treatment condition.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2, 3\\))\nThere are differences in WPM based on caffeine treatment condition."
  },
  {
    "objectID": "1_06_dummy_beech.html#descriptive-statistics-visualisations",
    "href": "1_06_dummy_beech.html#descriptive-statistics-visualisations",
    "title": "Dummy Coding",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 4\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study (i.e., comment on any observed differences among treatment groups).\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables and data visualisation &gt; bivariate associations - examples flashcard, paying particular attention to the type of data that you’re working with.\nMake sure to comment on any observed differences among the sample means of the four treatment conditions.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table, grouped by treatment condition:\n\ncaffeine |&gt;\n  group_by(treatment) |&gt;\n  summarise(n = n(), \n            Mean = mean(wpm), \n            SD = sd(wpm),\n            Minimum = min(wpm),\n            Maximum = max(wpm)) |&gt;\n    kable(caption = \"Descriptive Statistics\", digits = 2) |&gt;\n    kable_styling()\n\n\n\nTable 1: Descriptive Statistics\n\ntreatment\nn\nMean\nSD\nMinimum\nMaximum\n\n\n\ncontrol\n10\n112.15\n1.98\n109.43\n116.23\n\n\ncoffee\n10\n114.48\n1.82\n112.07\n117.16\n\n\nred_bull\n10\n116.65\n2.15\n113.00\n120.24\n\n\nmint_tea\n10\n111.09\n2.13\n107.94\n115.82\n\n\n\n\n\n\n\n\n\n\nSince we have a continuous outcome and a categorical predictor - either a boxplot or violin plot would be most appropriate for visualisations:\n\nggplot(data = caffeine, aes(x = treatment, y = wpm, fill = treatment)) +\n  geom_boxplot() +\n  labs(x = 'Treatment Condition', y = 'WPM')\n\n\n\nFigure 1: Association between Treatment Conditions and WPM\n\n\n\n\nggplot(data = caffeine, aes(x = treatment, y = wpm, fill = treatment, colour = treatment)) +\n  geom_violin(alpha = 0.5) +\n  geom_jitter(alpha = 0.5) +\n  theme(legend.position = 'none') +\n  labs(x = 'Treatment Condition', y = 'WPM')\n\n\n\nFigure 2: Association between Treatment Conditions and WPM\n\n\n\n\n\n\n\n\n\n\n\n\nInitial observations:\n\nThose in the Red Bull condition, on average, typed the most WPM, whilst those in the Mint Tea condition the fewest\n\nThe average WPM appears to be lower for those in the non-caffeine conditions (i.e., control - water / mint tea) in comparison to those in the caffeine drinks condition (red bull / coffee)\n\nThe range of WPM appears to be slightly higher in the cold drink conditions (i.e., control - water / mint tea) in comparison to those in the hot drink conditions (red bull / coffee)"
  },
  {
    "objectID": "1_06_dummy_beech.html#model-fitting-interpretation",
    "href": "1_06_dummy_beech.html#model-fitting-interpretation",
    "title": "Dummy Coding",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nFit the specified model, and assign it the name “caf_mdl1”.\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can fit multiple regression models with categorical predictors using the lm() function. For a recap, see the description & model specification flashcards.\nRecall that R computes the dummy variables for us. Thus, each row in the summary() output of the model will correspond to one of the estimated \\(\\beta\\)’s in the equation above. For a more in-depth overview and example, see the numeric outcomes & categorical predictors &gt; example flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit model\ncaf_mdl1 &lt;- lm(wpm ~ treatment, data=caffeine)\n\n\n#check model output\nsummary(caf_mdl1)\n\n\nCall:\nlm(formula = wpm ~ treatment, data = caffeine)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.652 -1.362 -0.151  1.125  4.729 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       112.1460     0.6402 175.179  &lt; 2e-16 ***\ntreatmentcoffee     2.3350     0.9053   2.579   0.0141 *  \ntreatmentred_bull   4.5060     0.9053   4.977 1.61e-05 ***\ntreatmentmint_tea  -1.0550     0.9053  -1.165   0.2516    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.024 on 36 degrees of freedom\nMultiple R-squared:  0.5563,    Adjusted R-squared:  0.5194 \nF-statistic: 15.05 on 3 and 36 DF,  p-value: 1.651e-06\n\n\nLet’s first map our coefficients and estimates:\n\n\n\n\n\n\n\nCoefficient\nEstimate\nRelation between \\(\\beta\\) and \\(\\mu\\)\n\n\n\n\n(Intercept)\n112.1460\n\\(\\beta_0 = \\hat \\mu_1\\)\n\n\ntreatmentcoffee\n2.3350\n\\(\\beta_0 + \\beta_1 = \\hat \\mu_2\\)\n\n\ntreatmentred_bull\n4.5060\n\\(\\beta_0 + \\beta_2 = \\hat \\mu_3\\)\n\n\ntreatmentmint_tea\n-1.0550\n\\(\\beta_0 + \\beta_3 = \\hat \\mu_4\\)\n\n\n\n\n\n\n\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\hat \\beta_0 = \\hat \\mu_1 = 112.15\\). The estimated average WPM for those in the control condition (water) was approximately 112.15.\nThe next estimate corresponds to treatmentcoffee and was \\(\\hat \\beta_1 = 2.34\\). The difference in mean WPM between Control and Coffee was estimated to be \\(2.34\\). Thus, \\(\\hat \\mu_2 = 112.15 + 2.34 = 114.49\\). In other words, people who have had coffee typed approximately 114.49 words, which was 2.34 words per minute more than those who have had water. This difference was statistically significant \\((p = .014)\\).\nThe estimate corresponding to treatmentred_bull was \\(\\hat \\beta_2 = 4.51\\). This was the estimated difference in mean WPM between Control and Red Bull, estimated to be \\(4.51\\). Thus, \\(\\hat \\mu_3 = 112.15 + 4.51 = 116.66\\). In other words, people who had red bull typed approximately 116.66 words, 4.51 words per minute more than those who had water. This difference was statistically significant \\((p &lt; .001)\\).\nThe estimate corresponding to treatmentmint_tea was \\(\\hat \\beta_3 = -1.06\\). This was the estimated difference in mean WPM between Control and Mint Tea, estimated to be \\(-1.06\\). Thus, \\(\\hat \\mu_4 = 112.15 + (-1.06) = 111.09\\). In other words, people who had mint tea typed approximately 111.09 words, 1.06 words per minute less than those who had water. This difference was not statistically significant \\((p = .252)\\)."
  },
  {
    "objectID": "1_06_dummy_beech.html#planned-comparisons-contrasts",
    "href": "1_06_dummy_beech.html#planned-comparisons-contrasts",
    "title": "Dummy Coding",
    "section": "Planned Comparisons / Contrasts",
    "text": "Planned Comparisons / Contrasts\n\nQuestion 6\n\n\nFormally state the two planned comparisons that the researchers were interested in as testable hypotheses.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nRecall that the researchers were also interested in addressing these two questions:\n\nWhether having some kind of caffeine (i.e., red bull or coffee), rather than no caffeine (i.e., control - water or mint tea), resulted in a difference in average WPM\nWhether there was a difference in average WPM between those with hot drinks (i.e., mint tea / coffee) in comparison to those with cold drinks (control - water / red bull)\n\nWe can specify the two hypotheses as follows:\n\n\nCaffeine vs No Caffeine\nHot vs Cold\n\n\n\n\\[\n\\begin{aligned}\n1. \\quad \\text{H}_0 &: \\mu_\\text{No Caffeine} = \\mu_\\text{Caffeine} \\\\\n\\\\\n    \\quad \\text{H}_0 &: \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Mint Tea}) = \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Red Bull}) \\\\  \n\\\\  \n\\\\\n    \\quad \\text{H}_1 &: \\mu_\\text{No Caffeine} \\neq \\mu_\\text{Caffeine} \\\\\n    \\\\\n    \\quad \\text{H}_1 &: \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Mint Tea}) \\neq \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Red Bull}) \\\\\n\\\\\n\\end{aligned}\n\\]\n\n\n\\[\n\\begin{aligned}\n2. \\quad H_0 &: \\mu_\\text{Hot Drink} = \\mu_\\text{Cold Drink} \\\\\n\\\\\n    \\quad H_0 &: \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Mint Tea}) = \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Red Bull}) \\\\  \n\\\\  \n\\\\  \n    \\quad H_1 &: \\mu_\\text{Hot Drink} \\neq \\mu_\\text{Cold Drink} \\\\  \n    \\\\  \n    \\quad H_1 &: \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Mint Tea}) \\neq \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Red Bull})  \\\\   \n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nAfter checking the levels of the factor treatment, use emmeans() to obtain the estimated treatment means and uncertainties for your factor.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nlevels(caffeine$treatment)\n\n[1] \"control\"  \"coffee\"   \"red_bull\" \"mint_tea\"\n\n\nUse the emmeans() to get the estimated means of our groups:\n\ntreatment_mean &lt;- emmeans(caf_mdl1, ~ treatment)\ntreatment_mean\n\n treatment emmean   SE df lower.CL upper.CL\n control      112 0.64 36      111      113\n coffee       114 0.64 36      113      116\n red_bull     117 0.64 36      115      118\n mint_tea     111 0.64 36      110      112\n\nConfidence level used: 0.95 \n\nplot(treatment_mean)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nSpecify the coefficients of the comparisons and run the contrast analysis, obtaining 95% confidence intervals.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\nRemember that ordering matters here - look again at the output of levels(caffeine$treatment) as this will help you when assigning your weights.\n\n\n\n\n\n\n\n Solution \n\n\nAs shown above via levels(), the ordering of the treatment factor is:\n\nControl (no caffeine / cold drink)\nCoffee (caffeine / hot drink)\nRed Bull (caffeine / cold drink)\nMint Tea (no caffeine / hot drink)\n\nFrom this ordering, we can specify our weights - based on the hypothesis, lets assign positive values to the no caffeine and hot drink conditions:\n\ntreatment_comp &lt;- list(\"No Caffeine - Caffeine\" = c(1/2, -1/2, -1/2, 1/2),\n             \"Hot Drink - Cold Drink\" = c(-1/2, 1/2, -1/2, 1/2)\n             )\n\nNow lets run our contrast analysis and get confidence intervals - to do so we use the contrast() function from emmeans():\n\n#run contrast analysis\ntreatment_comp_test &lt;- contrast(treatment_mean, method = treatment_comp)\n\n#examine output\ntreatment_comp_test\n\n contrast               estimate   SE df t.ratio p.value\n No Caffeine - Caffeine    -3.95 0.64 36  -6.167  &lt;.0001\n Hot Drink - Cold Drink    -1.61 0.64 36  -2.520  0.0163\n\n#obtain confidence intervals\nconfint(treatment_comp_test)\n\n contrast               estimate   SE df lower.CL upper.CL\n No Caffeine - Caffeine    -3.95 0.64 36    -5.25   -2.650\n Hot Drink - Cold Drink    -1.61 0.64 36    -2.91   -0.315\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\nQuestion 9\n\n\nInterpret the results of the contrast analysis in the context of the researchers hypotheses.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nHypothesis 1: Caffeine vs No Caffeine\nHypothesis 2: Hot vs Cold\n\n\n\nWe performed a test against \\(H_0: \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Mint Tea}) - \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Red Bull}) = 0\\). At the 5% significance level, there was evidence that the mean WPM for those who were in the no caffeine condition (i.e., water and mint tea) was significantly different from those in a caffeine condition (i.e., coffee and red bull) \\((t(36) = -6.17, p &lt; .001, \\text{two-sided})\\), and this difference was estimated to be -3.95. We are 95% confident that those who consumed no caffeine typed, on average, between 2.7 and 5.3 words less per minute than those who consumed some form of caffeine \\(CI_{95}[-5.25, -2.65]\\).\n\n\nWe performed a test against \\(H_0: \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Mint Tea}) - \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Red Bull}) = 0\\). At the 5% significance level, there was evidence that the average WPM for those in the hot drink condition (coffee and mint tea) significantly differed from those in the cold drink condition (water and red bull) \\((t(36) = -2.52, p = .016, \\text{two-sided})\\), and this difference was estimated to be -1.61. We are 95% confident that those who consumed a hot drink typed, on average, between 0.3 and 2.9 words less per minute than those who consumed a cold drink \\(CI_{95}[-2.91, -0.32]\\)."
  },
  {
    "objectID": "1_06_dummy_beech.html#study-design",
    "href": "1_06_dummy_beech.html#study-design",
    "title": "Dummy Coding",
    "section": "Study Design",
    "text": "Study Design\n\nQuestion 10\n\n\nFor each of the below experiment descriptions, note (1) the design, (2) number of variables of interest, (3) levels of categorical variables, (4) what you think the reference group should be and why.\n\n\nExperiment 1\nExperiment 2\nExperiment 3\n\n\n\nA group of researchers were interested in whether sleep deprivation influenced reaction time. They hypothesised that sleep deprived individuals would have slower reaction times than non-sleep deprived individuals.\nTo test this, they recruited 60 participants who were matched on a number of demographic variables including age and sex. One member of each pair (e.g., female, aged 18) was placed into a different sleep condition - ‘Sleep Deprived’ (4 hours per night) or ‘Non-Sleep Deprived’ (8 hours per night).\n\n\nA group of researchers were interested in replicating an experiment testing the Stroop Effect.\nThey recruited 50 participants who took part in Task A (word colour and meaning are congruent) and Task B (word colour and meaning are incongruent) where they were asked to name the color of the ink instead of reading the word. The order of presentation was counterbalanced across participants. The researchers hypothesised that participants would take significantly more time (‘response time’ measured in seconds) to complete Task B than Task A.\nYou can test yourself here for fun: Stroop Task\n\n\nA group of researchers wanted to test a hypothesised theory according to which patients with amnesia will have a deficit in explicit memory but not implicit memory. Huntingtons patients, on the other hand, will display the opposite: they will have no deficit in explicit memory, but will have a deficit in implicit memory.\nTo test this, researchers designed a study that included two variables: ‘Diagnosis’ (Amnesic, Huntingtons, Control) and ‘Task’ (Grammar, Classification, Recognition) where participants were randomly assigned to a Task condition. The first two tasks (Grammar and Classification) are known to reflect implicit memory processes, whereas the Recognition task is known to reflect explicit memory processes.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nExperiment 1\nExperiment 2\nExperiment 3\n\n\n\n\nDesign = Between-person: Matched pairs\nNumber of variables of interest = 2 - Sleep Condition and Reaction Time\nLevels of variables = Sleep Condition has 2 levels - Sleep Deprived and Non-Sleep Deprived; Reaction Time is a continuous measure, so has no associated levels\nReference Group = Sleep Condition - Non-Sleep Deprived. The non-sleep deprived individuals represent the normal level of functioning, which is the standard state without any experimental manipulation. This makes it a natural reference group to compare against the experimental group (sleep deprived). The hypothesis stated an interest in assessing whether sleep deprived individuals had slower reaction times in comparison to non-sleep deprived. The coefficient associated with the sleep deprived group in the linear model will represent the difference in reaction time due to sleep deprivation. A positive coefficient would indicate slower reaction times for the sleep deprived compared to the non-sleep deprived.\n\n\n\n\nDesign = Within-person: Repeated measures (this is a study design that you will learn more about in DAPR3!)\nNumber of variables of interest = 2 - Task and Response Time\nLevels of variables = Task has 2 levels - A and B; Response Time is a continuous measure, so has no associated levels\nReference Group = Task - A. Task A represents the baseline condition where processing is generally considered more straightforward due to the congruency between word meaning and color. This provides a natural baseline for comparison because there are fewer cognitive conflicts or processing challenges in Task A compared to Task B. The hypothesis specifically predicted that participants will take more time to complete Task B. The coefficient for Task B in the linear model will represent the difference in time it takes to complete Task B relative to Task A. A positive coefficient for Task B would support the hypothesis that Task B requires more time and highlight the cognitive interference noted in the Stroop Effect.\n\n\n\n\nDesign = Between-person: 3×3 factorial design\nNumber of variables of interest = 2 - Diagnosis and Task\nLevels of variables = Diagnosis has 3 levels - Amnesic, Huntingtons, and Control; Task has 3 levels - Grammar, Classification, and Recognition\nReference Groups = Diagnosis - Control; Task - Recognition. Selecting the Control group as the reference for Diagnosis allows for the assessment of memory deficits in both patient groups against the typical functioning of participants without cognitive impairments (i.e., individuals in this group provide a baseline of normal memory function related to both explicit and implicit memory tasks). By using Recognition as the reference for Task, the model can assess how performance on the Grammar and Classification tasks (representing implicit memory) differs from performance in explicit tasks across different groups."
  },
  {
    "objectID": "1_07_effects.html",
    "href": "1_07_effects.html",
    "title": "Effects Coding",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to specify sum-to-zero coding\nInterpret the output from a model using sum-to-zero coding\nUnderstand how to specify contrasts to test specific effects\n\n\nBe up to date with lectures\nHave completed Week 7 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nemmeans\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/RestaurantSpending.csv"
  },
  {
    "objectID": "1_07_effects.html#study-analysis-plan-overview",
    "href": "1_07_effects.html#study-analysis-plan-overview",
    "title": "Effects Coding",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\nSince there is repetition in the names of the levels of type (i.e., ‘No Music’, ‘Pop Music’, and ‘Classical Music’), it might be sensible to rename the variable to music with levels labelled as ‘None’, ‘Pop’, and ‘Classical’.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe str() function will return the overall structure of the dataset, this can be quite handy to look at\n\nConvert categorical variables to factors, and if needed, provide better variable names as indicated in the question\nLabel factors appropriately to aid with your model interpretations if required as indicated in the question\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\nAre scores within possible ranges (e.g., if we recorded people’s age, it would be impossible to have someone aged -31!)\n\nReview the numeric outcomes & categorical predictors flashcards, specifically ‘coding variables as factors’.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(rest_spend)\n\nspc_tbl_ [360 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id    : num [1:360] 1 2 3 4 5 6 7 8 9 10 ...\n $ type  : chr [1:360] \"No Music\" \"Pop Music\" \"Pop Music\" \"Pop Music\" ...\n $ amount: num [1:360] 23.1 20.6 19.2 16.7 25.9 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   type = col_character(),\n  ..   amount = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(rest_spend)\n\n# A tibble: 6 × 3\n     id type            amount\n  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1     1 No Music          23.1\n2     2 Pop Music         20.6\n3     3 Pop Music         19.2\n4     4 Pop Music         16.7\n5     5 Classical Music   25.9\n6     6 Pop Music         19.3\n\n#check for NAs - there are none - all FALSE\ntable(is.na(rest_spend))\n\n\nFALSE \n 1080 \n\n\nLet’s start with the music ‘type’ variable. This should be coded as factor (&lt;fctr&gt;), but can see from above it is currently coded as a character (&lt;chr&gt;). Let’s fix this, and rename ‘type’ to ‘music’ and remove the word ‘music’ form the labels of the levels of the factor to avoid repetition whilst we’re at it:\n\nrest_spend &lt;- rest_spend |&gt;\n    mutate(\n        type = factor(type, \n                           levels = c(\"No Music\", \"Pop Music\", \"Classical Music\"),\n                           labels = c(\"None\", \"Pop\", \"Classical\"))) |&gt;\n        rename(music = type)\n\nNext, let’s look at the ‘amount’ variable. Here we want to check for impossible values - i.e., cannot have a negative £ per head.\n\n# all looks ok - min and max both positive values\ndescribe(rest_spend$amount)\n\n   vars   n  mean   sd median trimmed  mad   min   max range  skew kurtosis\nX1    1 360 22.74 3.01  22.88   22.81 3.06 13.71 33.43 19.72 -0.19      0.2\n     se\nX1 0.16\n\n\n\n\n\n\n\n\nAll participant data was complete (no missing values), with restaurant spending per person within possible ranges. Music type was coded as a factor with three levels (none, pop, and classical).\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nSpecify the model to be fitted to address the research question, including the coding scheme applied to categorical predictors (e.g., effects or dummy coding) and a clear indication of the coding values assigned to each level\n\nSpecify the model to be fitted to address the research question\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook. The statistical models flashcards, especially the numeric outcomes & categorical predictors flashcards may also be useful to refer to. For a more in-depth overview and example, see the numeric outcomes & categorical predictors &gt; example flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nThe rest_spend dataset contained information on 360 hypothetical participants who took part in an experiment examining the effect of music on customer spending in a restaurant setting. Using a between-subjects design, the researchers had one of three types of music - classical, pop, or silence - played in a restaurant over 18 successive evenings. As well as recording the type of music played during the meal, the researchers also recorded the average spend per person (in £).\nAll participant data was complete (no missing values), with restaurant spending per person within possible ranges. Music type was coded as a factor with three levels (none, pop, and classical).\nBoxplots will be used to visualise the associations among spend per person and background music conditions. To address the research question of whether spend per person differs by background music condition, we can specify our model and coding scheme as follows:\n\\[\n\\text{Restaurant Spending} = \\beta_0 + \\beta_1 \\cdot \\text{Effect Level 1} + \\beta_2 \\cdot \\text{Effect Level 2} + \\epsilon\n\\]\nwhere:\n\\[\n\\text{Effect Level 1} = \\begin{cases}\n1  & \\text{if observation is from category 1} \\\\\n0  & \\text{if observation is from category 2} \\\\\n-1 & \\text{otherwise}\n\\end{cases}\n\\]\n\\[\n\\text{Effect Level 2} = \\begin{cases}\n0  & \\text{if observation is from category 1} \\\\\n1  & \\text{if observation is from category 2} \\\\\n-1 & \\text{otherwise}\n\\end{cases}\n\\]\nSchematically:\n\\[\n\\begin{matrix}\n\\textbf{Level}           & \\textbf{Effect Level 1} & \\textbf{Effect Level 2} \\\\\n\\hline\n\\text{None}              & 1   & 0    \\\\\n\\text{Pop}               & 0   & 1    \\\\\n\\text{Classical}         & -1  & -1\n\\end{matrix}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere are no differences in average spend per person based on background music conditions.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere are differences in average spend per person based on background music conditions."
  },
  {
    "objectID": "1_07_effects.html#descriptive-statistics-visualisations",
    "href": "1_07_effects.html#descriptive-statistics-visualisations",
    "title": "Effects Coding",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study (i.e., comment on any observed differences among treatment groups).\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables and data visualisation &gt; bivariate associations - examples flashcard, paying particular attention to the type of data that you’re working with.\nA nice additional step you could take with your data visialisation would be to add a line representing the grand mean (the mean of all the observations). You can do this by specifying geom_hline(). Within this argument, you will need to specify where the horizontal line should cut the y-axis via yintercept =. You might want to specify line: type (via lty =), width (via lwd =), and colour (via colour =). Make sure to comment on any observed differences among the conditions in comparison to the grand mean.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table, grouped by music condition:\n\nrest_spend |&gt; \n            group_by(music) |&gt;\n            summarise(n = n(),\n                      Mean = mean(amount),\n                      SD = sd(amount),\n                      Min = min(amount),\n                      Max = max(amount)) |&gt; \n            kable(caption = \"Restaurant Spending & Music Type Descriptive Statistics\", digits = 2) |&gt;\n            kable_styling()\n\n\n\nTable 1: Restaurant Spending & Music Type Descriptive Statistics\n\nmusic\nn\nMean\nSD\nMin\nMax\n\n\n\nNone\n120\n22.14\n3.44\n13.71\n33.43\n\n\nPop\n120\n21.90\n2.97\n15.60\n28.94\n\n\nClassical\n120\n24.17\n1.89\n19.05\n28.02\n\n\n\n\n\n\n\n\n\n\nSince we have a continuous outcome and a categorical predictor - either a boxplot or violin plot would be most appropriate for visualisations:\n\nggplot(data = rest_spend, aes(x = music, y = amount, fill = music)) +\n  geom_boxplot() +\n    geom_hline(yintercept = mean(rest_spend$amount), lty = 2, lwd = 1, colour = \"lightgrey\") +\n  labs(x = 'Background Music Type', y = 'Restaurant Spending (in GBP)')\n\n\n\nFigure 1: Associations between Restaurant Spending and Music Type\n\n\n\n\nggplot(data = rest_spend, aes(x = music, y = amount, fill = music, colour = music)) +\n  geom_violin(alpha = 0.5) +\n  geom_jitter(alpha = 0.5) +\n  geom_hline(yintercept = mean(rest_spend$amount), lty = 2, lwd = 1, colour = \"black\") +\n  theme(legend.position = 'none') +\n  labs(x = 'Background Music Type', y = 'Restaurant Spending (in GBP)')\n\n\n\nFigure 2: Associations between Restaurant Spending and Music Type\n\n\n\n\n\n\n\n\n\n\n\n\nInitial observations:\n\nThere are three types of music groups (\\(g = 3\\)), where there is one group for each music type: “Classical,” “None,” “Pop”. Each group has 120 observations\n\nIt seems that customers in the None and Pop music conditions had a similar average restaurant spending\n\nThe average restaurant spending seems to be higher for those who had in the Classical music condition in comparison to customers in both the None and Pop music type conditions"
  },
  {
    "objectID": "1_07_effects.html#model-fitting-interpretation",
    "href": "1_07_effects.html#model-fitting-interpretation",
    "title": "Effects Coding",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nApply effects coding to the factor of background music.\nFit the specified model, and assign it the name “mdl_ec”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can switch between coding schemes using the following code:\n\n#use dummy coding\ncontrasts(rest_spend$music) &lt;- \"contr.treatment\"\n\n#use effects (sum-to-zero) coding\ncontrasts(rest_spend$music) &lt;- \"contr.sum\"\n\nFor more information, see the numeric outcomes & categorical predictors &gt; dummy vs effects coding flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nApply Effects Coding\nFit Model\n\n\n\n\ncontrasts(rest_spend$music) &lt;- \"contr.sum\"\n\n#check coding matches our table above:\ncontrasts(rest_spend$music)\n\n          [,1] [,2]\nNone         1    0\nPop          0    1\nClassical   -1   -1\n\n\n\n\n\nmdl_ec &lt;- lm(amount ~ music, data = rest_spend)\n\n#check summary\nsummary(mdl_ec)\n\n\nCall:\nlm(formula = amount ~ music, data = rest_spend)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.433 -1.886  0.127  1.755 11.285 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  22.7382     0.1497 151.856  &lt; 2e-16 ***\nmusic1       -0.5968     0.2118  -2.818   0.0051 ** \nmusic2       -0.8392     0.2118  -3.963 8.94e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.841 on 357 degrees of freedom\nMultiple R-squared:  0.1151,    Adjusted R-squared:  0.1101 \nF-statistic: 23.21 on 2 and 357 DF,  p-value: 3.335e-10\n\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that under this constraint the interpretation of the coefficients becomes:\n\n\n\\(\\beta_0\\) represents the grand mean\n\n\\(\\beta_i\\) the effect due to group \\(i\\) — that is, the mean response in group \\(i\\) minus the grand mean\n\nFor more information, see the numeric outcomes & categorical predictors &gt; dummy vs effects coding flashcard.\nFor a more in-depth overview and example, see the numeric outcomes & categorical predictors &gt; example flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s first map our coefficients and estimates:\n\n\n\n\n\n\n\nCoefficient\nEstimate\nRelation between \\(\\beta\\) and \\(\\mu\\)\n\n\n\n\n(Intercept)\n22.7382\n\\(\\beta_0 = \\frac{\\mu_1 + \\mu_2 + \\mu_3}{3} = \\mu\\)\n\n\nmusic1\n-0.5968\n\\(\\beta_1 = \\mu_1 - \\mu\\)\n\n\nmusic2\n-0.8392\n\\(\\beta_2 = \\mu_2 - \\mu\\)\n\n\n\n\n\n\n\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\beta_0 = \\mu = 22.7382\\). This value represents the grand mean of the data. The estimated average spending for customers across background music conditions is approximately £22.74.\nThe next estimate corresponds to music1 and is \\(\\hat \\beta_1 = -0.5968\\). The difference in mean spending between None \\((\\hat \\mu_1)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(-0.5968\\). In other words, people with no music playing in the background seem to spend approximately £0.60 less than average, and spent \\(22.7382 + (-0.5968) = £22.14\\) in total. This difference in spending was statistically significant \\((p = .005)\\).\nThe estimate corresponding to music2 is \\(\\hat \\beta_2 = -0.8392\\). The difference in mean spending between Pop \\((\\hat \\mu_2)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(-0.8392\\). In other words, customers with Pop music playing in the background seem to spend approximately £0.84 less than average, and spent \\(22.7382 + (-0.8392) = £21.90\\) in total. This difference in spending was statistically significant \\((p &lt; .001)\\).\nThe estimate for music3, representing the difference of “Classical” to the grand mean is not shown by summary(). Because of the side-constraint, we know that \\(\\mu_3 = \\beta_0 - (\\beta_1 + \\beta_2)\\). The difference in mean spending between Classical and the grand mean was estimated to be \\(-(-0.5968 + -0.8392) = 1.436\\). In other words, customers with Classical music playing in the background seem to spend approximately £1.44 more than average, and spent \\(22.7382 - (-0.5968 + -0.8392) = £24.17\\) in total.\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nObtain the estimated (or predicted) group means for the “None,” “Pop,” and “Classical” background music conditions by using the predict() function.\n\n\n\n\n\n\nHint\n\n\n\n\n\nStep 1: Define a data frame via tibble() with a column having the same name as the factor in the fitted model (i.e., music). Then, specify all the groups (i.e., levels) for which you would like the predicted mean.\nStep 2: Pass the data frame to the predict function using the newdata = argument. The predict() function will match the column named music with the predictor called music in the fitted model ‘mdl_ec’.\nIf you’re still not sure, it might be helpful to review the model predicted values & residuals flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nStep 1:\n\nquery_groups &lt;- tibble(music = c(\"None\", \"Pop\", \"Classical\"))\nquery_groups\n\n# A tibble: 3 × 1\n  music    \n  &lt;chr&gt;    \n1 None     \n2 Pop      \n3 Classical\n\n\nStep 2:\n\npredict(mdl_ec, newdata = query_groups)\n\n       1        2        3 \n22.14139 21.89894 24.17414 \n\n\n\nPredicted mean of “None” = \\(\\hat \\mu_\\text{None}\\) = 22.14\nPredicted mean of “Pop” = \\(\\hat \\mu_\\text{Pop}\\) = 21.90\nPredicted mean of “Classical” = \\(\\hat \\mu_\\text{Classical}\\) = 24.17\n\nWe can see that these predicted means match our model estimates in Q5."
  },
  {
    "objectID": "1_07_effects.html#planned-comparisons-contrasts",
    "href": "1_07_effects.html#planned-comparisons-contrasts",
    "title": "Effects Coding",
    "section": "Planned Comparisons / Contrasts",
    "text": "Planned Comparisons / Contrasts\n\nQuestion 7\n\n\nFormally state the planned comparison that the researchers were interested in as a testable hypothesis.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nRecall that the researchers were also interested in addressing the following question:\n\nWhether having some kind of music playing (i.e., pop or classical), rather than no music (i.e., none), resulted in a difference in spending\n\nWe can specify the hypothesis as follows:\n\\[\n\\begin{aligned}\n    \\quad H_0 &: \\mu_\\text{No Music} = \\mu_\\text{Music} \\\\\n    \\quad H_0 &: \\mu_\\text{None} = \\frac{1}{2} (\\mu_\\text{Pop} + \\mu_\\text{Classical}) \\\\\n\\\\\n    \\quad H_1 &: \\mu_\\text{No Music} \\neq \\mu_\\text{Music} \\\\\n    \\quad H_1 &: \\mu_\\text{No Music} \\neq \\frac{1}{2} (\\mu_\\text{Pop} + \\mu_\\text{Classical}) \\\\\n\\\\\n\\end{aligned}\n\\]\n\n\n\n\n\nQuestion 8\n\n\nAfter checking the levels of the factor music, use emmeans() to obtain the estimated treatment means and uncertainties for your factor.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nlevels(rest_spend$music)\n\n[1] \"None\"      \"Pop\"       \"Classical\"\n\n\nUse the emmeans() to get the estimated means of our groups:\n\nmusic_mean &lt;- emmeans(mdl_ec, ~ music)\nmusic_mean\n\n music     emmean    SE  df lower.CL upper.CL\n None        22.1 0.259 357     21.6     22.7\n Pop         21.9 0.259 357     21.4     22.4\n Classical   24.2 0.259 357     23.7     24.7\n\nConfidence level used: 0.95 \n\nplot(music_mean)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nSpecify the coefficients of the comparisons and run the contrast analysis, obtaining 95% confidence intervals.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\nRemember that ordering matters here - look again at the output of levels(rest_spend$music) as this will help you when assigning your weights.\n\n\n\n\n\n\n\n Solution \n\n\nAs shown above via levels(), the ordering of the treatment factor is:\n\nNone (no music)\nPop (music)\nClassical (music)\n\nFrom this ordering, we can specify our weights - based on the hypothesis, lets assign positive values to the music conditions:\n\nmusic_comp &lt;- list(\"No Music - Music\" = c(-1, 1/2, 1/2))\n\nNow lets run our contrast analysis and get confidence intervals:\n\n#run contrast analysis\nmusic_comp_test &lt;- contrast(music_mean, method = music_comp)\n\n#examine output\nmusic_comp_test\n\n contrast         estimate    SE  df t.ratio p.value\n No Music - Music    0.895 0.318 357   2.818  0.0051\n\n#obtain confidence intervals\nconfint(music_comp_test)\n\n contrast         estimate    SE  df lower.CL upper.CL\n No Music - Music    0.895 0.318 357     0.27     1.52\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret the results of the contrast analysis in the context of the researchers hypotheses.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nWe performed a test against \\(H_0: \\mu_\\text{None} - \\frac{1}{2} (\\mu_\\text{Pop} + \\mu_\\text{Classical}) = 0\\). At the 5% significance level, there was evidence that restaurant spending per person for those who were in the no music condition (i.e., none) was significantly different from those in a music condition (i.e., pop and classical) \\(t(357) = 2.82, p = .005, \\text{two-sided})\\), and this difference was estimated to be \\(£~0.90\\). We are 95% confident that those who heard some form of background music spent on average, between \\(£~0.27\\) and \\(£~1.52\\) more per person on their meal than those who heard no background music \\((CI_{95}[0.27, 1.52])\\)."
  },
  {
    "objectID": "1_07_effects_cedar.html",
    "href": "1_07_effects_cedar.html",
    "title": "Effects Coding",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to specify sum-to-zero coding\nInterpret the output from a model using sum-to-zero coding\nUnderstand how to specify contrasts to test specific effects\n\n\nBe up to date with lectures\nHave completed Week 7 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nemmeans\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/RestaurantSpending.csv"
  },
  {
    "objectID": "1_07_effects_cedar.html#study-analysis-plan-overview",
    "href": "1_07_effects_cedar.html#study-analysis-plan-overview",
    "title": "Effects Coding",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\nSince there is repetition in the names of the levels of type (i.e., ‘No Music’, ‘Pop Music’, and ‘Classical Music’), it might be sensible to rename the variable to music with levels labelled as ‘None’, ‘Pop’, and ‘Classical’.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe str() function will return the overall structure of the dataset, this can be quite handy to look at\n\nConvert categorical variables to factors, and if needed, provide better variable names as indicated in the question\nLabel factors appropriately to aid with your model interpretations if required as indicated in the question\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\nAre scores within possible ranges (e.g., if we recorded people’s age, it would be impossible to have someone aged -31!)\n\nReview the numeric outcomes & categorical predictors flashcards, specifically ‘coding variables as factors’.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(rest_spend)\n\nspc_tbl_ [360 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id    : num [1:360] 1 2 3 4 5 6 7 8 9 10 ...\n $ type  : chr [1:360] \"No Music\" \"Pop Music\" \"Pop Music\" \"Pop Music\" ...\n $ amount: num [1:360] 23.1 20.6 19.2 16.7 25.9 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   type = col_character(),\n  ..   amount = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(rest_spend)\n\n# A tibble: 6 × 3\n     id type            amount\n  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1     1 No Music          23.1\n2     2 Pop Music         20.6\n3     3 Pop Music         19.2\n4     4 Pop Music         16.7\n5     5 Classical Music   25.9\n6     6 Pop Music         19.3\n\n#check for NAs - there are none - all FALSE\ntable(is.na(rest_spend))\n\n\nFALSE \n 1080 \n\n\nLet’s start with the music ‘type’ variable. This should be coded as factor (&lt;fctr&gt;), but can see from above it is currently coded as a character (&lt;chr&gt;). Let’s fix this, and rename ‘type’ to ‘music’ and remove the word ‘music’ form the labels of the levels of the factor to avoid repetition whilst we’re at it:\n\nrest_spend &lt;- rest_spend |&gt;\n    mutate(\n        type = factor(type, \n                           levels = c(\"No Music\", \"Pop Music\", \"Classical Music\"),\n                           labels = c(\"None\", \"Pop\", \"Classical\"))) |&gt;\n        rename(music = type)\n\nNext, let’s look at the ‘amount’ variable. Here we want to check for impossible values - i.e., cannot have a negative £ per head.\n\n# all looks ok - min and max both positive values\ndescribe(rest_spend$amount)\n\n   vars   n  mean   sd median trimmed  mad   min   max range  skew kurtosis\nX1    1 360 22.74 3.01  22.88   22.81 3.06 13.71 33.43 19.72 -0.19      0.2\n     se\nX1 0.16\n\n\n\n\n\n\n\n\nAll participant data was complete (no missing values), with restaurant spending per person within possible ranges. Music type was coded as a factor with three levels (none, pop, and classical).\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nSpecify the model to be fitted to address the research question, including the coding scheme applied to categorical predictors (e.g., effects or dummy coding) and a clear indication of the coding values assigned to each level\n\nSpecify the model to be fitted to address the research question\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook. The statistical models flashcards, especially the numeric outcomes & categorical predictors flashcards may also be useful to refer to. For a more in-depth overview and example, see the numeric outcomes & categorical predictors &gt; example flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nThe rest_spend dataset contained information on 360 hypothetical participants who took part in an experiment examining the effect of music on customer spending in a restaurant setting. Using a between-subjects design, the researchers had one of three types of music - classical, pop, or silence - played in a restaurant over 18 successive evenings. As well as recording the type of music played during the meal, the researchers also recorded the average spend per person (in £).\nAll participant data was complete (no missing values), with restaurant spending per person within possible ranges. Music type was coded as a factor with three levels (none, pop, and classical).\nBoxplots will be used to visualise the associations among spend per person and background music conditions. To address the research question of whether spend per person differs by background music condition, we can specify our model and coding scheme as follows:\n\\[\n\\text{Restaurant Spending} = \\beta_0 + \\beta_1 \\cdot \\text{Effect Level 1} + \\beta_2 \\cdot \\text{Effect Level 2} + \\epsilon\n\\]\nwhere:\n\\[\n\\text{Effect Level 1} = \\begin{cases}\n1  & \\text{if observation is from category 1} \\\\\n0  & \\text{if observation is from category 2} \\\\\n-1 & \\text{otherwise}\n\\end{cases}\n\\]\n\\[\n\\text{Effect Level 2} = \\begin{cases}\n0  & \\text{if observation is from category 1} \\\\\n1  & \\text{if observation is from category 2} \\\\\n-1 & \\text{otherwise}\n\\end{cases}\n\\]\nSchematically:\n\\[\n\\begin{matrix}\n\\textbf{Level}           & \\textbf{Effect Level 1} & \\textbf{Effect Level 2} \\\\\n\\hline\n\\text{None}              & 1   & 0    \\\\\n\\text{Pop}               & 0   & 1    \\\\\n\\text{Classical}         & -1  & -1\n\\end{matrix}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere are no differences in average spend per person based on background music conditions.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere are differences in average spend per person based on background music conditions."
  },
  {
    "objectID": "1_07_effects_cedar.html#descriptive-statistics-visualisations",
    "href": "1_07_effects_cedar.html#descriptive-statistics-visualisations",
    "title": "Effects Coding",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study (i.e., comment on any observed differences among treatment groups).\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables and data visualisation &gt; bivariate associations - examples flashcard, paying particular attention to the type of data that you’re working with.\nA nice additional step you could take with your data visialisation would be to add a line representing the grand mean (the mean of all the observations). You can do this by specifying geom_hline(). Within this argument, you will need to specify where the horizontal line should cut the y-axis via yintercept =. You might want to specify line: type (via lty =), width (via lwd =), and colour (via colour =). Make sure to comment on any observed differences among the conditions in comparison to the grand mean.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table, grouped by music condition:\n\nrest_spend |&gt; \n            group_by(music) |&gt;\n            summarise(n = n(),\n                      Mean = mean(amount),\n                      SD = sd(amount),\n                      Min = min(amount),\n                      Max = max(amount)) |&gt; \n            kable(caption = \"Restaurant Spending & Music Type Descriptive Statistics\", digits = 2) |&gt;\n            kable_styling()\n\n\n\nTable 1: Restaurant Spending & Music Type Descriptive Statistics\n\nmusic\nn\nMean\nSD\nMin\nMax\n\n\n\nNone\n120\n22.14\n3.44\n13.71\n33.43\n\n\nPop\n120\n21.90\n2.97\n15.60\n28.94\n\n\nClassical\n120\n24.17\n1.89\n19.05\n28.02\n\n\n\n\n\n\n\n\n\n\nSince we have a continuous outcome and a categorical predictor - either a boxplot or violin plot would be most appropriate for visualisations:\n\nggplot(data = rest_spend, aes(x = music, y = amount, fill = music)) +\n  geom_boxplot() +\n    geom_hline(yintercept = mean(rest_spend$amount), lty = 2, lwd = 1, colour = \"lightgrey\") +\n  labs(x = 'Background Music Type', y = 'Restaurant Spending (in GBP)')\n\n\n\nFigure 1: Associations between Restaurant Spending and Music Type\n\n\n\n\nggplot(data = rest_spend, aes(x = music, y = amount, fill = music, colour = music)) +\n  geom_violin(alpha = 0.5) +\n  geom_jitter(alpha = 0.5) +\n  geom_hline(yintercept = mean(rest_spend$amount), lty = 2, lwd = 1, colour = \"black\") +\n  theme(legend.position = 'none') +\n  labs(x = 'Background Music Type', y = 'Restaurant Spending (in GBP)')\n\n\n\nFigure 2: Associations between Restaurant Spending and Music Type\n\n\n\n\n\n\n\n\n\n\n\n\nInitial observations:\n\nThere are three types of music groups (\\(g = 3\\)), where there is one group for each music type: “Classical,” “None,” “Pop”. Each group has 120 observations\n\nIt seems that customers in the None and Pop music conditions had a similar average restaurant spending\n\nThe average restaurant spending seems to be higher for those who had in the Classical music condition in comparison to customers in both the None and Pop music type conditions"
  },
  {
    "objectID": "1_07_effects_cedar.html#model-fitting-interpretation",
    "href": "1_07_effects_cedar.html#model-fitting-interpretation",
    "title": "Effects Coding",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nApply effects coding to the factor of background music.\nFit the specified model, and assign it the name “mdl_ec”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can switch between coding schemes using the following code:\n\n#use dummy coding\ncontrasts(rest_spend$music) &lt;- \"contr.treatment\"\n\n#use effects (sum-to-zero) coding\ncontrasts(rest_spend$music) &lt;- \"contr.sum\"\n\nFor more information, see the numeric outcomes & categorical predictors &gt; dummy vs effects coding flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nApply Effects Coding\nFit Model\n\n\n\n\ncontrasts(rest_spend$music) &lt;- \"contr.sum\"\n\n#check coding matches our table above:\ncontrasts(rest_spend$music)\n\n          [,1] [,2]\nNone         1    0\nPop          0    1\nClassical   -1   -1\n\n\n\n\n\nmdl_ec &lt;- lm(amount ~ music, data = rest_spend)\n\n#check summary\nsummary(mdl_ec)\n\n\nCall:\nlm(formula = amount ~ music, data = rest_spend)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.433 -1.886  0.127  1.755 11.285 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  22.7382     0.1497 151.856  &lt; 2e-16 ***\nmusic1       -0.5968     0.2118  -2.818   0.0051 ** \nmusic2       -0.8392     0.2118  -3.963 8.94e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.841 on 357 degrees of freedom\nMultiple R-squared:  0.1151,    Adjusted R-squared:  0.1101 \nF-statistic: 23.21 on 2 and 357 DF,  p-value: 3.335e-10\n\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that under this constraint the interpretation of the coefficients becomes:\n\n\n\\(\\beta_0\\) represents the grand mean\n\n\\(\\beta_i\\) the effect due to group \\(i\\) — that is, the mean response in group \\(i\\) minus the grand mean\n\nFor more information, see the numeric outcomes & categorical predictors &gt; dummy vs effects coding flashcard.\nFor a more in-depth overview and example, see the numeric outcomes & categorical predictors &gt; example flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s first map our coefficients and estimates:\n\n\n\n\n\n\n\nCoefficient\nEstimate\nRelation between \\(\\beta\\) and \\(\\mu\\)\n\n\n\n\n(Intercept)\n22.7382\n\\(\\beta_0 = \\frac{\\mu_1 + \\mu_2 + \\mu_3}{3} = \\mu\\)\n\n\nmusic1\n-0.5968\n\\(\\beta_1 = \\mu_1 - \\mu\\)\n\n\nmusic2\n-0.8392\n\\(\\beta_2 = \\mu_2 - \\mu\\)\n\n\n\n\n\n\n\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\beta_0 = \\mu = 22.7382\\). This value represents the grand mean of the data. The estimated average spending for customers across background music conditions is approximately £22.74.\nThe next estimate corresponds to music1 and is \\(\\hat \\beta_1 = -0.5968\\). The difference in mean spending between None \\((\\hat \\mu_1)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(-0.5968\\). In other words, people with no music playing in the background seem to spend approximately £0.60 less than average, and spent \\(22.7382 + (-0.5968) = £22.14\\) in total. This difference in spending was statistically significant \\((p = .005)\\).\nThe estimate corresponding to music2 is \\(\\hat \\beta_2 = -0.8392\\). The difference in mean spending between Pop \\((\\hat \\mu_2)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(-0.8392\\). In other words, customers with Pop music playing in the background seem to spend approximately £0.84 less than average, and spent \\(22.7382 + (-0.8392) = £21.90\\) in total. This difference in spending was statistically significant \\((p &lt; .001)\\).\nThe estimate for music3, representing the difference of “Classical” to the grand mean is not shown by summary(). Because of the side-constraint, we know that \\(\\mu_3 = \\beta_0 - (\\beta_1 + \\beta_2)\\). The difference in mean spending between Classical and the grand mean was estimated to be \\(-(-0.5968 + -0.8392) = 1.436\\). In other words, customers with Classical music playing in the background seem to spend approximately £1.44 more than average, and spent \\(22.7382 - (-0.5968 + -0.8392) = £24.17\\) in total.\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nObtain the estimated (or predicted) group means for the “None,” “Pop,” and “Classical” background music conditions by using the predict() function.\n\n\n\n\n\n\nHint\n\n\n\n\n\nStep 1: Define a data frame via tibble() with a column having the same name as the factor in the fitted model (i.e., music). Then, specify all the groups (i.e., levels) for which you would like the predicted mean.\nStep 2: Pass the data frame to the predict function using the newdata = argument. The predict() function will match the column named music with the predictor called music in the fitted model ‘mdl_ec’.\nIf you’re still not sure, it might be helpful to review the model predicted values & residuals flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nStep 1:\n\nquery_groups &lt;- tibble(music = c(\"None\", \"Pop\", \"Classical\"))\nquery_groups\n\n# A tibble: 3 × 1\n  music    \n  &lt;chr&gt;    \n1 None     \n2 Pop      \n3 Classical\n\n\nStep 2:\n\npredict(mdl_ec, newdata = query_groups)\n\n       1        2        3 \n22.14139 21.89894 24.17414 \n\n\n\nPredicted mean of “None” = \\(\\hat \\mu_\\text{None}\\) = 22.14\nPredicted mean of “Pop” = \\(\\hat \\mu_\\text{Pop}\\) = 21.90\nPredicted mean of “Classical” = \\(\\hat \\mu_\\text{Classical}\\) = 24.17\n\nWe can see that these predicted means match our model estimates in Q5."
  },
  {
    "objectID": "1_07_effects_cedar.html#planned-comparisons-contrasts",
    "href": "1_07_effects_cedar.html#planned-comparisons-contrasts",
    "title": "Effects Coding",
    "section": "Planned Comparisons / Contrasts",
    "text": "Planned Comparisons / Contrasts\n\nQuestion 7\n\n\nFormally state the planned comparison that the researchers were interested in as a testable hypothesis.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nRecall that the researchers were also interested in addressing the following question:\n\nWhether having some kind of music playing (i.e., pop or classical), rather than no music (i.e., none), resulted in a difference in spending\n\nWe can specify the hypothesis as follows:\n\\[\n\\begin{aligned}\n    \\quad H_0 &: \\mu_\\text{No Music} = \\mu_\\text{Music} \\\\\n    \\quad H_0 &: \\mu_\\text{None} = \\frac{1}{2} (\\mu_\\text{Pop} + \\mu_\\text{Classical}) \\\\\n\\\\\n    \\quad H_1 &: \\mu_\\text{No Music} \\neq \\mu_\\text{Music} \\\\\n    \\quad H_1 &: \\mu_\\text{No Music} \\neq \\frac{1}{2} (\\mu_\\text{Pop} + \\mu_\\text{Classical}) \\\\\n\\\\\n\\end{aligned}\n\\]\n\n\n\n\n\nQuestion 8\n\n\nAfter checking the levels of the factor music, use emmeans() to obtain the estimated treatment means and uncertainties for your factor.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nlevels(rest_spend$music)\n\n[1] \"None\"      \"Pop\"       \"Classical\"\n\n\nUse the emmeans() to get the estimated means of our groups:\n\nmusic_mean &lt;- emmeans(mdl_ec, ~ music)\nmusic_mean\n\n music     emmean    SE  df lower.CL upper.CL\n None        22.1 0.259 357     21.6     22.7\n Pop         21.9 0.259 357     21.4     22.4\n Classical   24.2 0.259 357     23.7     24.7\n\nConfidence level used: 0.95 \n\nplot(music_mean)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nSpecify the coefficients of the comparisons and run the contrast analysis, obtaining 95% confidence intervals.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\nRemember that ordering matters here - look again at the output of levels(rest_spend$music) as this will help you when assigning your weights.\n\n\n\n\n\n\n\n Solution \n\n\nAs shown above via levels(), the ordering of the treatment factor is:\n\nNone (no music)\nPop (music)\nClassical (music)\n\nFrom this ordering, we can specify our weights - based on the hypothesis, lets assign positive values to the music conditions:\n\nmusic_comp &lt;- list(\"No Music - Music\" = c(-1, 1/2, 1/2))\n\nNow lets run our contrast analysis and get confidence intervals:\n\n#run contrast analysis\nmusic_comp_test &lt;- contrast(music_mean, method = music_comp)\n\n#examine output\nmusic_comp_test\n\n contrast         estimate    SE  df t.ratio p.value\n No Music - Music    0.895 0.318 357   2.818  0.0051\n\n#obtain confidence intervals\nconfint(music_comp_test)\n\n contrast         estimate    SE  df lower.CL upper.CL\n No Music - Music    0.895 0.318 357     0.27     1.52\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret the results of the contrast analysis in the context of the researchers hypotheses.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the manual contrasts flashcards, specifically the manual contrasts &gt; additive models flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nWe performed a test against \\(H_0: \\mu_\\text{None} - \\frac{1}{2} (\\mu_\\text{Pop} + \\mu_\\text{Classical}) = 0\\). At the 5% significance level, there was evidence that restaurant spending per person for those who were in the no music condition (i.e., none) was significantly different from those in a music condition (i.e., pop and classical) \\(t(357) = 2.82, p = .005, \\text{two-sided})\\), and this difference was estimated to be \\(£~0.90\\). We are 95% confident that those who heard some form of background music spent on average, between \\(£~0.27\\) and \\(£~1.52\\) more per person on their meal than those who heard no background music \\((CI_{95}[0.27, 1.52])\\)."
  },
  {
    "objectID": "1_08_assump_diag.html",
    "href": "1_08_assump_diag.html",
    "title": "Assumptions and Diagnostics",
    "section": "",
    "text": "At the end of this lab, you will be able to:\n\nSpecify the assumptions underlying a linear model with multiple predictors\nAssess if a fitted model satisfies the assumptions of your model (e.g., linearity, homoscedasticity, independence, and normality)\nIdentify whether multicollinearity is present\nAssess the effect of influential cases on linear model coefficients and overall model evaluations (e.g., outlyingness, high leverage, high influence)\n\n\nBe up to date with lectures\nHave completed Week 2 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\ncar\nperformance\nkableExtra\nsjPlot\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_08_assump_diag.html#assumptions",
    "href": "1_08_assump_diag.html#assumptions",
    "title": "Assumptions and Diagnostics",
    "section": "Assumptions",
    "text": "Assumptions\n\nQuestion 1\n\n\nLet’s start by using check_model() for our wb_mdl1 model - we can refer to these plots as a guide as we work through the assumptions questions of the lab.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the model assumptions &gt; linear models &gt; useful assumptions plots &gt; check_model() flaschard.\n\n\n\n\n\n\n\n\n\nThese plots cannot be used in your reports - they are to be used as a guide only.\n\n\n\n\n\n\n\n Solution \n\n\n\ncheck_model(wb_mdl1)\n\n\n\n\n\n\n\nThe check_model() function is a useful way to check the assumptions of models, as it also returns some useful notes to aid your interpretation. There does appear to be evidence that some assumptions may have been violated, but to be sure we need to check each assumption individually with plots that are more suitable for a statistics report.\n\n\n\n\n\nQuestion 2\n\n\nCheck if the fitted model satisfies the linearity assumption for wb_mdl1.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nHow you check this assumption depends on the number of predictors in your model:\n\nSingle predictor: Use either residual vs fitted values plot (plot(model, which = 1)), and/or a scatterplot with loess lines\n\nMultiple predictors: Use component-residual plots (also known as partial-residual plots) to check the assumption of linearity\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; linearity flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\ncrPlots(wb_mdl1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe smoother (the pink line) follows quite closely to a linear relationship (the dashed blue line), though there was some deviation. Overall, the evidence suggested that the linearity assumption was met.\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nCheck if the fitted model wb_mdl1 satisfy the equal variance (homoscedasticity) assumption.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plot.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse residualPlots() to plot residuals against the predictor. Since we are only interested in visually assessing our assumption checks, we can suppress the curvature test output by specifying tests = FALSE.\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; equal variances (homoscedasticity) flashcard.\n\nQuick tip if plotting using plot(model)\nAs the residuals can be positive or negative, we can make it easier to assess equal spread by improving the ‘resolution’ of the points.\nWe can make all residuals positive by discarding the sign (take the absolute value), and then take the square root to make them closer to each other.\nA plot of \\(\\sqrt{|\\text{Standardized residuals}|}\\) against the fitted values can be obtained via plot(model, which = 3).\n\n\n\n\n\n\n\n\n Solution \n\n\nWe can visually assess by plotting the Pearson residuals against the fitted values:\n\nresidualPlots(wb_mdl1, tests = FALSE)\n\n\n\n\n\n\n\nOr by plotting the \\(\\sqrt{|\\text{Standardized residuals}|}\\) against the fitted values:\n\nplot(wb_mdl1, which = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartial residual plots did show non-linear trends between residuals and predictors, hence there is evidence of non-constant variance i.e., heteroscedasticity. Thus, the data did not meet the assumption of equal variance, as the spread of the standardized residuals did not appear to be constant (for the most part) as the fitted values varied.\nIn the second plot, all points are above 0, but the majority of the points are not very close to each other. The line does not appear to be relatively flat, and so this also suggested that the error variance does change across the fitted values.\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nWrite a sentence summarising whether or not you consider the assumption of independence to have been met (you may have to assume certain aspects of the study design).\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; independence (of errors) flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nSince our data were collected from a between-persons study design, we can assume (i.e., based on design, we believe) the errors to be independent.\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nCheck if the fitted model wb_mdl1 satisfies the normality assumption.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; normality (of errors) flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nHistogram\nQQ Plot\n\n\n\n\nggplot(data = mwdata, aes(x = wb_mdl1$residuals)) +\n    geom_histogram() \n\n\n\n\n\n\n\n\n\n\n\n\n\nThe histogram indicated that the residuals (the differences between observed and predicted values) followed close to a normal distribution.\n\n\n\n\n\n\nplot(wb_mdl1, which = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe QQplot indicated that the residuals followed close to a normal distribution, as the points followed a linear pattern and there was no substantial skew or departure from normality. There was some evidence of heavier tails, and we may want to examine some observations more closely (e.g., 16, 78, 109)."
  },
  {
    "objectID": "1_08_assump_diag.html#multicollinearity",
    "href": "1_08_assump_diag.html#multicollinearity",
    "title": "Assumptions and Diagnostics",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nQuestion 6\n\n\nFor wb_mdl1, calculate the variance inflation factor (VIF) for the predictors in the model.\nWrite a sentence summarising whether or not you consider multicollinearity to be a problem here.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; multicollinearity flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\nvif(wb_mdl1)\n\noutdoor_time   social_int \n    1.001306     1.001306 \n\n\n\n\n\n\n\n\nThe VIF values for all predictors are &lt;5, indicating that multicollinearity is not adversely affecting model estimates."
  },
  {
    "objectID": "1_08_assump_diag.html#diagnostics",
    "href": "1_08_assump_diag.html#diagnostics",
    "title": "Assumptions and Diagnostics",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nQuestion 7\n\n\nCreate a new tibble which contains:\n\nThe original variables from the model (Hint, what does wb_mdl1$model give you?)\nThe fitted values from the model \\(\\hat y\\)\n\nThe residuals \\(\\hat \\epsilon\\)\n\nThe studentised residuals\nThe hat values\nThe Cook’s Distance values\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe following will likely be useful to consider when creating your tibble():\n\nThink about what wb_mdl1$model gives you\nfitted()\nresiduals()\nrstudent()\nhatvalues()\ncooks.distance()\n\n\n\n\n\n\n\n\n Solution \n\n\n\nmdl_diagnost &lt;- \n  tibble(\n  wb_mdl1$model,\n  fitted = fitted(wb_mdl1),\n  resid = residuals(wb_mdl1),\n  studres = rstudent(wb_mdl1),\n  hats = hatvalues(wb_mdl1),\n  cooksd = cooks.distance(wb_mdl1)\n)\n\n\n\n\n\n\nQuestion 8\n\n\nFrom the tibble above, comment on the following:\n\nLooking at the studentised residuals, are there any outliers?\n\nLooking at the hat values, are there any observations with high leverage?\n\nLooking at the Cook’s Distance values, are there any highly influential points?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAlongside the lecture materials, review the model assumptions &gt; linear models &gt; individual case diagnostics flashcard and consider the commonly used cut-off criteria.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nOutliers\nHigh Leverage\nInfluential Points\n\n\n\nIn a standard normal distribution, 95% of the values are roughly between -2 and 2. Because of this, studentised residuals of \\(&gt;2\\) or \\(&lt; -2\\) indicate potential outlyingness.\nWe can ask R how many of the absolute values (by specifying abs()) are \\(&gt;2\\):\n\ntable(abs(mdl_diagnost$studres) &gt; 2)\n\n\nFALSE  TRUE \n  189    11 \n\n\nWe have 11 TRUE observations, which tells us that they have |studentised residuals| \\(&gt;2\\).\nWe can identify which of our observations have these values:\n\nwhich(abs(mdl_diagnost$studres) &gt; 2)\n\n 16  50  53  58  62  76  78 109 126 151 163 \n 16  50  53  58  62  76  78 109 126 151 163 \n\n\nSo we know that observations (or rows) 16, 50, 53, 58, 62, 76, 78, 109, 126, 151, and 163 have absolute values that have studentised residuals of \\(&gt;2\\) or \\(&lt; -2\\).\nWe could also filter our newly created tibble to these observations to examine the values further:\n\nmwdata |&gt;\n    mutate(\n    studres = rstudent(wb_mdl1)) |&gt;\n  dplyr::filter(studres &gt; 2 | studres &lt; -2) |&gt;\n  arrange(desc(studres)) |&gt;\n  kable()  |&gt;   \n    kable_styling(full_width = F)\n\n\n\nage\noutdoor_time\nsocial_int\nroutine\nwellbeing\nlocation\nsteps_k\nstudres\n\n\n\n23\n26\n19\n1\n59\ncity\nNA\n3.904186\n\n\n34\n29\n11\n1\n50\nsuburb\n61.1\n2.402389\n\n\n39\n28\n11\n1\n49\nsuburb\n65.6\n2.234367\n\n\n22\n22\n11\n1\n47\ncity\n80.1\n2.060351\n\n\n58\n31\n16\n1\n30\nrural\n46.6\n-2.047644\n\n\n46\n19\n19\n1\n28\nrural\n34.8\n-2.167219\n\n\n44\n25\n11\n0\n26\nrural\n66.6\n-2.261542\n\n\n47\n24\n15\n0\n27\nrural\n53.5\n-2.292089\n\n\n35\n19\n17\n0\n26\nrural\n66.1\n-2.433253\n\n\n19\n23\n17\n0\n26\nrural\n60.0\n-2.602129\n\n\n36\n19\n16\n0\n22\nrural\n51.6\n-3.199777\n\n\n\n\n\n\n\n\n\n\n\nThere were 11 observations identified as potential outliers.\n\n\n\n\n\nHat values of more than \\(2 \\bar{h}\\) (2 times the average hat value) are considered high leverage. The average hat value, \\(\\bar{h}\\) is calculated as \\(\\frac{k + 1}{n}\\), where \\(k\\) is the number of predictors, and \\(n\\) is the sample size.\nFor our model: \\[\n\\bar h ~=~ \\frac{k+1}{n} ~=~ \\frac{2+1}{200} ~=~ \\frac{3}{200} ~=~ 0.015\n\\] and so:\n\\[\n2 \\bar{h} ~=~ 2 \\cdot 0.015 ~=~ 0.03\n\\]\nWe can ask whether any of observations have hat values which are greater than \\(2 \\bar h\\):\n\ntable(mdl_diagnost$hats &gt; 0.03)\n\n\nFALSE  TRUE \n  184    16 \n\n\nWe have 16 TRUE observations, which tells us that they have high leverage.\nWe can identify which of our observations have these values:\n\nwhich(mdl_diagnost$hats &gt; 0.03)\n\n 25  56  59  60  72  73  75  79 127 131 149 159 165 169 176 197 \n 25  56  59  60  72  73  75  79 127 131 149 159 165 169 176 197 \n\n\nSo we know that observations (or rows) 25, 56, 59, 60, 72, 73, 75, 79, 127, 131, 149, 159, 165, 169, 176, and 197 have hat values which are greater than \\(2 \\bar h\\).\nWe could also filter our newly created tibble to these observations to examine the values further:\n\nmwdata |&gt;\n    mutate(\n    hats = hatvalues(wb_mdl1)) |&gt;\n  dplyr::filter(hats &gt; 0.03) |&gt;\n  arrange(desc(hats)) |&gt;\n  kable()  |&gt;   \n    kable_styling(full_width = F)\n\n\n\nage\noutdoor_time\nsocial_int\nroutine\nwellbeing\nlocation\nsteps_k\nhats\n\n\n\n21\n9\n24\n1\n35\nsuburb\nNA\n0.0564084\n\n\n62\n31\n3\n1\n37\ncity\n49.2\n0.0452765\n\n\n69\n2\n19\n0\n39\nrural\n5.9\n0.0448793\n\n\n19\n7\n21\n0\n39\nrural\n40.0\n0.0411712\n\n\n63\n10\n21\n1\n41\nrural\n24.3\n0.0356713\n\n\n27\n1\n11\n1\n38\nrural\nNA\n0.0352975\n\n\n53\n35\n14\n1\n35\nrural\n24.4\n0.0345566\n\n\n21\n7\n5\n1\n30\nsuburb\n3.3\n0.0341635\n\n\n18\n28\n4\n0\n32\ncity\n71.6\n0.0336901\n\n\n30\n10\n4\n1\n36\nrural\n29.7\n0.0328599\n\n\n44\n5\n7\n1\n35\nrural\n15.1\n0.0313589\n\n\n69\n11\n4\n0\n31\nsuburb\n15.6\n0.0312095\n\n\n23\n29\n5\n1\n36\nrural\nNA\n0.0310672\n\n\n56\n32\n7\n1\n41\ncity\n58.6\n0.0309399\n\n\n35\n10\n20\n1\n46\ncity\nNA\n0.0305338\n\n\n21\n34\n13\n1\n48\nsuburb\n35.1\n0.0301977\n\n\n\n\n\n\n\n\n\n\n\nThere were 16 observations that had high leverage (&gt; \\(2 \\bar h\\)).\n\n\n\n\n\nWe are using a Cook’s Distance cut-off of \\(\\frac{4}{n-k-1}\\), where \\(k\\) is the number of predictors, and \\(n\\) is the sample size.\nFor our model: \\[\n\\text{D}_\\text{cutoff} = \\frac{4}{n-k-1} = \\frac{4}{200 - 2 - 1} = \\frac{4}{197} = 0.020\n\\]\nWe can ask whether any of observations have a high influence on our model estimates:\n\ntable(mdl_diagnost$cooksd &gt; 0.020)\n\n\nFALSE  TRUE \n  189    11 \n\n\nYes, we have 11 TRUE observations, which tells us that they are above the \\(D_{cutoff} = 0.020\\).\nWe can identify which of our observations have these values:\n\nwhich(mdl_diagnost$cooksd &gt; 0.020)\n\n 16  53  58  76  78 109 125 126 149 151 169 \n 16  53  58  76  78 109 125 126 149 151 169 \n\n\nSo we know that observations (or rows) 16, 53, 58, 76, 78, 109, 125, 126, 149, 151, and 169 have \\(D &gt; 0.020\\).\nWe could also filter our newly created tibble to these observations to examine the values further:\n\nmwdata |&gt;\n    mutate(\n    cooksd = cooks.distance(wb_mdl1)) |&gt;\n  dplyr::filter(cooksd &gt; 4/(200-2-1)) |&gt;\n  arrange(desc(cooksd)) |&gt;\n  kable()  |&gt;   \n    kable_styling(full_width = F)\n\n\n\nage\noutdoor_time\nsocial_int\nroutine\nwellbeing\nlocation\nsteps_k\ncooksd\n\n\n\n23\n26\n19\n1\n59\ncity\nNA\n0.1295568\n\n\n58\n31\n16\n1\n30\nrural\n46.6\n0.0376693\n\n\n19\n23\n17\n0\n26\nrural\n60.0\n0.0336478\n\n\n36\n19\n16\n0\n22\nrural\n51.6\n0.0326114\n\n\n34\n29\n11\n1\n50\nsuburb\n61.1\n0.0319559\n\n\n35\n10\n20\n1\n46\ncity\nNA\n0.0318858\n\n\n46\n19\n19\n1\n28\nrural\n34.8\n0.0314694\n\n\n21\n34\n13\n1\n48\nsuburb\n35.1\n0.0284437\n\n\n35\n19\n17\n0\n26\nrural\n66.1\n0.0247096\n\n\n39\n28\n11\n1\n49\nsuburb\n65.6\n0.0243298\n\n\n\n\n\nYou can also display the Cook’s Distance values themselves using plot(model, which = 4), and add a horizontal line at the \\(D_{cutoff} = 0.020\\) using abline(h = ???):\n\nplot(wb_mdl1, which = 4, abline(h=0.020, col=\"blue\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere were 11 observations that had a high influence on our model estimates.\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nUse the function influence.measures() to extract these delete-1 measures1 of influence.\nFor the purpose of the lab, focus on COVRATIO and DFBETA - explore these in more detail (you may want to examine values or even try plotting distributions).\nYou will need to calculate or choose a commonly used cut-off or threshold to compare against. The which() argument might come in handy to help you identify which specific observations are beyond this cut-off/threshold.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; individual case diagnostics flashcard.\nThe function influence.measures() returns an infl-type object. To plot this, we need to find a way to extract the actual numbers from it.\nWhat do you think names(influence.measures(wb_mdl1)) shows you? How can we use influence.measures(wb_mdl1)$&lt;insert name here&gt; to extract the matrix of numbers?\n\n\n\n\n\n\n\n Solution \n\n\n\n\nExtracting influence.measures()\nExamine DFBETA values\nPlotting COVRATIO statistics\n\n\n\n\n#extract measures\ninf_mes &lt;- influence.measures(wb_mdl1)\n\n#examine top ten rows, and round to 3 decimal places\nround(inf_mes$infmat[1:10,], 3)\n\n   dfb.1_ dfb.otd_ dfb.scl_  dffit cov.r cook.d   hat\n1   0.006   -0.008    0.002  0.012 1.024  0.000 0.009\n2   0.083   -0.168    0.061  0.203 1.016  0.014 0.025\n3  -0.006   -0.001    0.004 -0.016 1.020  0.000 0.005\n4   0.047   -0.050   -0.039 -0.081 1.020  0.002 0.012\n5   0.001    0.080   -0.091 -0.138 1.028  0.006 0.024\n6  -0.003    0.001   -0.008 -0.037 1.017  0.000 0.005\n7  -0.008   -0.001    0.015  0.018 1.036  0.000 0.020\n8   0.106   -0.119   -0.006  0.166 0.985  0.009 0.010\n9  -0.003    0.004   -0.001 -0.007 1.025  0.000 0.009\n10  0.002   -0.008    0.008  0.015 1.026  0.000 0.010\n\n\n\n\nDFbeta represents the difference in the beta coefficients when a case is excluded from the model versus when it’s included. A large DFbeta value would suggest that a case has a substantial impact on the estimated coefficients, and thus a high influence on the model results; a small DFbeta value would suggest that the case has less influence on the estimated coefficients.\nA commonly used cut-off or threshold to compare \\(|DFBETA|\\) values (absolute values) against is \\(\\frac{2}{\\sqrt{n}}\\) (see Belsley et al., (1980) p. 28 for more info)2.\nFor our model:\n\\[\n|\\text{DFBETA}_\\text{cutoff}| \\quad = \\quad \\frac{2}{\\sqrt{n}} \\quad = \\quad  \\frac{2}{\\sqrt{200}}  = 0.141\n\\]\nIn order to extract these in order to arrange in descending order, we need to save our delete-1 measures of influence as a dataframe (via as.data.frame()). Then we can then arrange our DFBETA values in descending order (via arrange(desc(???))). To avoid returning 200 rows of output (i.e., the length of the dataframe), we can ask for the first 15 rows via (head(., 15)):\n\n#save as a dataframe\ninf_mes1 &lt;- as.data.frame(inf_mes$infmat)\n\n#arrange dfbeta values in descending order using the absolute value, and show first 10 rows\n#inf_mes1 |&gt;\n#    arrange(desc(abs(dfb.1_))) |&gt;\n#    head(., 15)\n\nWe can see that we have 11 \\(|DFBETA|\\) values &gt; \\(\\frac{2}{\\sqrt{200}}\\), from observations (or rows) 16, 53, 56, 75, 76, 85, 101, 109, 149, 173, and 179 that we may want to examine further:\n\nwhich(abs(inf_mes1$dfb.1_) &gt; (2/sqrt(200)))\n\n [1]  16  53  56  75  76  85 101 109 149 173 179\n\n\n\n\nValues which are \\(&gt;1+\\frac{3(k+1)}{n}\\) or \\(&lt;1-\\frac{3(k+1)}{n}\\) are considered as having strong influence.\nFor our model, this is: \\[\n1 \\pm \\frac{3(k+1)}{n} \\quad = \\quad 1 \\pm\\frac{3(2+1)}{200} \\quad = \\quad 1\\pm \\frac{9}{200} \\quad = \\quad 1\\pm0.045\n\\]\nThe “infmat” bit of an infl-type object contains the numbers, as we can see from out output above. To use it with ggplot(), we will need to turn it into a dataframe (as.data.frame()), or a tibble (as_tibble()):\n\ninfdata &lt;- inf_mes$infmat |&gt;\n  as_tibble()\n\nNow we can build our plot. It would be useful to add vertical lines at the values \\(\\quad 1\\pm0.045\\). To do so, we can use the geom_vline() function:\n\nggplot(data = infdata, aes(x = cov.r)) + \n  geom_histogram() +\n  geom_vline(aes(xintercept = c(1-0.045), col = \"blue\")) +\n  geom_vline(aes(xintercept = c(1+0.045), col = \"red\")) + \n  theme(legend.position = \"none\")  #remove legend\n\n\n\n\n\n\n\nIt looks like a few observations may be having quite a strong influence on the standard errors here. We can check specifically how many observations are potentially having a having strong influence using the cut off \\(1\\pm0.045\\):\n\ntable(infdata$cov.r &lt; 1 - 0.045 | infdata$cov.r &gt; 1 + 0.045)\n\n\nFALSE  TRUE \n  185    15 \n\n\nWe can identify these 15 observations to investigate further:\n\nwhich(infdata$cov.r &lt; 1 - 0.045 | infdata$cov.r &gt; 1 + 0.045)\n\n [1]  16  25  50  58  62  72  73  78  79 109 127 151 159 165 176\n\n\nWe know that observations (or rows) 16, 25, 50, 58, 62, 72, 73, 78, 79, 109, 127, 151, 159, 165, and 176 have \\(\\text{COVRATIO  } 1\\pm0.045\\).\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nList what approach(es) would be appropriate to take given the issues highlighted above with the violations of assumptions and case diagnostic results. Briefly outline why these would be appropriate steps to take.\n\n\n\n\n Solution \n\n\nThere are lots of different options available to us. We may want to consider one of the approaches described in the model assumptions &gt; linear models &gt; next steps: what to do with violations of assumptions / problematic case diagnostic results flashcard."
  },
  {
    "objectID": "1_08_assump_diag.html#footnotes",
    "href": "1_08_assump_diag.html#footnotes",
    "title": "Assumptions and Diagnostics",
    "section": "Footnotes",
    "text": "Footnotes\n\nleave-one-out deletion diagnostics↩︎\nBelsley, D. A., Kuh, E., & Welsch, R. E. (2005). Regression diagnostics: Identifying influential data and sources of collinearity. John Wiley & Sons. DOI: 10.1002/0471725153↩︎"
  },
  {
    "objectID": "1_08_assump_diag_juniper.html",
    "href": "1_08_assump_diag_juniper.html",
    "title": "Assumptions and Diagnostics",
    "section": "",
    "text": "At the end of this lab, you will be able to:\n\nSpecify the assumptions underlying a linear model with multiple predictors\nAssess if a fitted model satisfies the assumptions of your model (e.g., linearity, homoscedasticity, independence, and normality)\nIdentify whether multicollinearity is present\nAssess the effect of influential cases on linear model coefficients and overall model evaluations (e.g., outlyingness, high leverage, high influence)\n\n\nBe up to date with lectures\nHave completed Week 2 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\ncar\nperformance\nkableExtra\nsjPlot\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_08_assump_diag_juniper.html#assumptions",
    "href": "1_08_assump_diag_juniper.html#assumptions",
    "title": "Assumptions and Diagnostics",
    "section": "Assumptions",
    "text": "Assumptions\n\nQuestion 1\n\n\nLet’s start by using check_model() for our wb_mdl1 model - we can refer to these plots as a guide as we work through the assumptions questions of the lab.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the model assumptions &gt; linear models &gt; useful assumptions plots &gt; check_model() flaschard.\n\n\n\n\n\n\n\n\n\nThese plots cannot be used in your reports - they are to be used as a guide only.\n\n\n\n\n\n\n\n Solution \n\n\n\ncheck_model(wb_mdl1)\n\n\n\n\n\n\n\nThe check_model() function is a useful way to check the assumptions of models, as it also returns some useful notes to aid your interpretation. There does appear to be evidence that some assumptions may have been violated, but to be sure we need to check each assumption individually with plots that are more suitable for a statistics report.\n\n\n\n\n\nQuestion 2\n\n\nCheck if the fitted model satisfies the linearity assumption for wb_mdl1.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nHow you check this assumption depends on the number of predictors in your model:\n\nSingle predictor: Use either residual vs fitted values plot (plot(model, which = 1)), and/or a scatterplot with loess lines\n\nMultiple predictors: Use component-residual plots (also known as partial-residual plots) to check the assumption of linearity\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; linearity flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\ncrPlots(wb_mdl1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe smoother (the pink line) follows quite closely to a linear relationship (the dashed blue line), though there was some deviation. Overall, the evidence suggested that the linearity assumption was met.\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nCheck if the fitted model wb_mdl1 satisfy the equal variance (homoscedasticity) assumption.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plot.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse residualPlots() to plot residuals against the predictor. Since we are only interested in visually assessing our assumption checks, we can suppress the curvature test output by specifying tests = FALSE.\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; equal variances (homoscedasticity) flashcard.\n\nQuick tip if plotting using plot(model)\nAs the residuals can be positive or negative, we can make it easier to assess equal spread by improving the ‘resolution’ of the points.\nWe can make all residuals positive by discarding the sign (take the absolute value), and then take the square root to make them closer to each other.\nA plot of \\(\\sqrt{|\\text{Standardized residuals}|}\\) against the fitted values can be obtained via plot(model, which = 3).\n\n\n\n\n\n\n\n\n Solution \n\n\nWe can visually assess by plotting the Pearson residuals against the fitted values:\n\nresidualPlots(wb_mdl1, tests = FALSE)\n\n\n\n\n\n\n\nOr by plotting the \\(\\sqrt{|\\text{Standardized residuals}|}\\) against the fitted values:\n\nplot(wb_mdl1, which = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartial residual plots did show non-linear trends between residuals and predictors, hence there is evidence of non-constant variance i.e., heteroscedasticity. Thus, the data did not meet the assumption of equal variance, as the spread of the standardized residuals did not appear to be constant (for the most part) as the fitted values varied.\nIn the second plot, all points are above 0, but the majority of the points are not very close to each other. The line does not appear to be relatively flat, and so this also suggested that the error variance does change across the fitted values.\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nWrite a sentence summarising whether or not you consider the assumption of independence to have been met (you may have to assume certain aspects of the study design).\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; independence (of errors) flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nSince our data were collected from a between-persons study design, we can assume (i.e., based on design, we believe) the errors to be independent.\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nCheck if the fitted model wb_mdl1 satisfies the normality assumption.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; normality (of errors) flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nHistogram\nQQ Plot\n\n\n\n\nggplot(data = mwdata, aes(x = wb_mdl1$residuals)) +\n    geom_histogram() \n\n\n\n\n\n\n\n\n\n\n\n\n\nThe histogram indicated that the residuals (the differences between observed and predicted values) followed close to a normal distribution.\n\n\n\n\n\n\nplot(wb_mdl1, which = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe QQplot indicated that the residuals followed close to a normal distribution, as the points followed a linear pattern and there was no substantial skew or departure from normality. There was some evidence of heavier tails, and we may want to examine some observations more closely (e.g., 16, 78, 109)."
  },
  {
    "objectID": "1_08_assump_diag_juniper.html#multicollinearity",
    "href": "1_08_assump_diag_juniper.html#multicollinearity",
    "title": "Assumptions and Diagnostics",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nQuestion 6\n\n\nFor wb_mdl1, calculate the variance inflation factor (VIF) for the predictors in the model.\nWrite a sentence summarising whether or not you consider multicollinearity to be a problem here.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; multicollinearity flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\nvif(wb_mdl1)\n\noutdoor_time   social_int \n    1.001306     1.001306 \n\n\n\n\n\n\n\n\nThe VIF values for all predictors are &lt;5, indicating that multicollinearity is not adversely affecting model estimates."
  },
  {
    "objectID": "1_08_assump_diag_juniper.html#diagnostics",
    "href": "1_08_assump_diag_juniper.html#diagnostics",
    "title": "Assumptions and Diagnostics",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nQuestion 7\n\n\nCreate a new tibble which contains:\n\nThe original variables from the model (Hint, what does wb_mdl1$model give you?)\nThe fitted values from the model \\(\\hat y\\)\n\nThe residuals \\(\\hat \\epsilon\\)\n\nThe studentised residuals\nThe hat values\nThe Cook’s Distance values\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe following will likely be useful to consider when creating your tibble():\n\nThink about what wb_mdl1$model gives you\nfitted()\nresiduals()\nrstudent()\nhatvalues()\ncooks.distance()\n\n\n\n\n\n\n\n\n Solution \n\n\n\nmdl_diagnost &lt;- \n  tibble(\n  wb_mdl1$model,\n  fitted = fitted(wb_mdl1),\n  resid = residuals(wb_mdl1),\n  studres = rstudent(wb_mdl1),\n  hats = hatvalues(wb_mdl1),\n  cooksd = cooks.distance(wb_mdl1)\n)\n\n\n\n\n\n\nQuestion 8\n\n\nFrom the tibble above, comment on the following:\n\nLooking at the studentised residuals, are there any outliers?\n\nLooking at the hat values, are there any observations with high leverage?\n\nLooking at the Cook’s Distance values, are there any highly influential points?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAlongside the lecture materials, review the model assumptions &gt; linear models &gt; individual case diagnostics flashcard and consider the commonly used cut-off criteria.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nOutliers\nHigh Leverage\nInfluential Points\n\n\n\nIn a standard normal distribution, 95% of the values are roughly between -2 and 2. Because of this, studentised residuals of \\(&gt;2\\) or \\(&lt; -2\\) indicate potential outlyingness.\nWe can ask R how many of the absolute values (by specifying abs()) are \\(&gt;2\\):\n\ntable(abs(mdl_diagnost$studres) &gt; 2)\n\n\nFALSE  TRUE \n  189    11 \n\n\nWe have 11 TRUE observations, which tells us that they have |studentised residuals| \\(&gt;2\\).\nWe can identify which of our observations have these values:\n\nwhich(abs(mdl_diagnost$studres) &gt; 2)\n\n 16  50  53  58  62  76  78 109 126 151 163 \n 16  50  53  58  62  76  78 109 126 151 163 \n\n\nSo we know that observations (or rows) 16, 50, 53, 58, 62, 76, 78, 109, 126, 151, and 163 have absolute values that have studentised residuals of \\(&gt;2\\) or \\(&lt; -2\\).\nWe could also filter our newly created tibble to these observations to examine the values further:\n\nmwdata |&gt;\n    mutate(\n    studres = rstudent(wb_mdl1)) |&gt;\n  dplyr::filter(studres &gt; 2 | studres &lt; -2) |&gt;\n  arrange(desc(studres)) |&gt;\n  kable()  |&gt;   \n    kable_styling(full_width = F)\n\n\n\nage\noutdoor_time\nsocial_int\nroutine\nwellbeing\nlocation\nsteps_k\nstudres\n\n\n\n23\n26\n19\n1\n59\ncity\nNA\n3.904186\n\n\n34\n29\n11\n1\n50\nsuburb\n61.1\n2.402389\n\n\n39\n28\n11\n1\n49\nsuburb\n65.6\n2.234367\n\n\n22\n22\n11\n1\n47\ncity\n80.1\n2.060351\n\n\n58\n31\n16\n1\n30\nrural\n46.6\n-2.047644\n\n\n46\n19\n19\n1\n28\nrural\n34.8\n-2.167219\n\n\n44\n25\n11\n0\n26\nrural\n66.6\n-2.261542\n\n\n47\n24\n15\n0\n27\nrural\n53.5\n-2.292089\n\n\n35\n19\n17\n0\n26\nrural\n66.1\n-2.433253\n\n\n19\n23\n17\n0\n26\nrural\n60.0\n-2.602129\n\n\n36\n19\n16\n0\n22\nrural\n51.6\n-3.199777\n\n\n\n\n\n\n\n\n\n\n\nThere were 11 observations identified as potential outliers.\n\n\n\n\n\nHat values of more than \\(2 \\bar{h}\\) (2 times the average hat value) are considered high leverage. The average hat value, \\(\\bar{h}\\) is calculated as \\(\\frac{k + 1}{n}\\), where \\(k\\) is the number of predictors, and \\(n\\) is the sample size.\nFor our model: \\[\n\\bar h ~=~ \\frac{k+1}{n} ~=~ \\frac{2+1}{200} ~=~ \\frac{3}{200} ~=~ 0.015\n\\] and so:\n\\[\n2 \\bar{h} ~=~ 2 \\cdot 0.015 ~=~ 0.03\n\\]\nWe can ask whether any of observations have hat values which are greater than \\(2 \\bar h\\):\n\ntable(mdl_diagnost$hats &gt; 0.03)\n\n\nFALSE  TRUE \n  184    16 \n\n\nWe have 16 TRUE observations, which tells us that they have high leverage.\nWe can identify which of our observations have these values:\n\nwhich(mdl_diagnost$hats &gt; 0.03)\n\n 25  56  59  60  72  73  75  79 127 131 149 159 165 169 176 197 \n 25  56  59  60  72  73  75  79 127 131 149 159 165 169 176 197 \n\n\nSo we know that observations (or rows) 25, 56, 59, 60, 72, 73, 75, 79, 127, 131, 149, 159, 165, 169, 176, and 197 have hat values which are greater than \\(2 \\bar h\\).\nWe could also filter our newly created tibble to these observations to examine the values further:\n\nmwdata |&gt;\n    mutate(\n    hats = hatvalues(wb_mdl1)) |&gt;\n  dplyr::filter(hats &gt; 0.03) |&gt;\n  arrange(desc(hats)) |&gt;\n  kable()  |&gt;   \n    kable_styling(full_width = F)\n\n\n\nage\noutdoor_time\nsocial_int\nroutine\nwellbeing\nlocation\nsteps_k\nhats\n\n\n\n21\n9\n24\n1\n35\nsuburb\nNA\n0.0564084\n\n\n62\n31\n3\n1\n37\ncity\n49.2\n0.0452765\n\n\n69\n2\n19\n0\n39\nrural\n5.9\n0.0448793\n\n\n19\n7\n21\n0\n39\nrural\n40.0\n0.0411712\n\n\n63\n10\n21\n1\n41\nrural\n24.3\n0.0356713\n\n\n27\n1\n11\n1\n38\nrural\nNA\n0.0352975\n\n\n53\n35\n14\n1\n35\nrural\n24.4\n0.0345566\n\n\n21\n7\n5\n1\n30\nsuburb\n3.3\n0.0341635\n\n\n18\n28\n4\n0\n32\ncity\n71.6\n0.0336901\n\n\n30\n10\n4\n1\n36\nrural\n29.7\n0.0328599\n\n\n44\n5\n7\n1\n35\nrural\n15.1\n0.0313589\n\n\n69\n11\n4\n0\n31\nsuburb\n15.6\n0.0312095\n\n\n23\n29\n5\n1\n36\nrural\nNA\n0.0310672\n\n\n56\n32\n7\n1\n41\ncity\n58.6\n0.0309399\n\n\n35\n10\n20\n1\n46\ncity\nNA\n0.0305338\n\n\n21\n34\n13\n1\n48\nsuburb\n35.1\n0.0301977\n\n\n\n\n\n\n\n\n\n\n\nThere were 16 observations that had high leverage (&gt; \\(2 \\bar h\\)).\n\n\n\n\n\nWe are using a Cook’s Distance cut-off of \\(\\frac{4}{n-k-1}\\), where \\(k\\) is the number of predictors, and \\(n\\) is the sample size.\nFor our model: \\[\n\\text{D}_\\text{cutoff} = \\frac{4}{n-k-1} = \\frac{4}{200 - 2 - 1} = \\frac{4}{197} = 0.020\n\\]\nWe can ask whether any of observations have a high influence on our model estimates:\n\ntable(mdl_diagnost$cooksd &gt; 0.020)\n\n\nFALSE  TRUE \n  189    11 \n\n\nYes, we have 11 TRUE observations, which tells us that they are above the \\(D_{cutoff} = 0.020\\).\nWe can identify which of our observations have these values:\n\nwhich(mdl_diagnost$cooksd &gt; 0.020)\n\n 16  53  58  76  78 109 125 126 149 151 169 \n 16  53  58  76  78 109 125 126 149 151 169 \n\n\nSo we know that observations (or rows) 16, 53, 58, 76, 78, 109, 125, 126, 149, 151, and 169 have \\(D &gt; 0.020\\).\nWe could also filter our newly created tibble to these observations to examine the values further:\n\nmwdata |&gt;\n    mutate(\n    cooksd = cooks.distance(wb_mdl1)) |&gt;\n  dplyr::filter(cooksd &gt; 4/(200-2-1)) |&gt;\n  arrange(desc(cooksd)) |&gt;\n  kable()  |&gt;   \n    kable_styling(full_width = F)\n\n\n\nage\noutdoor_time\nsocial_int\nroutine\nwellbeing\nlocation\nsteps_k\ncooksd\n\n\n\n23\n26\n19\n1\n59\ncity\nNA\n0.1295568\n\n\n58\n31\n16\n1\n30\nrural\n46.6\n0.0376693\n\n\n19\n23\n17\n0\n26\nrural\n60.0\n0.0336478\n\n\n36\n19\n16\n0\n22\nrural\n51.6\n0.0326114\n\n\n34\n29\n11\n1\n50\nsuburb\n61.1\n0.0319559\n\n\n35\n10\n20\n1\n46\ncity\nNA\n0.0318858\n\n\n46\n19\n19\n1\n28\nrural\n34.8\n0.0314694\n\n\n21\n34\n13\n1\n48\nsuburb\n35.1\n0.0284437\n\n\n35\n19\n17\n0\n26\nrural\n66.1\n0.0247096\n\n\n39\n28\n11\n1\n49\nsuburb\n65.6\n0.0243298\n\n\n\n\n\nYou can also display the Cook’s Distance values themselves using plot(model, which = 4), and add a horizontal line at the \\(D_{cutoff} = 0.020\\) using abline(h = ???):\n\nplot(wb_mdl1, which = 4, abline(h=0.020, col=\"blue\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere were 11 observations that had a high influence on our model estimates.\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nUse the function influence.measures() to extract these delete-1 measures1 of influence.\nFor the purpose of the lab, focus on COVRATIO and DFBETA - explore these in more detail (you may want to examine values or even try plotting distributions).\nYou will need to calculate or choose a commonly used cut-off or threshold to compare against. The which() argument might come in handy to help you identify which specific observations are beyond this cut-off/threshold.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor more information, as well as tips to aid your interpretation, review the model assumptions &gt; linear models &gt; individual case diagnostics flashcard.\nThe function influence.measures() returns an infl-type object. To plot this, we need to find a way to extract the actual numbers from it.\nWhat do you think names(influence.measures(wb_mdl1)) shows you? How can we use influence.measures(wb_mdl1)$&lt;insert name here&gt; to extract the matrix of numbers?\n\n\n\n\n\n\n\n Solution \n\n\n\n\nExtracting influence.measures()\nExamine DFBETA values\nPlotting COVRATIO statistics\n\n\n\n\n#extract measures\ninf_mes &lt;- influence.measures(wb_mdl1)\n\n#examine top ten rows, and round to 3 decimal places\nround(inf_mes$infmat[1:10,], 3)\n\n   dfb.1_ dfb.otd_ dfb.scl_  dffit cov.r cook.d   hat\n1   0.006   -0.008    0.002  0.012 1.024  0.000 0.009\n2   0.083   -0.168    0.061  0.203 1.016  0.014 0.025\n3  -0.006   -0.001    0.004 -0.016 1.020  0.000 0.005\n4   0.047   -0.050   -0.039 -0.081 1.020  0.002 0.012\n5   0.001    0.080   -0.091 -0.138 1.028  0.006 0.024\n6  -0.003    0.001   -0.008 -0.037 1.017  0.000 0.005\n7  -0.008   -0.001    0.015  0.018 1.036  0.000 0.020\n8   0.106   -0.119   -0.006  0.166 0.985  0.009 0.010\n9  -0.003    0.004   -0.001 -0.007 1.025  0.000 0.009\n10  0.002   -0.008    0.008  0.015 1.026  0.000 0.010\n\n\n\n\nDFbeta represents the difference in the beta coefficients when a case is excluded from the model versus when it’s included. A large DFbeta value would suggest that a case has a substantial impact on the estimated coefficients, and thus a high influence on the model results; a small DFbeta value would suggest that the case has less influence on the estimated coefficients.\nA commonly used cut-off or threshold to compare \\(|DFBETA|\\) values (absolute values) against is \\(\\frac{2}{\\sqrt{n}}\\) (see Belsley et al., (1980) p. 28 for more info)2.\nFor our model:\n\\[\n|\\text{DFBETA}_\\text{cutoff}| \\quad = \\quad \\frac{2}{\\sqrt{n}} \\quad = \\quad  \\frac{2}{\\sqrt{200}}  = 0.141\n\\]\nIn order to extract these in order to arrange in descending order, we need to save our delete-1 measures of influence as a dataframe (via as.data.frame()). Then we can then arrange our DFBETA values in descending order (via arrange(desc(???))). To avoid returning 200 rows of output (i.e., the length of the dataframe), we can ask for the first 15 rows via (head(., 15)):\n\n#save as a dataframe\ninf_mes1 &lt;- as.data.frame(inf_mes$infmat)\n\n#arrange dfbeta values in descending order using the absolute value, and show first 10 rows\n#inf_mes1 |&gt;\n#    arrange(desc(abs(dfb.1_))) |&gt;\n#    head(., 15)\n\nWe can see that we have 11 \\(|DFBETA|\\) values &gt; \\(\\frac{2}{\\sqrt{200}}\\), from observations (or rows) 16, 53, 56, 75, 76, 85, 101, 109, 149, 173, and 179 that we may want to examine further:\n\nwhich(abs(inf_mes1$dfb.1_) &gt; (2/sqrt(200)))\n\n [1]  16  53  56  75  76  85 101 109 149 173 179\n\n\n\n\nValues which are \\(&gt;1+\\frac{3(k+1)}{n}\\) or \\(&lt;1-\\frac{3(k+1)}{n}\\) are considered as having strong influence.\nFor our model, this is: \\[\n1 \\pm \\frac{3(k+1)}{n} \\quad = \\quad 1 \\pm\\frac{3(2+1)}{200} \\quad = \\quad 1\\pm \\frac{9}{200} \\quad = \\quad 1\\pm0.045\n\\]\nThe “infmat” bit of an infl-type object contains the numbers, as we can see from out output above. To use it with ggplot(), we will need to turn it into a dataframe (as.data.frame()), or a tibble (as_tibble()):\n\ninfdata &lt;- inf_mes$infmat |&gt;\n  as_tibble()\n\nNow we can build our plot. It would be useful to add vertical lines at the values \\(\\quad 1\\pm0.045\\). To do so, we can use the geom_vline() function:\n\nggplot(data = infdata, aes(x = cov.r)) + \n  geom_histogram() +\n  geom_vline(aes(xintercept = c(1-0.045), col = \"blue\")) +\n  geom_vline(aes(xintercept = c(1+0.045), col = \"red\")) + \n  theme(legend.position = \"none\")  #remove legend\n\n\n\n\n\n\n\nIt looks like a few observations may be having quite a strong influence on the standard errors here. We can check specifically how many observations are potentially having a having strong influence using the cut off \\(1\\pm0.045\\):\n\ntable(infdata$cov.r &lt; 1 - 0.045 | infdata$cov.r &gt; 1 + 0.045)\n\n\nFALSE  TRUE \n  185    15 \n\n\nWe can identify these 15 observations to investigate further:\n\nwhich(infdata$cov.r &lt; 1 - 0.045 | infdata$cov.r &gt; 1 + 0.045)\n\n [1]  16  25  50  58  62  72  73  78  79 109 127 151 159 165 176\n\n\nWe know that observations (or rows) 16, 25, 50, 58, 62, 72, 73, 78, 79, 109, 127, 151, 159, 165, and 176 have \\(\\text{COVRATIO  } 1\\pm0.045\\).\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nList what approach(es) would be appropriate to take given the issues highlighted above with the violations of assumptions and case diagnostic results. Briefly outline why these would be appropriate steps to take.\n\n\n\n\n Solution \n\n\nThere are lots of different options available to us. We may want to consider one of the approaches described in the model assumptions &gt; linear models &gt; next steps: what to do with violations of assumptions / problematic case diagnostic results flashcard."
  },
  {
    "objectID": "1_08_assump_diag_juniper.html#footnotes",
    "href": "1_08_assump_diag_juniper.html#footnotes",
    "title": "Assumptions and Diagnostics",
    "section": "Footnotes",
    "text": "Footnotes\n\nleave-one-out deletion diagnostics↩︎\nBelsley, D. A., Kuh, E., & Welsch, R. E. (2005). Regression diagnostics: Identifying influential data and sources of collinearity. John Wiley & Sons. DOI: 10.1002/0471725153↩︎"
  },
  {
    "objectID": "1_09_bootstrap.html",
    "href": "1_09_bootstrap.html",
    "title": "Bootstrapping",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the principles of bootstrapping\nUnderstand how to apply the bootstrap confidence interval to inference in linear models\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 2 and Week 9\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\ncar\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/science-faith-attitude.csv"
  },
  {
    "objectID": "1_09_bootstrap.html#study-overview-data-management",
    "href": "1_09_bootstrap.html#study-overview-data-management",
    "title": "Bootstrapping",
    "section": "Study Overview & Data Management",
    "text": "Study Overview & Data Management\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\nNote, to address the research question, we only need to refer to the kstot, age, and toomuchscience variables. Subset the data to only have those 3 columns.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nTo subset the data to only include the 3 variables of interest, we can use the select() function\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\nThere are numerous ways to deal with this. Two common commands are na.omit() and drop_na(). The former will remove all rows from a dataset that contain NA values in any column. In the latter, we can specify which columns we want to identify NA values in, and remove only rows containing NA values for those specific columns. In other words, the latter can help to preserve more data\n\n\n\nIf needed, provide better variable names\n\n\n\n\n\n\n\n\n Solution \n\n\n\n# Inspect top 6 rows\nhead(ebsurvey)\n\n# A tibble: 6 × 7\n     v5    v6 kstot   age  male toomuchscience solveprob\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1     1     2    12    35     1              2         0\n2     2     2    11    34     0              1         1\n3     3     2     7    40     0             NA        NA\n4     4     2     9    32     0              3         0\n5     5     2     6    35     0              3         1\n6     6     2    11    67     1             NA        NA\n\n# Check data dimensions\ndim(ebsurvey)\n\n[1] 21886     7\n\n\nThere are 21886 observations on 7 variables.\nHowever, today we will be only using the kstot, age, and toomuchscience variables, and so we subset the data to only include these:\n\nebsurvey &lt;- ebsurvey |&gt;\n    select(kstot, age, toomuchscience)\n\nAre there any NA values in the data?\n\n#check for NAs\nanyNA(ebsurvey)\n\n[1] TRUE\n\n#how many NAs?\ntable(is.na(ebsurvey))\n\n\nFALSE  TRUE \n54268 11390 \n\n#11390 NAs in data set \n\n#Omit the NAs - we are interested in all three columns so do not need to specify within drop_na()\nebsurvey &lt;- ebsurvey |&gt;\n    drop_na()\n\n# Check new data dimensions\ndim(ebsurvey)\n\n[1] 10503     3\n\n\nGive the variables more meaningful names. Rename kstot to science_knowledge and rename toomuchscience to attitude:\n\nebsurvey &lt;- ebsurvey |&gt;\n    rename(science_knowledge = kstot,\n           attitude = toomuchscience)\nhead(ebsurvey)\n\n# A tibble: 6 × 3\n  science_knowledge   age attitude\n              &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1                12    35        2\n2                11    34        1\n3                 9    32        3\n4                 6    35        3\n5                 9    37        1\n6                 5    63        2\n\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of any categorical variable(s))\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook. The statistical models flashcards may also be useful to refer to.\n\n\n\n\n\n\n\n Solution \n\n\nThe ebsurvey dataset, excluding missing values, included 10,503 individual respondents who were measured on 3 different attributes of interest: (1) score on a science “quiz” composed of 13 true/false items; (2) attitudes towards science and faith (question phrasing: “We rely too much on science and not enough on faith” with responses recorded on a 5-point scale from strongly disagree to strongly agree); and (3) their age (in years).\nHistograms will be used to visualise the marginal distributions of attitudes towards science and faith, scientific knowledge, and age. To understand the strength of association among the variables, we will estimate the the correlation coefficients. To address the research question of whether there is an association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age, we are going to fit the following multiple linear regression model:\n\\[\n\\text{Attitude} = \\beta_0  + \\beta_1 \\cdot \\text{Science Knowledge} + \\beta_2 \\cdot \\text{Age} + \\epsilon\n\\] Effects will be considered statistically significant at \\(\\alpha = .05\\).\nOur hypotheses are:\n\\(H_0: \\beta_1 = 0\\): There is no association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age\n\\(H_1: \\beta_1 \\neq 0\\): There is an association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age"
  },
  {
    "objectID": "1_09_bootstrap.html#descriptive-statistics-visualisations",
    "href": "1_09_bootstrap.html#descriptive-statistics-visualisations",
    "title": "Bootstrapping",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nAlongside descriptive statistics, visualise the marginal distributions of the attitude, science_knowledge, and age variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables and data visualisation &gt; marginal distributions - examples flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\n\n# drop columns 5, 6, 7 and 13 from describe output\nebsurvey |&gt; \n    describe() |&gt;\n    select(-c(5:7, 13)) |&gt;\n    kable(caption = \"Attitude, Scientfic Knowledge, and Age Descriptive Statistics\", align = \"c\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Attitude, Scientfic Knowledge, and Age Descriptive Statistics\n\n\nvars\nn\nmean\nsd\nmin\nmax\nrange\nskew\nkurtosis\n\n\n\nscience_knowledge\n1\n10503\n8.68\n2.61\n0\n13\n13\n-0.42\n-0.38\n\n\nage\n2\n10503\n44.93\n17.32\n15\n93\n78\n0.18\n-0.88\n\n\nattitude\n3\n10503\n2.20\n1.22\n0\n4\n4\n-0.25\n-0.87\n\n\n\n\n\n\n\n\n\n\n\n\nAttitude Towards Science & Faith\nScience Knowledge\nAge\n\n\n\n\nggplot(ebsurvey, aes(x = attitude)) +\n    geom_bar() +\n    labs(x = 'We Rely too Much on Science and not Enough on Faith', \n         y = 'Frequency')\n\n\n\nFigure 1: Bar Chart of Attitude Scores\n\n\n\n\n\n\n\n\n\nThe mean score on the science and faith attitude variable is just over 2. There are only 5 discrete values possible in the distribution, based on the response options available, but the distribution looks approximately normal, with a slight negative skew (see Figure 1).\n\n\n\n\n\n\nggplot(ebsurvey, aes(x = science_knowledge)) +\n    geom_histogram() +\n    labs(x = 'Science Knowledge Quiz Scores', \n         y = 'Frequency')\n\n\n\nFigure 2: Histogram of Scientific Knowledge Scores\n\n\n\n\n\n\n\n\n\nFigure 2 shows that the majority of values on the science knowledge quiz score cluster between about 5 and 11. There is a slight negative skew to the distribution. Overall there is little reason for concern as to the appropriateness of the variable for inclusion.\n\n\n\n\n\n\nggplot(ebsurvey, aes(x = age)) +\n    geom_histogram() +\n    labs(x = 'Age (years)', \n         y = 'Frequency')\n\n\n\nFigure 3: Histogram of Age\n\n\n\n\n\n\n\n\n\nThe mean age in the sample is about 45 years with a standard deviation of just over 17 years. The distribution looks approximately normal, with a slight positive skew (see Figure 3).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nProduce plots of the associations between the outcome variable and each of the explanatory variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview how to visually explore bivariate associations via the data explortation flashcards.\nFor specifically visualising associations between variables, see the visual exploration &gt; bivariate associations - examples.\nNote that using geom_point() here might not be the best idea - all we would see from the plot is all combinations of Attitude towards Science and Faith and a) Age and b) Science Knowledge that were observed in the data, and this is not very informative:\n\n\n\n\nFigure 4: Scatterplots displaying the associations between Attitude towards Science and Faith and a) Age, and b) Science Knowledge\n\n\n\nInstead, you may want to consider using geom_jitter() to add a little bit of noise (or jitter) to the plot. Within the geom_jitter() argument, take some time to experiment with the size = and alpha = arguments to find optimal values to aid interpretation.\n\n\n\n\n\n\n\n Solution \n\n\n\np1 &lt;- ggplot(data = ebsurvey, aes(x = age, y = attitude)) +\n    geom_jitter(size = .5, alpha = .3) +\n    labs(x = 'Age (in years)', y = \"Attitude towards Science and Faith\")\n\np2 &lt;- ggplot(data = ebsurvey, aes(x = science_knowledge, y = attitude)) +\n    geom_jitter(size = .5, alpha = .3)  +\n    labs(x = \"Science Knowledge Quiz Scores\", y = \"Attitude towards Science and Faith\")\n\np1 | p2 \n\n\n\nFigure 5: Scatterplots displaying the associations between Attitude towards Science and Faith and a) Age, and b) Science Knowledge\n\n\n\n\n\n\n\n\n\nIt does not seem like there is a strong linear dependence of attitude to science and faith on a person’s age or their scientific knowledge. We can make some rough observations:\n\nThe majority of respondents scored 2 or 3 (i.e., responded as neutral or agree) on the attitudes towards science and faith question\nVery few people strongly disagreed with the attitudes towards science and faith question, but this appeared to be slightly more common in younger respondents\nVery few people had scientific knowledge quiz scores &lt;5. Lower scientific knowledge quiz scores appeared to be associated with responses of 3 or 4 (i.e., responded as agree or strongly agree) on the attitudes towards science and faith question.\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nProduce a correlation matrix of the variables which are to be used in the analysis, and write a short paragraph describing the associations.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate the correlation coefficient and for examples, see the correlation flashcards. Remember to interpret in the context of the research question.\n\n\n\n\n\n\n\n Solution \n\n\nRecall that we can either index the dataframe or select the variables of interest:\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\n# correlation matrix of the three columns of interest (check which columns we need - in this case, 1,2,3)\nround(cor(ebsurvey[,c(1:3)]), digits = 2)\n\n                  science_knowledge   age attitude\nscience_knowledge              1.00 -0.12    -0.18\nage                           -0.12  1.00     0.05\nattitude                      -0.18  0.05     1.00\n\n\n\n\n\n# select only the columns we want by variable name, and pass this to cor()\nebsurvey |&gt; \n  select(attitude, science_knowledge, age) |&gt;\n  cor() |&gt;\n    kable(digits = 2, caption = \"Correlation Matrix\") |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 2: Correlation Matrix\n\n\nattitude\nscience_knowledge\nage\n\n\n\nattitude\n1.00\n-0.18\n0.05\n\n\nscience_knowledge\n-0.18\n1.00\n-0.12\n\n\nage\n0.05\n-0.12\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere was a weak, positive, linear association between attitude towards science and faith and age for the participants in the sample \\((r = .05)\\)\n\nThere was a weak, negative, linear association between attitude towards science and faith and scientific knowledge for the participants in the sample \\((r = -.18)\\)\n\nThere was a weak, negative, linear association between scientific knowledge and age for the participants in the sample \\((r = -.12)\\). The correlation is relatively small in absolute terms, and we therefore have little concern about multicollinearity influencing this regression analysis\nOverall, there were very weak linear associations among the variables of interest"
  },
  {
    "objectID": "1_09_bootstrap.html#model-fitting-interpretation",
    "href": "1_09_bootstrap.html#model-fitting-interpretation",
    "title": "Bootstrapping",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 6\n\n\nFit the specified model, and assign it the name “att_mdl”.\n\\[\n\\text{Attitude} = \\beta_0  + \\beta_1 \\cdot \\text{Science Knowledge} + \\beta_2 \\cdot \\text{Age} + \\epsilon\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nFor how to format and write your model in RMarkdown, see the LaTeX symbols and equations flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\natt_mdl &lt;- lm(attitude ~ science_knowledge + age, data = ebsurvey)\n\n\n\n\n\n\nQuestion 7\n\n\nCheck the assumptions of your model. Note any violations of the model assumptions.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the assumptions flashcards and consider the most efficient way to do this (might be a good idea to review the useful assumption plots).\n\n\n\n\n\n\n\n Solution \n\n\n\npar(mfrow = c(2,2)) # set 2 by 2 panels\nplot(att_mdl)\npar(mfrow = c(1,1)) # go back to 1 by 1 panels\n\n\n\nFigure 6: Assumption Plots for Attitudes Model\n\n\n\nBased on the visual inspection of the plots, the assumptions appear to be violated.\n\n\n\n\n\nQuestion 8\n\n\nBootstrap your model, computing 1000 bootstrap samples.\nProvide key model results in a formatted table, and interpret your coefficients in the context of the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\nBootstrapping\nReview the bootstrap flashcards for an overview and example.\nInterpretation\n\nIntercept: The intercept of a multiple regression model can be interpreted as the average expected value of the dependent variable when all of the independent variables equal zero.\nScientific Knowledge: This represents the average marginal effect of \\(X1\\) on \\(Y\\), and can be interpreted as the expected change in \\(Y\\) for a one-unit increase in \\(X1\\) controlling for \\(X2\\).\nAge: This represents the average marginal effect of \\(X2\\) on \\(Y\\), and can be interpreted as the expected change in \\(Y\\) for a one-unit increase in \\(X2\\) controlling for \\(X1\\).\n\nSee the multiple linear regression models &gt; interpretation of coefficients flashcard for a recap on interpretation.\nTable\nYou can’t use tab_model() here, but instead will need to use kable() and kable_styling(). Check over the tables flashcard, and in particular review the RMD bootcamp lesson which is signposted to.\n\n\n\n\n\n\n\n Solution \n\n\n\n#Run model\nboot_mdl &lt;- Boot(att_mdl, R = 1000)\n\n\nsummary(boot_mdl) |&gt;\n    kable(digits = 3, caption = 'Bootstrap Regression Results for Attitudes Model') |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 3: Bootstrap Regression Results for Attitudes Model\n\n\nR\noriginal\nbootBias\nbootSE\nbootMed\n\n\n\n(Intercept)\n1000\n2.788\n0.002\n0.053\n2.790\n\n\nscience_knowledge\n1000\n-0.080\n0.000\n0.004\n-0.080\n\n\nage\n1000\n0.002\n0.000\n0.001\n0.002\n\n\n\n\n\n\n\n\n\n\nIntercept\nScientific knowledge\nAge\n\n\n\n\nAs presented in Table 3, the estimated intercept was approximately 2.79. This represents the expected attitude towards science and faith score when all other variables were zero.\nIn this case, only a handful of respondents had a scientific knowledge quiz score of zero, and nobody was aged zero. Hence, in this example, the intercept itself isn’t very informative.\n\nA way to improve the model here to aid interpretation would be to mean centre age, and then refit the model with the mean centred age variable!\n\n\n\n\n\n\nAs presented in Table 3, the estimated value for the scientific knowledge slope was estimated to be approximately -0.08\nResults suggested that, holding age constant, for every one point increase in scientific knowledge quiz scores, attitude scores decreased by 0.08 points.\nKeeping in mind the valence of the question wording, this means that those who were more knowledgeable of science tended to be more favorable towards science – i.e. disagreeing with the statement.\n\n\n\n\nAs presented in Table 3, the estimated value for the age slope was estimated to be approximately 0.002\nResults suggested that, holding science knowledge constant, for every one year increase in age, attitude scores increased by 0.002 points.\nKeeping in mind the valence of the question wording, this means that older people tend to be less favorable towards science – i.e. agreeing with the statement.\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nObtain 95% confidence intervals for your bootstrapped model estimates.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the bootstrap flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nYou can use your preferred confidence level here, but by default this is 95%:\n\nConfint(boot_mdl, level = 0.95, type = \"perc\")\n\nBootstrap percent confidence intervals\n\n                      Estimate         2.5 %       97.5 %\n(Intercept)        2.788248712  2.6877669516  2.888953606\nscience_knowledge -0.080276256 -0.0887889092 -0.071671501\nage                0.002379446  0.0009551896  0.003710649\n\n\nIf you want to make it into a nice table, we can use kable():\n\nConfint(boot_mdl, type = \"perc\") |&gt;\n    kable(digits = 3, caption = 'Bootstrap 95% CIs') |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 4: Bootstrap 95% CIs\n\n\nEstimate\n2.5 %\n97.5 %\n\n\n\n(Intercept)\n2.788\n2.688\n2.889\n\n\nscience_knowledge\n-0.080\n-0.089\n-0.072\n\n\nage\n0.002\n0.001\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe are 95% confident that the population intercept is between 2.68 and 2.90\n\nWe are 95% confident that the population slope for science knowledge is between -0.09 and -0.07\n\nWe are 95% confident that the population slope for age is between 0.001 and 0.004"
  },
  {
    "objectID": "1_09_bootstrap.html#writing-up-presenting-results",
    "href": "1_09_bootstrap.html#writing-up-presenting-results",
    "title": "Bootstrapping",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 10\n\n\nInterpret the results from your bootstrapped model in the context of the research question.\nMake reference to your key result table(s) and plot(s).\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake sure to include a decision in relation to your null hypothesis - based on the evidence, should you reject or fail to reject the null?\n\n\n\n\n\n\n\n Solution \n\n\nWe used a subset of data from the 2005 Eurobarometer 63.1 survey to investigate whether there was an association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age.\nTo answer the research hypothesis, we fitted the following regression model: \\[\n\\text{Attitude} = \\beta_0 + \\beta_1 \\cdot \\text{Science Knowledge} + \\beta_2 \\cdot \\text{Age} + \\epsilon\n\\]\nWhich resulted in the following estimated regression coefficients for the original sample:\n\\[\n\\widehat{\\text{Attitude}} = 2.8 -0.08 \\cdot \\text{Science Knowledge} + 0.0024 \\cdot \\text{Age}\n\\]\nThe model did not satisfy the regression assumptions (see Figure 6) and for this reason we assessed statistical significance using the bootstrap approach with \\(R = 1000\\) resamples.\nThe 95% bootstrap confidence intervals are provided in Table 4. Results suggested that there was a negative and statistically significant association between attitudes towards science and faith and scientific knowledge after controlling for age \\((\\beta = -0.08, CI_{95}[-0.09, -0.07])\\). Since the 95% CI did not contain zero, we rejected the null hypothesis as there was evidence of an association between peoples’ attitudes towards science and faith and their scientific knowledge after accounting for their age. Specifically, results suggested that for every additional quiz question people got correct, we expected their attitude score to be lower by about 0.08 points, holding age constant. In other words, respondents with greater scientific knowledge tended to be more favorable towards it, regardless of their age."
  },
  {
    "objectID": "1_09_bootstrap_walnut.html",
    "href": "1_09_bootstrap_walnut.html",
    "title": "Bootstrapping",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the principles of bootstrapping\nUnderstand how to apply the bootstrap confidence interval to inference in linear models\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 2 and Week 9\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\ncar\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/science-faith-attitude.csv"
  },
  {
    "objectID": "1_09_bootstrap_walnut.html#study-overview-data-management",
    "href": "1_09_bootstrap_walnut.html#study-overview-data-management",
    "title": "Bootstrapping",
    "section": "Study Overview & Data Management",
    "text": "Study Overview & Data Management\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\nNote, to address the research question, we only need to refer to the kstot, age, and toomuchscience variables. Subset the data to only have those 3 columns.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nTo subset the data to only include the 3 variables of interest, we can use the select() function\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\nThere are numerous ways to deal with this. Two common commands are na.omit() and drop_na(). The former will remove all rows from a dataset that contain NA values in any column. In the latter, we can specify which columns we want to identify NA values in, and remove only rows containing NA values for those specific columns. In other words, the latter can help to preserve more data\n\n\n\nIf needed, provide better variable names\n\n\n\n\n\n\n\n\n Solution \n\n\n\n# Inspect top 6 rows\nhead(ebsurvey)\n\n# A tibble: 6 × 7\n     v5    v6 kstot   age  male toomuchscience solveprob\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1     1     2    12    35     1              2         0\n2     2     2    11    34     0              1         1\n3     3     2     7    40     0             NA        NA\n4     4     2     9    32     0              3         0\n5     5     2     6    35     0              3         1\n6     6     2    11    67     1             NA        NA\n\n# Check data dimensions\ndim(ebsurvey)\n\n[1] 21886     7\n\n\nThere are 21886 observations on 7 variables.\nHowever, today we will be only using the kstot, age, and toomuchscience variables, and so we subset the data to only include these:\n\nebsurvey &lt;- ebsurvey |&gt;\n    select(kstot, age, toomuchscience)\n\nAre there any NA values in the data?\n\n#check for NAs\nanyNA(ebsurvey)\n\n[1] TRUE\n\n#how many NAs?\ntable(is.na(ebsurvey))\n\n\nFALSE  TRUE \n54268 11390 \n\n#11390 NAs in data set \n\n#Omit the NAs - we are interested in all three columns so do not need to specify within drop_na()\nebsurvey &lt;- ebsurvey |&gt;\n    drop_na()\n\n# Check new data dimensions\ndim(ebsurvey)\n\n[1] 10503     3\n\n\nGive the variables more meaningful names. Rename kstot to science_knowledge and rename toomuchscience to attitude:\n\nebsurvey &lt;- ebsurvey |&gt;\n    rename(science_knowledge = kstot,\n           attitude = toomuchscience)\nhead(ebsurvey)\n\n# A tibble: 6 × 3\n  science_knowledge   age attitude\n              &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1                12    35        2\n2                11    34        1\n3                 9    32        3\n4                 6    35        3\n5                 9    37        1\n6                 5    63        2\n\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of any categorical variable(s))\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook. The statistical models flashcards may also be useful to refer to.\n\n\n\n\n\n\n\n Solution \n\n\nThe ebsurvey dataset, excluding missing values, included 10,503 individual respondents who were measured on 3 different attributes of interest: (1) score on a science “quiz” composed of 13 true/false items; (2) attitudes towards science and faith (question phrasing: “We rely too much on science and not enough on faith” with responses recorded on a 5-point scale from strongly disagree to strongly agree); and (3) their age (in years).\nHistograms will be used to visualise the marginal distributions of attitudes towards science and faith, scientific knowledge, and age. To understand the strength of association among the variables, we will estimate the the correlation coefficients. To address the research question of whether there is an association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age, we are going to fit the following multiple linear regression model:\n\\[\n\\text{Attitude} = \\beta_0  + \\beta_1 \\cdot \\text{Science Knowledge} + \\beta_2 \\cdot \\text{Age} + \\epsilon\n\\] Effects will be considered statistically significant at \\(\\alpha = .05\\).\nOur hypotheses are:\n\\(H_0: \\beta_1 = 0\\): There is no association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age\n\\(H_1: \\beta_1 \\neq 0\\): There is an association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age"
  },
  {
    "objectID": "1_09_bootstrap_walnut.html#descriptive-statistics-visualisations",
    "href": "1_09_bootstrap_walnut.html#descriptive-statistics-visualisations",
    "title": "Bootstrapping",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nAlongside descriptive statistics, visualise the marginal distributions of the attitude, science_knowledge, and age variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables and data visualisation &gt; marginal distributions - examples flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\n\n# drop columns 5, 6, 7 and 13 from describe output\nebsurvey |&gt; \n    describe() |&gt;\n    select(-c(5:7, 13)) |&gt;\n    kable(caption = \"Attitude, Scientfic Knowledge, and Age Descriptive Statistics\", align = \"c\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Attitude, Scientfic Knowledge, and Age Descriptive Statistics\n\n\nvars\nn\nmean\nsd\nmin\nmax\nrange\nskew\nkurtosis\n\n\n\nscience_knowledge\n1\n10503\n8.68\n2.61\n0\n13\n13\n-0.42\n-0.38\n\n\nage\n2\n10503\n44.93\n17.32\n15\n93\n78\n0.18\n-0.88\n\n\nattitude\n3\n10503\n2.20\n1.22\n0\n4\n4\n-0.25\n-0.87\n\n\n\n\n\n\n\n\n\n\n\n\nAttitude Towards Science & Faith\nScience Knowledge\nAge\n\n\n\n\nggplot(ebsurvey, aes(x = attitude)) +\n    geom_bar() +\n    labs(x = 'We Rely too Much on Science and not Enough on Faith', \n         y = 'Frequency')\n\n\n\nFigure 1: Bar Chart of Attitude Scores\n\n\n\n\n\n\n\n\n\nThe mean score on the science and faith attitude variable is just over 2. There are only 5 discrete values possible in the distribution, based on the response options available, but the distribution looks approximately normal, with a slight negative skew (see Figure 1).\n\n\n\n\n\n\nggplot(ebsurvey, aes(x = science_knowledge)) +\n    geom_histogram() +\n    labs(x = 'Science Knowledge Quiz Scores', \n         y = 'Frequency')\n\n\n\nFigure 2: Histogram of Scientific Knowledge Scores\n\n\n\n\n\n\n\n\n\nFigure 2 shows that the majority of values on the science knowledge quiz score cluster between about 5 and 11. There is a slight negative skew to the distribution. Overall there is little reason for concern as to the appropriateness of the variable for inclusion.\n\n\n\n\n\n\nggplot(ebsurvey, aes(x = age)) +\n    geom_histogram() +\n    labs(x = 'Age (years)', \n         y = 'Frequency')\n\n\n\nFigure 3: Histogram of Age\n\n\n\n\n\n\n\n\n\nThe mean age in the sample is about 45 years with a standard deviation of just over 17 years. The distribution looks approximately normal, with a slight positive skew (see Figure 3).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nProduce plots of the associations between the outcome variable and each of the explanatory variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview how to visually explore bivariate associations via the data explortation flashcards.\nFor specifically visualising associations between variables, see the visual exploration &gt; bivariate associations - examples.\nNote that using geom_point() here might not be the best idea - all we would see from the plot is all combinations of Attitude towards Science and Faith and a) Age and b) Science Knowledge that were observed in the data, and this is not very informative:\n\n\n\n\nFigure 4: Scatterplots displaying the associations between Attitude towards Science and Faith and a) Age, and b) Science Knowledge\n\n\n\nInstead, you may want to consider using geom_jitter() to add a little bit of noise (or jitter) to the plot. Within the geom_jitter() argument, take some time to experiment with the size = and alpha = arguments to find optimal values to aid interpretation.\n\n\n\n\n\n\n\n Solution \n\n\n\np1 &lt;- ggplot(data = ebsurvey, aes(x = age, y = attitude)) +\n    geom_jitter(size = .5, alpha = .3) +\n    labs(x = 'Age (in years)', y = \"Attitude towards Science and Faith\")\n\np2 &lt;- ggplot(data = ebsurvey, aes(x = science_knowledge, y = attitude)) +\n    geom_jitter(size = .5, alpha = .3)  +\n    labs(x = \"Science Knowledge Quiz Scores\", y = \"Attitude towards Science and Faith\")\n\np1 | p2 \n\n\n\nFigure 5: Scatterplots displaying the associations between Attitude towards Science and Faith and a) Age, and b) Science Knowledge\n\n\n\n\n\n\n\n\n\nIt does not seem like there is a strong linear dependence of attitude to science and faith on a person’s age or their scientific knowledge. We can make some rough observations:\n\nThe majority of respondents scored 2 or 3 (i.e., responded as neutral or agree) on the attitudes towards science and faith question\nVery few people strongly disagreed with the attitudes towards science and faith question, but this appeared to be slightly more common in younger respondents\nVery few people had scientific knowledge quiz scores &lt;5. Lower scientific knowledge quiz scores appeared to be associated with responses of 3 or 4 (i.e., responded as agree or strongly agree) on the attitudes towards science and faith question.\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nProduce a correlation matrix of the variables which are to be used in the analysis, and write a short paragraph describing the associations.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo review how to calculate the correlation coefficient and for examples, see the correlation flashcards. Remember to interpret in the context of the research question.\n\n\n\n\n\n\n\n Solution \n\n\nRecall that we can either index the dataframe or select the variables of interest:\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\n# correlation matrix of the three columns of interest (check which columns we need - in this case, 1,2,3)\nround(cor(ebsurvey[,c(1:3)]), digits = 2)\n\n                  science_knowledge   age attitude\nscience_knowledge              1.00 -0.12    -0.18\nage                           -0.12  1.00     0.05\nattitude                      -0.18  0.05     1.00\n\n\n\n\n\n# select only the columns we want by variable name, and pass this to cor()\nebsurvey |&gt; \n  select(attitude, science_knowledge, age) |&gt;\n  cor() |&gt;\n    kable(digits = 2, caption = \"Correlation Matrix\") |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 2: Correlation Matrix\n\n\nattitude\nscience_knowledge\nage\n\n\n\nattitude\n1.00\n-0.18\n0.05\n\n\nscience_knowledge\n-0.18\n1.00\n-0.12\n\n\nage\n0.05\n-0.12\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere was a weak, positive, linear association between attitude towards science and faith and age for the participants in the sample \\((r = .05)\\)\n\nThere was a weak, negative, linear association between attitude towards science and faith and scientific knowledge for the participants in the sample \\((r = -.18)\\)\n\nThere was a weak, negative, linear association between scientific knowledge and age for the participants in the sample \\((r = -.12)\\). The correlation is relatively small in absolute terms, and we therefore have little concern about multicollinearity influencing this regression analysis\nOverall, there were very weak linear associations among the variables of interest"
  },
  {
    "objectID": "1_09_bootstrap_walnut.html#model-fitting-interpretation",
    "href": "1_09_bootstrap_walnut.html#model-fitting-interpretation",
    "title": "Bootstrapping",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 6\n\n\nFit the specified model, and assign it the name “att_mdl”.\n\\[\n\\text{Attitude} = \\beta_0  + \\beta_1 \\cdot \\text{Science Knowledge} + \\beta_2 \\cdot \\text{Age} + \\epsilon\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nSee the statistical models flashcards, specifically the numeric outcomes & numeric predictors &gt; multiple linear regression models flashcards for a reminder on how to specify models, as well as an example.\nFor how to format and write your model in RMarkdown, see the LaTeX symbols and equations flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\natt_mdl &lt;- lm(attitude ~ science_knowledge + age, data = ebsurvey)\n\n\n\n\n\n\nQuestion 7\n\n\nCheck the assumptions of your model. Note any violations of the model assumptions.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the assumptions flashcards and consider the most efficient way to do this (might be a good idea to review the useful assumption plots).\n\n\n\n\n\n\n\n Solution \n\n\n\npar(mfrow = c(2,2)) # set 2 by 2 panels\nplot(att_mdl)\npar(mfrow = c(1,1)) # go back to 1 by 1 panels\n\n\n\nFigure 6: Assumption Plots for Attitudes Model\n\n\n\nBased on the visual inspection of the plots, the assumptions appear to be violated.\n\n\n\n\n\nQuestion 8\n\n\nBootstrap your model, computing 1000 bootstrap samples.\nProvide key model results in a formatted table, and interpret your coefficients in the context of the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\nBootstrapping\nReview the bootstrap flashcards for an overview and example.\nInterpretation\n\nIntercept: The intercept of a multiple regression model can be interpreted as the average expected value of the dependent variable when all of the independent variables equal zero.\nScientific Knowledge: This represents the average marginal effect of \\(X1\\) on \\(Y\\), and can be interpreted as the expected change in \\(Y\\) for a one-unit increase in \\(X1\\) controlling for \\(X2\\).\nAge: This represents the average marginal effect of \\(X2\\) on \\(Y\\), and can be interpreted as the expected change in \\(Y\\) for a one-unit increase in \\(X2\\) controlling for \\(X1\\).\n\nSee the multiple linear regression models &gt; interpretation of coefficients flashcard for a recap on interpretation.\nTable\nYou can’t use tab_model() here, but instead will need to use kable() and kable_styling(). Check over the tables flashcard, and in particular review the RMD bootcamp lesson which is signposted to.\n\n\n\n\n\n\n\n Solution \n\n\n\n#Run model\nboot_mdl &lt;- Boot(att_mdl, R = 1000)\n\n\nsummary(boot_mdl) |&gt;\n    kable(digits = 3, caption = 'Bootstrap Regression Results for Attitudes Model') |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 3: Bootstrap Regression Results for Attitudes Model\n\n\nR\noriginal\nbootBias\nbootSE\nbootMed\n\n\n\n(Intercept)\n1000\n2.788\n0.002\n0.053\n2.790\n\n\nscience_knowledge\n1000\n-0.080\n0.000\n0.004\n-0.080\n\n\nage\n1000\n0.002\n0.000\n0.001\n0.002\n\n\n\n\n\n\n\n\n\n\nIntercept\nScientific knowledge\nAge\n\n\n\n\nAs presented in Table 3, the estimated intercept was approximately 2.79. This represents the expected attitude towards science and faith score when all other variables were zero.\nIn this case, only a handful of respondents had a scientific knowledge quiz score of zero, and nobody was aged zero. Hence, in this example, the intercept itself isn’t very informative.\n\nA way to improve the model here to aid interpretation would be to mean centre age, and then refit the model with the mean centred age variable!\n\n\n\n\n\n\nAs presented in Table 3, the estimated value for the scientific knowledge slope was estimated to be approximately -0.08\nResults suggested that, holding age constant, for every one point increase in scientific knowledge quiz scores, attitude scores decreased by 0.08 points.\nKeeping in mind the valence of the question wording, this means that those who were more knowledgeable of science tended to be more favorable towards science – i.e. disagreeing with the statement.\n\n\n\n\nAs presented in Table 3, the estimated value for the age slope was estimated to be approximately 0.002\nResults suggested that, holding science knowledge constant, for every one year increase in age, attitude scores increased by 0.002 points.\nKeeping in mind the valence of the question wording, this means that older people tend to be less favorable towards science – i.e. agreeing with the statement.\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nObtain 95% confidence intervals for your bootstrapped model estimates.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the bootstrap flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nYou can use your preferred confidence level here, but by default this is 95%:\n\nConfint(boot_mdl, level = 0.95, type = \"perc\")\n\nBootstrap percent confidence intervals\n\n                      Estimate         2.5 %       97.5 %\n(Intercept)        2.788248712  2.6877669516  2.888953606\nscience_knowledge -0.080276256 -0.0887889092 -0.071671501\nage                0.002379446  0.0009551896  0.003710649\n\n\nIf you want to make it into a nice table, we can use kable():\n\nConfint(boot_mdl, type = \"perc\") |&gt;\n    kable(digits = 3, caption = 'Bootstrap 95% CIs') |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 4: Bootstrap 95% CIs\n\n\nEstimate\n2.5 %\n97.5 %\n\n\n\n(Intercept)\n2.788\n2.688\n2.889\n\n\nscience_knowledge\n-0.080\n-0.089\n-0.072\n\n\nage\n0.002\n0.001\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe are 95% confident that the population intercept is between 2.68 and 2.90\n\nWe are 95% confident that the population slope for science knowledge is between -0.09 and -0.07\n\nWe are 95% confident that the population slope for age is between 0.001 and 0.004"
  },
  {
    "objectID": "1_09_bootstrap_walnut.html#writing-up-presenting-results",
    "href": "1_09_bootstrap_walnut.html#writing-up-presenting-results",
    "title": "Bootstrapping",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 10\n\n\nInterpret the results from your bootstrapped model in the context of the research question.\nMake reference to your key result table(s) and plot(s).\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake sure to include a decision in relation to your null hypothesis - based on the evidence, should you reject or fail to reject the null?\n\n\n\n\n\n\n\n Solution \n\n\nWe used a subset of data from the 2005 Eurobarometer 63.1 survey to investigate whether there was an association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age.\nTo answer the research hypothesis, we fitted the following regression model: \\[\n\\text{Attitude} = \\beta_0 + \\beta_1 \\cdot \\text{Science Knowledge} + \\beta_2 \\cdot \\text{Age} + \\epsilon\n\\]\nWhich resulted in the following estimated regression coefficients for the original sample:\n\\[\n\\widehat{\\text{Attitude}} = 2.8 -0.08 \\cdot \\text{Science Knowledge} + 0.0024 \\cdot \\text{Age}\n\\]\nThe model did not satisfy the regression assumptions (see Figure 6) and for this reason we assessed statistical significance using the bootstrap approach with \\(R = 1000\\) resamples.\nThe 95% bootstrap confidence intervals are provided in Table 4. Results suggested that there was a negative and statistically significant association between attitudes towards science and faith and scientific knowledge after controlling for age \\((\\beta = -0.08, CI_{95}[-0.09, -0.07])\\). Since the 95% CI did not contain zero, we rejected the null hypothesis as there was evidence of an association between peoples’ attitudes towards science and faith and their scientific knowledge after accounting for their age. Specifically, results suggested that for every additional quiz question people got correct, we expected their attitude score to be lower by about 0.08 points, holding age constant. In other words, respondents with greater scientific knowledge tended to be more favorable towards it, regardless of their age."
  },
  {
    "objectID": "1_10_writeup_recap2.html",
    "href": "1_10_writeup_recap2.html",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to write-up and provide interpretation of a linear model with multiple predictors (including categorical)\nUnderstand how to specify dummy and sum-to-zero coding and interpret the model output\nUnderstand how to specify contrasts to test specific effects\nBe able to specify and assess the assumptions underlying a linear model with multiple predictors\nBe able to assess the effect of influential cases on linear model coefficients and overall model evaluations\n\n\nBe up to date with lectures\nHave completed Labs 7 - 10\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\nemmeans\ncar\n\nYou can download the data required for this lab here and here or read the datasets in via these links https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart1.csv and https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart2.csv"
  },
  {
    "objectID": "1_10_writeup_recap2.html#study-overview",
    "href": "1_10_writeup_recap2.html#study-overview",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Aim\nExplore the associations among academic outcomes, student/course characteristics (e.g., class time, online access), and attendance.\n\n\nResearch Questions\n\nRQ1: Does conscientiousness, frequency of access to online materials, and year of study in University predict course attendance?\nRQ2: Is there a difference in attendance between those with early/late classes in comparison to those with midday classes?\nRQ3: Is class attendance associated with final grades?\n\n\n\n Academics data codebook\n\n\nDescription\nThe data used for this write-up exercise are simulated, drawing on a meta-analysis that explored the association between student characteristics and grades. The simulated data are loosely based on the findings of this work, and acted to expand upon the methods and results reported in the paper:\nCredé, M., Roch, S. G., & Kieszczynka, U. M. (2010). Class attendance in college: A meta-analytic review of the relationship of class attendance with grades and student characteristics. Review of Educational Research, 80(2), 272-295. https://doi.org/10.3102/0034654310362998\nThe current study was split into two parts. In the first, researchers were interested in further exploring possible predictors of attendance in university courses. They collected information from 397 students across all years of study (i.e., UG (Y1 - Y4), MSc, and PhD), and recorded their class attendance across the academic year, their level of Conscientiousness (categorized as Low, Moderate, or High), the frequency of which they accessed online course materials (categorized as Rarely, Sometimes, or Often), and the timing of class (categorized as 9AM, 10AM, 11AM, 12PM 1PM, 2PM, 3PM, 4PM). In the second, researchers collected data from 200 students, and recorded their class attendance across the academic year and their final course grade.\nData Dictionary: Part 1\nThe data in DapR2_S1B2_PracticalPart1 contain six attributes collected from a simulated sample of \\(n=397\\) hypothetical individuals, and includes:\n\n\n\n\n\n\n\nVariable\n      Description\n    \n\n\npid\nParticipant ID number\n\n\nAttendance\nTotal attendance (in days)\n\n\nConscientiousness\nConscientiousness (Levels: Low, Moderate, High)\n\n\nTime\nTime of Class (Levels: 9AM, 10AM, 11AM, 12PM, 1PM, 2PM, 3PM, 4PM)\n\n\nOnlineAccess\nFrequency of access to online course materials (Levels: Rarely, Sometimes, Often)\n\n\nYear\nYear of Study in University (Y1, Y2, Y3, Y4, MsC, PhD)\n\n\n\n\n\n\nPreview: Part 1\nThe first six rows of the data are:\n\n\n\n\n\n\n\npid\n      Attendance\n      Conscientiousness\n      Time\n      OnlineAccess\n      Year\n    \n\n\n1\n9\nHigh\n3PM\nOften\nY3\n\n\n2\n10\nHigh\n2PM\nOften\nY3\n\n\n3\n0\nLow\n10AM\nRarely\nY2\n\n\n4\n8\nLow\n4PM\nOften\nY4\n\n\n5\n6\nHigh\n4PM\nSometimes\nY1\n\n\n6\n6\nHigh\n9AM\nSometimes\nY1\n\n\n\n\n\n\nData Dictionary: Part 2\nThe data in DapR2_S1B2_PracticalPart2 contain two attributes collected from a simulated sample of \\(n=200\\) hypothetical individuals, and includes:\n\n\n\n\n\n\n\nVariable\n      Description\n    \n\n\nMarks\nFinal grade (0-100)\n\n\nAttendance\nTotal attendance (in days)\n\n\n\n\n\n\nPreview: Part 2\nThe first six rows of the data are:\n\n\n\n\n\n\n\nMarks\n      Attendance\n    \n\n\n25.18480\n10.5\n\n\n25.83144\n11.0\n\n\n25.42314\n11.5\n\n\n26.36523\n12.0\n\n\n27.44285\n12.5\n\n\n29.04029\n13.0\n\n\n\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the DapR2_S1B2_PracticalPart1 and DapR2_S1B2_PracticalPart2 datasets into R, assigning them to objects named data1 and data2\n\n\n\n\n\n\n Solution \n\n\n\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(sjPlot)\nlibrary(kableExtra)\nlibrary(psych)\nlibrary(emmeans)\nlibrary(car)\n\n#Reading in two datasets and store in objects named 'data1' and  'data2'\ndata1 &lt;- read_csv(\"https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart1.csv\")\ndata2 &lt;- read_csv(\"https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart2.csv\")\n\n#check first six rows of each dataset\nhead(data1)\n\n# A tibble: 6 × 6\n    pid Attendance Conscientiousness Time  OnlineAccess Year \n  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;\n1     1          9 High              3PM   Often        Y3   \n2     2         10 High              2PM   Often        Y3   \n3     3          0 Low               10AM  Rarely       Y2   \n4     4          8 Low               4PM   Often        Y4   \n5     5          6 High              4PM   Sometimes    Y1   \n6     6          6 High              9AM   Sometimes    Y1   \n\nhead(data2)\n\n# A tibble: 6 × 2\n  Marks Attendance\n  &lt;dbl&gt;      &lt;dbl&gt;\n1  25.2       10.5\n2  25.8       11  \n3  25.4       11.5\n4  26.4       12  \n5  27.4       12.5\n6  29.0       13  \n\n\n\n\n\n\nProvided Analysis Code\nBelow you will find the code required to conduct the analysis to address the research questions. This should look similar (in most areas) to what you worked through in lecture.\n\n Provided Analysis Code"
  },
  {
    "objectID": "1_10_writeup_recap2.html#data-management",
    "href": "1_10_writeup_recap2.html#data-management",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Data Management",
    "text": "Data Management\n\n# load libraries\nlibrary(tidyverse) # for all things!\nlibrary(psych) # good for descriptive stats\nlibrary(patchwork) # grouping plots together\nlibrary(kableExtra) # useful for creating nice tables\nlibrary(sjPlot) #regression tables & plots\nlibrary(emmeans) #for contrasts\nlibrary(car) #for assumptions (crPlots, residualPlots, VIF) and bootstrapping\n\n# read in datasets\ndata1 &lt;- read_csv(\"https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart1.csv\")\ndata2 &lt;- read_csv(\"https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart2.csv\")"
  },
  {
    "objectID": "1_10_writeup_recap2.html#overall-rq1",
    "href": "1_10_writeup_recap2.html#overall-rq1",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Overall & RQ1",
    "text": "Overall & RQ1\n\n#######\n# Coding of Variables\n#######\n\n#check coding\nstr(data1)\n\nspc_tbl_ [397 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ pid              : num [1:397] 1 2 3 4 5 6 7 8 9 10 ...\n $ Attendance       : num [1:397] 9 10 0 8 6 6 9 14 5 10 ...\n $ Conscientiousness: chr [1:397] \"High\" \"High\" \"Low\" \"Low\" ...\n $ Time             : chr [1:397] \"3PM\" \"2PM\" \"10AM\" \"4PM\" ...\n $ OnlineAccess     : chr [1:397] \"Often\" \"Often\" \"Rarely\" \"Often\" ...\n $ Year             : chr [1:397] \"Y3\" \"Y3\" \"Y2\" \"Y4\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   pid = col_double(),\n  ..   Attendance = col_double(),\n  ..   Conscientiousness = col_character(),\n  ..   Time = col_character(),\n  ..   OnlineAccess = col_character(),\n  ..   Year = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nstr(data2)\n\nspc_tbl_ [200 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Marks     : num [1:200] 25.2 25.8 25.4 26.4 27.4 ...\n $ Attendance: num [1:200] 10.5 11 11.5 12 12.5 13 13.5 14 14.5 15 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Marks = col_double(),\n  ..   Attendance = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#check for NAs - none in dataset, so no missing values\ntable(is.na(data1))\n\n\nFALSE \n 2382 \n\ntable(is.na(data2))\n\n\nFALSE \n  400 \n\n# make variables factors\ndata1 &lt;- data1 |&gt;\n    mutate(OnlineAccess = as_factor(OnlineAccess),\n           Time = as_factor(Time),\n           Conscientiousness = as_factor(Conscientiousness),\n           Year = as_factor(Year))\n\n#specify reference levels (alternatively use the below tidyverse way like Year - see lecture example code)\ndata1$OnlineAccess &lt;- relevel(data1$OnlineAccess, \"Sometimes\")\ndata1$Conscientiousness &lt;- relevel(data1$Conscientiousness, \"Moderate\")\n\n#ordering of year variable - make chronological, Y1 as reference group\ndata1$Year &lt;- data1$Year |&gt;\n  factor(levels = c('Y1', 'Y2', 'Y3', 'Y4', 'MSc', 'PhD'))"
  },
  {
    "objectID": "1_10_writeup_recap2.html#part-1-data",
    "href": "1_10_writeup_recap2.html#part-1-data",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Part 1 Data",
    "text": "Part 1 Data\nRQ1\n\n###########\n# Descriptive Stats - Data Viz\n###########\n\n# Look at the marginal distributions of variables - use histograms for continuous outcomes, and barplots for categorical: \n\np1 &lt;- ggplot(data1, aes(Attendance)) + \n    geom_histogram() + \n    labs(x = \"Attendance\", y = \"Frequency\")\n\np2 &lt;- ggplot(data1, aes(Conscientiousness)) + \n    geom_bar() + \n    labs(x = \"Conscientiousness Level\", y = \"Frequency\")\n\np3 &lt;- ggplot(data1, aes(Year)) + \n    geom_bar() + \n    labs(x = \"Year of Study\", y = \"Frequency\")\n\np4 &lt;- ggplot(data1, aes(OnlineAccess)) + \n    geom_bar()  + \n    labs(x = \"Frequency of Access to Online Materials\", y = \"Frequency\")\n\np1 / p2 / p3 / p4\n\n\n\n\n\n\n# Look at the bivariate associations (note we are also removing the legend - it does not offer the reader any additional information and takes up space):\n\np5 &lt;- ggplot(data1, aes(x = Conscientiousness, y = Attendance, fill = Conscientiousness)) + \n    geom_boxplot() + \n    labs(x = \"Conscientiousness Level\", y = \"Attendance\") + \n    theme(legend.position = \"none\")\n\np6 &lt;- ggplot(data1, aes(x = OnlineAccess, y = Attendance, fill = OnlineAccess)) + \n    geom_boxplot() + \n    labs(x = \"Frequency of Access to Online Materials\", y = \"Attendance\") + \n    theme(legend.position = \"none\")\n\np7 &lt;- ggplot(data1, aes(x = Year, y = Attendance, fill = Year)) + \n    geom_boxplot() + \n    labs(x = \"Year of Study\", y = \"Attendance\") + \n    theme(legend.position = \"none\")\n\np5 / p6 / p7\n\n\n\n\n\n\n\n\n#######\n#Descriptive Stats - Numeric\n#######\n\n# check how many observations in each category\ntable(data1$Conscientiousness)\n\n\nModerate     High      Low \n     146      124      127 \n\ntable(data1$OnlineAccess)\n\n\nSometimes     Often    Rarely \n      170       126       101 \n\ntable(data1$Year)\n\n\n Y1  Y2  Y3  Y4 MSc PhD \n 89 100  66  71  48  23 \n\ndata1 |&gt;\n  group_by(Year, OnlineAccess, Conscientiousness) |&gt;\n  summarise(n = n(), \n            Mean = mean(Attendance), \n            SD = sd(Attendance),\n            Minimum = min(Attendance),\n            Maximum = max(Attendance)) |&gt;\n    kable(caption = \"Attendance and Academic Year, Frequency of Online Material Access, Conscientiousness Descriptive Statistics\", digits = 2) %&gt;%\n    kable_styling()   \n\n\nAttendance and Academic Year, Frequency of Online Material Access, Conscientiousness Descriptive Statistics\n\nYear\nOnlineAccess\nConscientiousness\nn\nMean\nSD\nMinimum\nMaximum\n\n\n\nY1\nSometimes\nModerate\n18\n25.33\n7.31\n14\n41\n\n\nY1\nSometimes\nHigh\n12\n27.92\n15.41\n6\n43\n\n\nY1\nSometimes\nLow\n7\n19.43\n8.98\n5\n33\n\n\nY1\nOften\nModerate\n12\n24.67\n7.66\n11\n36\n\n\nY1\nOften\nHigh\n7\n36.29\n10.89\n21\n49\n\n\nY1\nOften\nLow\n5\n18.60\n15.27\n7\n45\n\n\nY1\nRarely\nModerate\n7\n25.57\n11.28\n8\n40\n\n\nY1\nRarely\nHigh\n5\n31.60\n13.52\n9\n43\n\n\nY1\nRarely\nLow\n16\n14.19\n10.70\n2\n42\n\n\nY2\nSometimes\nModerate\n20\n34.00\n12.19\n5\n60\n\n\nY2\nSometimes\nHigh\n14\n41.36\n5.17\n32\n52\n\n\nY2\nSometimes\nLow\n11\n21.27\n20.51\n0\n54\n\n\nY2\nOften\nModerate\n13\n30.62\n11.62\n14\n51\n\n\nY2\nOften\nHigh\n10\n42.80\n9.51\n24\n53\n\n\nY2\nOften\nLow\n6\n15.33\n4.68\n10\n23\n\n\nY2\nRarely\nModerate\n8\n24.00\n6.12\n14\n31\n\n\nY2\nRarely\nHigh\n9\n31.33\n8.87\n15\n43\n\n\nY2\nRarely\nLow\n9\n10.33\n5.96\n0\n18\n\n\nY3\nSometimes\nModerate\n8\n34.62\n7.60\n27\n46\n\n\nY3\nSometimes\nHigh\n10\n38.60\n14.01\n1\n50\n\n\nY3\nSometimes\nLow\n8\n20.00\n17.03\n3\n41\n\n\nY3\nOften\nModerate\n3\n19.33\n19.01\n0\n38\n\n\nY3\nOften\nHigh\n6\n30.17\n16.22\n9\n43\n\n\nY3\nOften\nLow\n12\n14.83\n7.41\n8\n33\n\n\nY3\nRarely\nModerate\n7\n25.86\n8.69\n11\n39\n\n\nY3\nRarely\nHigh\n4\n35.00\n4.40\n30\n40\n\n\nY3\nRarely\nLow\n8\n23.38\n14.72\n9\n46\n\n\nY4\nSometimes\nModerate\n12\n37.25\n10.57\n22\n55\n\n\nY4\nSometimes\nHigh\n10\n38.70\n5.19\n30\n45\n\n\nY4\nSometimes\nLow\n9\n23.78\n10.23\n11\n38\n\n\nY4\nOften\nModerate\n8\n21.62\n12.65\n9\n42\n\n\nY4\nOften\nHigh\n7\n34.57\n16.21\n11\n60\n\n\nY4\nOften\nLow\n12\n17.75\n14.59\n6\n48\n\n\nY4\nRarely\nModerate\n5\n29.00\n11.55\n9\n38\n\n\nY4\nRarely\nHigh\n4\n34.75\n12.84\n22\n52\n\n\nY4\nRarely\nLow\n4\n13.50\n5.97\n6\n20\n\n\nMSc\nSometimes\nModerate\n5\n34.80\n11.78\n25\n53\n\n\nMSc\nSometimes\nHigh\n8\n42.00\n6.99\n31\n51\n\n\nMSc\nSometimes\nLow\n8\n19.12\n9.39\n8\n38\n\n\nMSc\nOften\nModerate\n5\n22.00\n13.34\n9\n44\n\n\nMSc\nOften\nHigh\n8\n43.00\n5.81\n37\n54\n\n\nMSc\nOften\nLow\n5\n19.20\n1.92\n16\n21\n\n\nMSc\nRarely\nModerate\n4\n31.00\n12.83\n16\n44\n\n\nMSc\nRarely\nHigh\n2\n45.00\n5.66\n41\n49\n\n\nMSc\nRarely\nLow\n3\n12.67\n9.61\n4\n23\n\n\nPhD\nSometimes\nModerate\n4\n38.50\n9.11\n25\n44\n\n\nPhD\nSometimes\nHigh\n4\n42.75\n3.50\n39\n47\n\n\nPhD\nSometimes\nLow\n2\n47.00\n4.24\n44\n50\n\n\nPhD\nOften\nModerate\n3\n39.00\n19.31\n22\n60\n\n\nPhD\nOften\nHigh\n2\n48.00\n4.24\n45\n51\n\n\nPhD\nOften\nLow\n2\n34.50\n27.58\n15\n54\n\n\nPhD\nRarely\nModerate\n4\n34.25\n7.14\n24\n40\n\n\nPhD\nRarely\nHigh\n2\n25.50\n9.19\n19\n32\n\n\n\n\n\n\n#######\n# Model Building\n#######\n\n#build model\nm1 &lt;- lm(Attendance ~ Conscientiousness + OnlineAccess + Year, data = data1)\n\n#check model summary\nsummary(m1)\n\n\nCall:\nlm(formula = Attendance ~ Conscientiousness + OnlineAccess + \n    Year, data = data1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-37.657  -6.990  -0.279   6.085  31.844 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             27.874      1.533  18.179  &lt; 2e-16 ***\nConscientiousnessHigh    7.366      1.392   5.292 2.03e-07 ***\nConscientiousnessLow   -10.292      1.399  -7.359 1.12e-12 ***\nOnlineAccessOften       -3.533      1.339  -2.639 0.008649 ** \nOnlineAccessRarely      -5.378      1.441  -3.732 0.000218 ***\nYearY2                   4.574      1.657   2.760 0.006049 ** \nYearY3                   3.418      1.853   1.844 0.065926 .  \nYearY4                   4.266      1.817   2.347 0.019418 *  \nYearMSc                  5.649      2.046   2.760 0.006051 ** \nYearPhD                 12.484      2.661   4.692 3.76e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 387 degrees of freedom\nMultiple R-squared:  0.3574,    Adjusted R-squared:  0.3424 \nF-statistic: 23.91 on 9 and 387 DF,  p-value: &lt; 2.2e-16\n\n\n\n#######\n# Check Assumptions of m1\n#######\n\n# Linearity: Can be assumed as working with categorical predictors\n\n# Independence of Errors: Using a between-subjects design, so can assume this\n\n# Normality (either use plot(model, which = 2) or hist(model$residuals))\nplot(m1, which = 2, main = \"Normality Assumption Check for m1\")\n\n\n\n\n\n\n# Equal Variances\nresidualPlot(m1, main = \"Equal Variances Assumption Check for m1\")\n\n\n\n\n\n\n#### Overall, assumption checks look fine\n\n\n#######\n#Table for Results\n#######\n\ntab_model(m1,\n          pred.labels = c('Intercept', 'Conscientiousness - High', 'Conscientiousness - Low', 'Online Access - Often', 'Online Access - Rarely', \n                              'UG Y2', 'UG Y3', 'UG Y4', 'MSc', 'PhD'),\n          title = \"RQ1: Regression Table for Attendance Model\")\n\n\nRQ1: Regression Table for Attendance Model\n\n\n \nAttendance\n\n\nPredictors\nEstimates\nCI\np\n\n\nIntercept\n27.87\n24.86 – 30.89\n&lt;0.001\n\n\nConscientiousness - High\n7.37\n4.63 – 10.10\n&lt;0.001\n\n\nConscientiousness - Low\n-10.29\n-13.04 – -7.54\n&lt;0.001\n\n\nOnline Access - Often\n-3.53\n-6.16 – -0.90\n0.009\n\n\nOnline Access - Rarely\n-5.38\n-8.21 – -2.54\n&lt;0.001\n\n\nUG Y2\n4.57\n1.32 – 7.83\n0.006\n\n\nUG Y3\n3.42\n-0.23 – 7.06\n0.066\n\n\nUG Y4\n4.27\n0.69 – 7.84\n0.019\n\n\nMSc\n5.65\n1.63 – 9.67\n0.006\n\n\nPhD\n12.48\n7.25 – 17.72\n&lt;0.001\n\n\nObservations\n397\n\n\nR2 / R2 adjusted\n0.357 / 0.342\n\n\n\n\n\nRQ2\n\n#######\n# Coding of Variables\n#######\n\n#ordering of time variable - make chronological\ndata1$Time &lt;- data1$Time |&gt; \n  factor(levels = c('9AM', '10AM', '11AM','12PM', '1PM', '2PM', '3PM', '4PM'))\n\n\n#######\n#Descriptive Stats\n#######\n\n# Numeric\ndata1 |&gt;\n  group_by(Time) |&gt;\n  summarise(n = n(), \n            Mean = mean(Attendance), \n            SD = sd(Attendance),\n            Minimum = min(Attendance),\n            Maximum = max(Attendance)) |&gt;\n    kable(caption = \"Attendance & Class Time Descriptive Statistics\", digits = 2) |&gt;\n    kable_styling()    \n\n\nAttendance & Class Time Descriptive Statistics\n\nTime\nn\nMean\nSD\nMinimum\nMaximum\n\n\n\n9AM\n56\n20.12\n10.08\n1\n49\n\n\n10AM\n48\n27.00\n14.23\n0\n60\n\n\n11AM\n46\n27.78\n14.57\n2\n52\n\n\n12PM\n47\n31.30\n14.11\n0\n55\n\n\n1PM\n45\n33.47\n14.44\n4\n60\n\n\n2PM\n46\n32.43\n12.44\n0\n60\n\n\n3PM\n52\n31.67\n13.58\n5\n54\n\n\n4PM\n57\n24.75\n13.78\n4\n54\n\n\n\n\n# check how many observations in each category\ntable(data1$Time)\n\n\n 9AM 10AM 11AM 12PM  1PM  2PM  3PM  4PM \n  56   48   46   47   45   46   52   57 \n\n# Visual\np8 &lt;- ggplot(data1, aes(Time)) + \n    geom_bar()\n\np9 &lt;- ggplot(data1, aes(x = Time, y = Attendance, fill = Time)) + \n    geom_boxplot()\n\np8 / p9\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\n#build model \nm2 &lt;- lm(Attendance ~ Time, data = data1)\n\n#check summary\nsummary(m2)\n\n\nCall:\nlm(formula = Attendance ~ Time, data = data1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.435 -10.298   1.327  10.246  33.000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   20.125      1.793  11.226  &lt; 2e-16 ***\nTime10AM       6.875      2.639   2.605  0.00953 ** \nTime11AM       7.658      2.669   2.869  0.00435 ** \nTime12PM      11.173      2.654   4.210 3.17e-05 ***\nTime1PM       13.342      2.686   4.968 1.02e-06 ***\nTime2PM       12.310      2.669   4.611 5.43e-06 ***\nTime3PM       11.548      2.583   4.470 1.03e-05 ***\nTime4PM        4.629      2.524   1.834  0.06740 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.41 on 389 degrees of freedom\nMultiple R-squared:  0.0974,    Adjusted R-squared:  0.08116 \nF-statistic: 5.997 on 7 and 389 DF,  p-value: 1.196e-06\n\n\n\n#######\n# Check Assumptions of m2\n#######\n\n# Linearity: Can be assumed as working with categorical predictors\n\n# Independence of Errors: Using a between-subjects design, so can assume this\n\n# Normality (either use plot(model, which = 2) or hist(model$residuals))\nplot(m2, which = 2)\n\n\n\n\n\n\n# Equal Variances\nresidualPlot(m2)\n\n\n\n\n\n\n#### Overall, assumption checks look fine\n\n\n#######\n#Contrast\n#######\n\n#Morning/Evening vs Afternoon\n\n#check order\nlevels(data1$Time)\n\n[1] \"9AM\"  \"10AM\" \"11AM\" \"12PM\" \"1PM\"  \"2PM\"  \"3PM\"  \"4PM\" \n\n#table of weights to present in table 1 analysis strategy\nTimePeriod &lt;- c(\"Early/Late\", \"Early/Late\", \"Midday\", \"Midday\", \"Midday\", \"Midday\", \"Early/Late\", \"Early/Late\")\nTime &lt;- c(\"9AM\", \"10AM\", \"11AM\", \"12PM\", \"1PM\", \"2PM\", \"3PM\", \"4PM\")\nWeight &lt;- c(1/4, 1/4, -1/4, -1/4, -1/4, -1/4, 1/4, 1/4)\nweights &lt;- tibble(TimePeriod, Time, Weight)\n\n\n#get means\ntime_mean &lt;- emmeans(m2, ~Time)\n\n#look at means\ntime_mean\n\n Time emmean   SE  df lower.CL upper.CL\n 9AM    20.1 1.79 389     16.6     23.6\n 10AM   27.0 1.94 389     23.2     30.8\n 11AM   27.8 1.98 389     23.9     31.7\n 12PM   31.3 1.96 389     27.5     35.1\n 1PM    33.5 2.00 389     29.5     37.4\n 2PM    32.4 1.98 389     28.5     36.3\n 3PM    31.7 1.86 389     28.0     35.3\n 4PM    24.8 1.78 389     21.3     28.2\n\nConfidence level used: 0.95 \n\n#plot means\nplot(time_mean)\n\n\n\n\n\n\n#specify weights for contrast\ntime_comp &lt;- list('Early or Late vs Middle of the Day' = c(-1/4,-1/4, 1/4, 1/4, 1/4, 1/4, -1/4, -1/4))\n\n#run contrast analysis\ntime_comp_test &lt;- contrast(time_mean, method = time_comp)\n\n#examine output\ntime_comp_test\n\n contrast                           estimate   SE  df t.ratio p.value\n Early or Late vs Middle of the Day     5.36 1.35 389   3.963  0.0001\n\n#obtain confidence intervals\nconfint(time_comp_test)\n\n contrast                           estimate   SE  df lower.CL upper.CL\n Early or Late vs Middle of the Day     5.36 1.35 389      2.7     8.01\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "1_10_writeup_recap2.html#part-2-data",
    "href": "1_10_writeup_recap2.html#part-2-data",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Part 2 Data",
    "text": "Part 2 Data\nRQ3\n\n#######\n#Descriptive Stats\n#######\n\ndata2 |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;    \n        kable(caption = \"Final Grades & Attendance Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()  \n\n\nFinal Grades & Attendance Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nMarks\n200\n49.79\n15.84\n25.01\n98.2\n\n\nAttendance\n200\n35.25\n14.47\n10.50\n60.0\n\n\n\n\ndata2 |&gt;\n    select(Attendance, Marks) |&gt;\n    cor() |&gt;\n    round(digits = 2)\n\n           Attendance Marks\nAttendance       1.00  0.91\nMarks            0.91  1.00\n\nggplot(data = data2, aes(x = Attendance, y = Marks)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE) + \n    labs(x = \"Attendance (in days)\", y = \"Final Grade\")\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\n#specify model\nm3 &lt;- lm(Marks ~ Attendance, data = data2)\n\n#check summary\nsummary(m3)\n\n\nCall:\nlm(formula = Marks ~ Attendance, data = data2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1477  -4.5210  -0.1861   4.2501  26.8415 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 14.83270    1.25534   11.82   &lt;2e-16 ***\nAttendance   0.99163    0.03296   30.09   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.727 on 198 degrees of freedom\nMultiple R-squared:  0.8205,    Adjusted R-squared:  0.8196 \nF-statistic: 905.3 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n\n\n#######\n# Check Assumptions of m3\n#######\n\n# Linearity (can also use plot(model, which = 1) in place of below)\nggplot(data2, aes(x = Attendance, y = Marks)) + \n    geom_point() + \n    geom_smooth(method = 'lm', se = F) + \n    geom_smooth(method = 'loess', se = F, colour = 'red') + \n    labs(x = \"Attendance\", y = \"Final Grade\", title = \"Scatterplot with linear (blue) and loess (red) lines\")\n\n\n\n\n\n\n# Independence of Errors: Using a between-subjects design, so can assume this\n\n# Normality (either use plot(model, which = 2) or hist(model$residuals))\nplot(m3, which = 2)\n\n\n\n\n\n\n# Equal Variances\nresidualPlot(m3)\n\n\n\n\n\n\n\n\n#######\n# Bootstrap Model\n#######\n\n# use 1000 resamples\nboot_m3 &lt;- Boot(m3, R = 1000)\n\n#check summary\nsummary(boot_m3)\n\n\nNumber of bootstrap replications R = 1000 \n            original   bootBias  bootSE bootMed\n(Intercept) 14.83270  0.0598374 1.02249 14.9135\nAttendance   0.99163 -0.0022338 0.03595  0.9882\n\n#confidence intervals\nconfint(boot_m3)\n\nBootstrap bca confidence intervals\n\n                 2.5 %    97.5 %\n(Intercept) 12.5939583 16.644285\nAttendance   0.9294931  1.074284"
  },
  {
    "objectID": "1_10_writeup_recap2_lilac.html",
    "href": "1_10_writeup_recap2_lilac.html",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to write-up and provide interpretation of a linear model with multiple predictors (including categorical)\nUnderstand how to specify dummy and sum-to-zero coding and interpret the model output\nUnderstand how to specify contrasts to test specific effects\nBe able to specify and assess the assumptions underlying a linear model with multiple predictors\nBe able to assess the effect of influential cases on linear model coefficients and overall model evaluations\n\n\nBe up to date with lectures\nHave completed Labs 7 - 10\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\nemmeans\ncar\n\nYou can download the data required for this lab here and here or read the datasets in via these links https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart1.csv and https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart2.csv"
  },
  {
    "objectID": "1_10_writeup_recap2_lilac.html#study-overview",
    "href": "1_10_writeup_recap2_lilac.html#study-overview",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Aim\nExplore the associations among academic outcomes, student/course characteristics (e.g., class time, online access), and attendance.\n\n\nResearch Questions\n\nRQ1: Does conscientiousness, frequency of access to online materials, and year of study in University predict course attendance?\nRQ2: Is there a difference in attendance between those with early/late classes in comparison to those with midday classes?\nRQ3: Is class attendance associated with final grades?\n\n\n\n Academics data codebook\n\n\nDescription\nThe data used for this write-up exercise are simulated, drawing on a meta-analysis that explored the association between student characteristics and grades. The simulated data are loosely based on the findings of this work, and acted to expand upon the methods and results reported in the paper:\nCredé, M., Roch, S. G., & Kieszczynka, U. M. (2010). Class attendance in college: A meta-analytic review of the relationship of class attendance with grades and student characteristics. Review of Educational Research, 80(2), 272-295. https://doi.org/10.3102/0034654310362998\nThe current study was split into two parts. In the first, researchers were interested in further exploring possible predictors of attendance in university courses. They collected information from 397 students across all years of study (i.e., UG (Y1 - Y4), MSc, and PhD), and recorded their class attendance across the academic year, their level of Conscientiousness (categorized as Low, Moderate, or High), the frequency of which they accessed online course materials (categorized as Rarely, Sometimes, or Often), and the timing of class (categorized as 9AM, 10AM, 11AM, 12PM 1PM, 2PM, 3PM, 4PM). In the second, researchers collected data from 200 students, and recorded their class attendance across the academic year and their final course grade.\nData Dictionary: Part 1\nThe data in DapR2_S1B2_PracticalPart1 contain six attributes collected from a simulated sample of \\(n=397\\) hypothetical individuals, and includes:\n\n\n\n\n\n\n\nVariable\n      Description\n    \n\n\npid\nParticipant ID number\n\n\nAttendance\nTotal attendance (in days)\n\n\nConscientiousness\nConscientiousness (Levels: Low, Moderate, High)\n\n\nTime\nTime of Class (Levels: 9AM, 10AM, 11AM, 12PM, 1PM, 2PM, 3PM, 4PM)\n\n\nOnlineAccess\nFrequency of access to online course materials (Levels: Rarely, Sometimes, Often)\n\n\nYear\nYear of Study in University (Y1, Y2, Y3, Y4, MsC, PhD)\n\n\n\n\n\n\nPreview: Part 1\nThe first six rows of the data are:\n\n\n\n\n\n\n\npid\n      Attendance\n      Conscientiousness\n      Time\n      OnlineAccess\n      Year\n    \n\n\n1\n9\nHigh\n3PM\nOften\nY3\n\n\n2\n10\nHigh\n2PM\nOften\nY3\n\n\n3\n0\nLow\n10AM\nRarely\nY2\n\n\n4\n8\nLow\n4PM\nOften\nY4\n\n\n5\n6\nHigh\n4PM\nSometimes\nY1\n\n\n6\n6\nHigh\n9AM\nSometimes\nY1\n\n\n\n\n\n\nData Dictionary: Part 2\nThe data in DapR2_S1B2_PracticalPart2 contain two attributes collected from a simulated sample of \\(n=200\\) hypothetical individuals, and includes:\n\n\n\n\n\n\n\nVariable\n      Description\n    \n\n\nMarks\nFinal grade (0-100)\n\n\nAttendance\nTotal attendance (in days)\n\n\n\n\n\n\nPreview: Part 2\nThe first six rows of the data are:\n\n\n\n\n\n\n\nMarks\n      Attendance\n    \n\n\n25.18480\n10.5\n\n\n25.83144\n11.0\n\n\n25.42314\n11.5\n\n\n26.36523\n12.0\n\n\n27.44285\n12.5\n\n\n29.04029\n13.0\n\n\n\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the DapR2_S1B2_PracticalPart1 and DapR2_S1B2_PracticalPart2 datasets into R, assigning them to objects named data1 and data2\n\n\n\n\n\n\n Solution \n\n\n\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(sjPlot)\nlibrary(kableExtra)\nlibrary(psych)\nlibrary(emmeans)\nlibrary(car)\n\n#Reading in two datasets and store in objects named 'data1' and  'data2'\ndata1 &lt;- read_csv(\"https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart1.csv\")\ndata2 &lt;- read_csv(\"https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart2.csv\")\n\n#check first six rows of each dataset\nhead(data1)\n\n# A tibble: 6 × 6\n    pid Attendance Conscientiousness Time  OnlineAccess Year \n  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;\n1     1          9 High              3PM   Often        Y3   \n2     2         10 High              2PM   Often        Y3   \n3     3          0 Low               10AM  Rarely       Y2   \n4     4          8 Low               4PM   Often        Y4   \n5     5          6 High              4PM   Sometimes    Y1   \n6     6          6 High              9AM   Sometimes    Y1   \n\nhead(data2)\n\n# A tibble: 6 × 2\n  Marks Attendance\n  &lt;dbl&gt;      &lt;dbl&gt;\n1  25.2       10.5\n2  25.8       11  \n3  25.4       11.5\n4  26.4       12  \n5  27.4       12.5\n6  29.0       13  \n\n\n\n\n\n\nProvided Analysis Code\nBelow you will find the code required to conduct the analysis to address the research questions. This should look similar (in most areas) to what you worked through in lecture.\n\n Provided Analysis Code"
  },
  {
    "objectID": "1_10_writeup_recap2_lilac.html#data-management",
    "href": "1_10_writeup_recap2_lilac.html#data-management",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Data Management",
    "text": "Data Management\n\n# load libraries\nlibrary(tidyverse) # for all things!\nlibrary(psych) # good for descriptive stats\nlibrary(patchwork) # grouping plots together\nlibrary(kableExtra) # useful for creating nice tables\nlibrary(sjPlot) #regression tables & plots\nlibrary(emmeans) #for contrasts\nlibrary(car) #for assumptions (crPlots, residualPlots, VIF) and bootstrapping\n\n# read in datasets\ndata1 &lt;- read_csv(\"https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart1.csv\")\ndata2 &lt;- read_csv(\"https://uoepsy.github.io/data/DapR2_S1B2_PracticalPart2.csv\")"
  },
  {
    "objectID": "1_10_writeup_recap2_lilac.html#overall-rq1",
    "href": "1_10_writeup_recap2_lilac.html#overall-rq1",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Overall & RQ1",
    "text": "Overall & RQ1\n\n#######\n# Coding of Variables\n#######\n\n#check coding\nstr(data1)\n\nspc_tbl_ [397 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ pid              : num [1:397] 1 2 3 4 5 6 7 8 9 10 ...\n $ Attendance       : num [1:397] 9 10 0 8 6 6 9 14 5 10 ...\n $ Conscientiousness: chr [1:397] \"High\" \"High\" \"Low\" \"Low\" ...\n $ Time             : chr [1:397] \"3PM\" \"2PM\" \"10AM\" \"4PM\" ...\n $ OnlineAccess     : chr [1:397] \"Often\" \"Often\" \"Rarely\" \"Often\" ...\n $ Year             : chr [1:397] \"Y3\" \"Y3\" \"Y2\" \"Y4\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   pid = col_double(),\n  ..   Attendance = col_double(),\n  ..   Conscientiousness = col_character(),\n  ..   Time = col_character(),\n  ..   OnlineAccess = col_character(),\n  ..   Year = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nstr(data2)\n\nspc_tbl_ [200 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Marks     : num [1:200] 25.2 25.8 25.4 26.4 27.4 ...\n $ Attendance: num [1:200] 10.5 11 11.5 12 12.5 13 13.5 14 14.5 15 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Marks = col_double(),\n  ..   Attendance = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#check for NAs - none in dataset, so no missing values\ntable(is.na(data1))\n\n\nFALSE \n 2382 \n\ntable(is.na(data2))\n\n\nFALSE \n  400 \n\n# make variables factors\ndata1 &lt;- data1 |&gt;\n    mutate(OnlineAccess = as_factor(OnlineAccess),\n           Time = as_factor(Time),\n           Conscientiousness = as_factor(Conscientiousness),\n           Year = as_factor(Year))\n\n#specify reference levels (alternatively use the below tidyverse way like Year - see lecture example code)\ndata1$OnlineAccess &lt;- relevel(data1$OnlineAccess, \"Sometimes\")\ndata1$Conscientiousness &lt;- relevel(data1$Conscientiousness, \"Moderate\")\n\n#ordering of year variable - make chronological, Y1 as reference group\ndata1$Year &lt;- data1$Year |&gt;\n  factor(levels = c('Y1', 'Y2', 'Y3', 'Y4', 'MSc', 'PhD'))"
  },
  {
    "objectID": "1_10_writeup_recap2_lilac.html#part-1-data",
    "href": "1_10_writeup_recap2_lilac.html#part-1-data",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Part 1 Data",
    "text": "Part 1 Data\nRQ1\n\n###########\n# Descriptive Stats - Data Viz\n###########\n\n# Look at the marginal distributions of variables - use histograms for continuous outcomes, and barplots for categorical: \n\np1 &lt;- ggplot(data1, aes(Attendance)) + \n    geom_histogram() + \n    labs(x = \"Attendance\", y = \"Frequency\")\n\np2 &lt;- ggplot(data1, aes(Conscientiousness)) + \n    geom_bar() + \n    labs(x = \"Conscientiousness Level\", y = \"Frequency\")\n\np3 &lt;- ggplot(data1, aes(Year)) + \n    geom_bar() + \n    labs(x = \"Year of Study\", y = \"Frequency\")\n\np4 &lt;- ggplot(data1, aes(OnlineAccess)) + \n    geom_bar()  + \n    labs(x = \"Frequency of Access to Online Materials\", y = \"Frequency\")\n\np1 / p2 / p3 / p4\n\n\n\n\n\n\n# Look at the bivariate associations (note we are also removing the legend - it does not offer the reader any additional information and takes up space):\n\np5 &lt;- ggplot(data1, aes(x = Conscientiousness, y = Attendance, fill = Conscientiousness)) + \n    geom_boxplot() + \n    labs(x = \"Conscientiousness Level\", y = \"Attendance\") + \n    theme(legend.position = \"none\")\n\np6 &lt;- ggplot(data1, aes(x = OnlineAccess, y = Attendance, fill = OnlineAccess)) + \n    geom_boxplot() + \n    labs(x = \"Frequency of Access to Online Materials\", y = \"Attendance\") + \n    theme(legend.position = \"none\")\n\np7 &lt;- ggplot(data1, aes(x = Year, y = Attendance, fill = Year)) + \n    geom_boxplot() + \n    labs(x = \"Year of Study\", y = \"Attendance\") + \n    theme(legend.position = \"none\")\n\np5 / p6 / p7\n\n\n\n\n\n\n\n\n#######\n#Descriptive Stats - Numeric\n#######\n\n# check how many observations in each category\ntable(data1$Conscientiousness)\n\n\nModerate     High      Low \n     146      124      127 \n\ntable(data1$OnlineAccess)\n\n\nSometimes     Often    Rarely \n      170       126       101 \n\ntable(data1$Year)\n\n\n Y1  Y2  Y3  Y4 MSc PhD \n 89 100  66  71  48  23 \n\ndata1 |&gt;\n  group_by(Year, OnlineAccess, Conscientiousness) |&gt;\n  summarise(n = n(), \n            Mean = mean(Attendance), \n            SD = sd(Attendance),\n            Minimum = min(Attendance),\n            Maximum = max(Attendance)) |&gt;\n    kable(caption = \"Attendance and Academic Year, Frequency of Online Material Access, Conscientiousness Descriptive Statistics\", digits = 2) %&gt;%\n    kable_styling()   \n\n\nAttendance and Academic Year, Frequency of Online Material Access, Conscientiousness Descriptive Statistics\n\nYear\nOnlineAccess\nConscientiousness\nn\nMean\nSD\nMinimum\nMaximum\n\n\n\nY1\nSometimes\nModerate\n18\n25.33\n7.31\n14\n41\n\n\nY1\nSometimes\nHigh\n12\n27.92\n15.41\n6\n43\n\n\nY1\nSometimes\nLow\n7\n19.43\n8.98\n5\n33\n\n\nY1\nOften\nModerate\n12\n24.67\n7.66\n11\n36\n\n\nY1\nOften\nHigh\n7\n36.29\n10.89\n21\n49\n\n\nY1\nOften\nLow\n5\n18.60\n15.27\n7\n45\n\n\nY1\nRarely\nModerate\n7\n25.57\n11.28\n8\n40\n\n\nY1\nRarely\nHigh\n5\n31.60\n13.52\n9\n43\n\n\nY1\nRarely\nLow\n16\n14.19\n10.70\n2\n42\n\n\nY2\nSometimes\nModerate\n20\n34.00\n12.19\n5\n60\n\n\nY2\nSometimes\nHigh\n14\n41.36\n5.17\n32\n52\n\n\nY2\nSometimes\nLow\n11\n21.27\n20.51\n0\n54\n\n\nY2\nOften\nModerate\n13\n30.62\n11.62\n14\n51\n\n\nY2\nOften\nHigh\n10\n42.80\n9.51\n24\n53\n\n\nY2\nOften\nLow\n6\n15.33\n4.68\n10\n23\n\n\nY2\nRarely\nModerate\n8\n24.00\n6.12\n14\n31\n\n\nY2\nRarely\nHigh\n9\n31.33\n8.87\n15\n43\n\n\nY2\nRarely\nLow\n9\n10.33\n5.96\n0\n18\n\n\nY3\nSometimes\nModerate\n8\n34.62\n7.60\n27\n46\n\n\nY3\nSometimes\nHigh\n10\n38.60\n14.01\n1\n50\n\n\nY3\nSometimes\nLow\n8\n20.00\n17.03\n3\n41\n\n\nY3\nOften\nModerate\n3\n19.33\n19.01\n0\n38\n\n\nY3\nOften\nHigh\n6\n30.17\n16.22\n9\n43\n\n\nY3\nOften\nLow\n12\n14.83\n7.41\n8\n33\n\n\nY3\nRarely\nModerate\n7\n25.86\n8.69\n11\n39\n\n\nY3\nRarely\nHigh\n4\n35.00\n4.40\n30\n40\n\n\nY3\nRarely\nLow\n8\n23.38\n14.72\n9\n46\n\n\nY4\nSometimes\nModerate\n12\n37.25\n10.57\n22\n55\n\n\nY4\nSometimes\nHigh\n10\n38.70\n5.19\n30\n45\n\n\nY4\nSometimes\nLow\n9\n23.78\n10.23\n11\n38\n\n\nY4\nOften\nModerate\n8\n21.62\n12.65\n9\n42\n\n\nY4\nOften\nHigh\n7\n34.57\n16.21\n11\n60\n\n\nY4\nOften\nLow\n12\n17.75\n14.59\n6\n48\n\n\nY4\nRarely\nModerate\n5\n29.00\n11.55\n9\n38\n\n\nY4\nRarely\nHigh\n4\n34.75\n12.84\n22\n52\n\n\nY4\nRarely\nLow\n4\n13.50\n5.97\n6\n20\n\n\nMSc\nSometimes\nModerate\n5\n34.80\n11.78\n25\n53\n\n\nMSc\nSometimes\nHigh\n8\n42.00\n6.99\n31\n51\n\n\nMSc\nSometimes\nLow\n8\n19.12\n9.39\n8\n38\n\n\nMSc\nOften\nModerate\n5\n22.00\n13.34\n9\n44\n\n\nMSc\nOften\nHigh\n8\n43.00\n5.81\n37\n54\n\n\nMSc\nOften\nLow\n5\n19.20\n1.92\n16\n21\n\n\nMSc\nRarely\nModerate\n4\n31.00\n12.83\n16\n44\n\n\nMSc\nRarely\nHigh\n2\n45.00\n5.66\n41\n49\n\n\nMSc\nRarely\nLow\n3\n12.67\n9.61\n4\n23\n\n\nPhD\nSometimes\nModerate\n4\n38.50\n9.11\n25\n44\n\n\nPhD\nSometimes\nHigh\n4\n42.75\n3.50\n39\n47\n\n\nPhD\nSometimes\nLow\n2\n47.00\n4.24\n44\n50\n\n\nPhD\nOften\nModerate\n3\n39.00\n19.31\n22\n60\n\n\nPhD\nOften\nHigh\n2\n48.00\n4.24\n45\n51\n\n\nPhD\nOften\nLow\n2\n34.50\n27.58\n15\n54\n\n\nPhD\nRarely\nModerate\n4\n34.25\n7.14\n24\n40\n\n\nPhD\nRarely\nHigh\n2\n25.50\n9.19\n19\n32\n\n\n\n\n\n\n#######\n# Model Building\n#######\n\n#build model\nm1 &lt;- lm(Attendance ~ Conscientiousness + OnlineAccess + Year, data = data1)\n\n#check model summary\nsummary(m1)\n\n\nCall:\nlm(formula = Attendance ~ Conscientiousness + OnlineAccess + \n    Year, data = data1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-37.657  -6.990  -0.279   6.085  31.844 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             27.874      1.533  18.179  &lt; 2e-16 ***\nConscientiousnessHigh    7.366      1.392   5.292 2.03e-07 ***\nConscientiousnessLow   -10.292      1.399  -7.359 1.12e-12 ***\nOnlineAccessOften       -3.533      1.339  -2.639 0.008649 ** \nOnlineAccessRarely      -5.378      1.441  -3.732 0.000218 ***\nYearY2                   4.574      1.657   2.760 0.006049 ** \nYearY3                   3.418      1.853   1.844 0.065926 .  \nYearY4                   4.266      1.817   2.347 0.019418 *  \nYearMSc                  5.649      2.046   2.760 0.006051 ** \nYearPhD                 12.484      2.661   4.692 3.76e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.35 on 387 degrees of freedom\nMultiple R-squared:  0.3574,    Adjusted R-squared:  0.3424 \nF-statistic: 23.91 on 9 and 387 DF,  p-value: &lt; 2.2e-16\n\n\n\n#######\n# Check Assumptions of m1\n#######\n\n# Linearity: Can be assumed as working with categorical predictors\n\n# Independence of Errors: Using a between-subjects design, so can assume this\n\n# Normality (either use plot(model, which = 2) or hist(model$residuals))\nplot(m1, which = 2, main = \"Normality Assumption Check for m1\")\n\n\n\n\n\n\n# Equal Variances\nresidualPlot(m1, main = \"Equal Variances Assumption Check for m1\")\n\n\n\n\n\n\n#### Overall, assumption checks look fine\n\n\n#######\n#Table for Results\n#######\n\ntab_model(m1,\n          pred.labels = c('Intercept', 'Conscientiousness - High', 'Conscientiousness - Low', 'Online Access - Often', 'Online Access - Rarely', \n                              'UG Y2', 'UG Y3', 'UG Y4', 'MSc', 'PhD'),\n          title = \"RQ1: Regression Table for Attendance Model\")\n\n\nRQ1: Regression Table for Attendance Model\n\n\n \nAttendance\n\n\nPredictors\nEstimates\nCI\np\n\n\nIntercept\n27.87\n24.86 – 30.89\n&lt;0.001\n\n\nConscientiousness - High\n7.37\n4.63 – 10.10\n&lt;0.001\n\n\nConscientiousness - Low\n-10.29\n-13.04 – -7.54\n&lt;0.001\n\n\nOnline Access - Often\n-3.53\n-6.16 – -0.90\n0.009\n\n\nOnline Access - Rarely\n-5.38\n-8.21 – -2.54\n&lt;0.001\n\n\nUG Y2\n4.57\n1.32 – 7.83\n0.006\n\n\nUG Y3\n3.42\n-0.23 – 7.06\n0.066\n\n\nUG Y4\n4.27\n0.69 – 7.84\n0.019\n\n\nMSc\n5.65\n1.63 – 9.67\n0.006\n\n\nPhD\n12.48\n7.25 – 17.72\n&lt;0.001\n\n\nObservations\n397\n\n\nR2 / R2 adjusted\n0.357 / 0.342\n\n\n\n\n\nRQ2\n\n#######\n# Coding of Variables\n#######\n\n#ordering of time variable - make chronological\ndata1$Time &lt;- data1$Time |&gt; \n  factor(levels = c('9AM', '10AM', '11AM','12PM', '1PM', '2PM', '3PM', '4PM'))\n\n\n#######\n#Descriptive Stats\n#######\n\n# Numeric\ndata1 |&gt;\n  group_by(Time) |&gt;\n  summarise(n = n(), \n            Mean = mean(Attendance), \n            SD = sd(Attendance),\n            Minimum = min(Attendance),\n            Maximum = max(Attendance)) |&gt;\n    kable(caption = \"Attendance & Class Time Descriptive Statistics\", digits = 2) |&gt;\n    kable_styling()    \n\n\nAttendance & Class Time Descriptive Statistics\n\nTime\nn\nMean\nSD\nMinimum\nMaximum\n\n\n\n9AM\n56\n20.12\n10.08\n1\n49\n\n\n10AM\n48\n27.00\n14.23\n0\n60\n\n\n11AM\n46\n27.78\n14.57\n2\n52\n\n\n12PM\n47\n31.30\n14.11\n0\n55\n\n\n1PM\n45\n33.47\n14.44\n4\n60\n\n\n2PM\n46\n32.43\n12.44\n0\n60\n\n\n3PM\n52\n31.67\n13.58\n5\n54\n\n\n4PM\n57\n24.75\n13.78\n4\n54\n\n\n\n\n# check how many observations in each category\ntable(data1$Time)\n\n\n 9AM 10AM 11AM 12PM  1PM  2PM  3PM  4PM \n  56   48   46   47   45   46   52   57 \n\n# Visual\np8 &lt;- ggplot(data1, aes(Time)) + \n    geom_bar()\n\np9 &lt;- ggplot(data1, aes(x = Time, y = Attendance, fill = Time)) + \n    geom_boxplot()\n\np8 / p9\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\n#build model \nm2 &lt;- lm(Attendance ~ Time, data = data1)\n\n#check summary\nsummary(m2)\n\n\nCall:\nlm(formula = Attendance ~ Time, data = data1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.435 -10.298   1.327  10.246  33.000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   20.125      1.793  11.226  &lt; 2e-16 ***\nTime10AM       6.875      2.639   2.605  0.00953 ** \nTime11AM       7.658      2.669   2.869  0.00435 ** \nTime12PM      11.173      2.654   4.210 3.17e-05 ***\nTime1PM       13.342      2.686   4.968 1.02e-06 ***\nTime2PM       12.310      2.669   4.611 5.43e-06 ***\nTime3PM       11.548      2.583   4.470 1.03e-05 ***\nTime4PM        4.629      2.524   1.834  0.06740 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.41 on 389 degrees of freedom\nMultiple R-squared:  0.0974,    Adjusted R-squared:  0.08116 \nF-statistic: 5.997 on 7 and 389 DF,  p-value: 1.196e-06\n\n\n\n#######\n# Check Assumptions of m2\n#######\n\n# Linearity: Can be assumed as working with categorical predictors\n\n# Independence of Errors: Using a between-subjects design, so can assume this\n\n# Normality (either use plot(model, which = 2) or hist(model$residuals))\nplot(m2, which = 2)\n\n\n\n\n\n\n# Equal Variances\nresidualPlot(m2)\n\n\n\n\n\n\n#### Overall, assumption checks look fine\n\n\n#######\n#Contrast\n#######\n\n#Morning/Evening vs Afternoon\n\n#check order\nlevels(data1$Time)\n\n[1] \"9AM\"  \"10AM\" \"11AM\" \"12PM\" \"1PM\"  \"2PM\"  \"3PM\"  \"4PM\" \n\n#table of weights to present in table 1 analysis strategy\nTimePeriod &lt;- c(\"Early/Late\", \"Early/Late\", \"Midday\", \"Midday\", \"Midday\", \"Midday\", \"Early/Late\", \"Early/Late\")\nTime &lt;- c(\"9AM\", \"10AM\", \"11AM\", \"12PM\", \"1PM\", \"2PM\", \"3PM\", \"4PM\")\nWeight &lt;- c(1/4, 1/4, -1/4, -1/4, -1/4, -1/4, 1/4, 1/4)\nweights &lt;- tibble(TimePeriod, Time, Weight)\n\n\n#get means\ntime_mean &lt;- emmeans(m2, ~Time)\n\n#look at means\ntime_mean\n\n Time emmean   SE  df lower.CL upper.CL\n 9AM    20.1 1.79 389     16.6     23.6\n 10AM   27.0 1.94 389     23.2     30.8\n 11AM   27.8 1.98 389     23.9     31.7\n 12PM   31.3 1.96 389     27.5     35.1\n 1PM    33.5 2.00 389     29.5     37.4\n 2PM    32.4 1.98 389     28.5     36.3\n 3PM    31.7 1.86 389     28.0     35.3\n 4PM    24.8 1.78 389     21.3     28.2\n\nConfidence level used: 0.95 \n\n#plot means\nplot(time_mean)\n\n\n\n\n\n\n#specify weights for contrast\ntime_comp &lt;- list('Early or Late vs Middle of the Day' = c(-1/4,-1/4, 1/4, 1/4, 1/4, 1/4, -1/4, -1/4))\n\n#run contrast analysis\ntime_comp_test &lt;- contrast(time_mean, method = time_comp)\n\n#examine output\ntime_comp_test\n\n contrast                           estimate   SE  df t.ratio p.value\n Early or Late vs Middle of the Day     5.36 1.35 389   3.963  0.0001\n\n#obtain confidence intervals\nconfint(time_comp_test)\n\n contrast                           estimate   SE  df lower.CL upper.CL\n Early or Late vs Middle of the Day     5.36 1.35 389      2.7     8.01\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "1_10_writeup_recap2_lilac.html#part-2-data",
    "href": "1_10_writeup_recap2_lilac.html#part-2-data",
    "title": "Block 2 Analysis & Write-Up Example",
    "section": "Part 2 Data",
    "text": "Part 2 Data\nRQ3\n\n#######\n#Descriptive Stats\n#######\n\ndata2 |&gt;\n    describe() |&gt;\n    select(2:4, 8:9) |&gt;\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) |&gt;    \n        kable(caption = \"Final Grades & Attendance Descriptive Statistics\", digits = 2) |&gt;\n        kable_styling()  \n\n\nFinal Grades & Attendance Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nMarks\n200\n49.79\n15.84\n25.01\n98.2\n\n\nAttendance\n200\n35.25\n14.47\n10.50\n60.0\n\n\n\n\ndata2 |&gt;\n    select(Attendance, Marks) |&gt;\n    cor() |&gt;\n    round(digits = 2)\n\n           Attendance Marks\nAttendance       1.00  0.91\nMarks            0.91  1.00\n\nggplot(data = data2, aes(x = Attendance, y = Marks)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE) + \n    labs(x = \"Attendance (in days)\", y = \"Final Grade\")\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\n#specify model\nm3 &lt;- lm(Marks ~ Attendance, data = data2)\n\n#check summary\nsummary(m3)\n\n\nCall:\nlm(formula = Marks ~ Attendance, data = data2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1477  -4.5210  -0.1861   4.2501  26.8415 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 14.83270    1.25534   11.82   &lt;2e-16 ***\nAttendance   0.99163    0.03296   30.09   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.727 on 198 degrees of freedom\nMultiple R-squared:  0.8205,    Adjusted R-squared:  0.8196 \nF-statistic: 905.3 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n\n\n#######\n# Check Assumptions of m3\n#######\n\n# Linearity (can also use plot(model, which = 1) in place of below)\nggplot(data2, aes(x = Attendance, y = Marks)) + \n    geom_point() + \n    geom_smooth(method = 'lm', se = F) + \n    geom_smooth(method = 'loess', se = F, colour = 'red') + \n    labs(x = \"Attendance\", y = \"Final Grade\", title = \"Scatterplot with linear (blue) and loess (red) lines\")\n\n\n\n\n\n\n# Independence of Errors: Using a between-subjects design, so can assume this\n\n# Normality (either use plot(model, which = 2) or hist(model$residuals))\nplot(m3, which = 2)\n\n\n\n\n\n\n# Equal Variances\nresidualPlot(m3)\n\n\n\n\n\n\n\n\n#######\n# Bootstrap Model\n#######\n\n# use 1000 resamples\nboot_m3 &lt;- Boot(m3, R = 1000)\n\n#check summary\nsummary(boot_m3)\n\n\nNumber of bootstrap replications R = 1000 \n            original   bootBias  bootSE bootMed\n(Intercept) 14.83270  0.0598374 1.02249 14.9135\nAttendance   0.99163 -0.0022338 0.03595  0.9882\n\n#confidence intervals\nconfint(boot_m3)\n\nBootstrap bca confidence intervals\n\n                 2.5 %    97.5 %\n(Intercept) 12.5939583 16.644285\nAttendance   0.9294931  1.074284"
  },
  {
    "objectID": "1_b1_reading.html",
    "href": "1_b1_reading.html",
    "title": "Block 1 Flash Cards",
    "section": "",
    "text": "Within this reading, the following packages are used:\n\ntidyverse\nsjPlot\nkableExtra\npsych\npatchwork\nplotly\n\nNote that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here."
  },
  {
    "objectID": "1_b1_reading.html#numeric-exploration",
    "href": "1_b1_reading.html#numeric-exploration",
    "title": "Block 1 Flash Cards",
    "section": "Numeric Exploration",
    "text": "Numeric Exploration\nNumeric exploration of data involves examining and describing key statistics like mean, median, and standard deviation via descriptives tables; and assessing the associations among variables through correlation coefficients. Exploring our data numerically helps us to identify patterns and associations in the data. When doing so, it is important to contextualise the descriptive statistics within the scope of the research question and associated scales.\nDescriptives\n\n Descriptives Tables\n\n\nThere are numerous packages available that allow us to pull out descriptive statistics from our dataset such as tidyverse and psych.\nWhen we pull out descriptive statistics, it is useful to present these in a well formatted table for your reader. There are lots of different ways of doing this, but one of the most common (and straightforward!) is to use the kable() function from the package kableExtra.\nThis allows us to give our table a clear caption (via caption = \"insert caption here\", align values within columns e.g., center aligned via align = \"??\"), and we can also round to however many decimal places we desire (standard for APA is 2 dp; via digits = ??).\nWe can also add in the function kable_styling(). This is really helpful for customsing your table e.g., the font size, position, and whether or not you want the table full width (as well as lots of other things - check out the helper function!).\nFor an overview of how to make tables in RMarkdown, see Lesson 4 of the RMD bootcamp.\n\n\n\n\n\n Descriptives Tables - Examples\n\n\n\n\nThe tidyverse way\nThe psych way\n\n\n\nWe can use the summarise() function to numerically summarise/describe our data. Some key values we may want to consider extracting are (though not limited to): the mean (via mean(), standard deviation (via sd()), minimum value (via min()), maximum value (via max()), standard error (via se()), and skewness (via skew()).\n\nNumeric values only example:\n\n\n\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# taking the mean and standard deviation of sepal length via the summarize function\n# returning a table with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\niris |&gt;\n    summarize(\n        M_Length = mean(Sepal.Length),\n        SD_Length = sd(Sepal.Length)\n    ) |&gt;\n    kable(caption = \"Sepal Length Descriptives (in cm)\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length Descriptives (in cm)\n\nM_Length\nSD_Length\n\n\n5.84\n0.83\n\n\n\n\n\n\n\n\n\nThe describe() function will produce a table of descriptive statistics. If you would like only a subset of this output (e.g., mean, sd), you can use select() after calling describe() e.g., describe() |&gt; select(mean, sd).\n\nNumeric values only example:\n\n\n\nlibrary(psych)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# we want to get descriptive statistics of the iris dataset, specifically the sepal length column\n# we specifically want to select the mean and standard deviation from the descriptive statistics available (try this without including this argument to see what values you all get out)\n# returning a table with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\ndescribe(iris$Sepal.Length) |&gt;\n    select(mean, sd) |&gt;\n    kable(caption = \"Sepal Length Descriptives (in cm)\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length Descriptives (in cm)\n\n\nmean\nsd\n\n\nX1\n5.84\n0.83\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelation\n\n Correlation Coefficient\n\n\nThe correlation coefficient - \\(r_{(x,y)}=\\frac{\\mathrm{cov}(x,y)}{s_xs_y}\\) - is a standardised number which quantifies the strength and direction of the linear association between two variables. In a population it is denoted by \\(\\rho\\), and in a sample it is denoted by \\(r\\).\nValues of \\(r\\) fall between \\(-1\\) and \\(1\\). How to interpret:\nSize\nMore extreme values (i.e., the The closer \\(r\\) is to \\(+/- 1\\)) the stronger the linear association, and the closer to \\(0\\) a weak/no association. Commonly used cut-offs are:\n\nWeak = \\(.1 &lt; |r| &lt; .3\\)\n\nModerate = \\(.3 &lt; |r| &lt; .5\\)\n\nStrong = \\(|r| &gt; .5\\)\n\n\n\n\n\n\n\n\n\n\nDirection\nThe sign of \\(r\\) says nothing about the strength of the association, but its nature and direction:\n\nPositive association means that values of one variable tend to be higher when values of the other variable are higher\n\n\n\n\n\n\n\n\n\n\nNegative association means that values of one variable tend to be lower when values of the other variable are higher\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Correlation Matrix\n\n\nA correlation matrix is a table showing the correlation coefficients between variables. Each cell in the table shows the association between two variables. The diagonals show the correlation of a variable with itself (and are therefore always equal to 1).\n\nIn R\nWe can create a correlation matrix by giving the cor() function a dataframe. It is important to remember that all variables must be numeric. One way to check this is by using the str() argument.\n\nLet’s check the structure of the iris dataset to ensure that all variables are numeric:\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nWe can see that the variable Species in column 5 is a factor - this means that we cannot include this in our correlation matrix. Therefore, we need to subset, or, in other words, select specific columns. We can do this either giving the column numbers inside [], or using select(). In our case, we want the variables in columns 1 - 4, just not 5.\nIf you had NA values within your dataset, you could choose to remove these NAs using na.rm = TRUE inside the cor() function.\n\nIn R\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\nround(cor(iris[,c(1:4)]), digits = 2)\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n\n\n\n\n\n# select only the columns we want by variable name, and pass this to cor()\niris |&gt; \n  select(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) |&gt;\n  cor() |&gt;\n  round(digits = 2)\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n\n\n\n\n\n\n\n\n\n\n\n Correlation - Hypothesis Testing\n\n\nThe hypotheses of the correlation test are, as always, statements about the population parameter (in this case the correlation between the two variables in the population - i.e., \\(\\rho\\)).\nIf we are conducting a two tailed test, then…\n\n\n\\(H_0: \\rho = 0\\). There is no linear association between \\(x\\) and \\(y\\) in the population\n\n\n\\(H_1: \\rho \\neq 0\\) There is a linear association between \\(x\\) and \\(y\\)\n\n\nIf we instead conduct a one-tailed test, then we are testing either…\n\n\n\\(H_0: \\rho \\leq 0\\) There is a negative or no linear association between \\(x\\) and \\(y\\)\n\n\n\\(H_1: \\rho &gt; 0\\) There is a positive linear association between \\(x\\) and \\(y\\)\n\n\nOR\n\n\n\\(H_0: \\rho \\geq 0\\) There is a positive or no linear association between \\(x\\) and \\(y\\)\n\n\n\\(H_1: \\rho &lt; 0\\) There is a negative linear association between \\(x\\) and \\(y\\)\n\n\nTest Statistic\nThe test statistic for this test is the \\(t\\) statistic, the formula for which depends on both the observed correlation (\\(r\\)) and the sample size (\\(n\\)):\n\\[t = r \\sqrt{\\frac{n-2}{1-r^2}}\\]\np-value\nWe calculate the \\(p\\)-value for our \\(t\\)-statistic as the long-run probability of a \\(t\\)-statistic with \\(n-2\\) degrees of freedom being less than, greater than, or more extreme in either direction (depending on the direction of our alternative hypothesis) than our observed \\(t\\)-statistic.\nAssumptions\nFor a test of Pearson’s correlation coefficient \\(r\\), we need to make sure a few conditions are met:\n\nBoth variables are quantitative (i.e., continuous)\n\nBoth variables are drawn from normally distributed populations\n\nThe association between the two variables is linear\n\nNo extreme outliers in dataset\n\nHomoscedasticity (homogeneity of variance)\n\n\n\n\n\n\n Correlation - Hypothesis Testing in R\n\n\n\nIn R\nWe can test the significance of the correlation coefficient really easily with the function cor.test():\n\ncor.test(iris$Sepal.Length, iris$Petal.Length)\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\n\nNote, by default, cor.test() will include only observations that have no missing data on either variable.\nWe can specify whether we want to conduct a one- or two-tailed test by adding the argument alternative = and specifying alternative = \"less\", alternative = \"greater\", or alternative = \"two.sided\" (the latter being the default).\n\n\n\n\n\n\n\nExample Interpretation\nThere was a strong positive association between sepal length and petal length \\((r = .87, t(148) = 21.65, p &lt; .001)\\). These results suggested that a greater sepal length was positively associated with a greater petal length.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor a detailed recap of all things correlation (including further details and examples), revisit the Correlation lecture from DAPR1."
  },
  {
    "objectID": "1_b1_reading.html#visual-exploration",
    "href": "1_b1_reading.html#visual-exploration",
    "title": "Block 1 Flash Cards",
    "section": "Visual Exploration",
    "text": "Visual Exploration\nVisual exploration of our data allows us to visualize the distributions of our data, and to identify potential associations among variables.\n\n How to Visualise Data\n\n\nTo visualise (i.e., plot) our data, we can use ggplot() from the tidyverse package. Note the key components of the ggplot() code:\n\n\ndata = where we provide the name of the dataframe\n\naes = where we provide the aesthetics. These are things which we map from the data to the graph. For instance, the \\(x\\)-axis, or if we wanted to colour the columns/bars according to some aspect of the data\n\n+ geom_... = where we add (using +) some geometry. These are the shapes (e.g., bars, points, etc.), which will be put in the correct place according to what we specified in aes()\n\n\nlabs() = where we provide labels for our plot (e.g., the \\(x\\)- and \\(y\\)-axis)\n\n\n\n\n\n\n\nNote\n\n\n\nThere are lots of arguments that you can further customise, some of which are specified in the examples below e.g., bins =, alpha =, fill =, linewidth =. linetype =, size = etc. For these, you can look up the helper function to see the range of arguments they can take using ? - e.g., ?fill.\nIf you’d like to read more about ggplot(), there is a handy cheatsheet.\n\n\nOne other thing to consider when visualising your data is how you are going to arrange your plots. Some handy tips on this:\n\nUse to wrap text in your titles and or axis labels\n\nThe patchwork package allows us to arrange multiple plots in two ways - | arranges the plots adjacent to one another, and / arranges the plots on top of one another\n\n\n\n\n\n\n Marginal Distributions - Examples\n\n\n\n\nHistogram\nDensity\nBoxplot\n\n\n\nA histogram shows the frequency of values which fall within bins of an equal width.\nBasic:\n\nx-axis: possible values of some variable, grouped into bins\ny-axis: frequency of a given value or values within bins\n\nWhat are bins?: A bin represents a range of scores\n\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram() +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nUpdating Bins:\nWithin geom_histogram(), we can specify bins = to specify the number of columns we want (for this example, lets say we want 10):\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(bins = 10) +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAlternatively, we can specify binwidth = to specify the width of each bin (it is very helpful to be aware of the scale of your variable here!):\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(binwidth = 0.1) +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nOutline Columns with Color:\nWithin geom_histogram(), we can specify color = to set a colored outline of the columns:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(color = \"darkred\") +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nFill Columns with Color:\nWithin geom_histogram(), we can specify fill = to fill the columns with a color:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(fill = \"darkred\") +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n“Density” is a bit similar to the notion of “relative frequency” (or “proportion”), in that for a density curve, the values on the y-axis are scaled so that the total area under the curve is equal to 1. In creating a curve for which the total area underneath is equal to one, we can use the area under the curve in a range of values to indicate the proportion of values in that range.\nBasic:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density() +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nFilled:\nWe can fill our plot with colour by specifying fill = within geom_density():\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density(fill = \"darkred\") +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nLine Type & Width:\nWe can change the type and width of the line by specifying linetype = and linewidth = within geom_density():\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density(linetype = 6, linewidth = 3) +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\nBoxplots provide a useful way of visualising the interquartile range (IQR). You can see what each part of the boxplot represents in Figure Figure 1.\n\n\n\n\nFigure 1: Anatomy of a Boxplot\n\n\n\nBasic:\nWe need to specify + geom_boxplot() to get a boxplot:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n  geom_boxplot() +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nRotate Boxplot:\nIf we had set aes(y = Sepal.Length) instead, then it would simply be rotated 90 degrees:\n\nggplot(data = iris, aes(y = Sepal.Length)) +\n  geom_boxplot() +\n    labs(y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Bivariate Associations - Examples\n\n\nUnlike in our marginal plots where we specified our x-axis variable within aes(), to visualise bivariate associations, we need to specify what variables we want on both our x- and y-axis.\n\n\nScatterplot\nScatterplot of Matrices (SPLOM)\n\n\n\nWe can use a scatterplot (since the variables are numeric and continuous) to visualise the association between the two numeric variables - these will be our x- and y-axis values.\nWe plot these values for each row of our dataset, and we should end up with a cloud of scattered points.\nHere we will want to comment on any key observations that we notice, including if we detect outliers or points that do not fit with the pattern in the rest of the data. Outliers are extreme observations that are not possible values of a variable or that do not seem to fit with the rest of the data. This could either be:\n\n\nmarginally along one axis: points that have an unusual (too high or too low) x-coordinate or y-coordinate\n\njointly: observations that do not fit with the rest of the point cloud\n\nBasic:\nWe need to specify + geom_point() to get a scatterplot:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nFill Points with Color:\nWithin geom_point(), we can specify color = to fill the points with a color:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point(color = \"darkred\") +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange Size and Opacity:\nWe can change the size (using size =) and the opacity (using alpha =) of our geom elements on the plot. Let’s include this below:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point(size = 3, alpha = 0.5) +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAdd a Line of Best Fit:\nWe can superimpose (i.e., add) a line of best fit by including the argument + geom_smooth(). Since we want to fit a straight line, we want to use method = \"lm\". We can also specify whether we want to display confidence intervals around our line by specifying se = TRUE / FALSE.\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\nUsing pairs.panels() is likely the most useful way to visualise the associations among numeric variables. It returns a scatterplot of matrices (SPLOM) returning you (1) the marginal distribution of each variable via a histogram, (2) the correlation between variables, and (3) bivariate scatterplots.\n\niris |&gt;\n    select(Sepal.Length, Petal.Length, Petal.Width) |&gt;\n    pairs.panels(main = \"Iris SPLOM\")\n\n\n\nFigure 2: Iris SPLOM\n\n\n\n\n\n\n\n\n\n\n\n Multivariate Associations - Examples\n\n\nTo visualise multivariate associations, just like we do for bivariate associations, we need to specify what variables we want on both our x- and y-axis. We also need to take an extra step by specifying a third variable - z - that acts as a differentiating factor across our data. This ‘z’ can be mapped to an aesthetic attribute such as color, shape, or size, allowing us to explore more dynamic patterns and ssociations in our data.\nIf you really wanted to, you could create a plot showing the associations among three variables at once. These are likely more useful when you have an interaction model. However, we wouldn’t really recommend doing this - they can be very difficult to interpret correctly, and given their interactive nature, definitely NOT something that you’d want to include in a stats report. But, for demonstration purposes only, we could create one using the plotly package.\n3D Scatterplot\n\nlibrary(plotly)\n\nplot_ly(data = iris, \n        x = ~Petal.Length, y = ~Sepal.Length, z = ~Petal.Width, \n        type = 'scatter3d', \n        mode = 'markers+lines',\n        scene = list(\n            xaxis = list(title = \"Petal Length\"),\n            yaxis = list(title = \"Sepal Length\"),\n            zaxis = list(title = \"Petal Width\")\n            )\n        )\n\n\n\n\n\nHeatmap of Correlations\n\nplot_ly(z = ~cor(iris[, c(1, 3:4)]), type = \"heatmap\")"
  },
  {
    "objectID": "1_b1_reading.html#deterministic-models",
    "href": "1_b1_reading.html#deterministic-models",
    "title": "Block 1 Flash Cards",
    "section": "Deterministic Models",
    "text": "Deterministic Models\n\n Description & Specification\n\n\nWe come across functions a lot in daily life, and probably don’t think much about it. In a slightly more mathematical setting, we can write down in words and in symbols the function describing the association between the side of a square and its perimeter (e.g., to capture how the perimeter varies as a function of its side). In this case, the perimeter is the dependent variable, and the side is the independent variable.\nThis is what we would refer to as a deterministic model, as it is a model of an exact relationship - there can be no deviation.\nModel Specification\n\n\nIn words\nIn symbols\n\n\n\nThe perimeter of a square is four times the length of its side.\n\n\nThe relationship between side and perimeter of squares is given by:\n\\[\n\\text{Perimeter} = 4 \\cdot \\text{Side}\n\\]\nIf you denote \\(y\\) as the dependent variable Perimeter, and \\(x\\) as the independent variable Side we can rewrite as:\n\\[\ny = 4 \\cdot x\n\\]\n\n\n\n\n\n\n\n\n Visualisation\n\n\nLet’s create a dataset called squares, containing the perimeter of four squares having sides of length \\(0, 2, 5, 9\\) metres, and then plot the squares data as points on a scatterplot.\nFirst, let’s make our squares data. Here we will use two important functions - tibble() and c(). The tibble() function allows us to construct a data frame. To store a sequence of numbers into R, we can combine the values using c(). A sequence of elements all of the same type is called a vector.\n\n#create data frame named squares\nsquares &lt;- tibble(\n  side = c(0, 2, 5, 9), \n  perimeter = 4 * side\n)\n\n#check that our values are contained within squares\nsquares\n\n# A tibble: 4 × 2\n   side perimeter\n  &lt;dbl&gt;     &lt;dbl&gt;\n1     0         0\n2     2         8\n3     5        20\n4     9        36\n\n\nNow we know how ggplot() works, we can start to build our plot. First we specify our data (we want to use the squares data frame), and then our aesthetics. Since the perimeter varies as a function of side, we want side on the \\(x\\)-axis, and perimeter on the \\(y\\)-axis. We want to create a scatterplot, so we need to specify our geom_... argument as geom_point(). Lastly, we will provide clearer axis labels, and include the units of measurement.\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +  \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4*Side')  \n\n\n\nFigure 3: Perimeter = 4*Side\n\n\n\nWe could also visualise the functional relationship by connecting the individual points with a line. To do so, we need to add a new argument - geom_line(). If you would like to change the colour of the line from the default, you can specify geom_line(colour = \"insert colour name\").\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +\n  geom_line(colour = \"darkred\") + \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4*Side')  \n\n\n\nFigure 4: Perimeter = 4*Side\n\n\n\n\n\n\n\n\n Predicted Values\n\n\nSometimes we can directly read a predicted value from the graph of the functional relationship.\nConsider the plot created above. For example, first we need to check where \\(x\\) = 2.5. Then, we draw a vertical dashed line until it meets the blue line. The \\(y\\) value corresponding to \\(x\\) = 2.5 can be read off the \\(y\\)-axis. In our case, we would say a side of 2.5m corresponds to a perimeter of 10m.\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +\n  geom_line(colour = \"blue\") + \n  geom_vline(xintercept = 2.5, colour = \"darkred\", lty = \"dashed\", lwd = 1) + \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4 * Side')  \n\n\n\nFigure 5: Perimeter = 4*Side\n\n\n\nHowever, in this case it is not that easy to read it from Figure 5 (especially without the superimposed dashed red line)… This leads us to the algebraic approach:\nWe can substitute the \\(x\\) value in the formula and calculate the corresponding \\(y\\) value where we would conclude that the predicted perimeter of squared paintings having a 2.5m side is 10m:\n\\[\ny = 4 \\cdot x  \\\\    \n\\]\n\\[\ny = 4 \\cdot 2.5 \\\\  \n\\]\n\\[\ny = 10  \\\\\n\\]"
  },
  {
    "objectID": "1_b1_reading.html#numeric-outcomes-numeric-predictors",
    "href": "1_b1_reading.html#numeric-outcomes-numeric-predictors",
    "title": "Block 1 Flash Cards",
    "section": "Numeric Outcomes & Numeric Predictors",
    "text": "Numeric Outcomes & Numeric Predictors\nSimple Linear Regression Models\n\n Description & Model Specification\n\n\nThe association between two variables (e.g., recall accuracy and age) will show deviations from the ‘average pattern’. Hence, we need to create a model that allows for deviations from the linear relationship - we need a statistical model.\nA statistical model includes both a deterministic function and a random error term. We typically refer to the outcome (‘dependent’) variable with the letter \\(y\\) and to our predictor (‘explanatory’/‘independent’) variables with the letter \\(x\\). A simple (i.e., one x variable only) linear regression model thus takes the following form (where the terms \\(\\beta_0\\) and \\(\\beta_1\\) are numbers specifying where the line going through the data meets the y-axis (i.e., the intercept - where \\(x\\) = 0; \\(\\beta_0\\)) and its slope (direction and gradient of line; \\(\\beta_1\\)):\nModel Specification\n\\[\ny_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i    \n\\]\nModel Specification: Annotated\n\\[\ny_i = \\underbrace{\\beta_0 + \\beta_1 \\cdot x_i}_{\\text{function of }x} + \\underbrace{\\epsilon_i}_{\\text{random error}}  \n\\\\\n\\]\n\\[\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\nModel Specification: Explained\nLet’s break down what \\(y_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\\) actually means by considering the statement in smaller parts:\n\n\n\\(y_i = \\beta_0 + \\beta_1 \\cdot x_i\\)\n\n\n\\(y_i\\) is our measured outcome variable (our DV)\n\n\n\\(x_i\\) is our measured predictor variable (our IV)\n\n\n\\(\\beta_0\\) is the model intercept\n\n\n\\(\\beta_1\\) is the model slope\n\n\n\n\\(\\epsilon \\sim N(0, \\sigma) \\text{ independently}\\)\n\n\n\\(\\epsilon\\) is the residual error\n\n\n\\(\\sim\\) means ‘distributed according to’\n\n\n\\(N(0, \\sigma) \\text{ independently}\\) means ‘normal distribution with a mean of 0 and a variance of \\(\\sigma\\)’\n\nTogether, we can say that the errors around the line have a mean of zero and constant spread as x varies\n\n\n\n\nIn R\nThere are basically two pieces of information that we need to pass to the lm() function:\n\nThe formula: The regression formula should be specified in the form y ~ x where \\(y\\) is the dependent variable (DV) and \\(x\\) the independent variable (IV).\nThe data: Specify which dataframe contains the variables specified in the formula.\n\nIn R, the syntax of the lm() function can be specified as follows (where DV = dependent variable, IV = independent variable, and data_name = the name of your dataset):\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ IV, data = data_name) \n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ data_name$IV)\n\n\n\n\nyou can also specify as:\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ 1 + IV, data = data_name) \n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ 1 + data_name$IV)\n\n\n\n\n\n\n\n\n\n\nWhy is there a 1 in the two bottom options?\n\n\n\n\n\nWhen we specify the linear model in R, we include after the tilde sign (\\(\\sim\\)), the variables that appear to the right of the \\(\\hat \\beta\\)s. The intercept, or \\(\\beta_0\\), is a constant. That is, we could write it as multiplied by 1.\nIncluding the 1 explicitly is not necessary because it is included by default (you can check this by comparing the outputs of A & B above with and without the 1 included - the estimates are the same!). After a while, you will find you just want to drop the 1 when calling lm() because you know that it’s going to be there, but in these early weeks we tried to keep it explicit to make it clear that you want the intercept to be estimated.\n\n\n\n\n\n\n\nExample\n\nResearch Question\nIs there an association between recall accuracy and age?\n\n\n Overview\n\n\nImagine that you were tasked to investigate whether there was an association between recall accuracy and age. You have been provided with data from twenty participants who studied passages of text (c500 words long), and were tested a week later. The testing phase presented participants with 100 statements about the text. They had to answer whether each statement was true or false, as well as rate their confidence in each answer (on a sliding scale from 0 to 100). The dataset contains, for each participant, the percentage of items correctly answered, their age (in years), and their average confidence rating.\nThe data are available at https://uoepsy.github.io/data/recalldata.csv\n\n\n\n\n\n Visualise Data\n\n\nThere are lots of different ways in which we can visualise our data (as per the Visual Exploration flashcards).\nFor the marginal distributions we will use density and boxplots, and for the bivariate associations a scatterplot.\n\n#save plots to individual objects in order to arrange \n\nplt1 &lt;- ggplot(data = recalldata, aes(x = recall_accuracy)) + \n    geom_density() +\n    xlim(0, 100) + #specify x-axis to range from 0-100\n    geom_boxplot(width = 1/100) + \n    labs(x = \"Recall Accuracy (%)\", title = \"Distribtion of \\nRecall Accuracy\")\n\nplt2 &lt;- ggplot(data = recalldata, aes(x = age)) + \n    geom_density() +\n    xlim(0, 100) + #specify x-axis to range from 0-100\n    geom_boxplot(width = 1/100) + \n    labs(x = \"Age (in years)\", title = \"Distribtion of \\nAge\")\n\nplt3 &lt;- ggplot(data = recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point() + \n    labs(x = \"Age (in years)\", y = \"Recall Accuracy (%)\", title = \"Association between Recall Accuracy and Age\")\n\n\n#load patchwork package to arrange plots\nlibrary(patchwork)\n\n#arrange plots where there are two plots in to panel (plt1 + plt2), one on bottom (plt3)\n(plt1 + plt2) / plt3\n\n\n\n\n\n\n\n\nThe marginal distribution of recall accuracy was unimodal with a negative skew with a mean of approximately 69.25. There was high variation in recall accuracy (SD = 14.53)\n\nThe marginal distribution of age was unimodal with a mean of approximately 48.8, where age ranged from 22 to 86\n\nThere appeared to be a weak negative association between recall accuracy and age, where older age was associated with lower recall accuracy\n\n\n\n\n\n\n Model & Hypothesis Specification\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\n\\[\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Age}_i + \\epsilon_i    \n\\]\n\n\n\\(H_0: \\beta_1 = 0\\)\nThere is no association between recall accuracy and age.\n\\(H_1: \\beta_1 \\neq 0\\)\nThere is an association between recall accuracy and age.\n\n\n\n\n\n\n\n\n Model Building\n\n\nTo fit the model in R we use the lm() function. The simple linear model is assigned/stored in an object called recall_simp:\n\nrecall_simp &lt;- lm(recall_accuracy ~ age, data = recalldata)\n\n\nrecall_simp\n\n\nCall:\nlm(formula = recall_accuracy ~ age, data = recalldata)\n\nCoefficients:\n(Intercept)          age  \n    84.0153      -0.3026  \n\n\nWhen we call the name of the fitted model, recall_simp, you can see the estimated regression coefficients \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\). The line of best-fit is thus given by:1\n\\[\n\\widehat{\\text{Recall Accuracy}} = 84.02 - 0.31 \\cdot \\text{Age}\n\\]\n\nAlternatively to get these same estimates, we could have used the summary() function:\n\nsummary(recall_simp)\n\n\nCall:\nlm(formula = recall_accuracy ~ age, data = recalldata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.164  -7.761  -2.656   9.593  26.180 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  84.0153    11.4453   7.341 8.16e-07 ***\nage          -0.3026     0.2253  -1.343    0.196    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.23 on 18 degrees of freedom\nMultiple R-squared:  0.09108,   Adjusted R-squared:  0.04058 \nF-statistic: 1.804 on 1 and 18 DF,  p-value: 0.196\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\n(Intercept)\nage\n\n\n\n\\(\\beta_0\\) = (Intercept) = 84.02\n\nThe intercept, or predicted recall accuracy when age was 0.\n\nAn individual aged 0 years was expected to have a recall accuracy of \\(84.02\\).\n\n\n\nNote: the intercept isn’t very useful here at all. It estimates the accuracy for a newborn (who wouldn’t be able to complete the task!).\n\n\n\\(\\beta_1\\) = age = -0.3\n\nThe estimated difference in recall accuracy for each additional year in age.\n\nEvery 1 additional year in age was associated with a non-significant \\(-0.3\\) percentage point decrease in recall accuracy \\((p = .196)\\). This suggested that age was not significantly associated with recall accuracy.\n\n\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\n\nggplot(recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point(size = 3, alpha = 0.5) +\n    geom_smooth(method = lm, se = FALSE) + \n    ylim(0,100) +\n    labs(x = \"Age (in years)\", y = \"Recall Accuracy (%)\", title = \"Association between Recall Accuracy and Age\")\n\n\n\nFigure 6: Association between Recall Accuracy and Age\n\n\n\nThe line that best fits the association between recall accuracy and age (see Figure 6) is only able to predict the average accuracy for a given value of age.\nThis is because there will be a distribution of recall accuracy at each value of age. The line will fit the trend/pattern in the values, but there will be individual-to-individual variability that we must accept around that average pattern.\n\n\n\nMultiple Linear Regression Models\n\n Description & Model Specification\n\n\nMultiple linear regression involves looking at one continuous outcome (i.e., DV), with two or more independent variables (i.e., IVs).\nA multiple linear regression model takes the following form:\n\\[\ny_i = \\beta_0 + \\beta_1 \\cdot x_{1_i} + \\beta_2 \\cdot x_{2_i} + .... + \\beta_j \\cdot x_{j_i} + \\epsilon_i\n\\]\n\\[\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\n\nIn R:\nMultiple and simple linear regression follow the same structure within the lm() function - the logic scales up to however many predictor variables we want to include in our model. You simply add (using the + sign) more independent variables. For example, if we wanted to build a multiple linear regression that included three independent variables, we could fit one of the following via the lm() function:\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ IV1 + IV2 + IV3, data = data_name)\n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ data_name$IV1 + data_name$IV2 + data_name$IV3)\n\n\n\n\n\n\n\n\n\n\n Interpretation of Coefficients\n\n\nYou’ll hear a lot of different ways that people explain multiple regression coefficients.\nFor the model \\(y = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon\\), the estimate \\(\\hat \\beta_1\\) will often be reported as:\n“the increase in \\(y\\) for a one unit increase in \\(x_1\\) when…”\n\n“holding the effect of \\(x_2\\) constant.”\n“controlling for differences in \\(x_2\\).”\n“partialling out the effects of \\(x_2\\).”\n“holding \\(x_2\\) equal.”\n“accounting for effects of \\(x_2\\).”\n\nFor models with 3+ predictors, just like building the model in R, the logic of the above simply extends.\nFor example “the increase in [outcome] for a one unit increase in [predictor] when…”\n\n“holding [other predictors] constant.”\n\n“accounting for [other predictors].”\n\n“controlling for differences in [other predictors].”\n\n“partialling out the effects of [other predictors].”\n\n“holding [other predictors] equal.”\n\n“accounting for effects of [other predictors].”\n\n\n\n\nExample\n\nResearch Question\nIs recall accuracy associated with recall confidence and age?\n\n\n Overview\n\n\nImagine that you were tasked to investigate whether recall accuracy was associated with recall confidence and age. You have been provided with data from twenty participants who studied passages of text (c500 words long), and were tested a week later. The testing phase presented participants with 100 statements about the text. They had to answer whether each statement was true or false, as well as rate their confidence in each answer (on a sliding scale from 0 to 100). The dataset contains, for each participant, the percentage of items correctly answered, their age (in years), and their average confidence rating.\nThe data are available at https://uoepsy.github.io/data/recalldata.csv\n\n\n\n\n\n Visualise Data\n\n\n\nrecalldata |&gt;\n    select(recall_accuracy, recall_confidence, age) |&gt;\n    pairs.panels(main = \"Recall SPLOM\")\n\n\n\nFigure 7: Recall SPLOM\n\n\n\n\n\n\n\n\n Model & Hypothesis Specification\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\n\\[\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Recall Confidence}_i + \\beta_2 \\cdot \\text{Age}_i + \\epsilon_i \\\\\n\\]\n\n\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere is no association between recall accuracy and recall confidence and/or age.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere is an association between recall accuracy and recall confidence and/or age.\n\n\n\n\n\n\n\n\n Model Building\n\n\n\nrecall_multi &lt;- lm(recall_accuracy ~ recall_confidence + age, data = recalldata)\n\n\nsummary(recall_multi)\n\n\nCall:\nlm(formula = recall_accuracy ~ recall_confidence + age, data = recalldata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.1935  -5.1751  -0.5528   2.5934  18.6814 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        36.1596    12.8413   2.816 0.011900 *  \nrecall_confidence   0.8957     0.1912   4.685 0.000213 ***\nage                -0.3392     0.1534  -2.212 0.040985 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.674 on 17 degrees of freedom\nMultiple R-squared:  0.6033,    Adjusted R-squared:  0.5566 \nF-statistic: 12.92 on 2 and 17 DF,  p-value: 0.0003867\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\n(Intercept)\nrecall_confidence\nage\n\n\n\n\\(\\beta_0\\) = (Intercept) = 36.16\n\nThe intercept, or predicted recall accuracy when recall confidence was 0 and age was 0.\n\nAn individual aged 0 years with no recall confidence was expected to have a recall accuracy of \\(36.16\\).\n\n\n\nNote: the intercept isn’t very useful here at all. It estimates the accuracy for a newborn (who wouldn’t be able to complete the task!).\n\n\n\\(\\beta_1\\) = recall_confidence = 0.9\n\nThe estimated difference in recall accuracy for each additional unit increase in confidence controlling for age.\n\nHolding age constant, each 1 additional unit in recall confidence was associated with a significant \\(0.9\\) percentage point increase in recall accuracy \\((p &lt; .001)\\).\n\n\n\n\n\n\\(\\beta_2\\) = age = -0.34\n\nThe estimated difference in recall accuracy for each additional year in age controlling for recall confidence.\n\nHolding recall confidence constant, every 1 additional year in age was associated with a significant \\(-0.34\\) percentage point decrease in recall accuracy \\((p = .041)\\).\n\n\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\nWhen we have 2+ predictors, we can’t just plot our data an add geom_smooth(method=lm), because that would give a visualisation of a linear model with just one predictor (whichever one is on the \\(x\\)-axis).\nInstead, we can use the function plot_model() from sjPlot.\n\nplot_model(recall_multi,\n           type = \"eff\",\n           terms = \"recall_confidence\",\n           show.data = TRUE)\n\nplot_model(recall_multi,\n           type = \"eff\",\n           terms = \"age\",\n           show.data = TRUE)\n\n\n\nFigure 8: Association between Recall Accuracy, Recall Confidence, and Age\n\n\n\n\n\nFigure 9: Association between Recall Accuracy, Recall Confidence, and Age"
  },
  {
    "objectID": "1_b1_reading.html#general---extracting-information",
    "href": "1_b1_reading.html#general---extracting-information",
    "title": "Block 1 Flash Cards",
    "section": "General - Extracting Information",
    "text": "General - Extracting Information\nIt is important to have a good grasp of how to understand and interpret the key components of your model summary() output, including model coefficients, standard errors, \\(t\\)-values, \\(p\\)-values, etc., and how these can be used in further calculations (such as confidence intervals). As well as knowing how to extract from R, it is necessary to understand how to compute some of these statistics by hand too.\n\n Model Call\n\n\n\n\n\n\nMultiple regression output in R, model formula highlighted\n\n\n\nThe call section at the very top of the summary() output shows us the formula that was specified in R to fit the regression model.\nIn the above, we can see that recall accuracy is our DV, recall confidence and age were our two IVs, and our dataset was named recalldata.\n\n\n\n\n\n Residuals\n\n\n\n\n\n\nMultiple regression output in R, residuals highlighted\n\n\n\nResiduals are the difference between the observed values and model predicted values of the DV.\nIdeally, for the model to be unbiased, we want our median value (the middle value of the residuals when ordered) to be around 0, as this would show that the errors are random fluctuations around the true line. When this is the case, we know that our model is doing a good job predicting values at the high and low ends of our dataset, and that our residuals were somewhat symmetrical.\n\n\n\n\n\n Model Coefficients\n\n\n\n\n\n\nMultiple regression output in R, model coefficients highlighted\n\n\n\n\n\nEstimates\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\nOur model estimates help us to build our best fitting equation of the line that represents the association between our DV and our IV(s).\nIn the above example, we can build our equation for our model from this information:\n\\[\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Recall Confidence}_i + \\beta_2 \\cdot \\text{Age}_i + \\epsilon_i\n\\] \\[\n\\widehat{\\text{Recall Accuracy}} = 36.16 + 0.90 \\cdot \\text{Recall Confidence} - 0.34 \\cdot \\text{Age}\n\\]\nHow to calculate \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\)\n\n\nBy Hand\nUsing R\n\n\n\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nStep 1: Calculate mean of both \\(x\\) and \\(y\\)\n\\(\\bar x = {\\frac{1+2+3+4+5}{5}} = 3\\)\n\\(\\bar y = {\\frac{5+7+8+6+9}{5}} = 7\\)\nStep 2: Calculate \\(\\beta_0\\) and \\(\\beta_1\\)\nWe need to calculate the slope first, as we need to know the value of \\(\\beta_1\\) in order to calculate \\(\\beta_0\\)\nSlope (\\(\\beta_1\\))\n\\[\n\\begin{align}\n& \\hat \\beta_1 = \\frac{SP_{xy}}{SS_x} \\\\  \n\\\\\n\\\\\n& \\text{Where}: \\\\\n& \\text{SP}_\\text{xy} = \\text{sum of cross-products:} \\\\\n& \\text{SP}_\\text{xy} = \\sum_{i = 1}^{n}(x_i - \\bar{x})(y_i - \\bar{y}) \\\\  \n& \\text{and} \\\\\n& \\text{SS}_\\text{x} = \\text{sums of squared deviations of x:} \\\\    \n& \\text{SS}_\\text{x} = \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 \\\\  \n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\text{SP}_\\text{xy} =\\sum_{i = 1}^{n}(x_i - \\bar{x})(y_i - \\bar{y}) = \\\\\n& (1-3)(5-7) + (2-3)(7-7) + (3-3)(8-7) + (4-3)(6-7) + (5-3)(9-7) = \\\\\n& 4 + 0 + 0 + (-1) + 4 = \\\\\n& 7 \\\\\n\\\\  \n& \\text{SS}_\\text{x}= \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 = \\\\\n& (1-3)^2 + (2-3)^2 + (3-3)^22 + (4-3)^2 + (5-3)^2 = \\\\\n& 4 + 1 + 0 + 1 + 4 = \\\\\n& 10 \\\\\n\\\\  \n& \\hat \\beta_1 = \\frac{SP_{xy}}{SS_x} = \\frac{7}{10} = 0.7 \\\\\n\\end{align}\n\\]\nIntercept (\\(\\beta_0\\))\n\\[\n\\begin{align}\n&\\hat \\beta_0 = \\bar{y} - \\hat \\beta_1 \\bar{x} \\\\\n&\\hat \\beta_0 = 7 - 0.7 \\cdot 3 \\\\\n&\\hat \\beta_0 = 7 - 2.1 \\\\\n&\\hat \\beta_0 = 4.9\n\\end{align}\n\\]\n\n\n\nIn R\nThere are numerous equivalent ways to obtain the estimated regression coefficients — that is, \\(\\hat \\beta_0\\), \\(\\hat \\beta_1\\), …., \\(\\hat \\beta_k\\) — from the fitted model (for this below example, our fitted model has been named mdl):\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\n\n\n\n\n\n\n\nThe standard error of the coefficient is an estimate of the standard deviation of the coefficient (i.e., how much uncertainty there is in our estimated coefficient).\nThe formula for the standard error of the slope is:\n\\[\n\\begin{align}\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{\\text{SS}_\\text{Residual}/(n-k-1)}{\\sum(x_{ij} - \\bar{x_{j}})^2(1-R_{xj}^2)}} \\\\  \n\\\\  \n& \\text{Where}: \\\\  \n\\\\  \n& \\text{SS}_\\text{Residual} = \\text{ residual sum of squares} \\\\  \n& n = \\text{ sample size} \\\\  \n& k = \\text{ number of predictors} \\\\  \n& x_{ij} = \\text{ the observed value of a predictor (j) for an individual (i)} \\\\  \n& \\bar{x_{j}} = \\text{the mean of a predictor (j)} \\\\  \n& R_{xj}^2 = \\text{the multiple correlation coefficient of the predictors} \\\\  \n\\end{align}\n\\]\nLet’s apply to a straightforward example. Suppose you have a simple linear regression model (i.e., with only one IV, which means that \\(R_{xj}^2 = 0\\) since there is only one predictor) and the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nThere are a number of steps you need to take to calculate by hand:\n\nCalculate sum of the squared residuals\n\nCalculate predicted values\n\nCalculate residuals (i.e., the difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)) for each observation)\n\nSquare the residuals\n\nCalculate the Sum of Squared Residuals\n\n\n\nCalculate the sum of squared deviations of the (\\(x\\)) values from their mean\nUse values from 1 & 2 to calculate \\(SE(\\hat \\beta_j)\\)\n\n\nStep 1.1: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n4.9 + (0.7*1) = 5.6\n\n\n2\n7\n4.9 + (0.7*2) = 6.3\n\n\n3\n8\n4.9 + (0.7*3) = 7\n\n\n4\n6\n4.9 + (0.7*4) = 7.7\n\n\n5\n9\n4.9 + (0.7*5) = 8.4\n\n\n\nStep 1.2: Calculate residuals\n\n\\(\\epsilon_1 = 5 − 5.6 = -0.6\\)\n\\(\\epsilon_2 = 7 - 6.3 = 0.7\\)\n\\(\\epsilon_3 = 8 - 7 = 1\\)\n\\(\\epsilon_4 = 6 - 7.7 = -1.7\\)\n\\(\\epsilon_5 = 9 − 8.4 = 0.6\\)\n\nStep 1.3: Square the residuals\n\n\\(\\epsilon_1^2 = -0.6^2 = 0.36\\)\n\\(\\epsilon_2^2 = 0.7^2 = 0.49\\)\n\\(\\epsilon_3^2 = 1^2 = 1\\)\n\\(\\epsilon_4^2 = -1.7^2 = 2.89\\)\n\\(\\epsilon_5^2 = 0.6^2 = 0.36\\)\n\nStep 1.4: Calculate the Sum of Squared Residuals\n\\[\n\\sum \\epsilon_i^2 = 0.36 + 0.49 + 1 + 2.89 + 0.36 = 5.1\n\\]\nStep 2. Calculate the sum of squared deviations of the (\\(x\\)) values from their mean\nThe mean of \\(x\\) can be calculated as: \\(\\bar x = {\\frac{1+2+3+4+5}{5}} = 3\\). Using this, we can then calculate the sum of squared deviations of \\(x\\):\n\\[\n\\begin{align}\n& \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 = \\\\\n& (1-3)^2 + (2-3)^2 + (3-3)^22 + (4-3)^2 + (5-3)^2 = \\\\\n& 4 + 1 + 0 + 1 + 4 = \\\\\n& 10 \\\\\n\\end{align}\n\\]\nStep 3: Calculate \\(SE(\\hat \\beta_j)\\)\nFrom this, we can finally calculate \\(SE(\\hat \\beta_j)\\):\n\\[\n\\begin{align}\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{\\text{SS}_\\text{Residual}/(n-k-1)}{\\sum(x_{ij} - \\bar{x_{j}})^2(1-R_{xj}^2)}} \\\\  \n& SE(\\hat \\beta_j) = \\sqrt{\\frac{5.1/(5-1-1)}{10 \\cdot (1-0)}} \\\\\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{5.1/3}{10}} \\\\\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{1.7}{10}} \\\\\n& SE(\\hat \\beta_j) = \\sqrt{0.17} \\\\\n& SE(\\hat \\beta_j) = 0.4207\n\\\\\n\\end{align}\n\\]\n\nIn R\nIf you wanted to obtain just the standard error for each estimated regression coefficient, you could do the following (for this below example, our fitted model has been named mdl):\n\nsummary(mdl)$coefficients[,2]\n\n\n\n\nThe t-statistic is the \\(\\beta\\) coefficient divided by the standard error:\n\\[\nt = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)}\n\\]\nwhich follows a \\(t\\)-distribution with \\(n-k-1\\) degrees of freedom (where \\(k\\) = number of predictors and \\(n\\) = sample size).\nWith this, we can test the the null hypothesis \\(H_0: \\beta_j = 0\\).\nGenerally speaking, you want your model coefficients to have large \\(t\\)-statistics as this would indicate that the standard error was small in comparison to the coefficient. The larger our \\(t\\)-statistic, the more confident we can be that the coefficient is not 0.\nHow to calculate \\(t = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)}\\)\n\n\nBy Hand\nIn R\n\n\n\nWe can calculate the test statistic \\(t\\) for \\(\\beta_\\text{Age}\\) (or \\(\\beta_2\\)) by hand from our recall_multi model as follows:\n\\[\n\\begin{align}\n\\\\\n& t = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)} \\\\  \n\\\\  \n& t = \\frac{-0.3392 - 0}{0.1534} \\\\\n\\\\  \n& t = -2.211213 \\\\  \n\\\\  \n& t = -2.21 \\\\  \n\\end{align}\n\\]\nWe then need to calculate \\(t^*\\):\n\nn &lt;- nrow(recalldata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 2.109816\n\n\nAnd finally compare \\(|t|\\) to \\(t^*\\). Since \\(|t|\\) is larger than \\(t^*\\) (-2.21 &gt; 2.11), we can reject the null hypothesis.\n\n\n\nIn R\nIf you wanted to obtain just the \\(t\\)-values for each estimated regression coefficient, you could use the following:\n\ncoef(summary(mdl))[, \"t value\"]\nsummary(mdl)$coefficients[,3]\n\nFor example:\n\ncoef(summary(recall_multi))[, \"t value\"]\n\n      (Intercept) recall_confidence               age \n         2.815890          4.684654         -2.211515 \n\n\n\nsummary(recall_multi)$coefficients[,3]\n\n      (Intercept) recall_confidence               age \n         2.815890          4.684654         -2.211515 \n\n\n\n\n\n\n\n\nFrom our \\(t\\)-value, we can compute our \\(p\\)-value. The \\(p\\)-value help us to understand whether our coefficient(s) are statistically significant (i.e., that the coefficient is statistically different from 0). The \\(p\\)-value of each estimate indicates the probability of observing a \\(t\\)-value at least as extreme as, or more extreme than, the one calculated from the sample data when assuming the null hypothesis to be true.\nIn Psychology, a \\(p\\)-value &lt; .05 is usually used to make statements regarding statistical significance (it is important that you always state your \\(\\alpha\\) level to help your reader understand any statements regarding statistical significance).\nThe number of asterisks marks corresponds with the significance of the coefficient (see the ‘Signif. codes’ legend just under the coefficients section).\n\nIn R\nIf you wanted to obtain just the \\(p\\)-values for each estimated regression coefficient, you could do the following (for this below example, our fitted model has been named mdl):\n\nsummary(mdl)$coefficients[,4]\n\n\n\n\n\n\n\n\n\n\n Confidence Intervals\n\n\nUsing the estimate and standard error of a given \\(\\beta\\) coefficient, we can create confidence intervals to estimate a plausible range of values for the true population parameter. Recall the formula for obtaining a confidence interval for the population slope is:\n\\[\n\\hat \\beta_j \\pm t^* \\cdot SE(\\hat \\beta_j)\n\\]\nwhere \\(t^*\\) denotes the critical value chosen from \\(t\\)-distribution with \\(n-k-1\\) degrees of freedom (where \\(k\\) = number of predictors and \\(n\\) = sample size) for a desired \\(\\alpha\\) level of confidence.\nHow to calculate \\(\\hat \\beta_j \\pm t^* \\cdot SE(\\hat \\beta_j)\\)\n\n\nBy Hand\nUsing R\n\n\n\nTo calculate by hand for \\(\\hat \\beta_\\text{Age}\\) from our recall_multi model, we first need to calculate \\(t^*\\):\n\nn &lt;- nrow(recalldata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 2.109816\n\n\nFor 95% confidence intervals, we use \\(t^* = 2.1098\\), and can simply substitute into the formula:\n\\[\n\\begin{align}\n& \\text{Lower CI} = \\hat \\beta_\\text{Age} - t^* \\cdot SE(\\hat \\beta_\\text{Age}) \\\\  \n& \\text{Lower CI} = -0.3392 - (2.1098 \\cdot 0.1534) \\\\  \n& \\text{Lower CI} = -0.6628433 \\\\\n& \\text{Lower CI} = -0.663 \\\\\n\\\\    \n& \\text{Upper CI} = \\hat \\beta_\\text{Age} + t^* \\cdot SE(\\hat \\beta_\\text{Age}) \\\\  \n& \\text{Upper CI} = -0.3392 + (2.1098 \\cdot 0.1534) \\\\\n& \\text{Upper CI} = -0.01555668 \\\\\n& \\text{Upper CI} = -0.016 \\\\\n\\end{align}\n\\]\n\n\n\nIn R\nWe can obtain the confidence intervals for the regression coefficients using the command confint().\n\nconfint(recall_multi)\n\n                       2.5 %      97.5 %\n(Intercept)        9.0668871 63.25228524\nrecall_confidence  0.4923220  1.29913640\nage               -0.6627188 -0.01559663\n\n\nOr alternatively use R to compute using the manual process (though it makes more sense to use confint() given it is less prone to typos!):\n\ntibble(\n  b2_LowerCI = round(-0.3392 - (qt(0.975, n-3) * 0.1534), 3),\n  b2_UpperCI = round(-0.3392 + (qt(0.975, n-3) * 0.1534), 3)\n      )\n\n# A tibble: 1 × 2\n  b2_LowerCI b2_UpperCI\n       &lt;dbl&gt;      &lt;dbl&gt;\n1     -0.663     -0.016\n\n\n\n\n\n\n\n\n\n\n\n \\(\\sigma\\)\n\n\n\n\n\n\nMultiple regression output in R, model standard deviation of the errors highlighted\n\n\n\nThe standard deviation of the errors, denoted by \\(\\sigma\\), is an important quantity that our model estimates. It represents how much individual data points tend to deviate above and below the regression line - in other words, it tells us how well the model fits the data.\nA small \\(\\sigma\\) indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large \\(\\sigma\\) suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\nThe estimated standard deviation of the errors is denoted \\(\\hat \\sigma\\), and is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root:\n\\[\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{\\text{SS}_\\text{Residual}}{n - k - 1}} \\\\\n\\qquad \\\\\n& \\text{Where:}  \\\\\n& \\text{SS}_\\text{Residual} = \\textrm{Sum of Squared Residuals} = \\sum_{i=1}^n{(\\epsilon_i)^2} \\\\\n\\\\  \n\\\\  \n& \\text{and so, equivalently:} \\\\  \n\\\\  \n& \\hat \\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{n - k - 1}} \\\\\n\\end{align}\n\\]\nHow to calculate \\(\\hat \\sigma\\)\n\n\nBy Hand\nUsing R\n\n\n\nThere are a number of steps you need to take to calculate by hand:\n\nCalculate predicted values\nCalculate residuals (i.e., the difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)) for each observation)\n\nSquare the residuals\n\nCalculate the Sum of Squared Residuals\n\nDetermine the Residual Standard Deviation (\\(\\sigma\\))\n\nLet’s apply to a straightforward example. Suppose you have a simple linear regression model (i.e., with only one IV) and the following data points:\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nStep 1: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n4.9 + (0.7*1) = 5.6\n\n\n2\n7\n4.9 + (0.7*2) = 6.3\n\n\n3\n8\n4.9 + (0.7*3) = 7\n\n\n4\n6\n4.9 + (0.7*4) = 7.7\n\n\n5\n9\n4.9 + (0.7*5) = 8.4\n\n\n\nStep 2: Calculate residuals\n\n\\(\\epsilon_1 = 5 − 5.6 = -0.6\\)\n\\(\\epsilon_2 = 7 - 6.3 = 0.7\\)\n\\(\\epsilon_3 = 8 - 7 = 1\\)\n\\(\\epsilon_4 = 6 - 7.7 = -1.7\\)\n\\(\\epsilon_5 = 9 − 8.4 = 0.6\\)\n\nStep 3: Square the residuals\n\n\\(\\epsilon_1^2 = -0.6^2 = 0.36\\)\n\\(\\epsilon_2^2 = 0.7^2 = 0.49\\)\n\\(\\epsilon_3^2 = 1^2 = 1\\)\n\\(\\epsilon_4^2 = -1.7^2 = 2.89\\)\n\\(\\epsilon_5^2 = 0.6^2 = 0.36\\)\n\nStep 4: Calculate the Sum of Squared Residuals\n\\[\n\\sum \\epsilon_i^2 = 0.36 + 0.49 + 1 + 2.89 + 0.36 = 5.1\n\\]\nStep 5: Determine the Residual Standard Deviation (\\(\\sigma\\))\n\\[\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{\\text{SS}_\\text{Residual}}{n - k - 1}} \\\\  \n\\\\   \n& \\hat \\sigma = \\sqrt{\\frac{5.1}{5 - 1 - 1}}  \\\\  \n\\\\   \n& \\hat \\sigma = \\sqrt{\\frac{5.1}{3}}  \\\\  \n\\\\   \n& \\hat \\sigma = \\sqrt{1.70}  \\\\    \n\\\\  \n& \\hat \\sigma = 1.304  \\\\  \n\\end{align}\n\\]\n\n\n\nIn R\nThere are a couple of equivalent ways to obtain the estimated standard deviation of the errors — that is, \\(\\hat \\sigma\\) — from the fitted model (for this example, our fitted model has been named mdl):\n\nsigma(mdl)\nsummary(mdl)"
  },
  {
    "objectID": "1_b1_reading.html#linear-models",
    "href": "1_b1_reading.html#linear-models",
    "title": "Block 1 Flash Cards",
    "section": "Linear Models",
    "text": "Linear Models\nAssessing model fit involves examining metrics like the sum of squares to measure variability explained by the model, the \\(F\\)-ratio to evaluate the overall significance of the model by comparing explained variance to unexplained variance, and \\(R\\)-squared / Adjusted \\(R\\)-squared to quantify the proportion of variance in the dependent variable explained by the independent variable(s).\n\n Sums of Squares\n\n\nTo quantify and assess a model’s utility in explaining variance in an outcome variable, we can split the total variability of that outcome variable into two terms: the variability explained by the model plus the variability left unexplained in the residuals.\nThe sum of squares measures the deviation or variation of data points away from the mean (i.e., how spread out are the numbers in a given dataset). We are trying to find the equation/function that best fits our data by varying the least from our data points.\nTotal Sum of Squares\nFormula:\n\\[\n\\text{SS}_\\text{Total} = \\sum_{i=1}^{n}(y_i - \\bar{y})^2\n\\] Can also be derived from:\n\\[\n\\text{SS}_\\text{Total} = \\text{SS}_\\text{Model} + \\text{SS}_\\text{Residual}\n\\]\nIn words:\nSquared distance of each data point from the mean of \\(y\\).\nDescription:\nHow much variation there is in the DV.\nExample:\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nSteps:\n\nCalculate the mean of \\(y\\) (\\(\\bar y\\))\n\nCalculate for each observation \\(y_i\\) - \\(\\bar y\\)\n\nSquare each of the obtained \\(y_i\\) - \\(\\bar y\\) values\n\nSum squared values\n\nStep 1: Calculate the mean of \\(y_i\\)\n\\(\\bar y = {\\frac{5+7+8+6+9}{5}} = 7\\)\nStep 2 & 3: Calculate for each observation \\(y_i\\) - \\(\\bar y\\) & square values\n\n\nObserved \\(y_i\\)\n\n\n\\(y_i\\) - \\(\\bar y\\)\n\n\\((y_i - \\bar y)^2\\)\n\n\n\n5\n5 - 7 = -2\n\\(-2^2 = 4\\)\n\n\n7\n7 - 7 = 0\n\\(0^2 = 0\\)\n\n\n8\n8 - 7 = 1\n\\(1^2 = 1\\)\n\n\n6\n6 - 7 = -1\n\\(-1^2 = 1\\)\n\n\n9\n9 - 7 = 2\n\\(2^2 = 4\\)\n\n\n\nStep 4: Calculate sum squared values\n\\(\\text{SS}_\\text{Total} = 4 + 0 + 1 + 1 + 4 = 10\\)\nResidual Sum of Squares\nFormula:\n\\[\n\\text{SS}_\\text{Residual} = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n\\]\nIn words:\nSquared distance of each point from the predicted value.\nDescription:\nHow much of the variation in the DV the model did not explain - a measure that captures the unexplained variation in your regression model. Lower residual sum of squares suggests that your model fits the data well, and higher suggests that the model poorly explains the data (in other words, the lower the value, the better the regression model). If the value was zero here, it would suggest the model fits perfectly with no error.\nExample:\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nSteps:\n\nCalculate predicted values (\\(\\hat{y}_i\\))\n\nCalculate residuals (i.e., the difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)) for each observation)\n\nSquare the residuals\n\nSum squared values\n\nStep 1: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n\\(4.9 + (0.7*1) = 5.6\\)\n\n\n2\n7\n\\(4.9 + (0.7*2) = 6.3\\)\n\n\n3\n8\n\\(4.9 + (0.7*3) = 7\\)\n\n\n4\n6\n\\(4.9 + (0.7*4) = 7.7\\)\n\n\n5\n9\n\\(4.9 + (0.7*5) = 8.4\\)\n\n\n\nStep 2: Calculate residuals\n\n\\(\\epsilon_1 = 5 − 5.6 = -0.6\\)\n\\(\\epsilon_2 = 7 - 6.3 = 0.7\\)\n\\(\\epsilon_3 = 8 - 7 = 1\\)\n\\(\\epsilon_4 = 6 - 7.7 = -1.7\\)\n\\(\\epsilon_5 = 9 − 8.4 = 0.6\\)\n\nStep 3: Square the residuals\n\n\\(\\epsilon_1^2 = -0.6^2 = 0.36\\)\n\\(\\epsilon_2^2 = 0.7^2 = 0.49\\)\n\\(\\epsilon_3^2 = 1^2 = 1\\)\n\\(\\epsilon_4^2 = -1.7^2 = 2.89\\)\n\\(\\epsilon_5^2 = 0.6^2 = 0.36\\)\n\nStep 4: Calculate sum of squared values\n\\(\\text{SS}_\\text{Residual} = 0.36 + 0.49 + 1 + 2.89 + 0.36 = 5.1\\)\nModel Sum of Squares\nFormula:\n\\[\n\\text{SS}_\\text{Model} = \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2\n\\]\nCan also be derived from:\n\\[\n\\text{SS}_\\text{Model} = \\text{SS}_\\text{Total} - \\text{SS}_\\text{Residual}\n\\]\nIn words:\nThe deviance of the predicted scores from the mean of \\(y\\).\nDescription:\nHow much of the variation in the DV your model explained - like a measure that captures how well the regression line fits your data.\nExample:\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nSteps:\n\nCalculate mean of \\(y\\) (\\(\\bar y\\))\n\nCalculate predicted values (\\(\\hat{y}_i\\))\n\nCalculate for each observation \\(\\hat{y}_i - \\bar y\\)\n\nSquaring each of the obtained \\(\\hat{y}_i - \\bar y\\) values\n\nSum squared values\n\nStep 1: Calculate the mean of \\(y_i\\) \n\\(\\bar y = {\\frac{5+7+8+6+9}{5}} = 7\\)\nStep 2: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n\\(4.9 + (0.7*1) = 5.6\\)\n\n\n2\n7\n\\(4.9 + (0.7*2) = 6.3\\)\n\n\n3\n8\n\\(4.9 + (0.7*3) = 7\\)\n\n\n4\n6\n\\(4.9 + (0.7*4) = 7.7\\)\n\n\n5\n9\n\\(4.9 + (0.7*5) = 8.4\\)\n\n\n\nStep 3 & 4: Calculate for each observation \\(\\hat{y}_i\\) - \\(\\bar y\\) & square values\n\n\n\n\\(\\hat{y}_i\\) - \\(\\bar y\\)\n\n\\((\\hat{y}_i - \\bar y)^2\\)\n\n\n\n\\(5.6 - 7 = -1.4\\)\n\\((-1.4)^2 = 1.96\\)\n\n\n\\(6.3 - 7 = -0.7\\)\n\\((-0.7)^2 = 0.49\\)\n\n\n\\(7 - 7 = 0\\)\n\\((0)^2 = 0\\)\n\n\n\\(7.7 - 7 = 0.7\\)\n\\((0.7)^2 = 0.49\\)\n\n\n\\(8.4 - 7 = 1.4\\)\n\\((1.4)^2 = 1.96\\)\n\n\n\nStep 5: Calculate sum of squared values\n\\(\\text{SS}_\\text{Model} = 1.96 + 0.49 + 0 + 0.49 + 1.96 = 4.9\\)\nAlternatively:\n\\[\n\\begin{align}\n& \\text{SS}_\\text{Model} = \\text{SS}_\\text{Total} - \\text{SS}_\\text{Residual} \\\\\n& \\text{SS}_\\text{Model} = 10 - 5.1 \\\\  \n& \\text{SS}_\\text{Model} = 4.9 \\\\  \n\\end{align}\n\\]\n\n\n\n\n\n\n F-ratio\n\n\nOverview:\nWe can perform a test to investigate if a model is ‘useful’ — that is, a test to see if our explanatory variable explains more variance in our outcome than we would expect by just some random chance variable.\nWith one predictor, the \\(F\\)-statistic is used to test the null hypothesis that the regression slope for that predictor is zero:\n\\[\nH_0: \\text{the model is ineffective, }b_1 = 0 \\\\  \n\\] \\[\nH_1 : \\text{the model is effective, }b_1  \\neq 0 \\\\  \n\\]\nIn multiple regression, the logic is the same, but we are now testing against the null hypothesis that all regression slopes are zero. Our test is framed in terms of the following hypotheses:\n\\[\nH_0: \\text{the model is ineffective, }b_1,...., b_k = 0 \\\\    \n\\]\n\\[\nH_1 : \\text{the model is effective, }b_1,...., b_k  \\neq 0 \\\\  \n\\]\nThe relevant test-statistic is the \\(F\\)-statistic, which uses “Mean Squares” (these are Sums of Squares divided by the relevant degrees of freedom). We then compare that against (you guessed it) an \\(F\\)-distribution! \\(F\\)-distributions vary according to two parameters, which are both degrees of freedom.\nFormula:\n\\[\n\\text{F}_{(df_{model},~df_{residual})} = \\frac{\\text{MS}_\\text{Model}}{\\text{MS}_\\text{Residual}} = \\frac{\\text{SS}_\\text{Model}/\\text{df}_\\text{Model}}{\\text{SS}_\\text{Residual}/\\text{df}_\\text{Residual}} \\\\\n\\quad \\\\\n\\]\n\\[\n\\begin{align}\n& \\text{Where:} \\\\\n& df_{model} = k \\\\\n& df_{residual} = n-k-1 \\\\\n& n = \\text{sample size} \\\\\n& k  = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\nDescription:\nTo test the significance of an overall model, we can conduct an \\(F\\)-test. The \\(F\\)-test compares your model to a model containing zero predictor variables (i.e., the intercept only model), and tests whether your added predictor variables significantly improved the model.\nIt is called the \\(F\\)-ratio because it is the ratio of the how much of the variation is explained by the model (per parameter) versus how much of the variation is unexplained (per remaining degrees of freedom).\nThe \\(F\\)-test involves testing the statistical significance of the \\(F\\)-ratio.\nQ: What does the \\(F\\)-ratio test?A: The null hypothesis that all regression slopes in a model are zero (i.e., explain no variance in your outcome/DV). The alternative hypothesis is that at least one of the slopes is not zero.\nThe \\(F\\)-ratio you see at the bottom of summary(model) is actually a comparison between two models: your model (with some explanatory variables in predicting \\(y\\)) and the null model.\nIn regression, the null model can be thought of as the model in which all explanatory variables have zero regression coefficients. It is also referred to as the intercept-only model, because if all predictor variable coefficients are zero, then we are only estimating \\(y\\) via an intercept (which will be the mean - \\(\\bar y\\)).\nInterpretation:\nAlongside viewing the \\(F\\)-ratio, you can see the results from testing the null hypothesis that all of the coefficients are \\(0\\) (the alternative hypothesis is that at least one coefficient is \\(\\neq 0\\). Under the null hypothesis that all coefficients = 0, the ratio of explained:unexplained variance should be approximately 1)\nIf your model predictors do explain some variance, the \\(F\\)-ratio will be significant, and you would reject the null, as this would suggest that your predictor variables included in your model improved the model fit (in comparison to the intercept only model).\nPoints to note:\n\nThe larger your \\(F\\)-ratio, the better your model\nThe \\(F\\)-ratio will be close to 1 when the null is true (i.e., that all slopes are zero)\n\nHow to calculate \\(F\\)-ratio\n\n\nBy Hand\nUsing R\n\n\n\nSteps:\n\nCalculate model sum of squares\nCalculate residual sum of squares\nCalculate total sum of squares\nCalculate \\(df_{model}\\)\n\nCalculate \\(df_{residual}\\)\n\n\nStep 1, 2, & 3\nFollow steps above in the Sums of Squares flashcard:\n\\[\n\\begin{align}\n& \\text{SS}_\\text{Total} = 10  \\\\\n& \\text{SS}_\\text{Residual} = 5.1 \\\\  \n& \\text{SS}_\\text{Model} = 4.9 \\\\  \n\\end{align}\n\\]\nStep 4: Calculate \\(df_{model}\\)\n\\[\n\\begin{align}\n&df_{model} = k  \\\\  \n&df_{model} = 1\n\\end{align}\n\\]\nStep 5: Calculate \\(df_{residual}\\)\n\\[\n\\begin{align}\n&df_{residual} = n-k-1   \\\\  \n&df_{residual} = 5-1-1  \\\\  \n&df_{residual} = 3  \n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\text{F}_{(df_{model},~df_{residual})} = \\frac{\\text{MS}_\\text{Model}}{\\text{MS}_\\text{Residual}} = \\frac{\\text{SS}_\\text{Model}/\\text{df}_\\text{Model}}{\\text{SS}_\\text{Residual}/\\text{df}_\\text{Residual}} \\\\  \n\\\\  \n&\\text{F}_{(df_{model},~df_{residual})} = \\frac{4.9/1}{5.1/3} \\\\  \n\\\\  \n&\\text{F}_{(df_{model},~df_{residual})} = \\frac{4.9}{1.7} \\\\  \n\\\\  \n&\\text{F}_{(df_{model},~df_{residual})} = 2.88  \n\\end{align}\n\\]\n\n\n\nIn R\nWe can see the \\(F\\)-statistic and associated \\(p\\)-value at the bottom of the output of summary(&lt;modelname&gt;):\n\n\n\n\nMultiple regression output in R, F statistic highlighted\n\n\n\nAlternatively, you can extract this information as it is stored in the summary() of the model:\n\n#F-Statistic\nsummary(recall_multi)$fstatistic\n\n   value    numdf    dendf \n12.92426  2.00000 17.00000 \n\n#P-Value\npf(summary(recall_multi)$fstatistic[1], \n   summary(recall_multi)$fstatistic[2], \n   summary(recall_multi)$fstatistic[3], \n   lower.tail = FALSE)\n\n       value \n0.0003866881 \n\n\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nThe linear model with recall confidence and age explained a significant amount of variance in recall accuracy beyond what we would expect by chance \\(F(2, 17) = 12.92, p &lt; .001\\).\n\n\n\n\n\n\n\n\n R-squared and Adjusted R-squared\n\n\nOverview:\n\\(R^2\\) represents the proportion of variance in \\(Y\\) that is explained by the model predictor variables.\nFormula:\nThe \\(R^2\\) coefficient is defined as the proportion of the total variability in the outcome variable which is explained by our model:\n\\[\nR^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Residual}}{SS_{Total}}\n\\]\nThe Adjusted \\(R^2\\) coefficient is defined as:\n\\[\n\\hat R^2 = 1 - \\frac{(1 - R^2)(n-1)}{n-k-1}\n\\quad \\\\\n\\]\n\\[\n\\begin{align}\n& \\text{Where:} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\n\nWhen to report Multiple \\(R^2\\) vs. Adjusted \\(R^2\\):\nThe Multiple \\(R^2\\) value should be reported for a simple linear regression model (i.e., one predictor).\nUnlike \\(R^2\\), Adjusted-\\(R^2\\) does not necessarily increase with the addition of more explanatory variables, by the inclusion of a penalty according to the number of explanatory variables in the model. Since Adjusted-\\(R^2\\) is adjusted for the number of predictors in the model, this should be used when there are 2 or more predictors in the model. As a side note, the Adjusted-\\(R^2\\) should always be less than or equal to \\(R^2\\).\nHow to calculate Multiple \\(R^2\\) & Adjusted \\(R^2\\)\n\n\nBy Hand\nUsing R\n\n\n\nUsing the information calculated above in the Sums of Squares flashcard above, we can simply substitute values into the formula for \\(R^2\\):\n\\[\n\\begin{align}  \n& R^2 = \\frac{\\text{SS}_{\\text{Model}}}{\\text{SS}_{\\text{Total}}} = 1 - \\frac{\\text{SS}_{\\text{Residual}}}{\\text{SS}_{\\text{Total}}} \\\\\n\\\\  \n& R^2 = \\frac{4.9}{10} = 1 - \\frac{5.1}{10} \\\\  \n\\\\  \n& R^2 = 0.49 = 0.49\n\\end{align}  \n\\]\nAnd for Adjusted-\\(R^2\\):\n\\[\n\\begin{align}  \n& \\text{Adjusted-R}^2 = 1 - \\frac{(1 - R^2)(n-1)}{n-k-1} \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - \\frac{(1 - 0.49)(5-1)}{5-1-1} \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - \\frac{(0.51)(4)}{3} \\\\  \n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - \\frac{2.04}{3} \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - 0.68 \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 0.32 \\\\\n\\end{align}\n\\]\n\n\n\nIn R\nWe can see both \\(R^2\\) and Adjusted-\\(R^2\\) in the second bottom row of the summary(&lt;modelname&gt;):\n\n\n\n\nMultiple regression output in R, R^2 statistic highlighted\n\n\n\nAlternatively, you can extract this information as it is stored in the summary() of the model:\n\n#R-Squared\nsummary(recall_multi)$r.squared\n\n[1] 0.6032536\n\n#Adjusted R-Squared\nsummary(recall_multi)$adj.r.squared\n\n[1] 0.5565775\n\n\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nTogether, recall confidence and age explained approximately 55.66% of the variance in recall accuracy."
  },
  {
    "objectID": "1_b1_reading.html#linear-models-1",
    "href": "1_b1_reading.html#linear-models-1",
    "title": "Block 1 Flash Cards",
    "section": "Linear Models",
    "text": "Linear Models\nOne useful thing we might want to do is compare our models with and without some predictor(s).There are numerous ways we can do this, but the method chosen depends on the models and underlying data:\n\n\n\n\n\n\n\n\n\n Nested vs Non-Nested Models\n\n\nNested Models\nConsider that you have two regression models where Model 1 contains a subset of the predictors contained in the other Model 2 and is fitted to the same data. More simply, Model 2 contains all of the predictors included in Model 1, plus additional predictor(s). This means that Model 1 is nested within Model 2, or that Model 1 is a submodel of Model 2. These two terms, at least in this setting, are interchangeable - it might be easier to think of Model 1 as your null and Model 2 as your alternative.\nNon-Nested Models\nConsider that you have two regression models where Model 1 contains different variables to those contained in Model 2, where both models are fitted to the same data. More simply, Model 1 and Model 2 contain unique variables that are not shared. This means that Model 1 and Model 2 are not nested.\n\n\n\n\n\n Incremental F-test\n\n\nIf (and only if) two models are nested, can we compare them using an incremental F-test.\nThis is a formal test of whether the additional predictors provide a better fitting model.\nFormally this is the test of:\n\n\\(H_0:\\) coefficients for the added/omitted variables are all zero.\n\\(H_1:\\) at least one of the added/omitted variables has a coefficient that is not zero.\n\nThe \\(F\\)-ratio for comparing the residual sums of squares between two models can be calculated as:\n\\[\nF_{(df_R-df_F),~df_F} = \\frac{(SSR_R-SSR_F)/(df_R-df_F)}{SSR_F / df_F} \\\\\n\\quad \\\\\n\\] \\[\n\\begin{align}\n& \\text{Where:} \\\\\n\\\\\n& SSR_R = \\text{residual sums of squares for the restricted model} \\\\\n& SSR_F = \\text{residual sums of squares for the full model} \\\\\n& df_R = \\text{residual degrees of freedom from the restricted model} \\\\\n& df_F = \\text{residual degrees of freedom from the full model} \\\\\n\\end{align}\n\\]\n\nIn R\nWe can conduct an incremental \\(F\\)-test to compare two models by fitting both models using lm(), and passing them to the anova() function:\n\nmodel1 &lt;- lm( ... )\nmodel2 &lt;- lm( ... )\nanova(model1, model2)\n\nIf we wanted to, for example, compare a model with just one predictor, \\(x1\\), to a model with 2 predictors: \\(x1\\), and \\(x2\\), we can assess the extent to which the variable \\(x2\\) improves model fit:\n\nmodel1 &lt;- lm(y ~ x1, data = data_name)\nmodel2 &lt;- lm(y ~ x1 + x2, data = data_name)\nanova(model1, model2)\n\nFor example:\n\n\n\n\nModel Comparisons using Incremental F-test\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nRecall confidence explained a significant amount of variance in recall accuracy beyond age \\((F(1, 17) = 21.95, p &lt; .001)\\).\n\n\n\n\n\n\n\n\n AIC & BIC\n\n\nAIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) combine information about the sample size, the number of model parameters, and the residual sums of squares (\\(SS_{residual}\\)). Models do not need to be nested to be compared via AIC and BIC, but they need to have been fit to the same dataset.\nAIC can be calculated as:\n\\[\n\\begin{align}\n& AIC = n\\,\\text{ln}\\left( \\frac{SS_{residual}}{n} \\right) + 2k \\\\\n\\end{align}\n\\quad \\\\\n\\]\nBIC can be calculated as:\n\\[\n\\begin{align}\n& BIC = n\\,\\text{ln}\\left( \\frac{SS_{residual}}{n} \\right) + k\\,\\text{ln}(n) \\\\\n\\end{align}\n\\quad \\\\\n\\]\nWhere for both AIC and BIC:\n\\[\n\\begin{align}\n& SS_{residual} = \\text{sum of squares residuals} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n& \\text{ln} = \\text{natural log function}\n\\end{align}\n\\]\nFor both of these fit indices, lower values are better, and both include a penalty for the number of predictors in the model (although BIC’s penalty is harsher).\nSo how do we determine whether there is a statistical difference between two models? To evaluate our model comparisons, we need to look at the difference (\\(\\Delta\\)) between the two values:\n\nAIC: There are no specific thresholds to suggest how big a difference in two models is needed to conclude that one is substantively better than the other\nBIC: Using the following \\(\\Delta BIC\\) cutoffs (Raftery, 1995):\n\n\n\nValue\nInterpretation of Difference between Models\n\n\n\n\\(\\Delta &lt; 2\\)\nNo evidence\n\n\n\\(2 &gt; \\Delta &lt; 6\\)\nPositive evidence\n\n\n\\(6 &gt; \\Delta &lt; 10\\)\nStrong evidence\n\n\n\\(\\Delta &gt; 10\\)\nVery strong evidence\n\n\n\n\nIn R\nWe can calculate AIC and BIC by using the AIC() and BIC() functions respectively:\n\n#AIC\nAIC(modelname)\n\n#BIC\nBIC(modelname)\n\nFor example, with AIC:\n\n\n\n\nModel Comparisons using AIC\n\n\n\nand BIC:\n\n\n\n\nModel Comparisons using BIC\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nBased on both AIC and BIC, the model predicting recall accuracy that included both recall confidence and age was better fitting \\((\\text{AIC} = 152.28; \\text{BIC} = 156.27)\\) than the model with age alone \\((\\text{AIC} = 166.86; \\text{BIC} = 169.85)\\)."
  },
  {
    "objectID": "1_b1_reading.html#latex-symbols-equations",
    "href": "1_b1_reading.html#latex-symbols-equations",
    "title": "Block 1 Flash Cards",
    "section": "LaTeX Symbols & Equations",
    "text": "LaTeX Symbols & Equations\nBy embedding LaTeX into RMarkdown, you can accurately and precisely format mathematical expressions, ensuring that they are not only technically correct but also visually appealing and easy to interpret.\n\n LaTeX Guide\n\n\nFor an overview of how to integrate LaTeX symbols and equations, review Lesson 9 of the RMD bootcamp."
  },
  {
    "objectID": "1_b1_reading.html#apa-formatting",
    "href": "1_b1_reading.html#apa-formatting",
    "title": "Block 1 Flash Cards",
    "section": "APA Formatting",
    "text": "APA Formatting\nAPA format is a writing/presentation style that is often used in psychology to ensure consistency in communication. APA formatting applies to all aspects of writing - from formatting of papers (including tables and figures), citation of sources, and reference lists. This means that it also applies to how you present results in your Psychology courses, including DAPR2.\n\n APA Formatting Guides\n\n\nAll results should be presented following APA guidelines.\nYou also need to follow APA style rules for tables and figures.\nMake sure to familiarise yourself with the above guides, and practice presenting your results following these rules."
  },
  {
    "objectID": "1_b1_reading.html#tables",
    "href": "1_b1_reading.html#tables",
    "title": "Block 1 Flash Cards",
    "section": "Tables",
    "text": "Tables\nWe want to ensure that we are presenting results in a well formatted table. To do so, there are lots of different packages available (see Lesson 4 of the RMD bootcamp).\nOne of the most convenient ways to present results from regression models is to use the tab_model() function from sjPlot.\n\n Creating tables via tab_model\n\n\nWithin tab_model(), there are lots of different ways that you can customise your table. The most common arguments that you should use are dv.labels, pred.labels, and title.\nYou can rename your DV and IV labels by specifying dv.labels and pred.labels. To do so, specify your variable name on the left, and what you would like this to be named in the table on the right. For title, you can simply specify in ““’s what you want your title to be e.g., title = \"This is my title\".\nHere’s an example if I had fitted a model with the following information:\n\nModel name = mdl_test\n\nModel DV = cognitive_score\n\nModel IVs = SES and age\n\n\n\nmdl_test &lt;- lm(cognitive_score ~ SES + age, data = data_name)\n\nI want to change the names of SES and age to be socio-economic status and age - in years respectively. What we need to pay attention to here is the ordering of the IVs - the ordering in our lm() must match that in tab_model(). I also want to name my table Regression Table for Cognitive Scores Model. Here is how we would do this in R:\n\nlibrary(sjPlot)\ntab_model(mdl_test,\n          pred.labels = c('Intercept', 'socio-economic status', 'age - in years'),\n          title = \"Regression Table for Cognitive Scores Model\")\n\nSee here for another short example."
  },
  {
    "objectID": "1_b1_reading.html#cross-referencing",
    "href": "1_b1_reading.html#cross-referencing",
    "title": "Block 1 Flash Cards",
    "section": "Cross Referencing",
    "text": "Cross Referencing\nCross-referencing is a very helpful way to direct your reader through your document, and the good news is that this can be done automatically in RMarkdown.\n\n Cross Referencing\n\n\nThere are three key components to allow you to successfully cross-reference within your RMarkdown document:\n\nA bookdown output format\nA caption to your figure or table\nA named/labeled code chunk\n\nOnce you have the above, you will be able to cross-reference using the syntax @ref(type:label), where label is the chunk name/label, and type is the environment being referenced (e.g. tab for table, fig for figure, etc.).\nFor an in-depth overview and example of how to cross-reference, see Lesson 7 of the RMD bootcamp."
  },
  {
    "objectID": "1_b1_reading.html#footnotes",
    "href": "1_b1_reading.html#footnotes",
    "title": "Block 1 Flash Cards",
    "section": "Footnotes",
    "text": "Footnotes\n\nYes, the error term is gone. This is because the line of best-fit gives you the prediction of the average recall accuracy for a given age, and not the individual recall accuracy of an individual person, which will almost surely be different from the prediction of the line.↩︎"
  },
  {
    "objectID": "1_b2_reading.html",
    "href": "1_b2_reading.html",
    "title": "Block 1 & 2 Flash Cards",
    "section": "",
    "text": "Within this reading, the following packages are used:\n\ntidyverse\nsjPlot\nkableExtra\npsych\npatchwork\nplotly\n\nNote that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here."
  },
  {
    "objectID": "1_b2_reading.html#numeric-exploration",
    "href": "1_b2_reading.html#numeric-exploration",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Numeric Exploration",
    "text": "Numeric Exploration\nNumeric exploration of data involves examining and describing key statistics like mean, median, and standard deviation via descriptives tables; and assessing the associations among variables through correlation coefficients. Exploring our data numerically helps us to identify patterns and associations in the data. When doing so, it is important to contextualise the descriptive statistics within the scope of the research question and associated scales.\nDescriptives\n\n Descriptives Tables\n\n\nThere are numerous packages available that allow us to pull out descriptive statistics from our dataset such as tidyverse and psych.\nWhen we pull out descriptive statistics, it is useful to present these in a well formatted table for your reader. There are lots of different ways of doing this, but one of the most common (and straightforward!) is to use the kable() function from the package kableExtra.\nThis allows us to give our table a clear caption (via caption = \"insert caption here\", align values within columns e.g., center aligned via align = \"??\"), and we can also round to however many decimal places we desire (standard for APA is 2 dp; via digits = ??).\nWe can also add in the function kable_styling(). This is really helpful for customsing your table e.g., the font size, position, and whether or not you want the table full width (as well as lots of other things - check out the helper function!).\nFor an overview of how to make tables in RMarkdown, see Lesson 4 of the RMD bootcamp.\n\n\n\n\n\n Descriptives Tables - Examples\n\n\n\n\nThe tidyverse way\nThe psych way\n\n\n\nWe can use the summarise() function to numerically summarise/describe our data. Some key values we may want to consider extracting are (though not limited to): the mean (via mean(), standard deviation (via sd()), minimum value (via min()), maximum value (via max()), standard error (via se()), and skewness (via skew()).\n\n\nNumeric values only example:\nCategorical and numeric values example:\n\n\n\n\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# taking the mean and standard deviation of sepal length via the summarize function\n# returning a table with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\niris |&gt;\n    summarize(\n        M_Length = mean(Sepal.Length),\n        SD_Length = sd(Sepal.Length)\n    ) |&gt;\n    kable(caption = \"Sepal Length Descriptives (in cm)\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length Descriptives (in cm)\n\nM_Length\nSD_Length\n\n\n5.84\n0.83\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# grouping by Species. NOTE: we can group by 2 variables - we would just separate by a comma within group_by( , )\n# taking the mean and standard deviation of sepal length via the summarize function\n# returning a table of sepal length grouped by species with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\n\niris |&gt;\n    group_by(Species) |&gt;\n    summarize(\n        M_Length = mean(Sepal.Length),\n        SD_Length = sd(Sepal.Length)\n    ) |&gt;\n    kable(caption = \"Sepal Length (in cm) Grouped by Species Descriptives Table\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length (in cm) Grouped by Species Descriptives Table\n\nSpecies\nM_Length\nSD_Length\n\n\n\nsetosa\n5.01\n0.35\n\n\nversicolor\n5.94\n0.52\n\n\nvirginica\n6.59\n0.64\n\n\n\n\n\n\n\n\n\n\nThe describe() function will produce a table of descriptive statistics. If you would like only a subset of this output (e.g., mean, sd), you can use select() after calling describe() e.g., describe() |&gt; select(mean, sd).\n\n\nNumeric values only example:\nCategorical and numeric values example:\n\n\n\n\nlibrary(psych)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# we want to get descriptive statistics of the iris dataset, specifically the sepal length column\n# we specifically want to select the mean and standard deviation from the descriptive statistics available (try this without including this argument to see what values you all get out)\n# returning a table with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\ndescribe(iris$Sepal.Length) |&gt;\n    select(mean, sd) |&gt;\n    kable(caption = \"Sepal Length Descriptives (in cm)\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length Descriptives (in cm)\n\n\nmean\nsd\n\n\nX1\n5.84\n0.83\n\n\n\n\n\n\nNote that this is quite an overly complex way to return these summary statistics - using the tidyverse() way is much more intuitive and straightforward!\n\nlibrary(psych)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# we want to get descriptive statistics of the iris dataset, specifically the sepal length column by Species\n# we want to return a matrix (hence mat = TRUE), then convert this to a dataframe\n# we specifically want to select the mean and standard deviation from the descriptive statistics available (try this without including this argument to see what values you all get out)\n# returning a table with a new column names of Group, Mean, SD; adding a caption; numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\n\n\ndescribeBy(Sepal.Length ~ Species, data = iris, mat = TRUE, digits = 2) |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column() |&gt; \n  select(group1, mean, sd) |&gt;\n    kable(col.names = c(\"Group\", \"Mean\", \"SD\"), caption = \"Sepal Length Descriptives (in cm)\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length Descriptives (in cm)\n\nGroup\nMean\nSD\n\n\n\nsetosa\n5.01\n0.35\n\n\nversicolor\n5.94\n0.52\n\n\nvirginica\n6.59\n0.64\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelation\n\n Correlation Coefficient\n\n\nThe correlation coefficient - \\(r_{(x,y)}=\\frac{\\mathrm{cov}(x,y)}{s_xs_y}\\) - is a standardised number which quantifies the strength and direction of the linear association between two variables. In a population it is denoted by \\(\\rho\\), and in a sample it is denoted by \\(r\\).\nValues of \\(r\\) fall between \\(-1\\) and \\(1\\). How to interpret:\nSize\nMore extreme values (i.e., the The closer \\(r\\) is to \\(+/- 1\\)) the stronger the linear association, and the closer to \\(0\\) a weak/no association. Commonly used cut-offs are:\n\nWeak = \\(.1 &lt; |r| &lt; .3\\)\n\nModerate = \\(.3 &lt; |r| &lt; .5\\)\n\nStrong = \\(|r| &gt; .5\\)\n\n\n\n\n\n\n\n\n\n\nDirection\nThe sign of \\(r\\) says nothing about the strength of the association, but its nature and direction:\n\nPositive association means that values of one variable tend to be higher when values of the other variable are higher\n\n\n\n\n\n\n\n\n\n\nNegative association means that values of one variable tend to be lower when values of the other variable are higher\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Correlation Matrix\n\n\nA correlation matrix is a table showing the correlation coefficients between variables. Each cell in the table shows the association between two variables. The diagonals show the correlation of a variable with itself (and are therefore always equal to 1).\n\nIn R\nWe can create a correlation matrix by giving the cor() function a dataframe. It is important to remember that all variables must be numeric. One way to check this is by using the str() argument.\n\nLet’s check the structure of the iris dataset to ensure that all variables are numeric:\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nWe can see that the variable Species in column 5 is a factor - this means that we cannot include this in our correlation matrix. Therefore, we need to subset, or, in other words, select specific columns. We can do this either giving the column numbers inside [], or using select(). In our case, we want the variables in columns 1 - 4, just not 5.\nIf you had NA values within your dataset, you could choose to remove these NAs using na.rm = TRUE inside the cor() function.\n\nIn R\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\nround(cor(iris[,c(1:4)]), digits = 2)\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n\n\n\n\n\n# select only the columns we want by variable name, and pass this to cor()\niris |&gt; \n  select(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) |&gt;\n  cor() |&gt;\n  round(digits = 2)\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n\n\n\n\n\n\n\n\n\n\n\n Correlation - Hypothesis Testing\n\n\nThe hypotheses of the correlation test are, as always, statements about the population parameter (in this case the correlation between the two variables in the population - i.e., \\(\\rho\\)).\nIf we are conducting a two tailed test, then…\n\n\n\\(H_0: \\rho = 0\\). There is no linear association between \\(x\\) and \\(y\\) in the population\n\n\n\\(H_1: \\rho \\neq 0\\) There is a linear association between \\(x\\) and \\(y\\)\n\n\nIf we instead conduct a one-tailed test, then we are testing either…\n\n\n\\(H_0: \\rho \\leq 0\\) There is a negative or no linear association between \\(x\\) and \\(y\\)\n\n\n\\(H_1: \\rho &gt; 0\\) There is a positive linear association between \\(x\\) and \\(y\\)\n\n\nOR\n\n\n\\(H_0: \\rho \\geq 0\\) There is a positive or no linear association between \\(x\\) and \\(y\\)\n\n\n\\(H_1: \\rho &lt; 0\\) There is a negative linear association between \\(x\\) and \\(y\\)\n\n\nTest Statistic\nThe test statistic for this test is the \\(t\\) statistic, the formula for which depends on both the observed correlation (\\(r\\)) and the sample size (\\(n\\)):\n\\[t = r \\sqrt{\\frac{n-2}{1-r^2}}\\]\np-value\nWe calculate the \\(p\\)-value for our \\(t\\)-statistic as the long-run probability of a \\(t\\)-statistic with \\(n-2\\) degrees of freedom being less than, greater than, or more extreme in either direction (depending on the direction of our alternative hypothesis) than our observed \\(t\\)-statistic.\nAssumptions\nFor a test of Pearson’s correlation coefficient \\(r\\), we need to make sure a few conditions are met:\n\nBoth variables are quantitative (i.e., continuous)\n\nBoth variables are drawn from normally distributed populations\n\nThe association between the two variables is linear\n\nNo extreme outliers in dataset\n\nHomoscedasticity (homogeneity of variance)\n\n\n\n\n\n\n Correlation - Hypothesis Testing in R\n\n\n\nIn R\nWe can test the significance of the correlation coefficient really easily with the function cor.test():\n\ncor.test(iris$Sepal.Length, iris$Petal.Length)\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\n\nNote, by default, cor.test() will include only observations that have no missing data on either variable.\nWe can specify whether we want to conduct a one- or two-tailed test by adding the argument alternative = and specifying alternative = \"less\", alternative = \"greater\", or alternative = \"two.sided\" (the latter being the default).\n\n\n\n\n\n\n\nExample Interpretation\nThere was a strong positive association between sepal length and petal length \\((r = .87, t(148) = 21.65, p &lt; .001)\\). These results suggested that a greater sepal length was positively associated with a greater petal length.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor a detailed recap of all things correlation (including further details and examples), revisit the Correlation lecture from DAPR1."
  },
  {
    "objectID": "1_b2_reading.html#visual-exploration",
    "href": "1_b2_reading.html#visual-exploration",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Visual Exploration",
    "text": "Visual Exploration\nVisual exploration of our data allows us to visualize the distributions of our data, and to identify potential associations among variables.\n\n How to Visualise Data\n\n\nTo visualise (i.e., plot) our data, we can use ggplot() from the tidyverse package. Note the key components of the ggplot() code:\n\n\ndata = where we provide the name of the dataframe\n\naes = where we provide the aesthetics. These are things which we map from the data to the graph. For instance, the \\(x\\)-axis, or if we wanted to colour the columns/bars according to some aspect of the data\n\n+ geom_... = where we add (using +) some geometry. These are the shapes (e.g., bars, points, etc.), which will be put in the correct place according to what we specified in aes()\n\n\nlabs() = where we provide labels for our plot (e.g., the \\(x\\)- and \\(y\\)-axis)\n\n\n\n\n\n\n\nNote\n\n\n\nThere are lots of arguments that you can further customise, some of which are specified in the examples below e.g., bins =, alpha =, fill =, linewidth =. linetype =, size = etc. For these, you can look up the helper function to see the range of arguments they can take using ? - e.g., ?fill.\nIf you’d like to read more about ggplot(), there is a handy cheatsheet.\n\n\nOne other thing to consider when visualising your data is how you are going to arrange your plots. Some handy tips on this:\n\nUse to wrap text in your titles and or axis labels\n\nThe patchwork package allows us to arrange multiple plots in two ways - | arranges the plots adjacent to one another, and / arranges the plots on top of one another\n\n\n\n\n\n\n Marginal Distributions - Examples\n\n\n\n\nHistogram\nDensity\nBoxplot\n\n\n\nA histogram shows the frequency of values which fall within bins of an equal width.\nBasic:\n\nx-axis: possible values of some variable, grouped into bins\ny-axis: frequency of a given value or values within bins\n\nWhat are bins?: A bin represents a range of scores\n\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram() +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nUpdating Bins:\nWithin geom_histogram(), we can specify bins = to specify the number of columns we want (for this example, lets say we want 10):\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(bins = 10) +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAlternatively, we can specify binwidth = to specify the width of each bin (it is very helpful to be aware of the scale of your variable here!):\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(binwidth = 0.1) +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nOutline Columns with Color:\nWithin geom_histogram(), we can specify color = to set a colored outline of the columns:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(color = \"darkred\") +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nFill Columns with Color:\nWithin geom_histogram(), we can specify fill = to fill the columns with a color:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(fill = \"darkred\") +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n“Density” is a bit similar to the notion of “relative frequency” (or “proportion”), in that for a density curve, the values on the y-axis are scaled so that the total area under the curve is equal to 1. In creating a curve for which the total area underneath is equal to one, we can use the area under the curve in a range of values to indicate the proportion of values in that range.\nBasic:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density() +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nFilled:\nWe can fill our plot with colour by specifying fill = within geom_density():\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density(fill = \"darkred\") +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nLine Type & Width:\nWe can change the type and width of the line by specifying linetype = and linewidth = within geom_density():\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density(linetype = 6, linewidth = 3) +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\nBoxplots provide a useful way of visualising the interquartile range (IQR). You can see what each part of the boxplot represents in Figure Figure 1.\n\n\n\n\nFigure 1: Anatomy of a Boxplot\n\n\n\nBasic:\nWe need to specify + geom_boxplot() to get a boxplot:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n  geom_boxplot() +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nRotate Boxplot:\nIf we had set aes(y = Sepal.Length) instead, then it would simply be rotated 90 degrees:\n\nggplot(data = iris, aes(y = Sepal.Length)) +\n  geom_boxplot() +\n    labs(y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Bivariate Associations - Examples\n\n\nUnlike in our marginal plots where we specified our x-axis variable within aes(), to visualise bivariate associations, we need to specify what variables we want on both our x- and y-axis.\n\n\nScatterplot\nScatterplot of Matrices (SPLOM)\nBoxplot\nViolin Plot\nFacets\n\n\n\nWe can use a scatterplot (since the variables are numeric and continuous) to visualise the association between the two numeric variables - these will be our x- and y-axis values.\nWe plot these values for each row of our dataset, and we should end up with a cloud of scattered points.\nHere we will want to comment on any key observations that we notice, including if we detect outliers or points that do not fit with the pattern in the rest of the data. Outliers are extreme observations that are not possible values of a variable or that do not seem to fit with the rest of the data. This could either be:\n\n\nmarginally along one axis: points that have an unusual (too high or too low) x-coordinate or y-coordinate\n\njointly: observations that do not fit with the rest of the point cloud\n\nBasic:\nWe need to specify + geom_point() to get a scatterplot:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nFill points with color:\nWithin geom_point(), we can specify color = to fill the points with a color:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point(color = \"darkred\") +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange size and opacity:\nWe can change the size (using size =) and the opacity (using alpha =) of our geom elements on the plot. Let’s include this below:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point(size = 3, alpha = 0.5) +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAdd a line of best fit:\nWe can superimpose (i.e., add) a line of best fit by including the argument + geom_smooth(). Since we want to fit a straight line, we want to use method = \"lm\". We can also specify whether we want to display confidence intervals around our line by specifying se = TRUE / FALSE.\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\nUsing pairs.panels() is likely the most useful way to visualise the associations among numeric variables. It returns a scatterplot of matrices (SPLOM) returning you (1) the marginal distribution of each variable via a histogram, (2) the correlation between variables, and (3) bivariate scatterplots.\n\niris |&gt;\n    select(Sepal.Length, Petal.Length, Petal.Width) |&gt;\n    pairs.panels(main = \"Iris SPLOM\")\n\n\n\nFigure 2: Iris SPLOM\n\n\n\n\n\nWe can use a boxplot to visualise the association between one numeric variable and one categorical variable - these will be our y- and x-axis values respectively. This can be helpful to visually compare the distribution of multiple groups.\nBasic:\nWe need to specify + geom_boxplot() to get a boxplot:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange boxplot fill colours by group:\nWithin aes(), we can specify fill = to fill the boxes with a color:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange boxplot line colours by group:\nWithin aes(), we can specify color = to colour the lines with a color:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAdding jitter:\nWe can add jittered points to a boxplot to better see the underlying distribution of the data (by adding a little random variation to each data point) via geom_jitter():\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n    geom_boxplot() +\n    geom_jitter() + \n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange legend position:\nWe can add the argument + theme(legend.position = ) to move (or even remove) the legend by specifying, for example, \"right\", \"left\", \"top\", \"bottom\", or \"none\" to remove.\n\n# legend at bottom of plot\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\") + \n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nLike a boxplot, we can use a violin plot to visualise the association between one numeric variable and one categorical variable - these will be our y- and x-axis values respectively. It combines a summary of the data’s range and a kernel density estimation, providing a detailed view of the distribution.\nBasic:\nWe need to specify + geom_violin() to get a violin plot:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length)) +\n    geom_violin() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange violin colours by group:\nWithin aes(), we can specify fill = to fill the violins with a color:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_violin() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange Size and opacity:\nWe can change the size (using size =) and the opacity (using alpha =) of our geom elements on the plot. Let’s include this below:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_violin(size = 1, alpha = 0.5) +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAdding jitter:\nWe can add jittered points to a violin plot to better see the underlying distribution of the data (by adding a little random variation to each data point) via geom_jitter():\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_violin() + \n    geom_jitter(alpha = 0.5) + \n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange legend position:\nWe can add the argument + theme(legend.position = ) to move (or even remove) the legend by specifying, for example, \"right\", \"left\", \"top\", \"bottom\", or \"none\" to remove.\n\n# no legend\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_violin() + \n    geom_jitter(alpha = 0.5) + \n    theme(legend.position = 'none') +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\nWhen we have two numeric variables, as well as categorical variables, we can use facet_wrap() / facet_grid() to help divide/arrange our plots. If we had two categorical variables, by simply stringing them together to further group our plots by specifying facet_wrap( ~ cat_variable1 + cat_variable2)\nBasic:\nWe need to specify + geom_point() to get a scatterplot, and either + facet_wrap() or + facet_grid() to separate by your categorical variable:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    facet_wrap(~Species) + \n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAdd a line of best fit:\nWe can superimpose (i.e., add) a line of best fit by including the argument + geom_smooth(). Since we want to fit a straight line, we want to use method = \"lm\". We can also specify whether we want to display confidence intervals around our line by specifying se = TRUE / FALSE. Note that a line is fitted for every level of your categorical variable:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE) +\n        facet_wrap(~Species) + \n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nSubplot layout:\nYou can change the overall layout of the subplots by specifying dir = within the facet_wrap() argument, where “h” will return a horizontal layout (this is the default) and “v” for vertical.\nYou can also change the layout of the subplot labels by specifying strip.position = within the facet_wrap() argument, where labels can be arranged to display at the “top” (this is the default), “bottom”, “left” or “right”.\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    facet_wrap(~Species, dir = \"v\", strip.position = \"right\") + \n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Multivariate Associations - Examples\n\n\nTo visualise multivariate associations, just like we do for bivariate associations, we need to specify what variables we want on both our x- and y-axis. We also need to take an extra step by specifying a third variable - z - that acts as a differentiating factor across our data. This ‘z’ can be mapped to an aesthetic attribute such as color, shape, or size, allowing us to explore more dynamic patterns and ssociations in our data.\nIf you really wanted to, you could create a plot showing the associations among three variables at once. These are likely more useful when you have an interaction model. However, we wouldn’t really recommend doing this - they can be very difficult to interpret correctly, and given their interactive nature, definitely NOT something that you’d want to include in a stats report. But, for demonstration purposes only, we could create one using the plotly package.\n3D Scatterplot\n\nlibrary(plotly)\n\nplot_ly(data = iris, \n        x = ~Petal.Length, y = ~Sepal.Length, z = ~Petal.Width, \n        type = 'scatter3d', \n        mode = 'markers+lines',\n        scene = list(\n            xaxis = list(title = \"Petal Length\"),\n            yaxis = list(title = \"Sepal Length\"),\n            zaxis = list(title = \"Petal Width\")\n            )\n        )\n\n\n\n\n\nHeatmap of Correlations\n\nplot_ly(z = ~cor(iris[, c(1, 3:4)]), type = \"heatmap\")"
  },
  {
    "objectID": "1_b2_reading.html#deterministic-models",
    "href": "1_b2_reading.html#deterministic-models",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Deterministic Models",
    "text": "Deterministic Models\n\n Description & Specification\n\n\nWe come across functions a lot in daily life, and probably don’t think much about it. In a slightly more mathematical setting, we can write down in words and in symbols the function describing the association between the side of a square and its perimeter (e.g., to capture how the perimeter varies as a function of its side). In this case, the perimeter is the dependent variable, and the side is the independent variable.\nThis is what we would refer to as a deterministic model, as it is a model of an exact relationship - there can be no deviation.\nModel Specification\n\n\nIn words\nIn symbols\n\n\n\nThe perimeter of a square is four times the length of its side.\n\n\nThe relationship between side and perimeter of squares is given by:\n\\[\n\\text{Perimeter} = 4 \\cdot \\text{Side}\n\\]\nIf you denote \\(y\\) as the dependent variable Perimeter, and \\(x\\) as the independent variable Side we can rewrite as:\n\\[\ny = 4 \\cdot x\n\\]\n\n\n\n\n\n\n\n\n Visualisation\n\n\nLet’s create a dataset called squares, containing the perimeter of four squares having sides of length \\(0, 2, 5, 9\\) metres, and then plot the squares data as points on a scatterplot.\nFirst, let’s make our squares data. Here we will use two important functions - tibble() and c(). The tibble() function allows us to construct a data frame. To store a sequence of numbers into R, we can combine the values using c(). A sequence of elements all of the same type is called a vector.\n\n#create data frame named squares\nsquares &lt;- tibble(\n  side = c(0, 2, 5, 9), \n  perimeter = 4 * side\n)\n\n#check that our values are contained within squares\nsquares\n\n# A tibble: 4 × 2\n   side perimeter\n  &lt;dbl&gt;     &lt;dbl&gt;\n1     0         0\n2     2         8\n3     5        20\n4     9        36\n\n\nNow we know how ggplot() works, we can start to build our plot. First we specify our data (we want to use the squares data frame), and then our aesthetics. Since the perimeter varies as a function of side, we want side on the \\(x\\)-axis, and perimeter on the \\(y\\)-axis. We want to create a scatterplot, so we need to specify our geom_... argument as geom_point(). Lastly, we will provide clearer axis labels, and include the units of measurement.\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +  \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4*Side')  \n\n\n\nFigure 3: Perimeter = 4*Side\n\n\n\nWe could also visualise the functional relationship by connecting the individual points with a line. To do so, we need to add a new argument - geom_line(). If you would like to change the colour of the line from the default, you can specify geom_line(colour = \"insert colour name\").\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +\n  geom_line(colour = \"darkred\") + \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4*Side')  \n\n\n\nFigure 4: Perimeter = 4*Side\n\n\n\n\n\n\n\n\n Predicted Values\n\n\nSometimes we can directly read a predicted value from the graph of the functional relationship.\nConsider the plot created above. For example, first we need to check where \\(x\\) = 2.5. Then, we draw a vertical dashed line until it meets the blue line. The \\(y\\) value corresponding to \\(x\\) = 2.5 can be read off the \\(y\\)-axis. In our case, we would say a side of 2.5m corresponds to a perimeter of 10m.\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +\n  geom_line(colour = \"blue\") + \n  geom_vline(xintercept = 2.5, colour = \"darkred\", lty = \"dashed\", lwd = 1) + \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4 * Side')  \n\n\n\nFigure 5: Perimeter = 4*Side\n\n\n\nHowever, in this case it is not that easy to read it from Figure 5 (especially without the superimposed dashed red line)… This leads us to the algebraic approach:\nWe can substitute the \\(x\\) value in the formula and calculate the corresponding \\(y\\) value where we would conclude that the predicted perimeter of squared paintings having a 2.5m side is 10m:\n\\[\ny = 4 \\cdot x  \\\\    \n\\]\n\\[\ny = 4 \\cdot 2.5 \\\\  \n\\]\n\\[\ny = 10  \\\\\n\\]"
  },
  {
    "objectID": "1_b2_reading.html#numeric-outcomes-numeric-predictors",
    "href": "1_b2_reading.html#numeric-outcomes-numeric-predictors",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Numeric Outcomes & Numeric Predictors",
    "text": "Numeric Outcomes & Numeric Predictors\nSimple Linear Regression Models\n\n Description & Model Specification\n\n\nThe association between two variables (e.g., recall accuracy and age) will show deviations from the ‘average pattern’. Hence, we need to create a model that allows for deviations from the linear relationship - we need a statistical model.\nA statistical model includes both a deterministic function and a random error term. We typically refer to the outcome (‘dependent’) variable with the letter \\(y\\) and to our predictor (‘explanatory’/‘independent’) variables with the letter \\(x\\). A simple (i.e., one x variable only) linear regression model thus takes the following form (where the terms \\(\\beta_0\\) and \\(\\beta_1\\) are numbers specifying where the line going through the data meets the y-axis (i.e., the intercept - where \\(x\\) = 0; \\(\\beta_0\\)) and its slope (direction and gradient of line; \\(\\beta_1\\)):\nModel Specification\n\\[\ny_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i    \n\\]\nModel Specification: Annotated\n\\[\ny_i = \\underbrace{\\beta_0 + \\beta_1 \\cdot x_i}_{\\text{function of }x} + \\underbrace{\\epsilon_i}_{\\text{random error}}  \n\\\\\n\\]\n\\[\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\nModel Specification: Explained\nLet’s break down what \\(y_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\\) actually means by considering the statement in smaller parts:\n\n\n\\(y_i = \\beta_0 + \\beta_1 \\cdot x_i\\)\n\n\n\\(y_i\\) is our measured outcome variable (our DV)\n\n\n\\(x_i\\) is our measured predictor variable (our IV)\n\n\n\\(\\beta_0\\) is the model intercept\n\n\n\\(\\beta_1\\) is the model slope\n\n\n\n\\(\\epsilon \\sim N(0, \\sigma) \\text{ independently}\\)\n\n\n\\(\\epsilon\\) is the residual error\n\n\n\\(\\sim\\) means ‘distributed according to’\n\n\n\\(N(0, \\sigma) \\text{ independently}\\) means ‘normal distribution with a mean of 0 and a variance of \\(\\sigma\\)’\n\nTogether, we can say that the errors around the line have a mean of zero and constant spread as x varies\n\n\n\n\nIn R\nThere are basically two pieces of information that we need to pass to the lm() function:\n\nThe formula: The regression formula should be specified in the form y ~ x where \\(y\\) is the dependent variable (DV) and \\(x\\) the independent variable (IV).\nThe data: Specify which dataframe contains the variables specified in the formula.\n\nIn R, the syntax of the lm() function can be specified as follows (where DV = dependent variable, IV = independent variable, and data_name = the name of your dataset):\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ IV, data = data_name) \n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ data_name$IV)\n\n\n\n\nyou can also specify as:\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ 1 + IV, data = data_name) \n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ 1 + data_name$IV)\n\n\n\n\n\n\n\n\n\n\nWhy is there a 1 in the two bottom options?\n\n\n\n\n\nWhen we specify the linear model in R, we include after the tilde sign (\\(\\sim\\)), the variables that appear to the right of the \\(\\hat \\beta\\)s. The intercept, or \\(\\beta_0\\), is a constant. That is, we could write it as multiplied by 1.\nIncluding the 1 explicitly is not necessary because it is included by default (you can check this by comparing the outputs of A & B above with and without the 1 included - the estimates are the same!). After a while, you will find you just want to drop the 1 when calling lm() because you know that it’s going to be there, but in these early weeks we tried to keep it explicit to make it clear that you want the intercept to be estimated.\n\n\n\n\n\n\n\nExample\n\nResearch Question\nIs there an association between recall accuracy and age?\n\n\n Overview\n\n\nImagine that you were tasked to investigate whether there was an association between recall accuracy and age. You have been provided with data from twenty participants who studied passages of text (c500 words long), and were tested a week later. The testing phase presented participants with 100 statements about the text. They had to answer whether each statement was true or false, as well as rate their confidence in each answer (on a sliding scale from 0 to 100). The dataset contains, for each participant, the percentage of items correctly answered, their age (in years), and their average confidence rating.\nThe data are available at https://uoepsy.github.io/data/recalldata.csv\n\n\n\n\n\n Visualise Data\n\n\nThere are lots of different ways in which we can visualise our data (as per the Visual Exploration flashcards).\nFor the marginal distributions we will use density and boxplots, and for the bivariate associations a scatterplot.\n\n#save plots to individual objects in order to arrange \n\nplt1 &lt;- ggplot(data = recalldata, aes(x = recall_accuracy)) + \n    geom_density() +\n    xlim(0, 100) + #specify x-axis to range from 0-100\n    geom_boxplot(width = 1/100) + \n    labs(x = \"Recall Accuracy (%)\", title = \"Distribtion of \\nRecall Accuracy\")\n\nplt2 &lt;- ggplot(data = recalldata, aes(x = age)) + \n    geom_density() +\n    xlim(0, 100) + #specify x-axis to range from 0-100\n    geom_boxplot(width = 1/100) + \n    labs(x = \"Age (in years)\", title = \"Distribtion of \\nAge\")\n\nplt3 &lt;- ggplot(data = recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point() + \n    labs(x = \"Age (in years)\", y = \"Recall Accuracy (%)\", title = \"Association between Recall Accuracy and Age\")\n\n\n#load patchwork package to arrange plots\nlibrary(patchwork)\n\n#arrange plots where there are two plots in to panel (plt1 + plt2), one on bottom (plt3)\n(plt1 + plt2) / plt3\n\n\n\n\n\n\n\n\nThe marginal distribution of recall accuracy was unimodal with a negative skew with a mean of approximately 69.25. There was high variation in recall accuracy (SD = 14.53)\n\nThe marginal distribution of age was unimodal with a mean of approximately 48.8, where age ranged from 22 to 86\n\nThere appeared to be a weak negative association between recall accuracy and age, where older age was associated with lower recall accuracy\n\n\n\n\n\n\n Model & Hypothesis Specification\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\n\\[\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Age}_i + \\epsilon_i    \n\\]\n\n\n\\(H_0: \\beta_1 = 0\\)\nThere is no association between recall accuracy and age.\n\\(H_1: \\beta_1 \\neq 0\\)\nThere is an association between recall accuracy and age.\n\n\n\n\n\n\n\n\n Model Building\n\n\nTo fit the model in R we use the lm() function. The simple linear model is assigned/stored in an object called recall_simp:\n\nrecall_simp &lt;- lm(recall_accuracy ~ age, data = recalldata)\n\n\nrecall_simp\n\n\nCall:\nlm(formula = recall_accuracy ~ age, data = recalldata)\n\nCoefficients:\n(Intercept)          age  \n    84.0153      -0.3026  \n\n\nWhen we call the name of the fitted model, recall_simp, you can see the estimated regression coefficients \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\). The line of best-fit is thus given by:1\n\\[\n\\widehat{\\text{Recall Accuracy}} = 84.02 - 0.31 \\cdot \\text{Age}\n\\]\n\nAlternatively to get these same estimates, we could have used the summary() function:\n\nsummary(recall_simp)\n\n\nCall:\nlm(formula = recall_accuracy ~ age, data = recalldata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.164  -7.761  -2.656   9.593  26.180 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  84.0153    11.4453   7.341 8.16e-07 ***\nage          -0.3026     0.2253  -1.343    0.196    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.23 on 18 degrees of freedom\nMultiple R-squared:  0.09108,   Adjusted R-squared:  0.04058 \nF-statistic: 1.804 on 1 and 18 DF,  p-value: 0.196\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\n(Intercept)\nage\n\n\n\n\\(\\beta_0\\) = (Intercept) = 84.02\n\nThe intercept, or predicted recall accuracy when age was 0.\n\nAn individual aged 0 years was expected to have a recall accuracy of \\(84.02\\).\n\n\n\nNote: the intercept isn’t very useful here at all. It estimates the accuracy for a newborn (who wouldn’t be able to complete the task!).\n\n\n\\(\\beta_1\\) = age = -0.3\n\nThe estimated difference in recall accuracy for each additional year in age.\n\nEvery 1 additional year in age was associated with a non-significant \\(-0.3\\) percentage point decrease in recall accuracy \\((p = .196)\\). This suggested that age was not significantly associated with recall accuracy.\n\n\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\n\nggplot(recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point(size = 3, alpha = 0.5) +\n    geom_smooth(method = lm, se = FALSE) + \n    ylim(0,100) +\n    labs(x = \"Age (in years)\", y = \"Recall Accuracy (%)\", title = \"Association between Recall Accuracy and Age\")\n\n\n\nFigure 6: Association between Recall Accuracy and Age\n\n\n\nThe line that best fits the association between recall accuracy and age (see Figure 6) is only able to predict the average accuracy for a given value of age.\nThis is because there will be a distribution of recall accuracy at each value of age. The line will fit the trend/pattern in the values, but there will be individual-to-individual variability that we must accept around that average pattern.\n\n\n\nMultiple Linear Regression Models\n\n Description & Model Specification\n\n\nMultiple linear regression involves looking at one continuous outcome (i.e., DV), with two or more independent variables (i.e., IVs).\nA multiple linear regression model takes the following form:\n\\[\ny_i = \\beta_0 + \\beta_1 \\cdot x_{1_i} + \\beta_2 \\cdot x_{2_i} + .... + \\beta_j \\cdot x_{j_i} + \\epsilon_i\n\\]\n\\[\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\n\nIn R:\nMultiple and simple linear regression follow the same structure within the lm() function - the logic scales up to however many predictor variables we want to include in our model. You simply add (using the + sign) more independent variables. For example, if we wanted to build a multiple linear regression that included three independent variables, we could fit one of the following via the lm() function:\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ IV1 + IV2 + IV3, data = data_name)\n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ data_name$IV1 + data_name$IV2 + data_name$IV3)\n\n\n\n\n\n\n\n\n\n\n Interpretation of Coefficients\n\n\nYou’ll hear a lot of different ways that people explain multiple regression coefficients.\nFor the model \\(y = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon\\), the estimate \\(\\hat \\beta_1\\) will often be reported as:\n“the increase in \\(y\\) for a one unit increase in \\(x_1\\) when…”\n\n“holding the effect of \\(x_2\\) constant.”\n“controlling for differences in \\(x_2\\).”\n“partialling out the effects of \\(x_2\\).”\n“holding \\(x_2\\) equal.”\n“accounting for effects of \\(x_2\\).”\n\nFor models with 3+ predictors, just like building the model in R, the logic of the above simply extends.\nFor example “the increase in [outcome] for a one unit increase in [predictor] when…”\n\n“holding [other predictors] constant.”\n\n“accounting for [other predictors].”\n\n“controlling for differences in [other predictors].”\n\n“partialling out the effects of [other predictors].”\n\n“holding [other predictors] equal.”\n\n“accounting for effects of [other predictors].”\n\n\n\n\nExample\n\nResearch Question\nIs recall accuracy associated with recall confidence and age?\n\n\n Overview\n\n\nImagine that you were tasked to investigate whether recall accuracy was associated with recall confidence and age. You have been provided with data from twenty participants who studied passages of text (c500 words long), and were tested a week later. The testing phase presented participants with 100 statements about the text. They had to answer whether each statement was true or false, as well as rate their confidence in each answer (on a sliding scale from 0 to 100). The dataset contains, for each participant, the percentage of items correctly answered, their age (in years), and their average confidence rating.\nThe data are available at https://uoepsy.github.io/data/recalldata.csv\n\n\n\n\n\n Visualise Data\n\n\n\nrecalldata |&gt;\n    select(recall_accuracy, recall_confidence, age) |&gt;\n    pairs.panels(main = \"Recall SPLOM\")\n\n\n\nFigure 7: Recall SPLOM\n\n\n\n\n\n\n\n\n Model & Hypothesis Specification\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\n\\[\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Recall Confidence}_i + \\beta_2 \\cdot \\text{Age}_i + \\epsilon_i \\\\\n\\]\n\n\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere is no association between recall accuracy and recall confidence and/or age.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere is an association between recall accuracy and recall confidence and/or age.\n\n\n\n\n\n\n\n\n Model Building\n\n\n\nrecall_multi &lt;- lm(recall_accuracy ~ recall_confidence + age, data = recalldata)\n\n\nsummary(recall_multi)\n\n\nCall:\nlm(formula = recall_accuracy ~ recall_confidence + age, data = recalldata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.1935  -5.1751  -0.5528   2.5934  18.6814 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        36.1596    12.8413   2.816 0.011900 *  \nrecall_confidence   0.8957     0.1912   4.685 0.000213 ***\nage                -0.3392     0.1534  -2.212 0.040985 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.674 on 17 degrees of freedom\nMultiple R-squared:  0.6033,    Adjusted R-squared:  0.5566 \nF-statistic: 12.92 on 2 and 17 DF,  p-value: 0.0003867\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\n(Intercept)\nrecall_confidence\nage\n\n\n\n\\(\\beta_0\\) = (Intercept) = 36.16\n\nThe intercept, or predicted recall accuracy when recall confidence was 0 and age was 0.\n\nAn individual aged 0 years with no recall confidence was expected to have a recall accuracy of \\(36.16\\).\n\n\n\nNote: the intercept isn’t very useful here at all. It estimates the accuracy for a newborn (who wouldn’t be able to complete the task!).\n\n\n\\(\\beta_1\\) = recall_confidence = 0.9\n\nThe estimated difference in recall accuracy for each additional unit increase in confidence controlling for age.\n\nHolding age constant, each 1 additional unit in recall confidence was associated with a significant \\(0.9\\) percentage point increase in recall accuracy \\((p &lt; .001)\\).\n\n\n\n\n\n\\(\\beta_2\\) = age = -0.34\n\nThe estimated difference in recall accuracy for each additional year in age controlling for recall confidence.\n\nHolding recall confidence constant, every 1 additional year in age was associated with a significant \\(-0.34\\) percentage point decrease in recall accuracy \\((p = .041)\\).\n\n\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\nWhen we have 2+ predictors, we can’t just plot our data an add geom_smooth(method=lm), because that would give a visualisation of a linear model with just one predictor (whichever one is on the \\(x\\)-axis).\nInstead, we can use the function plot_model() from sjPlot.\n\nplot_model(recall_multi,\n           type = \"eff\",\n           terms = \"recall_confidence\",\n           show.data = TRUE)\n\nplot_model(recall_multi,\n           type = \"eff\",\n           terms = \"age\",\n           show.data = TRUE)\n\n\n\nFigure 8: Association between Recall Accuracy, Recall Confidence, and Age\n\n\n\n\n\nFigure 9: Association between Recall Accuracy, Recall Confidence, and Age"
  },
  {
    "objectID": "1_b2_reading.html#numeric-outcomes-categorical-predictors",
    "href": "1_b2_reading.html#numeric-outcomes-categorical-predictors",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Numeric Outcomes & Categorical Predictors",
    "text": "Numeric Outcomes & Categorical Predictors\n\n Description & Model Specification\n\n\nIn both simple and multiple linear regression models, we examine the association between one continuous dependent variable (DV) using 1 (in the case of simple) or 2+ (in the case of multiple) predictor variables, which could include categorical predictors. When incorporating categorical variables, we use techniques such as dummy/treatment or effects/sum-to-zero coding to convert and represent these categorical predictors in a numerical format which is suitable for regression analysis.\nThe interpretation of the coefficients is very specific. Whereas we talked about coefficients being interpreted as “the change in \\(y\\) associated with a 1-unit increase in \\(x\\)”, for categorical explanatory variables, coefficients can be considered to examine differences in group means.\n\nIn R:\nMultiple and simple linear regression models with categorical predictors follow the same structure within the lm() function. You simply add (using the + sign) more independent variables. For example, if we wanted to build a linear regression model that included one independent categorical variable which had three levels, we could fit one of the following via the lm() function:\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ IV1, data = data_name)\n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ data_name$IV1)\n\n\n\n\n\n\n\n\n\n\n Binary Predictors\n\n\nBinary variables have two categories (more commonly referred to as levels), and these levels (e.g., Yes/No, Dog/Cat, Right/Left, Smoker/Non-Smoker) are simply entered in the model as a series of 0s and 1s. Numeric variables that represent categorical data are typically referred to as dummy variables.\nOur coefficients are just the same as before. The intercept is where our predictor equals zero, and the slope is the change in our outcome variable associated with a 1-unit change in our predictor.\nHowever, “zero” for this predictor variable now corresponds to a whole level. This is known as the “reference level”. Accordingly, the 1-unit change in our predictor (the move from “zero” to “one”) corresponds to the difference between the two levels.\nWhen used as predictors in multiple regression models, binary variables behave much the same way. The coefficient will give us the estimated change in \\(y\\) when moving from one level to the other, whilst holding other predictors constant (for more info, see the Multiple Linear Regression Models - Interpretation of Coefficients flashcard).\n\n\n\n\n\n Dummy vs Effects Coding\n\n\nPossible side-constraints on the parameters are:\n\n\n\n\n\n\n\n\nName\nConstraint\nMeaning of \\(\\beta_0\\)\n\nIn R\n\n\n\nSum to zero (Effects Coding)\n\\(\\beta_1 + \\beta_2 + \\beta_3 = 0\\)\n\\(\\beta_0 = \\mu\\)\ncontr.sum\n\n\nReference group (Dummy Coding)\n\\(\\beta_1 = 0\\)\n\\(\\beta_0 = \\mu_1\\)\ncontr.treatment\n\n\n\nDummy Coding\nBy default R uses the reference group constraint - i.e., dummy coding (sometimes called treatment contrast coding). If your factor has \\(g\\) levels, your regression model will have \\(g-1\\) dummy variables (R creates them for you, as we’ve seen in the examples above).\nOne level of the categorical variable is considered as the ‘baseline’, ‘reference level’, or ‘reference group’ - R automatically takes the first level alphabetically as the baseline (e.g., if you had a ‘pet’ variable with levels dog, hamster, and cat, then cat would be taken as the reference level).\nWhen we use this approach, the intercept is the estimated \\(y\\) when all predictors (i.e., \\(x\\)’s) are zero. Because the reference level is kind of like “0” in our contrast matrix, this is part of the intercept estimate. We get out a coefficient for each subsequent level, which are the estimated differences from each level to the reference group.\nEffects Coding\nEffects coding (sometimes called sum-to-zero coding) is the next most commonly used in psychological research. These are a way of comparing each level to the overall (or grand) mean. This involves a bit of trickery that uses -1s and 1s rather than 0s and 1s, in order to make “0” be mid-way between all the levels - the average of the levels.\nR automatically takes the last level alphabetically as level which is dropped (e.g., if you had a ‘pet’ variable with levels dog, hamster, and cat, then hamster would not be represented).\nWhen we use this approach, the intercept is the estimated average \\(y\\) when averaged across all levels of the predictor variable. In other words, it is the estimated grand mean of \\(y\\). The coefficients represent the estimated difference for that level from the overall grand mean.\n\nIn R\nIf we want to use effects coding, we can apply:\n\ncontrasts(iris$Species) &lt;- \"contr.sum\"\n\nWe can switch back to the default reference group constraint by applying either of these:\n\n# Option 1\ncontrasts(iris$Species) &lt;- NULL\n\n# Option 2\ncontrasts(iris$Species) &lt;- \"contr.treatment\"\n\n\n\n\n\n\n\n Coding Variables as Factors\n\n\nWhen we have categorical predictors, it is important that we tell R specifically to code them appropriately as factors.\n\nIn R\nWe can use various functions to convert between different types of data, such as:\n\n\nfactor() / as_factor() - to turn a variable into a factor\n\n\nas.numeric() - to turn a variable into numbers\n\n\nAs a first step, it is a good idea to look at the structure of the dataset you are working with. For the purpose of this example, our dataset is called “tips” (you might recall this from DAPR1):\n\nstr(tips)\n\nspc_tbl_ [157 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Bill  : num [1:157] 23.7 36.1 32 17.4 15.4 ...\n $ Tip   : num [1:157] 10 7 5.01 3.61 3 2.5 3.44 2.42 3 2 ...\n $ Credit: chr [1:157] \"n\" \"n\" \"y\" \"y\" ...\n $ Guests: num [1:157] 2 3 2 2 2 2 2 2 2 2 ...\n $ Day   : chr [1:157] \"f\" \"f\" \"f\" \"f\" ...\n $ Server: chr [1:157] \"A\" \"B\" \"A\" \"B\" ...\n $ PctTip: num [1:157] 42.2 19.4 15.7 20.8 19.5 13.4 16 12.4 12.7 10.7 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Bill = col_double(),\n  ..   Tip = col_double(),\n  ..   Credit = col_character(),\n  ..   Guests = col_double(),\n  ..   Day = col_character(),\n  ..   Server = col_character(),\n  ..   PctTip = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nFrom the output, we can see that Credit (whether guests paid with a credit card; n/y responses) was coded as a &lt;chr&gt; or character variable. If we wanted to set this as a factor so that R recognises it as a categorical variable, we can use on of the following:\n\n\nas_factor()\nfactor()\n\n\n\n\ntips &lt;- tips |&gt; \n  mutate(Credit = as_factor(Credit))\n\n\n\nWe could also use the factor() function, and at the same time label factors appropriately to aid reader interpretation (it may not be immediately clear to some that n represents ‘No’ and y represents ‘Yes’). To do so, we list the all levels of Credit, and provide a new label corresponding to each level:\n\ntips$Credit &lt;- factor(tips$Credit, \n                      levels = c(\"n\", \"y\"),\n                      labels = c(\"No\", \"Yes\"))\n\n\n\n\nUsing either of the above approaches, if we now run str(tips) again, you should see that Credit is now coded as a factor with 2 levels:\n\nstr(tips)\n\ntibble [157 × 7] (S3: tbl_df/tbl/data.frame)\n $ Bill  : num [1:157] 23.7 36.1 32 17.4 15.4 ...\n $ Tip   : num [1:157] 10 7 5.01 3.61 3 2.5 3.44 2.42 3 2 ...\n $ Credit: Factor w/ 2 levels \"n\",\"y\": 1 1 2 2 1 1 1 1 1 1 ...\n $ Guests: num [1:157] 2 3 2 2 2 2 2 2 2 2 ...\n $ Day   : chr [1:157] \"f\" \"f\" \"f\" \"f\" ...\n $ Server: chr [1:157] \"A\" \"B\" \"A\" \"B\" ...\n $ PctTip: num [1:157] 42.2 19.4 15.7 20.8 19.5 13.4 16 12.4 12.7 10.7 ...\n\n\n\n\n\n\n\n Specifying Reference Levels\n\n\nWhen you have a categorical variable coded as a factor, R will default to using alphabetical ordering. We could override this by making it a factor with an ordering to it’s levels (see the use of factor() and levels()). Functions like fct_relevel() might be handy too.\n\n\n\nExample\n\nResearch Question\nDoes sepal length differ by species?\n\n\n Overview\n\n\nImagine that you were tasked to investigate whether sepal length differs by species. You have been provided with the in-built dataset, iris, which contains information concerning the sepal length (in cm), sepal width (in cm), petal length (in cm), and petal width (in cm) from three different species of iris (setosa, versicolor, and virginica). There are measurements for 50 flowers from each of the iris species (i.e., total \\(n\\) = 150).\n\n\n\n\n\n Visualise Data\n\n\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n Model & Hypothesis Specification\n\n\n\n\nDummy Coding\nEffects Coding\n\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\nWe first need to define the dummy variables for Species:\n\\[\n\\text{Species}_\\text{Versicolor} = \\begin{cases}  \n1 & \\text{if Species is Versicolor} \\\\  \n0 & \\text{otherwise}  \n\\end{cases}  \n\\quad    \n\\]\n\\[\n\\text{Species}_\\text{Virginica} = \\begin{cases}  \n1 & \\text{if Species is Virginica} \\\\  \n0 & \\text{otherwise}  \n\\\\  \n\\end{cases}  \n\\quad  \n\\]\n\\[\n(\\text{Species}_\\text{Setosa } \\text{ is the reference level})  \n\\]\nBased on the above dummy coding, we are going to fit the following regression model:\n\\[\n\\begin{align}\n\\text{Sepal Length} = \\beta_0 + \\beta_1 \\cdot \\text{Species}_\\text{Versicolor} + \\beta_2 \\cdot \\text{Species}_\\text{Virginica} + \\epsilon\n\\end{align}\n\\]\n\n\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere are no differences in sepal length based on iris species.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere are differences in sepal length based on iris species.\n\n\n\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\nWe first need to define the effects coding for Species:\n\\[\n\\begin{matrix}\n\\textbf{Level}           & \\textbf{Species Level 1} & \\textbf{Species Level 2} \\\\\n\\hline\n\\text{Setosa}              & 1   & 0    \\\\\n\\text{Versicolor}               & 0   & 1    \\\\\n\\text{Virginica}         & -1  & -1 \\\\\n\\end{matrix}\n\\]\nBased on the above effects coding, we are going to fit the following regression model:\n\\[\n\\begin{align}\n\\text{Sepal Length} = \\beta_0 + \\beta_1 \\cdot \\text{Species Level 1} + \\beta_2 \\cdot \\text{Species Level 2} + \\epsilon\n\\end{align}\n\\]\n\n\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere are no differences in average sepal length based on iris species (i.e., the average sepal length across species is equal to the grand mean).\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere are differences in average sepal length based on iris species (i.e., the average sepal length across species is not equal to the grand mean).\n\n\n\n\n\n\n\n\n\n\n\n Model Building\n\n\n\n\nDummy Coding\nEffects Coding\n\n\n\nFirst we need to check the levels of the Species variable:\n\n#check what levels we have\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nFrom the above, we can see that Species has 3 levels - “setosa”, “versicolor”, and “virginica”.\nIf we put these into a model, assuming R’s default ordering, we know that R will automatically apply dummy (or treatment coding, i.e., contrasts(iris$Species) &lt;- \"contr.treatment\"), and “setosa” will be taken as our reference group:\n\n#fit model\nspec_model &lt;- lm(Sepal.Length ~ Species, data = iris)\nsummary(spec_model)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.0060     0.0728  68.762  &lt; 2e-16 ***\nSpeciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\nSpeciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nFirst we need to tell R to apply effects (or sum-to-zero) coding and check the ordering of the levels:\n\ncontrasts(iris$Species) &lt;- \"contr.sum\"\ncontrasts(iris$Species) \n\n           [,1] [,2]\nsetosa        1    0\nversicolor    0    1\nvirginica    -1   -1\n\n\nThen we can run our model:\n\n#fit model\nspec_model2 &lt;- lm(Sepal.Length ~ Species, data = iris)\nsummary(spec_model2)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.84333    0.04203 139.020   &lt;2e-16 ***\nSpecies1    -0.83733    0.05944 -14.086   &lt;2e-16 ***\nSpecies2     0.09267    0.05944   1.559    0.121    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\nDummy Coding\nEffects Coding\n\n\n\n\n\n\n\n\n\n\nCoefficient\nEstimate\nCorresponds to\n\n\n\n(Intercept)\n5.0060\n\\(\\beta_0 = \\hat \\mu_1\\)\n\n\nSpeciesversicolor\n0.9300\n\\(\\beta_0 + \\beta_1 = \\hat \\mu_2\\)\n\n\nSpeciesvirginica\n1.5820\n\\(\\beta_0 + \\beta_2 = \\hat \\mu_3\\)\n\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\hat \\beta_0 = \\hat \\mu_1 = 5.01\\). The estimated average sepal length for the species setosa was approximately \\(5.01~cm\\).\nThe second estimate corresponds to Speciesversicolor and was \\(\\hat \\beta_1 = 0.93\\). The difference in mean sepal length between setosa and versicolor species was estimated to be \\(0.93~cm\\). Thus, \\(\\hat \\mu_2 = 5.01 + 0.93 = 5.94\\). We could say - the species iris versicolor had a sepal length of approximately \\(5.94~cm\\), and this was approximately \\(0.93~cm\\) longer than the iris setosa. This difference was statistically significant \\((p &lt; .001)\\).\nThe third estimate corresponds to Speciesvirginica and was \\(\\hat \\beta_2 = 1.58\\). The difference in mean sepal length between setosa and virginica species was estimated to be \\(1.58~cm\\). Thus, \\(\\hat \\mu_2 = 5.01 + 1.58 = 6.59\\). We could say - the species iris virginica had a sepal length of approximately \\(6.59~cm\\), and this was approximately \\(1.58~cm\\) longer than the iris setosa. This difference was statistically significant \\((p &lt; .001)\\).\n\n\n\n\n\n\n\n\n\n\nCoefficient\nEstimate\nCorresponds to\n\n\n\n(Intercept)\n5.84333\n\\(\\beta_0 = \\frac{\\mu_1 + \\mu_2 + \\mu_3}{3} = \\mu\\)\n\n\nSpecies1\n-0.83733\n\\(\\beta_1 = \\mu_1 - \\mu\\)\n\n\nSpecies2\n0.09267\n\\(\\beta_2 = \\mu_2 - \\mu\\)\n\n\n\n\nThe first estimate corresponding to (Intercept) contains \\(\\hat \\beta_0 = \\hat \\mu = 5.84\\). The estimated average sepal length across iris species was approximately \\(5.84~cm\\).\nThe second estimate corresponds to Species1 and was \\(\\hat \\beta_1 = -0.84\\). The difference in mean sepal length between setosa \\((\\hat \\mu_1)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(0.84~cm\\). In other words, the iris species of setosa had a sepal length \\(0.84~cm\\) shorter than average, where its length was estimated to be \\(5.84333 + (-0.83733) = 5~cm\\). This difference in length was statistically significant \\((p &lt; .001)\\).\nThe third estimate corresponds to Species2 and was \\(\\hat \\beta_2 = 0.09\\). The difference in mean sepal length between versicolor \\((\\hat \\mu_2)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(0.09~cm\\). In other words, the iris species of versicolor had a sepal length \\(0.09~cm\\) longer than average, where its length was estimated to be \\(5.84333 + 0.09267 = 5.94~cm\\). This difference in length was not statistically significant \\((p = .121)\\).\nThe estimate for Species3, representing the difference of “virginica” to the grand mean is not shown by summary(). Because of the side-constraint, we know that \\(\\mu_3 = \\beta_0 - (\\beta_1 + \\beta_2)\\). The difference in sepal length between virginica and the grand mean was estimated to be \\(-(-0.83733 + 0.09267) = 0.74466\\). In other words, the virginica iris species had a sepal length \\(0.74~cm\\) longer than average, where its length was estimated to be \\(5.84333 - (-0.83733 + 0.09267) = 6.59~cm\\).\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\nThere are a couple of ways that we can visualise our model, eithe rusing the sjPlot or effects packages:\n\n\nsjPlot\neffects\n\n\n\n\nlibrary(sjPlot)\n\nplot_model(spec_model,\n           type = \"eff\",\n           terms = \"Species\") +\n    labs(title = \"Sepal Length by Species\",\n       x = \"Species\", \n       y = \"Sepal Length\")\n\n\n\n\n\n\n\n\n\n\nlibrary(effects)\n\neffect(term = c(\"Species\"), mod = spec_model) |&gt;\n  as.data.frame() |&gt;\n  ggplot(aes(x = Species, y = fit, col = Species)) +\n  geom_pointrange(aes(ymin = lower, ymax = upper))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Specifying Reference Levels\n\n\nLet’s say we wanted to change the reference level in our “spec_model” above, there are a few different ways that we can do this.\nFirst we should check the current ordering of the levels:\n\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nWe can then change the reference level to be “versicolor” (using one of the below methods):\n\n\nfct_relevel()\nrelevel()\nfactor()\n\n\n\n\niris &lt;- iris |&gt; \n  mutate(\n    Species = fct_relevel(Species, \"versicolor\")\n  )\n\n\n\n\niris$Species &lt;- relevel(iris$Species, \"versicolor\")\n\n\n\n\niris$Species &lt;- iris$Species |&gt; \n  factor(., levels = c(\"versicolor\", \"setosa\", \"virginica\"))\n\n\n\n\nAnd then re-run our model:\n\n#fit model\nspec_model2 &lt;- lm(Sepal.Length ~ Species, data = iris)\nsummary(spec_model2)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.84333    0.04203 139.020   &lt;2e-16 ***\nSpecies1     0.09267    0.05944   1.559    0.121    \nSpecies2    -0.83733    0.05944 -14.086   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "1_b2_reading.html#general---extracting-information",
    "href": "1_b2_reading.html#general---extracting-information",
    "title": "Block 1 & 2 Flash Cards",
    "section": "General - Extracting Information",
    "text": "General - Extracting Information\nIt is important to have a good grasp of how to understand and interpret the key components of your model summary() output, including model coefficients, standard errors, \\(t\\)-values, \\(p\\)-values, etc., and how these can be used in further calculations (such as confidence intervals). As well as knowing how to extract from R, it is necessary to understand how to compute some of these statistics by hand too.\n\n Model Call\n\n\n\n\n\n\nMultiple regression output in R, model formula highlighted\n\n\n\nThe call section at the very top of the summary() output shows us the formula that was specified in R to fit the regression model.\nIn the above, we can see that recall accuracy is our DV, recall confidence and age were our two IVs, and our dataset was named recalldata.\n\n\n\n\n\n Residuals\n\n\n\n\n\n\nMultiple regression output in R, residuals highlighted\n\n\n\nResiduals are the difference between the observed values and model predicted values of the DV.\nIdeally, for the model to be unbiased, we want our median value (the middle value of the residuals when ordered) to be around 0, as this would show that the errors are random fluctuations around the true line. When this is the case, we know that our model is doing a good job predicting values at the high and low ends of our dataset, and that our residuals were somewhat symmetrical.\n\n\n\n\n\n Model Coefficients\n\n\n\n\n\n\nMultiple regression output in R, model coefficients highlighted\n\n\n\n\n\nEstimates\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\nOur model estimates help us to build our best fitting equation of the line that represents the association between our DV and our IV(s).\nIn the above example, we can build our equation for our model from this information:\n\\[\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Recall Confidence}_i + \\beta_2 \\cdot \\text{Age}_i + \\epsilon_i\n\\] \\[\n\\widehat{\\text{Recall Accuracy}} = 36.16 + 0.90 \\cdot \\text{Recall Confidence} - 0.34 \\cdot \\text{Age}\n\\]\nHow to calculate \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\)\n\n\nBy Hand\nUsing R\n\n\n\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nStep 1: Calculate mean of both \\(x\\) and \\(y\\)\n\\(\\bar x = {\\frac{1+2+3+4+5}{5}} = 3\\)\n\\(\\bar y = {\\frac{5+7+8+6+9}{5}} = 7\\)\nStep 2: Calculate \\(\\beta_0\\) and \\(\\beta_1\\)\nWe need to calculate the slope first, as we need to know the value of \\(\\beta_1\\) in order to calculate \\(\\beta_0\\)\nSlope (\\(\\beta_1\\))\n\\[\n\\begin{align}\n& \\hat \\beta_1 = \\frac{SP_{xy}}{SS_x} \\\\  \n\\\\\n\\\\\n& \\text{Where}: \\\\\n& \\text{SP}_\\text{xy} = \\text{sum of cross-products:} \\\\\n& \\text{SP}_\\text{xy} = \\sum_{i = 1}^{n}(x_i - \\bar{x})(y_i - \\bar{y}) \\\\  \n& \\text{and} \\\\\n& \\text{SS}_\\text{x} = \\text{sums of squared deviations of x:} \\\\    \n& \\text{SS}_\\text{x} = \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 \\\\  \n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\text{SP}_\\text{xy} =\\sum_{i = 1}^{n}(x_i - \\bar{x})(y_i - \\bar{y}) = \\\\\n& (1-3)(5-7) + (2-3)(7-7) + (3-3)(8-7) + (4-3)(6-7) + (5-3)(9-7) = \\\\\n& 4 + 0 + 0 + (-1) + 4 = \\\\\n& 7 \\\\\n\\\\  \n& \\text{SS}_\\text{x}= \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 = \\\\\n& (1-3)^2 + (2-3)^2 + (3-3)^22 + (4-3)^2 + (5-3)^2 = \\\\\n& 4 + 1 + 0 + 1 + 4 = \\\\\n& 10 \\\\\n\\\\  \n& \\hat \\beta_1 = \\frac{SP_{xy}}{SS_x} = \\frac{7}{10} = 0.7 \\\\\n\\end{align}\n\\]\nIntercept (\\(\\beta_0\\))\n\\[\n\\begin{align}\n&\\hat \\beta_0 = \\bar{y} - \\hat \\beta_1 \\bar{x} \\\\\n&\\hat \\beta_0 = 7 - 0.7 \\cdot 3 \\\\\n&\\hat \\beta_0 = 7 - 2.1 \\\\\n&\\hat \\beta_0 = 4.9\n\\end{align}\n\\]\n\n\n\nIn R\nThere are numerous equivalent ways to obtain the estimated regression coefficients — that is, \\(\\hat \\beta_0\\), \\(\\hat \\beta_1\\), …., \\(\\hat \\beta_k\\) — from the fitted model (for this below example, our fitted model has been named mdl):\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\n\n\n\n\n\n\n\nThe standard error of the coefficient is an estimate of the standard deviation of the coefficient (i.e., how much uncertainty there is in our estimated coefficient).\nThe formula for the standard error of the slope is:\n\\[\n\\begin{align}\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{\\text{SS}_\\text{Residual}/(n-k-1)}{\\sum(x_{ij} - \\bar{x_{j}})^2(1-R_{xj}^2)}} \\\\  \n\\\\  \n& \\text{Where}: \\\\  \n\\\\  \n& \\text{SS}_\\text{Residual} = \\text{ residual sum of squares} \\\\  \n& n = \\text{ sample size} \\\\  \n& k = \\text{ number of predictors} \\\\  \n& x_{ij} = \\text{ the observed value of a predictor (j) for an individual (i)} \\\\  \n& \\bar{x_{j}} = \\text{the mean of a predictor (j)} \\\\  \n& R_{xj}^2 = \\text{the multiple correlation coefficient of the predictors} \\\\  \n\\end{align}\n\\]\nLet’s apply to a straightforward example. Suppose you have a simple linear regression model (i.e., with only one IV, which means that \\(R_{xj}^2 = 0\\) since there is only one predictor) and the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nThere are a number of steps you need to take to calculate by hand:\n\nCalculate sum of the squared residuals\n\nCalculate predicted values\n\nCalculate residuals (i.e., the difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)) for each observation)\n\nSquare the residuals\n\nCalculate the Sum of Squared Residuals\n\n\n\nCalculate the sum of squared deviations of the (\\(x\\)) values from their mean\nUse values from 1 & 2 to calculate \\(SE(\\hat \\beta_j)\\)\n\n\nStep 1.1: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n4.9 + (0.7*1) = 5.6\n\n\n2\n7\n4.9 + (0.7*2) = 6.3\n\n\n3\n8\n4.9 + (0.7*3) = 7\n\n\n4\n6\n4.9 + (0.7*4) = 7.7\n\n\n5\n9\n4.9 + (0.7*5) = 8.4\n\n\n\nStep 1.2: Calculate residuals\n\n\\(\\epsilon_1 = 5 − 5.6 = -0.6\\)\n\\(\\epsilon_2 = 7 - 6.3 = 0.7\\)\n\\(\\epsilon_3 = 8 - 7 = 1\\)\n\\(\\epsilon_4 = 6 - 7.7 = -1.7\\)\n\\(\\epsilon_5 = 9 − 8.4 = 0.6\\)\n\nStep 1.3: Square the residuals\n\n\\(\\epsilon_1^2 = -0.6^2 = 0.36\\)\n\\(\\epsilon_2^2 = 0.7^2 = 0.49\\)\n\\(\\epsilon_3^2 = 1^2 = 1\\)\n\\(\\epsilon_4^2 = -1.7^2 = 2.89\\)\n\\(\\epsilon_5^2 = 0.6^2 = 0.36\\)\n\nStep 1.4: Calculate the Sum of Squared Residuals\n\\[\n\\sum \\epsilon_i^2 = 0.36 + 0.49 + 1 + 2.89 + 0.36 = 5.1\n\\]\nStep 2. Calculate the sum of squared deviations of the (\\(x\\)) values from their mean\nThe mean of \\(x\\) can be calculated as: \\(\\bar x = {\\frac{1+2+3+4+5}{5}} = 3\\). Using this, we can then calculate the sum of squared deviations of \\(x\\):\n\\[\n\\begin{align}\n& \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 = \\\\\n& (1-3)^2 + (2-3)^2 + (3-3)^22 + (4-3)^2 + (5-3)^2 = \\\\\n& 4 + 1 + 0 + 1 + 4 = \\\\\n& 10 \\\\\n\\end{align}\n\\]\nStep 3: Calculate \\(SE(\\hat \\beta_j)\\)\nFrom this, we can finally calculate \\(SE(\\hat \\beta_j)\\):\n\\[\n\\begin{align}\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{\\text{SS}_\\text{Residual}/(n-k-1)}{\\sum(x_{ij} - \\bar{x_{j}})^2(1-R_{xj}^2)}} \\\\  \n& SE(\\hat \\beta_j) = \\sqrt{\\frac{5.1/(5-1-1)}{10 \\cdot (1-0)}} \\\\\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{5.1/3}{10}} \\\\\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{1.7}{10}} \\\\\n& SE(\\hat \\beta_j) = \\sqrt{0.17} \\\\\n& SE(\\hat \\beta_j) = 0.4207\n\\\\\n\\end{align}\n\\]\n\nIn R\nIf you wanted to obtain just the standard error for each estimated regression coefficient, you could do the following (for this below example, our fitted model has been named mdl):\n\nsummary(mdl)$coefficients[,2]\n\n\n\n\nThe t-statistic is the \\(\\beta\\) coefficient divided by the standard error:\n\\[\nt = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)}\n\\]\nwhich follows a \\(t\\)-distribution with \\(n-k-1\\) degrees of freedom (where \\(k\\) = number of predictors and \\(n\\) = sample size).\nWith this, we can test the the null hypothesis \\(H_0: \\beta_j = 0\\).\nGenerally speaking, you want your model coefficients to have large \\(t\\)-statistics as this would indicate that the standard error was small in comparison to the coefficient. The larger our \\(t\\)-statistic, the more confident we can be that the coefficient is not 0.\nHow to calculate \\(t = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)}\\)\n\n\nBy Hand\nIn R\n\n\n\nWe can calculate the test statistic \\(t\\) for \\(\\beta_\\text{Age}\\) (or \\(\\beta_2\\)) by hand from our recall_multi model as follows:\n\\[\n\\begin{align}\n\\\\\n& t = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)} \\\\  \n\\\\  \n& t = \\frac{-0.3392 - 0}{0.1534} \\\\\n\\\\  \n& t = -2.211213 \\\\  \n\\\\  \n& t = -2.21 \\\\  \n\\end{align}\n\\]\nWe then need to calculate \\(t^*\\):\n\nn &lt;- nrow(recalldata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 2.109816\n\n\nAnd finally compare \\(|t|\\) to \\(t^*\\). Since \\(|t|\\) is larger than \\(t^*\\) (-2.21 &gt; 2.11), we can reject the null hypothesis.\n\n\n\nIn R\nIf you wanted to obtain just the \\(t\\)-values for each estimated regression coefficient, you could use the following:\n\ncoef(summary(mdl))[, \"t value\"]\nsummary(mdl)$coefficients[,3]\n\nFor example:\n\ncoef(summary(recall_multi))[, \"t value\"]\n\n      (Intercept) recall_confidence               age \n         2.815890          4.684654         -2.211515 \n\n\n\nsummary(recall_multi)$coefficients[,3]\n\n      (Intercept) recall_confidence               age \n         2.815890          4.684654         -2.211515 \n\n\n\n\n\n\n\n\nFrom our \\(t\\)-value, we can compute our \\(p\\)-value. The \\(p\\)-value help us to understand whether our coefficient(s) are statistically significant (i.e., that the coefficient is statistically different from 0). The \\(p\\)-value of each estimate indicates the probability of observing a \\(t\\)-value at least as extreme as, or more extreme than, the one calculated from the sample data when assuming the null hypothesis to be true.\nIn Psychology, a \\(p\\)-value &lt; .05 is usually used to make statements regarding statistical significance (it is important that you always state your \\(\\alpha\\) level to help your reader understand any statements regarding statistical significance).\nThe number of asterisks marks corresponds with the significance of the coefficient (see the ‘Signif. codes’ legend just under the coefficients section).\n\nIn R\nIf you wanted to obtain just the \\(p\\)-values for each estimated regression coefficient, you could do the following (for this below example, our fitted model has been named mdl):\n\nsummary(mdl)$coefficients[,4]\n\n\n\n\n\n\n\n\n\n\n Confidence Intervals\n\n\nUsing the estimate and standard error of a given \\(\\beta\\) coefficient, we can create confidence intervals to estimate a plausible range of values for the true population parameter. Recall the formula for obtaining a confidence interval for the population slope is:\n\\[\n\\hat \\beta_j \\pm t^* \\cdot SE(\\hat \\beta_j)\n\\]\nwhere \\(t^*\\) denotes the critical value chosen from \\(t\\)-distribution with \\(n-k-1\\) degrees of freedom (where \\(k\\) = number of predictors and \\(n\\) = sample size) for a desired \\(\\alpha\\) level of confidence.\nHow to calculate \\(\\hat \\beta_j \\pm t^* \\cdot SE(\\hat \\beta_j)\\)\n\n\nBy Hand\nUsing R\n\n\n\nTo calculate by hand for \\(\\hat \\beta_\\text{Age}\\) from our recall_multi model, we first need to calculate \\(t^*\\):\n\nn &lt;- nrow(recalldata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 2.109816\n\n\nFor 95% confidence intervals, we use \\(t^* = 2.1098\\), and can simply substitute into the formula:\n\\[\n\\begin{align}\n& \\text{Lower CI} = \\hat \\beta_\\text{Age} - t^* \\cdot SE(\\hat \\beta_\\text{Age}) \\\\  \n& \\text{Lower CI} = -0.3392 - (2.1098 \\cdot 0.1534) \\\\  \n& \\text{Lower CI} = -0.6628433 \\\\\n& \\text{Lower CI} = -0.663 \\\\\n\\\\    \n& \\text{Upper CI} = \\hat \\beta_\\text{Age} + t^* \\cdot SE(\\hat \\beta_\\text{Age}) \\\\  \n& \\text{Upper CI} = -0.3392 + (2.1098 \\cdot 0.1534) \\\\\n& \\text{Upper CI} = -0.01555668 \\\\\n& \\text{Upper CI} = -0.016 \\\\\n\\end{align}\n\\]\n\n\n\nIn R\nWe can obtain the confidence intervals for the regression coefficients using the command confint().\n\nconfint(recall_multi)\n\n                       2.5 %      97.5 %\n(Intercept)        9.0668871 63.25228524\nrecall_confidence  0.4923220  1.29913640\nage               -0.6627188 -0.01559663\n\n\nOr alternatively use R to compute using the manual process (though it makes more sense to use confint() given it is less prone to typos!):\n\ntibble(\n  b2_LowerCI = round(-0.3392 - (qt(0.975, n-3) * 0.1534), 3),\n  b2_UpperCI = round(-0.3392 + (qt(0.975, n-3) * 0.1534), 3)\n      )\n\n# A tibble: 1 × 2\n  b2_LowerCI b2_UpperCI\n       &lt;dbl&gt;      &lt;dbl&gt;\n1     -0.663     -0.016\n\n\n\n\n\n\n\n\n\n\n\n \\(\\sigma\\)\n\n\n\n\n\n\nMultiple regression output in R, model standard deviation of the errors highlighted\n\n\n\nThe standard deviation of the errors, denoted by \\(\\sigma\\), is an important quantity that our model estimates. It represents how much individual data points tend to deviate above and below the regression line - in other words, it tells us how well the model fits the data.\nA small \\(\\sigma\\) indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large \\(\\sigma\\) suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\nThe estimated standard deviation of the errors is denoted \\(\\hat \\sigma\\), and is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root:\n\\[\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{\\text{SS}_\\text{Residual}}{n - k - 1}} \\\\\n\\qquad \\\\\n& \\text{Where:}  \\\\\n& \\text{SS}_\\text{Residual} = \\textrm{Sum of Squared Residuals} = \\sum_{i=1}^n{(\\epsilon_i)^2} \\\\\n\\\\  \n\\\\  \n& \\text{and so, equivalently:} \\\\  \n\\\\  \n& \\hat \\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{n - k - 1}} \\\\\n\\end{align}\n\\]\nHow to calculate \\(\\hat \\sigma\\)\n\n\nBy Hand\nUsing R\n\n\n\nThere are a number of steps you need to take to calculate by hand:\n\nCalculate predicted values\nCalculate residuals (i.e., the difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)) for each observation)\n\nSquare the residuals\n\nCalculate the Sum of Squared Residuals\n\nDetermine the Residual Standard Deviation (\\(\\sigma\\))\n\nLet’s apply to a straightforward example. Suppose you have a simple linear regression model (i.e., with only one IV) and the following data points:\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nStep 1: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n4.9 + (0.7*1) = 5.6\n\n\n2\n7\n4.9 + (0.7*2) = 6.3\n\n\n3\n8\n4.9 + (0.7*3) = 7\n\n\n4\n6\n4.9 + (0.7*4) = 7.7\n\n\n5\n9\n4.9 + (0.7*5) = 8.4\n\n\n\nStep 2: Calculate residuals\n\n\\(\\epsilon_1 = 5 − 5.6 = -0.6\\)\n\\(\\epsilon_2 = 7 - 6.3 = 0.7\\)\n\\(\\epsilon_3 = 8 - 7 = 1\\)\n\\(\\epsilon_4 = 6 - 7.7 = -1.7\\)\n\\(\\epsilon_5 = 9 − 8.4 = 0.6\\)\n\nStep 3: Square the residuals\n\n\\(\\epsilon_1^2 = -0.6^2 = 0.36\\)\n\\(\\epsilon_2^2 = 0.7^2 = 0.49\\)\n\\(\\epsilon_3^2 = 1^2 = 1\\)\n\\(\\epsilon_4^2 = -1.7^2 = 2.89\\)\n\\(\\epsilon_5^2 = 0.6^2 = 0.36\\)\n\nStep 4: Calculate the Sum of Squared Residuals\n\\[\n\\sum \\epsilon_i^2 = 0.36 + 0.49 + 1 + 2.89 + 0.36 = 5.1\n\\]\nStep 5: Determine the Residual Standard Deviation (\\(\\sigma\\))\n\\[\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{\\text{SS}_\\text{Residual}}{n - k - 1}} \\\\  \n\\\\   \n& \\hat \\sigma = \\sqrt{\\frac{5.1}{5 - 1 - 1}}  \\\\  \n\\\\   \n& \\hat \\sigma = \\sqrt{\\frac{5.1}{3}}  \\\\  \n\\\\   \n& \\hat \\sigma = \\sqrt{1.70}  \\\\    \n\\\\  \n& \\hat \\sigma = 1.304  \\\\  \n\\end{align}\n\\]\n\n\n\nIn R\nThere are a couple of equivalent ways to obtain the estimated standard deviation of the errors — that is, \\(\\hat \\sigma\\) — from the fitted model (for this example, our fitted model has been named mdl):\n\nsigma(mdl)\nsummary(mdl)"
  },
  {
    "objectID": "1_b2_reading.html#additive-models",
    "href": "1_b2_reading.html#additive-models",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Additive Models",
    "text": "Additive Models\n\n Steps In R\n\n\nAfter specifying our hypotheses, to test our contrasts, we can use the emmeans package and follow the below structure:\n\n\nStep 1: Fit and run the model using lm()\n\n\nStep 2: Use the emmeans() function to obtain the estimated means of each group. You can visualise these by using plot() on the obtained estimated means of the groups\n\nStep 3: Check the order of your levels via levels()\n\n\nStep 4: Define the contrast by specifying the weights following the rules outlined above (as well as paying attention to the ordering of the levels)\n\nStep 5: Test the pre-specified group contrast(s) via contrast()\n\n\nStep 6: Obtain confidence intervals via confint()\n\n\nAfter completing these steps, the last task would be to interpret the results of the contrast analysis in the context of the hypothesis.\n\n\n\nExample\n\nResearch Question\nDoes the sepal length of an iris grown in Western states (i.e., iris setosa) differ from the sepal length of an Iris grown in Eastern states (i.e., iris versicolor and virginica)?\n\n\n Specify Hypotheses\n\n\nBased on the research question, we are asking whether there is a difference between the average sepal length of iris setosa (Western states), and the combined average sepal length of iris versicolor and iris virginica (Eastern state)s. To assess this for the Eastern states, we need to compute the average of the mean sepal lengths of the two species, iris versicolor and iris virginica.\nWith this in mind, we could specify our hypotheses as:\n\\[\n\\begin{aligned}\n    \\quad H_0 &: \\mu_\\text{Western} = \\mu_\\text{Eastern} \\\\\n    \\\\  \n    \\quad H_0 &: \\mu_\\text{Setosa} = \\frac{1}{2} (\\mu_\\text{Versicolor} + \\mu_\\text{Virginica}) \\\\\n\\\\  \n\\\\\n    \\quad H_1 &: \\mu_\\text{Western} \\neq \\mu_\\text{Eastern} \\\\\n    \\\\\n    \\quad H_1 &: \\mu_\\text{Setosa} \\neq \\frac{1}{2} (\\mu_\\text{Versicolor} + \\mu_\\text{Virginica}) \\\\\n\\\\\n\\end{aligned}\n\\]\n\n\n\n\n\n Conduct Contrast Analysis\n\n\nFollow steps 1-6 outlined above:\n\n# Step 1: Fit and run the model \nspec_model &lt;- lm(Sepal.Length ~ Species, data = iris)\n\n\n# Step 2: Use`emmeans()`& `plot()`\nlibrary(emmeans)\nseplength_mean &lt;- emmeans(spec_model, ~ Species)\nseplength_mean \n\n Species    emmean     SE  df lower.CL upper.CL\n setosa       5.01 0.0728 147     4.86     5.15\n versicolor   5.94 0.0728 147     5.79     6.08\n virginica    6.59 0.0728 147     6.44     6.73\n\nConfidence level used: 0.95 \n\nplot(seplength_mean)\n\n\n\n\n\n\n\n\n# Step 3: Check levels order via `levels()`\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\n\n# Step 4: Define contrast & weights - want to compare Iris setosa to iris versicolor and iris virginica\nseplength_comp &lt;- list(\"Western State Iris - Eastern State Iris\" = c(-1, 1/2, 1/2))\n\n\n# Step 5: run contrast analysis\nseplength_comp_test &lt;- contrast(seplength_mean, method = seplength_comp)\nseplength_comp_test\n\n contrast                                estimate     SE  df t.ratio p.value\n Western State Iris - Eastern State Iris     1.26 0.0892 147  14.086  &lt;.0001\n\n\n\n# Step 6: confidence intervals\nconfint(seplength_comp_test)\n\n contrast                                estimate     SE  df lower.CL upper.CL\n Western State Iris - Eastern State Iris     1.26 0.0892 147     1.08     1.43\n\nConfidence level used: 0.95 \n\n\n\n# Bonus Step: Run inferential test and return CIs in one command\nsummary(seplength_comp_test, infer = TRUE)\n\n contrast                                estimate     SE  df lower.CL upper.CL\n Western State Iris - Eastern State Iris     1.26 0.0892 147     1.08     1.43\n t.ratio p.value\n  14.086  &lt;.0001\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n Results Interpretation\n\n\nImportant to write up our findings in the context of the hypothesis / research question:\n\n\n\n\n\n\nWe performed a test against \\(H_0: \\mu_\\text{Setosa} = \\frac{1}{2} (\\mu_\\text{Versicolor} + \\mu_\\text{Virginica}) = 0\\). At the 5% significance level, there was evidence that iris sepal length significantly differed between Western and Eastern states in the US \\((t(147) = 14.09, p &lt; .001, \\text{two-sided})\\), and this difference was estimated to be \\(1.26~cm\\). We are 95% confident that an iris grown in an Eastern state, on average, would be between \\(1.08~cm\\) and \\(1.43~cm\\) longer than those grown in a Western state \\((CI_{95}[1.08, 1.43])\\)."
  },
  {
    "objectID": "1_b2_reading.html#linear-models",
    "href": "1_b2_reading.html#linear-models",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Linear Models",
    "text": "Linear Models\nAssessing model fit involves examining metrics like the sum of squares to measure variability explained by the model, the \\(F\\)-ratio to evaluate the overall significance of the model by comparing explained variance to unexplained variance, and \\(R\\)-squared / Adjusted \\(R\\)-squared to quantify the proportion of variance in the dependent variable explained by the independent variable(s).\n\n Sums of Squares\n\n\nTo quantify and assess a model’s utility in explaining variance in an outcome variable, we can split the total variability of that outcome variable into two terms: the variability explained by the model plus the variability left unexplained in the residuals.\nThe sum of squares measures the deviation or variation of data points away from the mean (i.e., how spread out are the numbers in a given dataset). We are trying to find the equation/function that best fits our data by varying the least from our data points.\nTotal Sum of Squares\nFormula:\n\\[\n\\text{SS}_\\text{Total} = \\sum_{i=1}^{n}(y_i - \\bar{y})^2\n\\] Can also be derived from:\n\\[\n\\text{SS}_\\text{Total} = \\text{SS}_\\text{Model} + \\text{SS}_\\text{Residual}\n\\]\nIn words:\nSquared distance of each data point from the mean of \\(y\\).\nDescription:\nHow much variation there is in the DV.\nExample:\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nSteps:\n\nCalculate the mean of \\(y\\) (\\(\\bar y\\))\n\nCalculate for each observation \\(y_i\\) - \\(\\bar y\\)\n\nSquare each of the obtained \\(y_i\\) - \\(\\bar y\\) values\n\nSum squared values\n\nStep 1: Calculate the mean of \\(y_i\\)\n\\(\\bar y = {\\frac{5+7+8+6+9}{5}} = 7\\)\nStep 2 & 3: Calculate for each observation \\(y_i\\) - \\(\\bar y\\) & square values\n\n\nObserved \\(y_i\\)\n\n\n\\(y_i\\) - \\(\\bar y\\)\n\n\\((y_i - \\bar y)^2\\)\n\n\n\n5\n5 - 7 = -2\n\\(-2^2 = 4\\)\n\n\n7\n7 - 7 = 0\n\\(0^2 = 0\\)\n\n\n8\n8 - 7 = 1\n\\(1^2 = 1\\)\n\n\n6\n6 - 7 = -1\n\\(-1^2 = 1\\)\n\n\n9\n9 - 7 = 2\n\\(2^2 = 4\\)\n\n\n\nStep 4: Calculate sum squared values\n\\(\\text{SS}_\\text{Total} = 4 + 0 + 1 + 1 + 4 = 10\\)\nResidual Sum of Squares\nFormula:\n\\[\n\\text{SS}_\\text{Residual} = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n\\]\nIn words:\nSquared distance of each point from the predicted value.\nDescription:\nHow much of the variation in the DV the model did not explain - a measure that captures the unexplained variation in your regression model. Lower residual sum of squares suggests that your model fits the data well, and higher suggests that the model poorly explains the data (in other words, the lower the value, the better the regression model). If the value was zero here, it would suggest the model fits perfectly with no error.\nExample:\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nSteps:\n\nCalculate predicted values (\\(\\hat{y}_i\\))\n\nCalculate residuals (i.e., the difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)) for each observation)\n\nSquare the residuals\n\nSum squared values\n\nStep 1: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n\\(4.9 + (0.7*1) = 5.6\\)\n\n\n2\n7\n\\(4.9 + (0.7*2) = 6.3\\)\n\n\n3\n8\n\\(4.9 + (0.7*3) = 7\\)\n\n\n4\n6\n\\(4.9 + (0.7*4) = 7.7\\)\n\n\n5\n9\n\\(4.9 + (0.7*5) = 8.4\\)\n\n\n\nStep 2: Calculate residuals\n\n\\(\\epsilon_1 = 5 − 5.6 = -0.6\\)\n\\(\\epsilon_2 = 7 - 6.3 = 0.7\\)\n\\(\\epsilon_3 = 8 - 7 = 1\\)\n\\(\\epsilon_4 = 6 - 7.7 = -1.7\\)\n\\(\\epsilon_5 = 9 − 8.4 = 0.6\\)\n\nStep 3: Square the residuals\n\n\\(\\epsilon_1^2 = -0.6^2 = 0.36\\)\n\\(\\epsilon_2^2 = 0.7^2 = 0.49\\)\n\\(\\epsilon_3^2 = 1^2 = 1\\)\n\\(\\epsilon_4^2 = -1.7^2 = 2.89\\)\n\\(\\epsilon_5^2 = 0.6^2 = 0.36\\)\n\nStep 4: Calculate sum of squared values\n\\(\\text{SS}_\\text{Residual} = 0.36 + 0.49 + 1 + 2.89 + 0.36 = 5.1\\)\nModel Sum of Squares\nFormula:\n\\[\n\\text{SS}_\\text{Model} = \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2\n\\]\nCan also be derived from:\n\\[\n\\text{SS}_\\text{Model} = \\text{SS}_\\text{Total} - \\text{SS}_\\text{Residual}\n\\]\nIn words:\nThe deviance of the predicted scores from the mean of \\(y\\).\nDescription:\nHow much of the variation in the DV your model explained - like a measure that captures how well the regression line fits your data.\nExample:\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nSteps:\n\nCalculate mean of \\(y\\) (\\(\\bar y\\))\n\nCalculate predicted values (\\(\\hat{y}_i\\))\n\nCalculate for each observation \\(\\hat{y}_i - \\bar y\\)\n\nSquaring each of the obtained \\(\\hat{y}_i - \\bar y\\) values\n\nSum squared values\n\nStep 1: Calculate the mean of \\(y_i\\) \n\\(\\bar y = {\\frac{5+7+8+6+9}{5}} = 7\\)\nStep 2: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n\\(4.9 + (0.7*1) = 5.6\\)\n\n\n2\n7\n\\(4.9 + (0.7*2) = 6.3\\)\n\n\n3\n8\n\\(4.9 + (0.7*3) = 7\\)\n\n\n4\n6\n\\(4.9 + (0.7*4) = 7.7\\)\n\n\n5\n9\n\\(4.9 + (0.7*5) = 8.4\\)\n\n\n\nStep 3 & 4: Calculate for each observation \\(\\hat{y}_i\\) - \\(\\bar y\\) & square values\n\n\n\n\\(\\hat{y}_i\\) - \\(\\bar y\\)\n\n\\((\\hat{y}_i - \\bar y)^2\\)\n\n\n\n\\(5.6 - 7 = -1.4\\)\n\\((-1.4)^2 = 1.96\\)\n\n\n\\(6.3 - 7 = -0.7\\)\n\\((-0.7)^2 = 0.49\\)\n\n\n\\(7 - 7 = 0\\)\n\\((0)^2 = 0\\)\n\n\n\\(7.7 - 7 = 0.7\\)\n\\((0.7)^2 = 0.49\\)\n\n\n\\(8.4 - 7 = 1.4\\)\n\\((1.4)^2 = 1.96\\)\n\n\n\nStep 5: Calculate sum of squared values\n\\(\\text{SS}_\\text{Model} = 1.96 + 0.49 + 0 + 0.49 + 1.96 = 4.9\\)\nAlternatively:\n\\[\n\\begin{align}\n& \\text{SS}_\\text{Model} = \\text{SS}_\\text{Total} - \\text{SS}_\\text{Residual} \\\\\n& \\text{SS}_\\text{Model} = 10 - 5.1 \\\\  \n& \\text{SS}_\\text{Model} = 4.9 \\\\  \n\\end{align}\n\\]\n\n\n\n\n\n\n F-ratio\n\n\nOverview:\nWe can perform a test to investigate if a model is ‘useful’ — that is, a test to see if our explanatory variable explains more variance in our outcome than we would expect by just some random chance variable.\nWith one predictor, the \\(F\\)-statistic is used to test the null hypothesis that the regression slope for that predictor is zero:\n\\[\nH_0: \\text{the model is ineffective, }b_1 = 0 \\\\  \n\\] \\[\nH_1 : \\text{the model is effective, }b_1  \\neq 0 \\\\  \n\\]\nIn multiple regression, the logic is the same, but we are now testing against the null hypothesis that all regression slopes are zero. Our test is framed in terms of the following hypotheses:\n\\[\nH_0: \\text{the model is ineffective, }b_1,...., b_k = 0 \\\\    \n\\]\n\\[\nH_1 : \\text{the model is effective, }b_1,...., b_k  \\neq 0 \\\\  \n\\]\nThe relevant test-statistic is the \\(F\\)-statistic, which uses “Mean Squares” (these are Sums of Squares divided by the relevant degrees of freedom). We then compare that against (you guessed it) an \\(F\\)-distribution! \\(F\\)-distributions vary according to two parameters, which are both degrees of freedom.\nFormula:\n\\[\n\\text{F}_{(df_{model},~df_{residual})} = \\frac{\\text{MS}_\\text{Model}}{\\text{MS}_\\text{Residual}} = \\frac{\\text{SS}_\\text{Model}/\\text{df}_\\text{Model}}{\\text{SS}_\\text{Residual}/\\text{df}_\\text{Residual}} \\\\\n\\quad \\\\\n\\]\n\\[\n\\begin{align}\n& \\text{Where:} \\\\\n& df_{model} = k \\\\\n& df_{residual} = n-k-1 \\\\\n& n = \\text{sample size} \\\\\n& k  = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\nDescription:\nTo test the significance of an overall model, we can conduct an \\(F\\)-test. The \\(F\\)-test compares your model to a model containing zero predictor variables (i.e., the intercept only model), and tests whether your added predictor variables significantly improved the model.\nIt is called the \\(F\\)-ratio because it is the ratio of the how much of the variation is explained by the model (per parameter) versus how much of the variation is unexplained (per remaining degrees of freedom).\nThe \\(F\\)-test involves testing the statistical significance of the \\(F\\)-ratio.\nQ: What does the \\(F\\)-ratio test?A: The null hypothesis that all regression slopes in a model are zero (i.e., explain no variance in your outcome/DV). The alternative hypothesis is that at least one of the slopes is not zero.\nThe \\(F\\)-ratio you see at the bottom of summary(model) is actually a comparison between two models: your model (with some explanatory variables in predicting \\(y\\)) and the null model.\nIn regression, the null model can be thought of as the model in which all explanatory variables have zero regression coefficients. It is also referred to as the intercept-only model, because if all predictor variable coefficients are zero, then we are only estimating \\(y\\) via an intercept (which will be the mean - \\(\\bar y\\)).\nInterpretation:\nAlongside viewing the \\(F\\)-ratio, you can see the results from testing the null hypothesis that all of the coefficients are \\(0\\) (the alternative hypothesis is that at least one coefficient is \\(\\neq 0\\). Under the null hypothesis that all coefficients = 0, the ratio of explained:unexplained variance should be approximately 1)\nIf your model predictors do explain some variance, the \\(F\\)-ratio will be significant, and you would reject the null, as this would suggest that your predictor variables included in your model improved the model fit (in comparison to the intercept only model).\nPoints to note:\n\nThe larger your \\(F\\)-ratio, the better your model\nThe \\(F\\)-ratio will be close to 1 when the null is true (i.e., that all slopes are zero)\n\nHow to calculate \\(F\\)-ratio\n\n\nBy Hand\nUsing R\n\n\n\nSteps:\n\nCalculate model sum of squares\nCalculate residual sum of squares\nCalculate total sum of squares\nCalculate \\(df_{model}\\)\n\nCalculate \\(df_{residual}\\)\n\n\nStep 1, 2, & 3\nFollow steps above in the Sums of Squares flashcard:\n\\[\n\\begin{align}\n& \\text{SS}_\\text{Total} = 10  \\\\\n& \\text{SS}_\\text{Residual} = 5.1 \\\\  \n& \\text{SS}_\\text{Model} = 4.9 \\\\  \n\\end{align}\n\\]\nStep 4: Calculate \\(df_{model}\\)\n\\[\n\\begin{align}\n&df_{model} = k  \\\\  \n&df_{model} = 1\n\\end{align}\n\\]\nStep 5: Calculate \\(df_{residual}\\)\n\\[\n\\begin{align}\n&df_{residual} = n-k-1   \\\\  \n&df_{residual} = 5-1-1  \\\\  \n&df_{residual} = 3  \n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\text{F}_{(df_{model},~df_{residual})} = \\frac{\\text{MS}_\\text{Model}}{\\text{MS}_\\text{Residual}} = \\frac{\\text{SS}_\\text{Model}/\\text{df}_\\text{Model}}{\\text{SS}_\\text{Residual}/\\text{df}_\\text{Residual}} \\\\  \n\\\\  \n&\\text{F}_{(df_{model},~df_{residual})} = \\frac{4.9/1}{5.1/3} \\\\  \n\\\\  \n&\\text{F}_{(df_{model},~df_{residual})} = \\frac{4.9}{1.7} \\\\  \n\\\\  \n&\\text{F}_{(df_{model},~df_{residual})} = 2.88  \n\\end{align}\n\\]\n\n\n\nIn R\nWe can see the \\(F\\)-statistic and associated \\(p\\)-value at the bottom of the output of summary(&lt;modelname&gt;):\n\n\n\n\nMultiple regression output in R, F statistic highlighted\n\n\n\nAlternatively, you can extract this information as it is stored in the summary() of the model:\n\n#F-Statistic\nsummary(recall_multi)$fstatistic\n\n   value    numdf    dendf \n12.92426  2.00000 17.00000 \n\n#P-Value\npf(summary(recall_multi)$fstatistic[1], \n   summary(recall_multi)$fstatistic[2], \n   summary(recall_multi)$fstatistic[3], \n   lower.tail = FALSE)\n\n       value \n0.0003866881 \n\n\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nThe linear model with recall confidence and age explained a significant amount of variance in recall accuracy beyond what we would expect by chance \\(F(2, 17) = 12.92, p &lt; .001\\).\n\n\n\n\n\n\n\n\n R-squared and Adjusted R-squared\n\n\nOverview:\n\\(R^2\\) represents the proportion of variance in \\(Y\\) that is explained by the model predictor variables.\nFormula:\nThe \\(R^2\\) coefficient is defined as the proportion of the total variability in the outcome variable which is explained by our model:\n\\[\nR^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Residual}}{SS_{Total}}\n\\]\nThe Adjusted \\(R^2\\) coefficient is defined as:\n\\[\n\\hat R^2 = 1 - \\frac{(1 - R^2)(n-1)}{n-k-1}\n\\quad \\\\\n\\]\n\\[\n\\begin{align}\n& \\text{Where:} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\n\nWhen to report Multiple \\(R^2\\) vs. Adjusted \\(R^2\\):\nThe Multiple \\(R^2\\) value should be reported for a simple linear regression model (i.e., one predictor).\nUnlike \\(R^2\\), Adjusted-\\(R^2\\) does not necessarily increase with the addition of more explanatory variables, by the inclusion of a penalty according to the number of explanatory variables in the model. Since Adjusted-\\(R^2\\) is adjusted for the number of predictors in the model, this should be used when there are 2 or more predictors in the model. As a side note, the Adjusted-\\(R^2\\) should always be less than or equal to \\(R^2\\).\nHow to calculate Multiple \\(R^2\\) & Adjusted \\(R^2\\)\n\n\nBy Hand\nUsing R\n\n\n\nUsing the information calculated above in the Sums of Squares flashcard above, we can simply substitute values into the formula for \\(R^2\\):\n\\[\n\\begin{align}  \n& R^2 = \\frac{\\text{SS}_{\\text{Model}}}{\\text{SS}_{\\text{Total}}} = 1 - \\frac{\\text{SS}_{\\text{Residual}}}{\\text{SS}_{\\text{Total}}} \\\\\n\\\\  \n& R^2 = \\frac{4.9}{10} = 1 - \\frac{5.1}{10} \\\\  \n\\\\  \n& R^2 = 0.49 = 0.49\n\\end{align}  \n\\]\nAnd for Adjusted-\\(R^2\\):\n\\[\n\\begin{align}  \n& \\text{Adjusted-R}^2 = 1 - \\frac{(1 - R^2)(n-1)}{n-k-1} \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - \\frac{(1 - 0.49)(5-1)}{5-1-1} \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - \\frac{(0.51)(4)}{3} \\\\  \n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - \\frac{2.04}{3} \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - 0.68 \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 0.32 \\\\\n\\end{align}\n\\]\n\n\n\nIn R\nWe can see both \\(R^2\\) and Adjusted-\\(R^2\\) in the second bottom row of the summary(&lt;modelname&gt;):\n\n\n\n\nMultiple regression output in R, R^2 statistic highlighted\n\n\n\nAlternatively, you can extract this information as it is stored in the summary() of the model:\n\n#R-Squared\nsummary(recall_multi)$r.squared\n\n[1] 0.6032536\n\n#Adjusted R-Squared\nsummary(recall_multi)$adj.r.squared\n\n[1] 0.5565775\n\n\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nTogether, recall confidence and age explained approximately 55.66% of the variance in recall accuracy."
  },
  {
    "objectID": "1_b2_reading.html#linear-models-1",
    "href": "1_b2_reading.html#linear-models-1",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Linear Models",
    "text": "Linear Models\nOne useful thing we might want to do is compare our models with and without some predictor(s).There are numerous ways we can do this, but the method chosen depends on the models and underlying data:\n\n\n\n\n\n\n\n\n\n Nested vs Non-Nested Models\n\n\nNested Models\nConsider that you have two regression models where Model 1 contains a subset of the predictors contained in the other Model 2 and is fitted to the same data. More simply, Model 2 contains all of the predictors included in Model 1, plus additional predictor(s). This means that Model 1 is nested within Model 2, or that Model 1 is a submodel of Model 2. These two terms, at least in this setting, are interchangeable - it might be easier to think of Model 1 as your null and Model 2 as your alternative.\nNon-Nested Models\nConsider that you have two regression models where Model 1 contains different variables to those contained in Model 2, where both models are fitted to the same data. More simply, Model 1 and Model 2 contain unique variables that are not shared. This means that Model 1 and Model 2 are not nested.\n\n\n\n\n\n Incremental F-test\n\n\nIf (and only if) two models are nested, can we compare them using an incremental F-test.\nThis is a formal test of whether the additional predictors provide a better fitting model.\nFormally this is the test of:\n\n\\(H_0:\\) coefficients for the added/omitted variables are all zero.\n\\(H_1:\\) at least one of the added/omitted variables has a coefficient that is not zero.\n\nThe \\(F\\)-ratio for comparing the residual sums of squares between two models can be calculated as:\n\\[\nF_{(df_R-df_F),~df_F} = \\frac{(SSR_R-SSR_F)/(df_R-df_F)}{SSR_F / df_F} \\\\\n\\quad \\\\\n\\] \\[\n\\begin{align}\n& \\text{Where:} \\\\\n\\\\\n& SSR_R = \\text{residual sums of squares for the restricted model} \\\\\n& SSR_F = \\text{residual sums of squares for the full model} \\\\\n& df_R = \\text{residual degrees of freedom from the restricted model} \\\\\n& df_F = \\text{residual degrees of freedom from the full model} \\\\\n\\end{align}\n\\]\n\nIn R\nWe can conduct an incremental \\(F\\)-test to compare two models by fitting both models using lm(), and passing them to the anova() function:\n\nmodel1 &lt;- lm( ... )\nmodel2 &lt;- lm( ... )\nanova(model1, model2)\n\nIf we wanted to, for example, compare a model with just one predictor, \\(x1\\), to a model with 2 predictors: \\(x1\\), and \\(x2\\), we can assess the extent to which the variable \\(x2\\) improves model fit:\n\nmodel1 &lt;- lm(y ~ x1, data = data_name)\nmodel2 &lt;- lm(y ~ x1 + x2, data = data_name)\nanova(model1, model2)\n\nFor example:\n\n\n\n\nModel Comparisons using Incremental F-test\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nRecall confidence explained a significant amount of variance in recall accuracy beyond age \\((F(1, 17) = 21.95, p &lt; .001)\\).\n\n\n\n\n\n\n\n\n AIC & BIC\n\n\nAIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) combine information about the sample size, the number of model parameters, and the residual sums of squares (\\(SS_{residual}\\)). Models do not need to be nested to be compared via AIC and BIC, but they need to have been fit to the same dataset.\nAIC can be calculated as:\n\\[\n\\begin{align}\n& AIC = n\\,\\text{ln}\\left( \\frac{SS_{residual}}{n} \\right) + 2k \\\\\n\\end{align}\n\\quad \\\\\n\\]\nBIC can be calculated as:\n\\[\n\\begin{align}\n& BIC = n\\,\\text{ln}\\left( \\frac{SS_{residual}}{n} \\right) + k\\,\\text{ln}(n) \\\\\n\\end{align}\n\\quad \\\\\n\\]\nWhere for both AIC and BIC:\n\\[\n\\begin{align}\n& SS_{residual} = \\text{sum of squares residuals} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n& \\text{ln} = \\text{natural log function}\n\\end{align}\n\\]\nFor both of these fit indices, lower values are better, and both include a penalty for the number of predictors in the model (although BIC’s penalty is harsher).\nSo how do we determine whether there is a statistical difference between two models? To evaluate our model comparisons, we need to look at the difference (\\(\\Delta\\)) between the two values:\n\nAIC: There are no specific thresholds to suggest how big a difference in two models is needed to conclude that one is substantively better than the other\nBIC: Using the following \\(\\Delta BIC\\) cutoffs (Raftery, 1995):\n\n\n\nValue\nInterpretation of Difference between Models\n\n\n\n\\(\\Delta &lt; 2\\)\nNo evidence\n\n\n\\(2 &gt; \\Delta &lt; 6\\)\nPositive evidence\n\n\n\\(6 &gt; \\Delta &lt; 10\\)\nStrong evidence\n\n\n\\(\\Delta &gt; 10\\)\nVery strong evidence\n\n\n\n\nIn R\nWe can calculate AIC and BIC by using the AIC() and BIC() functions respectively:\n\n#AIC\nAIC(modelname)\n\n#BIC\nBIC(modelname)\n\nFor example, with AIC:\n\n\n\n\nModel Comparisons using AIC\n\n\n\nand BIC:\n\n\n\n\nModel Comparisons using BIC\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nBased on both AIC and BIC, the model predicting recall accuracy that included both recall confidence and age was better fitting \\((\\text{AIC} = 152.28; \\text{BIC} = 156.27)\\) than the model with age alone \\((\\text{AIC} = 166.86; \\text{BIC} = 169.85)\\)."
  },
  {
    "objectID": "1_b2_reading.html#linear-models-2",
    "href": "1_b2_reading.html#linear-models-2",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Linear Models",
    "text": "Linear Models\nLinear models rely on numerous underlying assumptions about the data. These assumptions ensure that the association between variables is appropriately captured, and that inferences drawn from the model are accurate and valid. Model diagnostics can help further assess whether these assumptions hold. When these assumptions are violated, there are numerous techniques that can be employed, such as through data transformations or using robust alternatives, to ensure reliable model interpretations.\n\n Linearity\n\n\nSimple Linear Regression\nIn simple linear regression with only one explanatory variable, we could assess linearity through a simple scatterplot of the outcome variable against the explanatory. This would allow us to check if the errors have a mean of zero. If this assumption was met, the residuals would appear to be randomly scattered around zero.\nThe rationale for this is that, once you remove from the data the linear trend, what’s left over in the residuals should not have any trend, i.e. have a mean of zero.\nMultiple Regression\nIn multiple regression, however, it becomes more necessary to rely on diagnostic plots of the model residuals. This is because we need to know whether the relations are linear between the outcome and each predictor after accounting for the other predictors in the model.\nIn order to assess this, we use partial-residual plots (also known as ‘component-residual plots’). This is a plot with each explanatory variable \\(x_j\\) on the x-axis, and partial residuals on the y-axis***.\nPartial residuals for a predictor \\(x_j\\) are calculated as: \\[\n\\hat \\epsilon + \\hat \\beta_j x_j\n\\]\n\nIn R\n\n\nSimple Linear Regression\nMultiple Linear Regression\n\n\n\n\n#specify model\nrecall_simp &lt;- lm(recall_accuracy ~ age, data = recalldata)\n\n#create plot\nggplot(recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE, colour = \"blue\") + #fit straight line to data\n    geom_smooth(method = \"loess\", se = FALSE, colour = \"red\") + #fit loess line to data\n    labs(x = \"Age\", y = \"Recall Accuracy\")\n\n\n\n\n\n\n\n\nInterpretation Guidance\nThe loess line should closely follow the data.\n\n\n\nWe can create these plots for all predictors in the model by using the crPlots() function from the car package:\n\n#specify model\nrecall_mdl &lt;- lm(recall_accuracy ~ recall_confidence + age, data = recalldata)\n\n#create plots\ncrPlots(recall_mdl)\n\n\n\n\n\n\n\n\nInterpretation Guidance\nYou are looking for the pink line to follow a linear trend line (i.e., follow the blue line). In other words, the loess line should closely follow the linear line.\n\n\n\n\n\n\n\n\n\n\n\n Independence (of errors)\n\n\nThe ‘independence of errors’ assumption is the condition that the errors do not have some underlying relationship which is causing them to influence one another. \nThere are many sources of possible dependence, and often these are issues of study design. For example, we may have groups of observations in our data which we would expect to be related (e.g., multiple trials from the same participant). Our modelling strategy would need to take this into account. \nTesting for the independence of errors can be pretty difficult, unless you know the potential source of correlation between cases (more on this in DAPR3!).\n\n\n\n\n\n Normality (of errors)\n\n\nThe normality assumption is the condition that the errors \\(\\epsilon\\) are normally distributed in the population.\nWe can visually assess this condition through histograms, density plots, and quantile-quantile plots (QQplots) of our residuals \\(\\hat \\epsilon\\).\n\n\nHistogram\nQQPlot\n\n\n\n\nhist(recall_mdl$residuals)\n\n\n\n\n\n\n\n\n\n\nplot(recall_mdl, which = 2)\n\n\n\n\n\n\n\n\n\n\n\nInterpretation Guidance\nRemember that departures from a linear trend in QQ plots indicate a lack of normality.\n\n\n\n\n\n\n Equal Variances (Homoscedasticity)\n\n\nThe equal variances assumption is that the error variance \\(\\sigma^2\\) is constant across values of the predictor(s) \\(x_1, \\dots, x_k\\), and across values of the fitted values \\(\\hat y\\). This sometimes gets termed “Constant” vs “Non-constant” variance. This is presented visually in Figure 10 and Figure 11.\n\n\n\n\nFigure 10: Non-constant variance for numeric and categorical X\n\n\n\n\n\n\n\nFigure 11: Constant variance for numeric and categorical X\n\n\n\n\nIn R\nWe can create plots of the Pearson residuals against the predicted values \\(\\hat y\\) and against the predictors \\(x_1\\), … \\(x_k\\) by using the residualPlots() function from the car package. This function also provides the results of a lack-of-fit test for each of these relationships (note when it is the fitted values \\(\\hat y\\) it gets called “Tukey’s test”).\n\nlibrary(car)\nresidualPlots(recall_mdl)\n\n\n\n\n\n\n\n                  Test stat Pr(&gt;|Test stat|)\nrecall_confidence    1.4473           0.1671\nage                 -0.0474           0.9627\nTukey test           0.8769           0.3805\n\n\nAlternatively, we can use:\n\nplot(recall_mdl, which = 1)\n\n\n\n\n\n\n\n\n\nInterpretation Guidance\nIf the assumption is met, you should see a random scatter of \\((x,y)\\) points with constant mean and variance functions i.e., the vertical spread of the residuals should roughly be the same everywhere.\n\n\n\n\n\n\n Useful Assumption Plots\n\n\n\n\nplot(modelname)\ncheck_model(modelname)\n\n\n\nWe can run plot(mymodel) which will cycle through these plots (asking us to press enter each time to move to the next plot), or we can arrange these plots in a matrix via par(mfrow), for example in a 2 x 2 matrix as shown below (make sure to always reset your graphical parameters! If needed, we could also extract specific plots using, for instance: plot(mymodel, which = 3) for the third plot.\n\nIn R\n\npar(mfrow=c(2,2))\nplot(recall_mdl)\n\n\n\n\n\n\npar(mfrow=c(1,1))\n\n\n\nInterpretation Guidance\n\nTop Left: For the Residuals vs Fitted plot, we want the red line to be horizontal at close to zero across the plot. We don’t want the residuals (the points) to be fanning in/out.\n\nTop Right: For the Normal Q-Q plot, we want the residuals (the points) to follow closely to the diagonal line, indicating that they are relatively normally distributed.2\n\nBottom Left: For the Scale-Location plot, we want the red line to be horizontal across the plot. These plots allow us to examine the extent to which the variance of the residuals changes across the fitted values. If it is angled, we are likely to see fanning in/out of the points in the residuals vs fitted plot.\nBottom Right: The Residuals vs Leverage plot indicates points that might be of individual interest as they may be unduly influencing the model. There are funnel-shaped lines on this plot (sometimes out of scope of the plotting window). Ideally, we want our residuals inside the funnel - the further the residual is to the right (the more leverage it has), the closer to the 0 we want it to be.\n\nNote, if we have only categorical predictors in our model, many of these will show vertical lines of points. This doesn’t indicate that anything is wrong, and the same principles described above continue to apply\n\n\n\nThe check_model() function from the performance package is a useful way to check the assumptions of models, as it also returns some useful notes to aid your interpretation. However, it is important to check each assumption individually with plots that are more suitable for a statistics report.\n\nIn R\n\nlibrary(performance)\ncheck_model(recall_mdl)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Multicollinearity\n\n\nFor the linear model with multiple explanatory variables, we need to also think about multicollinearity - this is when two (or more) of the predictors in our regression model are moderately or highly correlated.\nWe can assess multicollinearity using the variance inflation factor (VIF), which for a given predictor \\(x_j\\) is calculated as:\n\\[\nVIF_j = \\frac{1}{1-R_j^2} \\\\\n\\]\n\nInterpretation Guidance\nSuggested cut-offs for VIF are varied. Some suggest 10, others 5. Define what you will consider an acceptable value prior to calculating it. You could loosely interpret VIF values \\(&gt;5\\) as moderate multicollinearity and values \\(&gt;10\\) as severe multicollinearity.\n\n\nIn R\nThe vif() function from the car package will provide VIF values for each predictor in your model.\n\nvif(INSERT_MODEL_NAME)\n\n\n\n\n\n\n\n Individual Case Diagnostics\n\n\nWe have seen that some specific individual cases in our data can influence our model more than others. We can identify these as:\n\n\nRegression outliers: A large residual \\(\\hat \\epsilon_i\\) - i.e., a big discrepancy between their predicted y-value and their observed y-value.\n\n\nStandardised residuals: For residual \\(\\hat \\epsilon_i\\), divide by the estimate of the standard deviation of the residuals. In R, the rstandard() function will give you these\n\nStudentised residuals: For residual \\(\\hat \\epsilon_i\\), divide by the estimate of the standard deviation of the residuals excluding case \\(i\\). In R, the rstudent() function will give you these.\n\n\n\nHigh leverage cases: These are cases which have considerable potential to influence the regression model (e.g., cases with an unusual combination of predictor values).\n\n\nHat values: are used to assess leverage. In R, The hatvalues() function will retrieve these.\n\n\n\nHigh influence cases: When a case has high leverage and is an outlier, it will have a large influence on the regression model.\n\n\nCook’s Distance: combines leverage (hatvalues) with outlying-ness to capture influence: \\(D_i = \\text{Outlyingness} \\times \\text{Leverage}\\). Cook’s distance refers to the average distance the \\(\\hat{y}\\) values will move if a given case is removed. In R, the cooks.distance() function will provide these values. Alongside Cook’s Distance, we can examine the extent to which model estimates and predictions are affected when an entire case is dropped from the dataset and the model is refitted.\n\n\n\n\nDFFit: the change in the predicted value at the \\(i^{th}\\) observation with and without the \\(i^{th}\\) observation is included in the regression.\n\n\nDFbeta: the change in a specific coefficient with and without the \\(i^{th}\\) observation is included in the regression. DFbeta represents the difference in the beta coefficients when a case is excluded from the model versus when it’s included. A large DFbeta value would suggest that a case has a substantial impact on the estimated coefficients, and thus a high influence on the model results; a small DFbeta value would suggest that the case has less influence on the estimated coefficients. A commonly used cut-off or threshold to compare \\(|DFBETA|\\) values (absolute values) against is \\(\\frac{2}{\\sqrt{n}}\\) (see Belsley et al., (1980) p. 28 for more info)3.\n\nDFbetas: the change in a specific coefficient divided by the standard error, with and without the \\(i^{th}\\) observation is included in the regression.\n\n\nCOVRATIO: measures the effect of an observation on the covariance matrix of the parameter estimates. In simpler terms, it captures an observation’s influence on standard errors. Values which are \\(&gt;1+\\frac{3(k+1)}{n}\\) or \\(&lt;1-\\frac{3(k+1)}{n}\\) are considered as having strong influence.\n\n\nIn R, we can get lots of these measures with the influence.measures() function:\n\n\ninfluence.measures(my_model) will give you out a dataframe of the various measures.\n\nsummary(influence.measures(my_model)) will provide a nice summary of what R deems to be the influential points.\n\n\n\n\n\n\n\n Next Steps: What to do with Violations of Assumptions / Problematic Case Diagnostic Results\n\n\nThere are lots of different options available, and there is no one right answer. Assuming that we have no issues with model specification (i.e., are not missing variables, have modeled appropriately), then we may want to consider one of the below approaches (note: this is not an exhaustive list!)\n\n\nInvestigate Observations\nSensitivity Analysis\nBootstrapping\nOLS vs WLS Regression\nData Transformations\nUsing Non-Linear Models\nRemoving Observations\n\n\n\nThe first step is to re-examine your data. It is important to be familiar with your dataset, as you need to know what values are typical, normal, and possible. Could it be the case that you have missed some impossible values (e.g., a negative value of a persons height), values outwith the possible range (e.g., a score of 55 on a survey where scores can only range 10-50), values that don’t make any sense (e.g., an age of 200), or maybe there are even typos / data entry errors (e.g., forgetting to put a decimal point, so having a height of 152m instead of 1.52m)!\nIf there is a simple error in the data, it could be that you can fix the typo. If that is not possible (maybe you didn’t collect the data, so are unsure of what the value(s) should/could be), you will need to delete the value (i.e., set as an NA), because you know that it is incorrect.\nWe should aim to never change a legitimate value where possible (and remember that if you have a large dataset, a small number of extreme values will be unlikely to have a strong influence on your results).\nIf there is an extreme, but legitimate value that you have determined is adversely influencing your model (i.e., by examining the assumptions and diagnostics as outlined above), you may want to consider ways to reduce this influence (e.g., winsorizing - which essentially truncates or caps the identified extreme values to a specified percentile, in turn reducing their influence on the model without completely eliminating the observation(s). For example, you could replace values below the 5th percentile with the 5th percentile value, and values above the 95th percentile with the 95th percentile value).\nIf after re-examining your data you cannot identify any atypical, non-normal, or impossible values, you may need to select a different approach as outlined below.\n\n\nThis allows us to assess the sensitivity of our results (i.e., parameter estimates, p-values, confidence intervals) to changes in our modelling approach (i.e., the removal of observations).\nWe can re-fit our model after excluding our identified outliers and potentially influential observations, and compare these results to the original model.\n\n\n\n\n\n\nProcess of Removing Observations\n\n\n\n\n\nThe current example involves removing all identified outliers and potentially influential observations at the same time. Ideally, and to ensure a more thorough sensitivity analysis, you would remove each of these observations one at a time, assess the effects on the model by comparing to your original, reassessing the remaining pre-identified observations, and repeating the process if necessary.\n\n\n\n\n\nOriginal Model\nModel with Observations Removed\nCompare summary() output\n\n\n\n\n## wellbeing model\nwb_mdl1 &lt;- lm(wellbeing ~ outdoor_time + social_int, data = mwdata) \nsummary(wb_mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ outdoor_time + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n## wellbeing model\nwb_mdl2 &lt;- lm(wellbeing ~ outdoor_time + social_int, data = mwdata[-c(16, 25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, 101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, 173, 176, 179, 197), ])\nsummary(wb_mdl2)\n\n\nCall:\nlm(formula = wellbeing ~ outdoor_time + social_int, data = mwdata[-c(16, \n    25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, \n    101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, \n    173, 176, 179, 197), ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7700 -2.6445 -0.6073  2.8586  9.6605 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  27.91311    1.42612  19.573  &lt; 2e-16 ***\noutdoor_time  0.19356    0.04901   3.950 0.000116 ***\nsocial_int    0.39830    0.08964   4.443 1.62e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.044 on 165 degrees of freedom\nMultiple R-squared:  0.1774,    Adjusted R-squared:  0.1675 \nF-statistic:  17.8 on 2 and 165 DF,  p-value: 1.004e-07\n\n\n\n\n\ntab_model(wb_mdl1, wb_mdl2,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"outdoor_time\" = \"Outdoor Time (hours per week)\",\n                          \"social_int\" = \"Social Interactions (number per week)\"),\n          title = \"Regression Table for Wellbeing Models wb1 and wb2\")\n\n\nRegression Table for Wellbeing Models wb1 and wb2\n\n\n\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n28.62\n25.69 – 31.55\n&lt;0.001\n27.91\n25.10 – 30.73\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n0.20\n0.10 – 0.30\n&lt;0.001\n0.19\n0.10 – 0.29\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n0.33\n0.16 – 0.51\n&lt;0.001\n0.40\n0.22 – 0.58\n&lt;0.001\n\n\nObservations\n200\n168\n\n\nR2 / R2 adjusted\n0.126 / 0.118\n0.177 / 0.167\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe conducted a sensitivity analysis to assess how robust our conclusions were regarding outdoor time and the weekly number of social interactions in the presence of previously identified outliers and potentially influential observations. We re-fit the model, excluding these 28 observations (14% of our original sample), and compared these model results (wb_mdl2) to those of our original model (wb_mdl1).\nThere was little difference in the estimates from wb_mdl1 and wb_mdl2, and so we can conclude that after conducting a sensitivity analysis, there were no meaningful differences in our results, and hence our conclusions from our original model hold. Specifically:\n\nThe direction of all model estimates are the same in wb_mdl1 and wb_mdl2 (i.e., all positive)\nThere is no difference in statistical significance, and the p-values were of a similar magnitude (i.e., all &lt; .001)\nThe estimate and confidence intervals for outdoor_time are very similar\nThere are some quantitative differences in the estimate and confidence intervals for social_int. The estimate differs slightly in magnitude by 0.07), but given that this remains positive and significant, we do not need to be too concerned about this.\n\n\n\n\n\n\nThe bootstrap method is an alternative non-parametric method of constructing a standard error. Instead of having to rely on calculating the standard error with a formula and potentially applying fancy mathematical corrections, bootstrapping involves mimicking the idea of “repeatedly sampling from the population”. It does so by repeatedly resampling with replacement from our original sample.\nWhat this means is that we don’t have to rely on any assumptions about our model residuals, because we actually generate an actual distribution that we can take as an approximation of our sampling distribution, meaning that we can actually look at where 95% of the distribution falls, without having to rely on any summing of squared deviations.\nNote, the bootstrap may provide us with an alternative way of conducting inference, but our model may still be mis-specified. It is also very important to remember that bootstrapping is entirely reliant on utilising our original sample to pretend that it is a population (and mimic sampling from that population). If our original sample is not representative of the population that we’re interested in, bootstrapping doesn’t help us at all.\n\n\nThe method of ordinary least squares regression (OLS: i.e., the type of regression model you have been fitting on the course) assumes that there is constant variance in the errors (homoscedasticity). The method of weighted least squares (WLS) can be used when the ordinary least squares assumption of constant variance in the errors is violated (i.e., you have evidence of heteroscedasticity, like we do in Q3 of this lab).\nIf we have some specific belief that your non-constant variance is due to differences in the variances of the outcome between various groups, then it might be better to use Weighted Least Squares.\nAs an example, imagine we are looking at weight of different dog breeds (Figure 12). The weights of chihuahuas are all quite close together (between 2 to 5kg), but the weight of, for example, spaniels is anywhere from 8 to 25kg - a much bigger variance.\n\n\n\n\nFigure 12: The weights of 49 dogs, of 7 breeds\n\n\n\nRecall that the default way that lm() deals with categorical predictors such as dog breed, is to compare each one to a reference level. In this case, that reference level is “beagle” (first in the alphabet). Looking at Figure 12 above, which comparison do you feel more confident in?\n\n\nA: Beagles (14kg) vs Pugs (9.1kg). A difference of 4.9kg.\n\n\nB: Beagles (14kg) vs Spaniels (19kg). A difference of 5kg.\n\nHopefully, your intuition is that A looks like a clearer difference than B because there’s less overlap between Beagles and Pugs than between Beagles and Spaniels. Our standard linear model, however, assumes the standard errors are identical for each comparison:\n\n\n\nCall:\nlm(formula = weight ~ breed, data = dogdf)\n...\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             13.996      1.649   8.489 1.17e-10 ***\nbreedpug                -4.858      2.332  -2.084   0.0433 *  \nbreedspaniel             5.052      2.332   2.167   0.0360 *  \nbreedchihuahua         -10.078      2.332  -4.322 9.28e-05 ***\nbreedboxer              20.625      2.332   8.846 3.82e-11 ***\nbreedgolden retriever   17.923      2.332   7.687 1.54e-09 ***\nbreedlurcher             5.905      2.332   2.533   0.0151 *  \n---\n\n\nFurthermore, we can see that we have heteroscedasticity in our residuals - the variance is not constant across the model:\n\nplot(dogmodel, which=3)\n\n\n\n\n\n\n\nWeighted least squares is a method that allows us to apply weights to each observation, where the size of the weight indicates the precision of the information contained in that observation.\nWe can, in our dog-breeds example, allocate different weights to each breed. Accordingly, the Chihuahuas are given higher weights (and so Chihuahua comparisons result in a smaller SE), and Spaniels and Retrievers are given lower weights.\n\nlibrary(nlme)\nload(url(\"https://uoepsy.github.io/data/dogweight.RData\"))\ndogmod_wls = gls(weight ~ breed, data = dogdf, \n                 weights = varIdent(form = ~ 1 | breed))\nsummary(dogmod_wls)\n\n\n\nCoefficients:\n                           Value Std.Error   t-value p-value\n(Intercept)            13.995640  1.044722 13.396516  0.0000\nbreedpug               -4.858097  1.271562 -3.820576  0.0004\nbreedspaniel            5.051696  2.763611  1.827933  0.0747\nbreedchihuahua        -10.077615  1.095964 -9.195207  0.0000\nbreedboxer             20.625429  1.820370 11.330351  0.0000\nbreedgolden retriever  17.922779  2.976253  6.021927  0.0000\nbreedlurcher            5.905261  1.362367  4.334559  0.0001\n\n\nWe can also apply weights that change according to continuous predictors (e.g. observations with a smaller value of \\(x\\) are given more weight than observations with larger values).\n\n\nA data transformation involves the replacement of a variable (e.g., \\(y\\)) by a function of that variable in order to change the shape of a distribution or association (e.g., to help reduce skew). We can transform the outcome variable prior to fitting the model, using something such as log(y) or sqrt(y). This will sometimes allow us to estimate a model for which our assumptions are satisfied.\nSome of the most common (not an exhaustive list) transformations are:\n\n\nLog (log(y)): Often used for reducing right skewness. Note, this transformation cannot be applied to zero or negative values (make sure to check your data!)\n\nSquare root (sqrt(y)): Also often used for reducing right skewness. This transformation can be applied to zero values (but not negative), and is commonly applied to count data\n\n\n\n\n\nFigure 13: A model of a transformed outcome variable can sometimes avoid violations of assumptions that arise when modeling the outcome variable directly. Data from https://uoepsy.github.io/data/trouble1.csv\n\n\n\nThe major downside of this is that we are no longer modelling \\(y\\), but some transformation \\(f(y)\\) (\\(y\\) with some function \\(f\\) applied to it). Interpretation of the coefficients changes accordingly, such that we are no longer talking in terms of changes in y, but changes in \\(f(y)\\). When the transformation function used is non-linear (see the Right-Hand of Figure 14) a change in \\(f(y)\\) is not the same for every \\(y\\).\n\n\n\n\nFigure 14: The log transformation is non-linear\n\n\n\nFor certain transformations, we can re-express coefficients to be interpretable with respect to \\(y\\) itself. For instance, the model using a log transform \\(ln(y) = b_0 + b_1(x)\\) gives us a coefficient that represents statement A below. We can re-express this by taking the opposite function to logarithm, the exponent, exp(). Similar to how this works in logistic regression, the exponentiated coefficients obtained from exp(coef(model)) are multiplicative, meaning we can say something such as statement B\n\n\n\nA: “a 1 unit change in \\(x\\) is associated with a \\(b\\) unit change in \\(ln(y)\\)”.\n\n\nB: “a 1 unit change in \\(x\\) is associated with \\(e^b\\) percent change in \\(y\\).”\n\n\nFinding the optimal transformation to use can be difficult, but there are methods out there to help you. One such method is the BoxCox transformation, which can be conducted using BoxCox(variable, lambda=\"auto\"), from the forecast package.4\n\n\n\n\nGeneralized Linear Models\nHigher Order Terms\n\n\n\nGeneralized Linear Models (GLMs) can appropriately deal with data that do not follow a normal distribution (which is a requirement for traditional linear models). They can accommodate various types of distributions, including the Poisson, binomial, and gamma distributions. This makes them suitable for modelling count data (e.g., number of sunny days Edinburgh has per year - yes, count data can include 0!), binary data (where there are only two possible values e.g., doesn’t wear glasses vs wear glasses, smoker vs non-smoker, i.e., values that are yes/no or 0/1), and other types of non-normal data.\nWe will explore some GLMs later in the course (Semester 2 Block 4), where we will work with logistic regression models.\n\n\nHigher order regression terms refer to the inclusion of polynomial terms of degree higher than one in a regression model. In a linear regression model, the association between the dependent variable (\\(Y\\)) and the independent variable (\\(X\\)) is assumed to be linear, which means the association can be represented by a straight line. However, in many real-world scenarios, associations between variables are not strictly linear, and including higher order regression terms can help capture more complex relationships. Higher order terms that you could incorporate include quadratic, cubic, or higher degree polynomial terms.\nFor example, in a quadratic regression model, the relationship between \\(Y\\) and \\(X\\) can be represented as:\n\\[\nY = \\beta_0 + \\beta_1 \\cdot X + \\beta_2 \\cdot X^2 + \\epsilon\n\\] \\[\n\\begin{align}\n& \\text{Where:} \\\\\n& Y = \\text{Dependent Variable} \\\\\n& X = \\text{Independent Variable} \\\\\n\\end{align}\n\\]\nAs in our models we’ve seen so far, \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\) are the coefficients to be estimated in the above model. What is different from what we’ve seen in DAPR2 is the term \\(\\beta_2 \\cdot X^2\\), and this represents the quadratic term. This allows for a curved as opposed to straight line to represent the association between \\(Y\\) and \\(X\\), and hence can allow us to capture more complex relationships. For example, we can model the association between height and age:\n\n\n\n\nFigure 15: Two linear models, one with a quadratic term (right)\n\n\n\nPlease note that these types of models are beyond the scope of the DAPR2 course, but if you want to know more, please do read up on these in your own time.\n\n\n\n\n\nRemoving outliers and potentially influential observations should be a last resort - not all outliers are inherently ‘bad’ - we do expect natural variation in our population(s) of interest. Outliers can be informative about the topic under investigation, and this is why you need to be very careful about excluding outliers due only to their ‘extremeness’. In doing so, you can distort your results by removing variability - i.e., by forcing the data to be more normal and less variable than it actually is, and reduce statistical power by reducing the size of your sample.\nIf you do decide to remove observations, you will need to document what specific data points you excluded, and provide an explanation as to why these were excluded.\nTo set specific values to NA in our dataset (and save this updated dataset in a new object named mwdata2), we could use the following code. For the purpose of this demonstration, lets say that we wanted to set any age values of &lt;20 as NA. In the original dataset mwdata, we had 3 individuals aged 18, and 6 aged 19, so we should end up with 9 NA values in mwdata2 column age:\n\n#specify age column in original dataset, where age is &lt; 20, for values to be set to NA and save to new object named mwdata2 to avoid overwriting original data\nmwdata2 &lt;-  mwdata |&gt; \n    mutate(age = replace(age, age &lt; 20, NA))\n\n#check how many NA values we have - there should be 9 (so 9 TRUEs):\ntable(is.na(mwdata2$age))\n\n\nFALSE  TRUE \n  191     9 \n\n\nIf we wanted to remove a full row from the datset, we could use the following code. For the purpose of this demonstration, lets say that we wanted to remove all rows that were highlighted in the above assumption and diagnostic checks as potentially having an adverse influence on our model estimates:\n\n# create new dataset 'mwdata3' without (by specifying -) identified outliers and potentially influential observations\nmwdata3 &lt;- mwdata[-c(16, 25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, 101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, 173, 176, 179, 197), ]\n\n# check dimensions - should now have 32 rows less than original dataset 200 - 32 = 168\ndim(mwdata3)\n\n[1] 168   7"
  },
  {
    "objectID": "1_b2_reading.html#latex-symbols-equations",
    "href": "1_b2_reading.html#latex-symbols-equations",
    "title": "Block 1 & 2 Flash Cards",
    "section": "LaTeX Symbols & Equations",
    "text": "LaTeX Symbols & Equations\nBy embedding LaTeX into RMarkdown, you can accurately and precisely format mathematical expressions, ensuring that they are not only technically correct but also visually appealing and easy to interpret.\n\n LaTeX Guide\n\n\nFor an overview of how to integrate LaTeX symbols and equations, review Lesson 9 of the RMD bootcamp."
  },
  {
    "objectID": "1_b2_reading.html#apa-formatting",
    "href": "1_b2_reading.html#apa-formatting",
    "title": "Block 1 & 2 Flash Cards",
    "section": "APA Formatting",
    "text": "APA Formatting\nAPA format is a writing/presentation style that is often used in psychology to ensure consistency in communication. APA formatting applies to all aspects of writing - from formatting of papers (including tables and figures), citation of sources, and reference lists. This means that it also applies to how you present results in your Psychology courses, including DAPR2.\n\n APA Formatting Guides\n\n\nAll results should be presented following APA guidelines.\nYou also need to follow APA style rules for tables and figures.\nMake sure to familiarise yourself with the above guides, and practice presenting your results following these rules."
  },
  {
    "objectID": "1_b2_reading.html#tables",
    "href": "1_b2_reading.html#tables",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Tables",
    "text": "Tables\nWe want to ensure that we are presenting results in a well formatted table. To do so, there are lots of different packages available (see Lesson 4 of the RMD bootcamp).\nOne of the most convenient ways to present results from regression models is to use the tab_model() function from sjPlot.\n\n Creating tables via tab_model\n\n\nWithin tab_model(), there are lots of different ways that you can customise your table. The most common arguments that you should use are dv.labels, pred.labels, and title.\nYou can rename your DV and IV labels by specifying dv.labels and pred.labels. To do so, specify your variable name on the left, and what you would like this to be named in the table on the right. For title, you can simply specify in ““’s what you want your title to be e.g., title = \"This is my title\".\nHere’s an example if I had fitted a model with the following information:\n\nModel name = mdl_test\n\nModel DV = cognitive_score\n\nModel IVs = SES and age\n\n\n\nmdl_test &lt;- lm(cognitive_score ~ SES + age, data = data_name)\n\nI want to change the names of SES and age to be socio-economic status and age - in years respectively. What we need to pay attention to here is the ordering of the IVs - the ordering in our lm() must match that in tab_model(). I also want to name my table Regression Table for Cognitive Scores Model. Here is how we would do this in R:\n\nlibrary(sjPlot)\ntab_model(mdl_test,\n          pred.labels = c('Intercept', 'socio-economic status', 'age - in years'),\n          title = \"Regression Table for Cognitive Scores Model\")\n\nSee here for another short example."
  },
  {
    "objectID": "1_b2_reading.html#cross-referencing",
    "href": "1_b2_reading.html#cross-referencing",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Cross Referencing",
    "text": "Cross Referencing\nCross-referencing is a very helpful way to direct your reader through your document, and the good news is that this can be done automatically in RMarkdown.\n\n Cross Referencing\n\n\nThere are three key components to allow you to successfully cross-reference within your RMarkdown document:\n\nA bookdown output format\nA caption to your figure or table\nA named/labeled code chunk\n\nOnce you have the above, you will be able to cross-reference using the syntax @ref(type:label), where label is the chunk name/label, and type is the environment being referenced (e.g. tab for table, fig for figure, etc.).\nFor an in-depth overview and example of how to cross-reference, see Lesson 7 of the RMD bootcamp."
  },
  {
    "objectID": "1_b2_reading.html#footnotes",
    "href": "1_b2_reading.html#footnotes",
    "title": "Block 1 & 2 Flash Cards",
    "section": "Footnotes",
    "text": "Footnotes\n\nYes, the error term is gone. This is because the line of best-fit gives you the prediction of the average recall accuracy for a given age, and not the individual recall accuracy of an individual person, which will almost surely be different from the prediction of the line.↩︎\nQQplots plot the values against the associated percentiles of the normal distribution. So if we had ten values, it would order them lowest to highest, then plot them on the y against the 10th, 20th, 30th.. and so on percentiles of the standard normal distribution (mean 0, SD 1)↩︎\nBelsley, D. A., Kuh, E., & Welsch, R. E. (2005). Regression diagnostics: Identifying influential data and sources of collinearity. John Wiley & Sons. DOI: 10.1002/0471725153↩︎\nThis method finds an appropriate value for \\(\\lambda\\) such that the transformation \\((sign(x) |x|^{\\lambda}-1)/\\lambda\\) results in a close to normal distribution.↩︎"
  },
  {
    "objectID": "1_b3_reading.html",
    "href": "1_b3_reading.html",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "",
    "text": "Within this reading, the following packages are used:\n\ntidyverse\nsjPlot\nkableExtra\npsych\npatchwork\nplotly\nemmeans\nperformance\ncar\ninteractions\n\nNote that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here."
  },
  {
    "objectID": "1_b3_reading.html#numeric-exploration",
    "href": "1_b3_reading.html#numeric-exploration",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Numeric Exploration",
    "text": "Numeric Exploration\nNumeric exploration of data involves examining and describing key statistics like mean, median, and standard deviation via descriptives tables; and assessing the associations among variables through correlation coefficients. Exploring our data numerically helps us to identify patterns and associations in the data. When doing so, it is important to contextualise the descriptive statistics within the scope of the research question and associated scales.\nDescriptives\n\n Descriptives Tables\n\n\nThere are numerous packages available that allow us to pull out descriptive statistics from our dataset such as tidyverse and psych.\nWhen we pull out descriptive statistics, it is useful to present these in a well formatted table for your reader. There are lots of different ways of doing this, but one of the most common (and straightforward!) is to use the kable() function from the package kableExtra.\nThis allows us to give our table a clear caption (via caption = \"insert caption here\", align values within columns e.g., center aligned via align = \"??\"), and we can also round to however many decimal places we desire (standard for APA is 2 dp; via digits = ??).\nWe can also add in the function kable_styling(). This is really helpful for customsing your table e.g., the font size, position, and whether or not you want the table full width (as well as lots of other things - check out the helper function!).\nFor an overview of how to make tables in RMarkdown, see Lesson 4 of the RMD bootcamp.\n\n\n\n\n\n Descriptives Tables - Examples\n\n\n\n\nThe tidyverse way\nThe psych way\n\n\n\nWe can use the summarise() function to numerically summarise/describe our data. Some key values we may want to consider extracting are (though not limited to): the mean (via mean(), standard deviation (via sd()), minimum value (via min()), maximum value (via max()), standard error (via se()), and skewness (via skew()).\n\n\nNumeric values only example:\nCategorical and numeric values example:\n\n\n\n\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# taking the mean and standard deviation of sepal length via the summarize function\n# returning a table with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\niris |&gt;\n    summarize(\n        M_Length = mean(Sepal.Length),\n        SD_Length = sd(Sepal.Length)\n    ) |&gt;\n    kable(caption = \"Sepal Length Descriptives (in cm)\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length Descriptives (in cm)\n\nM_Length\nSD_Length\n\n\n5.84\n0.83\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# grouping by Species. NOTE: we can group by 2 variables - we would just separate by a comma within group_by( , )\n# taking the mean and standard deviation of sepal length via the summarize function\n# returning a table of sepal length grouped by species with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\n\niris |&gt;\n    group_by(Species) |&gt;\n    summarize(\n        M_Length = mean(Sepal.Length),\n        SD_Length = sd(Sepal.Length)\n    ) |&gt;\n    kable(caption = \"Sepal Length (in cm) Grouped by Species Descriptives Table\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length (in cm) Grouped by Species Descriptives Table\n\nSpecies\nM_Length\nSD_Length\n\n\n\nsetosa\n5.01\n0.35\n\n\nversicolor\n5.94\n0.52\n\n\nvirginica\n6.59\n0.64\n\n\n\n\n\n\n\n\n\n\nThe describe() function will produce a table of descriptive statistics. If you would like only a subset of this output (e.g., mean, sd), you can use select() after calling describe() e.g., describe() |&gt; select(mean, sd).\n\n\nNumeric values only example:\nCategorical and numeric values example:\n\n\n\n\nlibrary(psych)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# we want to get descriptive statistics of the iris dataset, specifically the sepal length column\n# we specifically want to select the mean and standard deviation from the descriptive statistics available (try this without including this argument to see what values you all get out)\n# returning a table with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\ndescribe(iris$Sepal.Length) |&gt;\n    select(mean, sd) |&gt;\n    kable(caption = \"Sepal Length Descriptives (in cm)\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length Descriptives (in cm)\n\n\nmean\nsd\n\n\nX1\n5.84\n0.83\n\n\n\n\n\n\nNote that this is quite an overly complex way to return these summary statistics - using the tidyverse() way is much more intuitive and straightforward!\n\nlibrary(psych)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# we want to get descriptive statistics of the iris dataset, specifically the sepal length column by Species\n# we want to return a matrix (hence mat = TRUE), then convert this to a dataframe\n# we specifically want to select the mean and standard deviation from the descriptive statistics available (try this without including this argument to see what values you all get out)\n# returning a table with a new column names of Group, Mean, SD; adding a caption; numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\n\n\ndescribeBy(Sepal.Length ~ Species, data = iris, mat = TRUE, digits = 2) |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column() |&gt; \n  select(group1, mean, sd) |&gt;\n    kable(col.names = c(\"Group\", \"Mean\", \"SD\"), caption = \"Sepal Length Descriptives (in cm)\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\nSepal Length Descriptives (in cm)\n\nGroup\nMean\nSD\n\n\n\nsetosa\n5.01\n0.35\n\n\nversicolor\n5.94\n0.52\n\n\nvirginica\n6.59\n0.64\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelation\n\n Correlation Coefficient\n\n\nThe correlation coefficient - \\(r_{(x,y)}=\\frac{\\mathrm{cov}(x,y)}{s_xs_y}\\) - is a standardised number which quantifies the strength and direction of the linear association between two variables. In a population it is denoted by \\(\\rho\\), and in a sample it is denoted by \\(r\\).\nValues of \\(r\\) fall between \\(-1\\) and \\(1\\). How to interpret:\nSize\nMore extreme values (i.e., the The closer \\(r\\) is to \\(+/- 1\\)) the stronger the linear association, and the closer to \\(0\\) a weak/no association. Commonly used cut-offs are:\n\nWeak = \\(.1 &lt; |r| &lt; .3\\)\n\nModerate = \\(.3 &lt; |r| &lt; .5\\)\n\nStrong = \\(|r| &gt; .5\\)\n\n\n\n\n\n\n\n\n\n\nDirection\nThe sign of \\(r\\) says nothing about the strength of the association, but its nature and direction:\n\nPositive association means that values of one variable tend to be higher when values of the other variable are higher\n\n\n\n\n\n\n\n\n\n\nNegative association means that values of one variable tend to be lower when values of the other variable are higher\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Correlation Matrix\n\n\nA correlation matrix is a table showing the correlation coefficients between variables. Each cell in the table shows the association between two variables. The diagonals show the correlation of a variable with itself (and are therefore always equal to 1).\n\nIn R\nWe can create a correlation matrix by giving the cor() function a dataframe. It is important to remember that all variables must be numeric. One way to check this is by using the str() argument.\n\nLet’s check the structure of the iris dataset to ensure that all variables are numeric:\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nWe can see that the variable Species in column 5 is a factor - this means that we cannot include this in our correlation matrix. Therefore, we need to subset, or, in other words, select specific columns. We can do this either giving the column numbers inside [], or using select(). In our case, we want the variables in columns 1 - 4, just not 5.\nIf you had NA values within your dataset, you could choose to remove these NAs using na.rm = TRUE inside the cor() function.\n\nIn R\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\nround(cor(iris[,c(1:4)]), digits = 2)\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n\n\n\n\n\n# select only the columns we want by variable name, and pass this to cor()\niris |&gt; \n  select(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) |&gt;\n  cor() |&gt;\n  round(digits = 2)\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n\n\n\n\n\n\n\n\n\n\n\n Correlation - Hypothesis Testing\n\n\nThe hypotheses of the correlation test are, as always, statements about the population parameter (in this case the correlation between the two variables in the population - i.e., \\(\\rho\\)).\nIf we are conducting a two tailed test, then…\n\n\n\\(H_0: \\rho = 0\\). There is no linear association between \\(x\\) and \\(y\\) in the population\n\n\n\\(H_1: \\rho \\neq 0\\) There is a linear association between \\(x\\) and \\(y\\)\n\n\nIf we instead conduct a one-tailed test, then we are testing either…\n\n\n\\(H_0: \\rho \\leq 0\\) There is a negative or no linear association between \\(x\\) and \\(y\\)\n\n\n\\(H_1: \\rho &gt; 0\\) There is a positive linear association between \\(x\\) and \\(y\\)\n\n\nOR\n\n\n\\(H_0: \\rho \\geq 0\\) There is a positive or no linear association between \\(x\\) and \\(y\\)\n\n\n\\(H_1: \\rho &lt; 0\\) There is a negative linear association between \\(x\\) and \\(y\\)\n\n\nTest Statistic\nThe test statistic for this test is the \\(t\\) statistic, the formula for which depends on both the observed correlation (\\(r\\)) and the sample size (\\(n\\)):\n\\[t = r \\sqrt{\\frac{n-2}{1-r^2}}\\]\np-value\nWe calculate the \\(p\\)-value for our \\(t\\)-statistic as the long-run probability of a \\(t\\)-statistic with \\(n-2\\) degrees of freedom being less than, greater than, or more extreme in either direction (depending on the direction of our alternative hypothesis) than our observed \\(t\\)-statistic.\nAssumptions\nFor a test of Pearson’s correlation coefficient \\(r\\), we need to make sure a few conditions are met:\n\nBoth variables are quantitative (i.e., continuous)\n\nBoth variables are drawn from normally distributed populations\n\nThe association between the two variables is linear\n\nNo extreme outliers in dataset\n\nHomoscedasticity (homogeneity of variance)\n\n\n\n\n\n\n Correlation - Hypothesis Testing in R\n\n\n\nIn R\nWe can test the significance of the correlation coefficient really easily with the function cor.test():\n\ncor.test(iris$Sepal.Length, iris$Petal.Length)\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\n\nNote, by default, cor.test() will include only observations that have no missing data on either variable.\nWe can specify whether we want to conduct a one- or two-tailed test by adding the argument alternative = and specifying alternative = \"less\", alternative = \"greater\", or alternative = \"two.sided\" (the latter being the default).\n\n\n\n\n\n\n\nExample Interpretation\nThere was a strong positive association between sepal length and petal length \\((r = .87, t(148) = 21.65, p &lt; .001)\\). These results suggested that a greater sepal length was positively associated with a greater petal length.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor a detailed recap of all things correlation (including further details and examples), revisit the Correlation lecture from DAPR1."
  },
  {
    "objectID": "1_b3_reading.html#visual-exploration",
    "href": "1_b3_reading.html#visual-exploration",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Visual Exploration",
    "text": "Visual Exploration\nVisual exploration of our data allows us to visualize the distributions of our data, and to identify potential associations among variables.\n\n How to Visualise Data\n\n\nTo visualise (i.e., plot) our data, we can use ggplot() from the tidyverse package. Note the key components of the ggplot() code:\n\n\ndata = where we provide the name of the dataframe\n\naes = where we provide the aesthetics. These are things which we map from the data to the graph. For instance, the \\(x\\)-axis, or if we wanted to colour the columns/bars according to some aspect of the data\n\n+ geom_... = where we add (using +) some geometry. These are the shapes (e.g., bars, points, etc.), which will be put in the correct place according to what we specified in aes()\n\n\nlabs() = where we provide labels for our plot (e.g., the \\(x\\)- and \\(y\\)-axis)\n\n\n\n\n\n\n\nNote\n\n\n\nThere are lots of arguments that you can further customise, some of which are specified in the examples below e.g., bins =, alpha =, fill =, linewidth =. linetype =, size = etc. For these, you can look up the helper function to see the range of arguments they can take using ? - e.g., ?fill.\nIf you’d like to read more about ggplot(), there is a handy cheatsheet.\n\n\nOne other thing to consider when visualising your data is how you are going to arrange your plots. Some handy tips on this:\n\nUse to wrap text in your titles and or axis labels\n\nThe patchwork package allows us to arrange multiple plots in two ways - | arranges the plots adjacent to one another, and / arranges the plots on top of one another\n\n\n\n\n\n\n Marginal Distributions - Examples\n\n\n\n\nHistogram\nDensity\nBoxplot\n\n\n\nA histogram shows the frequency of values which fall within bins of an equal width.\nBasic:\n\nx-axis: possible values of some variable, grouped into bins\ny-axis: frequency of a given value or values within bins\n\nWhat are bins?: A bin represents a range of scores\n\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram() +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nUpdating Bins:\nWithin geom_histogram(), we can specify bins = to specify the number of columns we want (for this example, lets say we want 10):\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(bins = 10) +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAlternatively, we can specify binwidth = to specify the width of each bin (it is very helpful to be aware of the scale of your variable here!):\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(binwidth = 0.1) +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nOutline Columns with Color:\nWithin geom_histogram(), we can specify color = to set a colored outline of the columns:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(color = \"darkred\") +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nFill Columns with Color:\nWithin geom_histogram(), we can specify fill = to fill the columns with a color:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(fill = \"darkred\") +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n“Density” is a bit similar to the notion of “relative frequency” (or “proportion”), in that for a density curve, the values on the y-axis are scaled so that the total area under the curve is equal to 1. In creating a curve for which the total area underneath is equal to one, we can use the area under the curve in a range of values to indicate the proportion of values in that range.\nBasic:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density() +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nFilled:\nWe can fill our plot with colour by specifying fill = within geom_density():\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density(fill = \"darkred\") +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nLine Type & Width:\nWe can change the type and width of the line by specifying linetype = and linewidth = within geom_density():\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density(linetype = 6, linewidth = 3) +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\nBoxplots provide a useful way of visualising the interquartile range (IQR). You can see what each part of the boxplot represents in Figure Figure 1.\n\n\n\n\nFigure 1: Anatomy of a Boxplot\n\n\n\nBasic:\nWe need to specify + geom_boxplot() to get a boxplot:\n\nggplot(data = iris, aes(x = Sepal.Length)) +\n  geom_boxplot() +\n    labs(x = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nRotate Boxplot:\nIf we had set aes(y = Sepal.Length) instead, then it would simply be rotated 90 degrees:\n\nggplot(data = iris, aes(y = Sepal.Length)) +\n  geom_boxplot() +\n    labs(y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Bivariate Associations - Examples\n\n\nUnlike in our marginal plots where we specified our x-axis variable within aes(), to visualise bivariate associations, we need to specify what variables we want on both our x- and y-axis.\n\n\nScatterplot\nScatterplot of Matrices (SPLOM)\nBoxplot\nViolin Plot\nFacets\n\n\n\nWe can use a scatterplot (since the variables are numeric and continuous) to visualise the association between the two numeric variables - these will be our x- and y-axis values.\nWe plot these values for each row of our dataset, and we should end up with a cloud of scattered points.\nHere we will want to comment on any key observations that we notice, including if we detect outliers or points that do not fit with the pattern in the rest of the data. Outliers are extreme observations that are not possible values of a variable or that do not seem to fit with the rest of the data. This could either be:\n\n\nmarginally along one axis: points that have an unusual (too high or too low) x-coordinate or y-coordinate\n\njointly: observations that do not fit with the rest of the point cloud\n\nBasic:\nWe need to specify + geom_point() to get a scatterplot:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nFill points with color:\nWithin geom_point(), we can specify color = to fill the points with a color:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point(color = \"darkred\") +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange size and opacity:\nWe can change the size (using size =) and the opacity (using alpha =) of our geom elements on the plot. Let’s include this below:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point(size = 3, alpha = 0.5) +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAdd a line of best fit:\nWe can superimpose (i.e., add) a line of best fit by including the argument + geom_smooth(). Since we want to fit a straight line, we want to use method = \"lm\". We can also specify whether we want to display confidence intervals around our line by specifying se = TRUE / FALSE.\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\nUsing pairs.panels() is likely the most useful way to visualise the associations among numeric variables. It returns a scatterplot of matrices (SPLOM) returning you (1) the marginal distribution of each variable via a histogram, (2) the correlation between variables, and (3) bivariate scatterplots.\n\niris |&gt;\n    select(Sepal.Length, Petal.Length, Petal.Width) |&gt;\n    pairs.panels(main = \"Iris SPLOM\")\n\n\n\nFigure 2: Iris SPLOM\n\n\n\n\n\nWe can use a boxplot to visualise the association between one numeric variable and one categorical variable - these will be our y- and x-axis values respectively. This can be helpful to visually compare the distribution of multiple groups.\nBasic:\nWe need to specify + geom_boxplot() to get a boxplot:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange boxplot fill colours by group:\nWithin aes(), we can specify fill = to fill the boxes with a color:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange boxplot line colours by group:\nWithin aes(), we can specify color = to colour the lines with a color:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAdding jitter:\nWe can add jittered points to a boxplot to better see the underlying distribution of the data (by adding a little random variation to each data point) via geom_jitter():\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n    geom_boxplot() +\n    geom_jitter() + \n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange legend position:\nWe can add the argument + theme(legend.position = ) to move (or even remove) the legend by specifying, for example, \"right\", \"left\", \"top\", \"bottom\", or \"none\" to remove.\n\n# legend at bottom of plot\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\") + \n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nLike a boxplot, we can use a violin plot to visualise the association between one numeric variable and one categorical variable - these will be our y- and x-axis values respectively. It combines a summary of the data’s range and a kernel density estimation, providing a detailed view of the distribution.\nBasic:\nWe need to specify + geom_violin() to get a violin plot:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length)) +\n    geom_violin() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange violin colours by group:\nWithin aes(), we can specify fill = to fill the violins with a color:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_violin() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange Size and opacity:\nWe can change the size (using size =) and the opacity (using alpha =) of our geom elements on the plot. Let’s include this below:\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_violin(size = 1, alpha = 0.5) +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAdding jitter:\nWe can add jittered points to a violin plot to better see the underlying distribution of the data (by adding a little random variation to each data point) via geom_jitter():\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_violin() + \n    geom_jitter(alpha = 0.5) + \n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nChange legend position:\nWe can add the argument + theme(legend.position = ) to move (or even remove) the legend by specifying, for example, \"right\", \"left\", \"top\", \"bottom\", or \"none\" to remove.\n\n# no legend\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_violin() + \n    geom_jitter(alpha = 0.5) + \n    theme(legend.position = 'none') +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\nWhen we have two numeric variables, as well as categorical variables, we can use facet_wrap() / facet_grid() to help divide/arrange our plots. If we had two categorical variables, by simply stringing them together to further group our plots by specifying facet_wrap( ~ cat_variable1 + cat_variable2)\nBasic:\nWe need to specify + geom_point() to get a scatterplot, and either + facet_wrap() or + facet_grid() to separate by your categorical variable:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    facet_wrap(~Species) + \n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nAdd a line of best fit:\nWe can superimpose (i.e., add) a line of best fit by including the argument + geom_smooth(). Since we want to fit a straight line, we want to use method = \"lm\". We can also specify whether we want to display confidence intervals around our line by specifying se = TRUE / FALSE. Note that a line is fitted for every level of your categorical variable:\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE) +\n        facet_wrap(~Species) + \n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\nSubplot layout:\nYou can change the overall layout of the subplots by specifying dir = within the facet_wrap() argument, where “h” will return a horizontal layout (this is the default) and “v” for vertical.\nYou can also change the layout of the subplot labels by specifying strip.position = within the facet_wrap() argument, where labels can be arranged to display at the “top” (this is the default), “bottom”, “left” or “right”.\n\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    facet_wrap(~Species, dir = \"v\", strip.position = \"right\") + \n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Multivariate Associations - Examples\n\n\nTo visualise multivariate associations, just like we do for bivariate associations, we need to specify what variables we want on both our x- and y-axis. We also need to take an extra step by specifying a third variable - z - that acts as a differentiating factor across our data. This ‘z’ can be mapped to an aesthetic attribute such as color, shape, or size, allowing us to explore more dynamic patterns and ssociations in our data.\nIf you really wanted to, you could create a plot showing the associations among three variables at once. These are likely more useful when you have an interaction model. However, we wouldn’t really recommend doing this - they can be very difficult to interpret correctly, and given their interactive nature, definitely NOT something that you’d want to include in a stats report. But, for demonstration purposes only, we could create one using the plotly package.\n3D Scatterplot\n\nlibrary(plotly)\n\nplot_ly(data = iris, \n        x = ~Petal.Length, y = ~Sepal.Length, z = ~Petal.Width, \n        type = 'scatter3d', \n        mode = 'markers+lines',\n        scene = list(\n            xaxis = list(title = \"Petal Length\"),\n            yaxis = list(title = \"Sepal Length\"),\n            zaxis = list(title = \"Petal Width\")\n            )\n        )\n\n\n\n\n\nHeatmap of Correlations\n\nplot_ly(z = ~cor(iris[, c(1, 3:4)]), type = \"heatmap\")"
  },
  {
    "objectID": "1_b3_reading.html#deterministic-models",
    "href": "1_b3_reading.html#deterministic-models",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Deterministic Models",
    "text": "Deterministic Models\n\n Description & Specification\n\n\nWe come across functions a lot in daily life, and probably don’t think much about it. In a slightly more mathematical setting, we can write down in words and in symbols the function describing the association between the side of a square and its perimeter (e.g., to capture how the perimeter varies as a function of its side). In this case, the perimeter is the dependent variable, and the side is the independent variable.\nThis is what we would refer to as a deterministic model, as it is a model of an exact relationship - there can be no deviation.\nModel Specification\n\n\nIn words\nIn symbols\n\n\n\nThe perimeter of a square is four times the length of its side.\n\n\nThe relationship between side and perimeter of squares is given by:\n\\[\n\\text{Perimeter} = 4 \\cdot \\text{Side}\n\\]\nIf you denote \\(y\\) as the dependent variable Perimeter, and \\(x\\) as the independent variable Side we can rewrite as:\n\\[\ny = 4 \\cdot x\n\\]\n\n\n\n\n\n\n\n\n Visualisation\n\n\nLet’s create a dataset called squares, containing the perimeter of four squares having sides of length \\(0, 2, 5, 9\\) metres, and then plot the squares data as points on a scatterplot.\nFirst, let’s make our squares data. Here we will use two important functions - tibble() and c(). The tibble() function allows us to construct a data frame. To store a sequence of numbers into R, we can combine the values using c(). A sequence of elements all of the same type is called a vector.\n\n#create data frame named squares\nsquares &lt;- tibble(\n  side = c(0, 2, 5, 9), \n  perimeter = 4 * side\n)\n\n#check that our values are contained within squares\nsquares\n\n# A tibble: 4 × 2\n   side perimeter\n  &lt;dbl&gt;     &lt;dbl&gt;\n1     0         0\n2     2         8\n3     5        20\n4     9        36\n\n\nNow we know how ggplot() works, we can start to build our plot. First we specify our data (we want to use the squares data frame), and then our aesthetics. Since the perimeter varies as a function of side, we want side on the \\(x\\)-axis, and perimeter on the \\(y\\)-axis. We want to create a scatterplot, so we need to specify our geom_... argument as geom_point(). Lastly, we will provide clearer axis labels, and include the units of measurement.\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +  \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4*Side')  \n\n\n\nFigure 3: Perimeter = 4*Side\n\n\n\nWe could also visualise the functional relationship by connecting the individual points with a line. To do so, we need to add a new argument - geom_line(). If you would like to change the colour of the line from the default, you can specify geom_line(colour = \"insert colour name\").\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +\n  geom_line(colour = \"darkred\") + \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4*Side')  \n\n\n\nFigure 4: Perimeter = 4*Side\n\n\n\n\n\n\n\n\n Predicted Values\n\n\nSometimes we can directly read a predicted value from the graph of the functional relationship.\nConsider the plot created above. For example, first we need to check where \\(x\\) = 2.5. Then, we draw a vertical dashed line until it meets the blue line. The \\(y\\) value corresponding to \\(x\\) = 2.5 can be read off the \\(y\\)-axis. In our case, we would say a side of 2.5m corresponds to a perimeter of 10m.\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +\n  geom_line(colour = \"blue\") + \n  geom_vline(xintercept = 2.5, colour = \"darkred\", lty = \"dashed\", lwd = 1) + \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4 * Side')  \n\n\n\nFigure 5: Perimeter = 4*Side\n\n\n\nHowever, in this case it is not that easy to read it from Figure 5 (especially without the superimposed dashed red line)… This leads us to the algebraic approach:\nWe can substitute the \\(x\\) value in the formula and calculate the corresponding \\(y\\) value where we would conclude that the predicted perimeter of squared paintings having a 2.5m side is 10m:\n\\[\ny = 4 \\cdot x  \\\\    \n\\]\n\\[\ny = 4 \\cdot 2.5 \\\\  \n\\]\n\\[\ny = 10  \\\\\n\\]"
  },
  {
    "objectID": "1_b3_reading.html#numeric-outcomes-numeric-predictors",
    "href": "1_b3_reading.html#numeric-outcomes-numeric-predictors",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Numeric Outcomes & Numeric Predictors",
    "text": "Numeric Outcomes & Numeric Predictors\nSimple Linear Regression Models\n\n Description & Model Specification\n\n\nThe association between two variables (e.g., recall accuracy and age) will show deviations from the ‘average pattern’. Hence, we need to create a model that allows for deviations from the linear relationship - we need a statistical model.\nA statistical model includes both a deterministic function and a random error term. We typically refer to the outcome (‘dependent’) variable with the letter \\(y\\) and to our predictor (‘explanatory’/‘independent’) variables with the letter \\(x\\). A simple (i.e., one x variable only) linear regression model thus takes the following form (where the terms \\(\\beta_0\\) and \\(\\beta_1\\) are numbers specifying where the line going through the data meets the y-axis (i.e., the intercept - where \\(x\\) = 0; \\(\\beta_0\\)) and its slope (direction and gradient of line; \\(\\beta_1\\)):\nModel Specification\n\\[\ny_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i    \n\\]\nModel Specification: Annotated\n\\[\ny_i = \\underbrace{\\beta_0 + \\beta_1 \\cdot x_i}_{\\text{function of }x} + \\underbrace{\\epsilon_i}_{\\text{random error}}  \n\\\\\n\\]\n\\[\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\nModel Specification: Explained\nLet’s break down what \\(y_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\\) actually means by considering the statement in smaller parts:\n\n\n\\(y_i = \\beta_0 + \\beta_1 \\cdot x_i\\)\n\n\n\\(y_i\\) is our measured outcome variable (our DV)\n\n\n\\(x_i\\) is our measured predictor variable (our IV)\n\n\n\\(\\beta_0\\) is the model intercept\n\n\n\\(\\beta_1\\) is the model slope\n\n\n\n\\(\\epsilon \\sim N(0, \\sigma) \\text{ independently}\\)\n\n\n\\(\\epsilon\\) is the residual error\n\n\n\\(\\sim\\) means ‘distributed according to’\n\n\n\\(N(0, \\sigma) \\text{ independently}\\) means ‘normal distribution with a mean of 0 and a variance of \\(\\sigma\\)’\n\nTogether, we can say that the errors around the line have a mean of zero and constant spread as x varies\n\n\n\n\nIn R\nThere are basically two pieces of information that we need to pass to the lm() function:\n\nThe formula: The regression formula should be specified in the form y ~ x where \\(y\\) is the dependent variable (DV) and \\(x\\) the independent variable (IV).\nThe data: Specify which dataframe contains the variables specified in the formula.\n\nIn R, the syntax of the lm() function can be specified as follows (where DV = dependent variable, IV = independent variable, and data_name = the name of your dataset):\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ IV, data = data_name) \n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ data_name$IV)\n\n\n\n\nyou can also specify as:\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ 1 + IV, data = data_name) \n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ 1 + data_name$IV)\n\n\n\n\n\n\n\n\n\n\nWhy is there a 1 in the two bottom options?\n\n\n\n\n\nWhen we specify the linear model in R, we include after the tilde sign (\\(\\sim\\)), the variables that appear to the right of the \\(\\hat \\beta\\)s. The intercept, or \\(\\beta_0\\), is a constant. That is, we could write it as multiplied by 1.\nIncluding the 1 explicitly is not necessary because it is included by default (you can check this by comparing the outputs of A & B above with and without the 1 included - the estimates are the same!). After a while, you will find you just want to drop the 1 when calling lm() because you know that it’s going to be there, but in these early weeks we tried to keep it explicit to make it clear that you want the intercept to be estimated.\n\n\n\n\n\n\n\nExample\n\nResearch Question\nIs there an association between recall accuracy and age?\n\n\n Overview\n\n\nImagine that you were tasked to investigate whether there was an association between recall accuracy and age. You have been provided with data from twenty participants who studied passages of text (c500 words long), and were tested a week later. The testing phase presented participants with 100 statements about the text. They had to answer whether each statement was true or false, as well as rate their confidence in each answer (on a sliding scale from 0 to 100). The dataset contains, for each participant, the percentage of items correctly answered, their age (in years), and their average confidence rating.\nThe data are available at https://uoepsy.github.io/data/recalldata.csv\n\n\n\n\n\n Visualise Data\n\n\nThere are lots of different ways in which we can visualise our data (as per the Visual Exploration flashcards).\nFor the marginal distributions we will use density and boxplots, and for the bivariate associations a scatterplot.\n\n#save plots to individual objects in order to arrange \n\nplt1 &lt;- ggplot(data = recalldata, aes(x = recall_accuracy)) + \n    geom_density() +\n    xlim(0, 100) + #specify x-axis to range from 0-100\n    geom_boxplot(width = 1/100) + \n    labs(x = \"Recall Accuracy (%)\", title = \"Distribtion of \\nRecall Accuracy\")\n\nplt2 &lt;- ggplot(data = recalldata, aes(x = age)) + \n    geom_density() +\n    xlim(0, 100) + #specify x-axis to range from 0-100\n    geom_boxplot(width = 1/100) + \n    labs(x = \"Age (in years)\", title = \"Distribtion of \\nAge\")\n\nplt3 &lt;- ggplot(data = recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point() + \n    labs(x = \"Age (in years)\", y = \"Recall Accuracy (%)\", title = \"Association between Recall Accuracy and Age\")\n\n\n#load patchwork package to arrange plots\nlibrary(patchwork)\n\n#arrange plots where there are two plots in to panel (plt1 + plt2), one on bottom (plt3)\n(plt1 + plt2) / plt3\n\n\n\n\n\n\n\n\nThe marginal distribution of recall accuracy was unimodal with a negative skew with a mean of approximately 69.25. There was high variation in recall accuracy (SD = 14.53)\n\nThe marginal distribution of age was unimodal with a mean of approximately 48.8, where age ranged from 22 to 86\n\nThere appeared to be a weak negative association between recall accuracy and age, where older age was associated with lower recall accuracy\n\n\n\n\n\n\n Model & Hypothesis Specification\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\n\\[\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Age}_i + \\epsilon_i    \n\\]\n\n\n\\(H_0: \\beta_1 = 0\\)\nThere is no association between recall accuracy and age.\n\\(H_1: \\beta_1 \\neq 0\\)\nThere is an association between recall accuracy and age.\n\n\n\n\n\n\n\n\n Model Building\n\n\nTo fit the model in R we use the lm() function. The simple linear model is assigned/stored in an object called recall_simp:\n\nrecall_simp &lt;- lm(recall_accuracy ~ age, data = recalldata)\n\n\nrecall_simp\n\n\nCall:\nlm(formula = recall_accuracy ~ age, data = recalldata)\n\nCoefficients:\n(Intercept)          age  \n    84.0153      -0.3026  \n\n\nWhen we call the name of the fitted model, recall_simp, you can see the estimated regression coefficients \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\). The line of best-fit is thus given by:1\n\\[\n\\widehat{\\text{Recall Accuracy}} = 84.02 - 0.31 \\cdot \\text{Age}\n\\]\n\nAlternatively to get these same estimates, we could have used the summary() function:\n\nsummary(recall_simp)\n\n\nCall:\nlm(formula = recall_accuracy ~ age, data = recalldata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.164  -7.761  -2.656   9.593  26.180 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  84.0153    11.4453   7.341 8.16e-07 ***\nage          -0.3026     0.2253  -1.343    0.196    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.23 on 18 degrees of freedom\nMultiple R-squared:  0.09108,   Adjusted R-squared:  0.04058 \nF-statistic: 1.804 on 1 and 18 DF,  p-value: 0.196\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\n(Intercept)\nage\n\n\n\n\\(\\beta_0\\) = (Intercept) = 84.02\n\nThe intercept, or predicted recall accuracy when age was 0.\n\nAn individual aged 0 years was expected to have a recall accuracy of \\(84.02\\).\n\n\n\nNote: the intercept isn’t very useful here at all. It estimates the accuracy for a newborn (who wouldn’t be able to complete the task!).\n\n\n\\(\\beta_1\\) = age = -0.3\n\nThe estimated difference in recall accuracy for each additional year in age.\n\nEvery 1 additional year in age was associated with a non-significant \\(-0.3\\) percentage point decrease in recall accuracy \\((p = .196)\\). This suggested that age was not significantly associated with recall accuracy.\n\n\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\n\nggplot(recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point(size = 3, alpha = 0.5) +\n    geom_smooth(method = lm, se = FALSE) + \n    ylim(0,100) +\n    labs(x = \"Age (in years)\", y = \"Recall Accuracy (%)\", title = \"Association between Recall Accuracy and Age\")\n\n\n\nFigure 6: Association between Recall Accuracy and Age\n\n\n\nThe line that best fits the association between recall accuracy and age (see Figure 6) is only able to predict the average accuracy for a given value of age.\nThis is because there will be a distribution of recall accuracy at each value of age. The line will fit the trend/pattern in the values, but there will be individual-to-individual variability that we must accept around that average pattern.\n\n\n\nMultiple Linear Regression Models\n\n Description & Model Specification\n\n\nMultiple linear regression involves looking at one continuous outcome (i.e., DV), with two or more independent variables (i.e., IVs).\nA multiple linear regression model takes the following form:\n\\[\ny_i = \\beta_0 + \\beta_1 \\cdot x_{1_i} + \\beta_2 \\cdot x_{2_i} + .... + \\beta_j \\cdot x_{j_i} + \\epsilon_i\n\\]\n\\[\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\n\nIn R:\nMultiple and simple linear regression follow the same structure within the lm() function - the logic scales up to however many predictor variables we want to include in our model. You simply add (using the + sign) more independent variables. For example, if we wanted to build a multiple linear regression that included three independent variables, we could fit one of the following via the lm() function:\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ IV1 + IV2 + IV3, data = data_name)\n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ data_name$IV1 + data_name$IV2 + data_name$IV3)\n\n\n\n\n\n\n\n\n\n\n Interpretation of Coefficients\n\n\nYou’ll hear a lot of different ways that people explain multiple regression coefficients.\nFor the model \\(y = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon\\), the estimate \\(\\hat \\beta_1\\) will often be reported as:\n“the increase in \\(y\\) for a one unit increase in \\(x_1\\) when…”\n\n“holding the effect of \\(x_2\\) constant.”\n“controlling for differences in \\(x_2\\).”\n“partialling out the effects of \\(x_2\\).”\n“holding \\(x_2\\) equal.”\n“accounting for effects of \\(x_2\\).”\n\nFor models with 3+ predictors, just like building the model in R, the logic of the above simply extends.\nFor example “the increase in [outcome] for a one unit increase in [predictor] when…”\n\n“holding [other predictors] constant.”\n\n“accounting for [other predictors].”\n\n“controlling for differences in [other predictors].”\n\n“partialling out the effects of [other predictors].”\n\n“holding [other predictors] equal.”\n\n“accounting for effects of [other predictors].”\n\n\n\n\nExample\n\nResearch Question\nIs recall accuracy associated with recall confidence and age?\n\n\n Overview\n\n\nImagine that you were tasked to investigate whether recall accuracy was associated with recall confidence and age. You have been provided with data from twenty participants who studied passages of text (c500 words long), and were tested a week later. The testing phase presented participants with 100 statements about the text. They had to answer whether each statement was true or false, as well as rate their confidence in each answer (on a sliding scale from 0 to 100). The dataset contains, for each participant, the percentage of items correctly answered, their age (in years), and their average confidence rating.\nThe data are available at https://uoepsy.github.io/data/recalldata.csv\n\n\n\n\n\n Visualise Data\n\n\n\nrecalldata |&gt;\n    select(recall_accuracy, recall_confidence, age) |&gt;\n    pairs.panels(main = \"Recall SPLOM\")\n\n\n\nFigure 7: Recall SPLOM\n\n\n\n\n\n\n\n\n Model & Hypothesis Specification\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\n\\[\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Recall Confidence}_i + \\beta_2 \\cdot \\text{Age}_i + \\epsilon_i \\\\\n\\]\n\n\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere is no association between recall accuracy and recall confidence and/or age.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere is an association between recall accuracy and recall confidence and/or age.\n\n\n\n\n\n\n\n\n Model Building\n\n\n\nrecall_multi &lt;- lm(recall_accuracy ~ recall_confidence + age, data = recalldata)\n\n\nsummary(recall_multi)\n\n\nCall:\nlm(formula = recall_accuracy ~ recall_confidence + age, data = recalldata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.1935  -5.1751  -0.5528   2.5934  18.6814 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        36.1596    12.8413   2.816 0.011900 *  \nrecall_confidence   0.8957     0.1912   4.685 0.000213 ***\nage                -0.3392     0.1534  -2.212 0.040985 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.674 on 17 degrees of freedom\nMultiple R-squared:  0.6033,    Adjusted R-squared:  0.5566 \nF-statistic: 12.92 on 2 and 17 DF,  p-value: 0.0003867\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\n(Intercept)\nrecall_confidence\nage\n\n\n\n\\(\\beta_0\\) = (Intercept) = 36.16\n\nThe intercept, or predicted recall accuracy when recall confidence was 0 and age was 0.\n\nAn individual aged 0 years with no recall confidence was expected to have a recall accuracy of \\(36.16\\).\n\n\n\nNote: the intercept isn’t very useful here at all. It estimates the accuracy for a newborn (who wouldn’t be able to complete the task!).\n\n\n\\(\\beta_1\\) = recall_confidence = 0.9\n\nThe estimated difference in recall accuracy for each additional unit increase in confidence controlling for age.\n\nHolding age constant, each 1 additional unit in recall confidence was associated with a significant \\(0.9\\) percentage point increase in recall accuracy \\((p &lt; .001)\\).\n\n\n\n\n\n\\(\\beta_2\\) = age = -0.34\n\nThe estimated difference in recall accuracy for each additional year in age controlling for recall confidence.\n\nHolding recall confidence constant, every 1 additional year in age was associated with a significant \\(-0.34\\) percentage point decrease in recall accuracy \\((p = .041)\\).\n\n\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\nWhen we have 2+ predictors, we can’t just plot our data an add geom_smooth(method=lm), because that would give a visualisation of a linear model with just one predictor (whichever one is on the \\(x\\)-axis).\nInstead, we can use the function plot_model() from sjPlot.\n\nplot_model(recall_multi,\n           type = \"eff\",\n           terms = \"recall_confidence\",\n           show.data = TRUE)\n\nplot_model(recall_multi,\n           type = \"eff\",\n           terms = \"age\",\n           show.data = TRUE)\n\n\n\nFigure 8: Association between Recall Accuracy, Recall Confidence, and Age\n\n\n\n\n\nFigure 9: Association between Recall Accuracy, Recall Confidence, and Age"
  },
  {
    "objectID": "1_b3_reading.html#numeric-outcomes-categorical-predictors",
    "href": "1_b3_reading.html#numeric-outcomes-categorical-predictors",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Numeric Outcomes & Categorical Predictors",
    "text": "Numeric Outcomes & Categorical Predictors\n\n Description & Model Specification\n\n\nIn both simple and multiple linear regression models, we examine the association between one continuous dependent variable (DV) using 1 (in the case of simple) or 2+ (in the case of multiple) predictor variables, which could include categorical predictors. When incorporating categorical variables, we use techniques such as dummy/treatment or effects/sum-to-zero coding to convert and represent these categorical predictors in a numerical format which is suitable for regression analysis.\nThe interpretation of the coefficients is very specific. Whereas we talked about coefficients being interpreted as “the change in \\(y\\) associated with a 1-unit increase in \\(x\\)”, for categorical explanatory variables, coefficients can be considered to examine differences in group means.\n\nIn R:\nMultiple and simple linear regression models with categorical predictors follow the same structure within the lm() function. You simply add (using the + sign) more independent variables. For example, if we wanted to build a linear regression model that included one independent categorical variable which had three levels, we could fit one of the following via the lm() function:\n\n\nOption A\nOption B\n\n\n\n\nmodel_name &lt;- lm(DV ~ IV1, data = data_name)\n\n\n\n\nmodel_name &lt;- lm(data_name$DV ~ data_name$IV1)\n\n\n\n\n\n\n\n\n\n\n Binary Predictors\n\n\nBinary variables have two categories (more commonly referred to as levels), and these levels (e.g., Yes/No, Dog/Cat, Right/Left, Smoker/Non-Smoker) are simply entered in the model as a series of 0s and 1s. Numeric variables that represent categorical data are typically referred to as dummy variables.\nOur coefficients are just the same as before. The intercept is where our predictor equals zero, and the slope is the change in our outcome variable associated with a 1-unit change in our predictor.\nHowever, “zero” for this predictor variable now corresponds to a whole level. This is known as the “reference level”. Accordingly, the 1-unit change in our predictor (the move from “zero” to “one”) corresponds to the difference between the two levels.\nWhen used as predictors in multiple regression models, binary variables behave much the same way. The coefficient will give us the estimated change in \\(y\\) when moving from one level to the other, whilst holding other predictors constant (for more info, see the Multiple Linear Regression Models - Interpretation of Coefficients flashcard).\n\n\n\n\n\n Dummy vs Effects Coding\n\n\nPossible side-constraints on the parameters are:\n\n\n\n\n\n\n\n\nName\nConstraint\nMeaning of \\(\\beta_0\\)\n\nIn R\n\n\n\nSum to zero (Effects Coding)\n\\(\\beta_1 + \\beta_2 + \\beta_3 = 0\\)\n\\(\\beta_0 = \\mu\\)\ncontr.sum\n\n\nReference group (Dummy Coding)\n\\(\\beta_1 = 0\\)\n\\(\\beta_0 = \\mu_1\\)\ncontr.treatment\n\n\n\nDummy Coding\nBy default R uses the reference group constraint - i.e., dummy coding (sometimes called treatment contrast coding). If your factor has \\(g\\) levels, your regression model will have \\(g-1\\) dummy variables (R creates them for you, as we’ve seen in the examples above).\nOne level of the categorical variable is considered as the ‘baseline’, ‘reference level’, or ‘reference group’ - R automatically takes the first level alphabetically as the baseline (e.g., if you had a ‘pet’ variable with levels dog, hamster, and cat, then cat would be taken as the reference level).\nWhen we use this approach, the intercept is the estimated \\(y\\) when all predictors (i.e., \\(x\\)’s) are zero. Because the reference level is kind of like “0” in our contrast matrix, this is part of the intercept estimate. We get out a coefficient for each subsequent level, which are the estimated differences from each level to the reference group.\nEffects Coding\nEffects coding (sometimes called sum-to-zero coding) is the next most commonly used in psychological research. These are a way of comparing each level to the overall (or grand) mean. This involves a bit of trickery that uses -1s and 1s rather than 0s and 1s, in order to make “0” be mid-way between all the levels - the average of the levels.\nR automatically takes the last level alphabetically as level which is dropped (e.g., if you had a ‘pet’ variable with levels dog, hamster, and cat, then hamster would not be represented).\nWhen we use this approach, the intercept is the estimated average \\(y\\) when averaged across all levels of the predictor variable. In other words, it is the estimated grand mean of \\(y\\). The coefficients represent the estimated difference for that level from the overall grand mean.\n\nIn R\nIf we want to use effects coding, we can apply:\n\ncontrasts(iris$Species) &lt;- \"contr.sum\"\n\nWe can switch back to the default reference group constraint by applying either of these:\n\n# Option 1\ncontrasts(iris$Species) &lt;- NULL\n\n# Option 2\ncontrasts(iris$Species) &lt;- \"contr.treatment\"\n\n\n\n\n\n\n\n Coding Variables as Factors\n\n\nWhen we have categorical predictors, it is important that we tell R specifically to code them appropriately as factors.\n\nIn R\nWe can use various functions to convert between different types of data, such as:\n\n\nfactor() / as_factor() - to turn a variable into a factor\n\n\nas.numeric() - to turn a variable into numbers\n\n\nAs a first step, it is a good idea to look at the structure of the dataset you are working with. For the purpose of this example, our dataset is called “tips” (you might recall this from DAPR1):\n\nstr(tips)\n\nspc_tbl_ [157 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Bill  : num [1:157] 23.7 36.1 32 17.4 15.4 ...\n $ Tip   : num [1:157] 10 7 5.01 3.61 3 2.5 3.44 2.42 3 2 ...\n $ Credit: chr [1:157] \"n\" \"n\" \"y\" \"y\" ...\n $ Guests: num [1:157] 2 3 2 2 2 2 2 2 2 2 ...\n $ Day   : chr [1:157] \"f\" \"f\" \"f\" \"f\" ...\n $ Server: chr [1:157] \"A\" \"B\" \"A\" \"B\" ...\n $ PctTip: num [1:157] 42.2 19.4 15.7 20.8 19.5 13.4 16 12.4 12.7 10.7 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Bill = col_double(),\n  ..   Tip = col_double(),\n  ..   Credit = col_character(),\n  ..   Guests = col_double(),\n  ..   Day = col_character(),\n  ..   Server = col_character(),\n  ..   PctTip = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nFrom the output, we can see that Credit (whether guests paid with a credit card; n/y responses) was coded as a &lt;chr&gt; or character variable. If we wanted to set this as a factor so that R recognises it as a categorical variable, we can use on of the following:\n\n\nas_factor()\nfactor()\n\n\n\n\ntips &lt;- tips |&gt; \n  mutate(Credit = as_factor(Credit))\n\n\n\nWe could also use the factor() function, and at the same time label factors appropriately to aid reader interpretation (it may not be immediately clear to some that n represents ‘No’ and y represents ‘Yes’). To do so, we list the all levels of Credit, and provide a new label corresponding to each level:\n\ntips$Credit &lt;- factor(tips$Credit, \n                      levels = c(\"n\", \"y\"),\n                      labels = c(\"No\", \"Yes\"))\n\n\n\n\nUsing either of the above approaches, if we now run str(tips) again, you should see that Credit is now coded as a factor with 2 levels:\n\nstr(tips)\n\ntibble [157 × 7] (S3: tbl_df/tbl/data.frame)\n $ Bill  : num [1:157] 23.7 36.1 32 17.4 15.4 ...\n $ Tip   : num [1:157] 10 7 5.01 3.61 3 2.5 3.44 2.42 3 2 ...\n $ Credit: Factor w/ 2 levels \"n\",\"y\": 1 1 2 2 1 1 1 1 1 1 ...\n $ Guests: num [1:157] 2 3 2 2 2 2 2 2 2 2 ...\n $ Day   : chr [1:157] \"f\" \"f\" \"f\" \"f\" ...\n $ Server: chr [1:157] \"A\" \"B\" \"A\" \"B\" ...\n $ PctTip: num [1:157] 42.2 19.4 15.7 20.8 19.5 13.4 16 12.4 12.7 10.7 ...\n\n\n\n\n\n\n\n Specifying Reference Levels\n\n\nWhen you have a categorical variable coded as a factor, R will default to using alphabetical ordering. We could override this by making it a factor with an ordering to it’s levels (see the use of factor() and levels()). Functions like fct_relevel() might be handy too.\n\n\n\nExample\n\nResearch Question\nDoes sepal length differ by species?\n\n\n Overview\n\n\nImagine that you were tasked to investigate whether sepal length differs by species. You have been provided with the in-built dataset, iris, which contains information concerning the sepal length (in cm), sepal width (in cm), petal length (in cm), and petal width (in cm) from three different species of iris (setosa, versicolor, and virginica). There are measurements for 50 flowers from each of the iris species (i.e., total \\(n\\) = 150).\n\n\n\n\n\n Visualise Data\n\n\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\n Model & Hypothesis Specification\n\n\n\n\nDummy Coding\nEffects Coding\n\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\nWe first need to define the dummy variables for Species:\n\\[\n\\text{Species}_\\text{Versicolor} = \\begin{cases}  \n1 & \\text{if Species is Versicolor} \\\\  \n0 & \\text{otherwise}  \n\\end{cases}  \n\\quad    \n\\]\n\\[\n\\text{Species}_\\text{Virginica} = \\begin{cases}  \n1 & \\text{if Species is Virginica} \\\\  \n0 & \\text{otherwise}  \n\\\\  \n\\end{cases}  \n\\quad  \n\\]\n\\[\n(\\text{Species}_\\text{Setosa } \\text{ is the reference level})  \n\\]\nBased on the above dummy coding, we are going to fit the following regression model:\n\\[\n\\begin{align}\n\\text{Sepal Length} = \\beta_0 + \\beta_1 \\cdot \\text{Species}_\\text{Versicolor} + \\beta_2 \\cdot \\text{Species}_\\text{Virginica} + \\epsilon\n\\end{align}\n\\]\n\n\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere are no differences in sepal length based on iris species.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere are differences in sepal length based on iris species.\n\n\n\n\n\n\n\nModel Specification\nHypothesis Specification\n\n\n\nWe first need to define the effects coding for Species:\n\\[\n\\begin{matrix}\n\\textbf{Level}           & \\textbf{Species Level 1} & \\textbf{Species Level 2} \\\\\n\\hline\n\\text{Setosa}              & 1   & 0    \\\\\n\\text{Versicolor}               & 0   & 1    \\\\\n\\text{Virginica}         & -1  & -1 \\\\\n\\end{matrix}\n\\]\nBased on the above effects coding, we are going to fit the following regression model:\n\\[\n\\begin{align}\n\\text{Sepal Length} = \\beta_0 + \\beta_1 \\cdot \\text{Species Level 1} + \\beta_2 \\cdot \\text{Species Level 2} + \\epsilon\n\\end{align}\n\\]\n\n\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere are no differences in average sepal length based on iris species (i.e., the average sepal length across species is equal to the grand mean).\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere are differences in average sepal length based on iris species (i.e., the average sepal length across species is not equal to the grand mean).\n\n\n\n\n\n\n\n\n\n\n\n Model Building\n\n\n\n\nDummy Coding\nEffects Coding\n\n\n\nFirst we need to check the levels of the Species variable:\n\n#check what levels we have\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nFrom the above, we can see that Species has 3 levels - “setosa”, “versicolor”, and “virginica”.\nIf we put these into a model, assuming R’s default ordering, we know that R will automatically apply dummy (or treatment coding, i.e., contrasts(iris$Species) &lt;- \"contr.treatment\"), and “setosa” will be taken as our reference group:\n\n#fit model\nspec_model &lt;- lm(Sepal.Length ~ Species, data = iris)\nsummary(spec_model)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.0060     0.0728  68.762  &lt; 2e-16 ***\nSpeciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\nSpeciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nFirst we need to tell R to apply effects (or sum-to-zero) coding and check the ordering of the levels:\n\ncontrasts(iris$Species) &lt;- \"contr.sum\"\ncontrasts(iris$Species) \n\n           [,1] [,2]\nsetosa        1    0\nversicolor    0    1\nvirginica    -1   -1\n\n\nThen we can run our model:\n\n#fit model\nspec_model2 &lt;- lm(Sepal.Length ~ Species, data = iris)\nsummary(spec_model2)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.84333    0.04203 139.020   &lt;2e-16 ***\nSpecies1    -0.83733    0.05944 -14.086   &lt;2e-16 ***\nSpecies2     0.09267    0.05944   1.559    0.121    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\nDummy Coding\nEffects Coding\n\n\n\n\n\n\n\n\n\n\nCoefficient\nEstimate\nCorresponds to\n\n\n\n(Intercept)\n5.0060\n\\(\\beta_0 = \\hat \\mu_1\\)\n\n\nSpeciesversicolor\n0.9300\n\\(\\beta_0 + \\beta_1 = \\hat \\mu_2\\)\n\n\nSpeciesvirginica\n1.5820\n\\(\\beta_0 + \\beta_2 = \\hat \\mu_3\\)\n\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\hat \\beta_0 = \\hat \\mu_1 = 5.01\\). The estimated average sepal length for the species setosa was approximately \\(5.01~cm\\).\nThe second estimate corresponds to Speciesversicolor and was \\(\\hat \\beta_1 = 0.93\\). The difference in mean sepal length between setosa and versicolor species was estimated to be \\(0.93~cm\\). Thus, \\(\\hat \\mu_2 = 5.01 + 0.93 = 5.94\\). We could say - the species iris versicolor had a sepal length of approximately \\(5.94~cm\\), and this was approximately \\(0.93~cm\\) longer than the iris setosa. This difference was statistically significant \\((p &lt; .001)\\).\nThe third estimate corresponds to Speciesvirginica and was \\(\\hat \\beta_2 = 1.58\\). The difference in mean sepal length between setosa and virginica species was estimated to be \\(1.58~cm\\). Thus, \\(\\hat \\mu_2 = 5.01 + 1.58 = 6.59\\). We could say - the species iris virginica had a sepal length of approximately \\(6.59~cm\\), and this was approximately \\(1.58~cm\\) longer than the iris setosa. This difference was statistically significant \\((p &lt; .001)\\).\n\n\n\n\n\n\n\n\n\n\nCoefficient\nEstimate\nCorresponds to\n\n\n\n(Intercept)\n5.84333\n\\(\\beta_0 = \\frac{\\mu_1 + \\mu_2 + \\mu_3}{3} = \\mu\\)\n\n\nSpecies1\n-0.83733\n\\(\\beta_1 = \\mu_1 - \\mu\\)\n\n\nSpecies2\n0.09267\n\\(\\beta_2 = \\mu_2 - \\mu\\)\n\n\n\n\nThe first estimate corresponding to (Intercept) contains \\(\\hat \\beta_0 = \\hat \\mu = 5.84\\). The estimated average sepal length across iris species was approximately \\(5.84~cm\\).\nThe second estimate corresponds to Species1 and was \\(\\hat \\beta_1 = -0.84\\). The difference in mean sepal length between setosa \\((\\hat \\mu_1)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(0.84~cm\\). In other words, the iris species of setosa had a sepal length \\(0.84~cm\\) shorter than average, where its length was estimated to be \\(5.84333 + (-0.83733) = 5~cm\\). This difference in length was statistically significant \\((p &lt; .001)\\).\nThe third estimate corresponds to Species2 and was \\(\\hat \\beta_2 = 0.09\\). The difference in mean sepal length between versicolor \\((\\hat \\mu_2)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(0.09~cm\\). In other words, the iris species of versicolor had a sepal length \\(0.09~cm\\) longer than average, where its length was estimated to be \\(5.84333 + 0.09267 = 5.94~cm\\). This difference in length was not statistically significant \\((p = .121)\\).\nThe estimate for Species3, representing the difference of “virginica” to the grand mean is not shown by summary(). Because of the side-constraint, we know that \\(\\mu_3 = \\beta_0 - (\\beta_1 + \\beta_2)\\). The difference in sepal length between virginica and the grand mean was estimated to be \\(-(-0.83733 + 0.09267) = 0.74466\\). In other words, the virginica iris species had a sepal length \\(0.74~cm\\) longer than average, where its length was estimated to be \\(5.84333 - (-0.83733 + 0.09267) = 6.59~cm\\).\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\nThere are a couple of ways that we can visualise our model, eithe rusing the sjPlot or effects packages:\n\n\nsjPlot\neffects\n\n\n\n\nlibrary(sjPlot)\n\nplot_model(spec_model,\n           type = \"eff\",\n           terms = \"Species\") +\n    labs(title = \"Sepal Length by Species\",\n       x = \"Species\", \n       y = \"Sepal Length\")\n\n\n\n\n\n\n\n\n\n\nlibrary(effects)\n\neffect(term = c(\"Species\"), mod = spec_model) |&gt;\n  as.data.frame() |&gt;\n  ggplot(aes(x = Species, y = fit, col = Species)) +\n  geom_pointrange(aes(ymin = lower, ymax = upper))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Specifying Reference Levels\n\n\nLet’s say we wanted to change the reference level in our “spec_model” above, there are a few different ways that we can do this.\nFirst we should check the current ordering of the levels:\n\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nWe can then change the reference level to be “versicolor” (using one of the below methods):\n\n\nfct_relevel()\nrelevel()\nfactor()\n\n\n\n\niris &lt;- iris |&gt; \n  mutate(\n    Species = fct_relevel(Species, \"versicolor\")\n  )\n\n\n\n\niris$Species &lt;- relevel(iris$Species, \"versicolor\")\n\n\n\n\niris$Species &lt;- iris$Species |&gt; \n  factor(., levels = c(\"versicolor\", \"setosa\", \"virginica\"))\n\n\n\n\nAnd then re-run our model:\n\n#fit model\nspec_model2 &lt;- lm(Sepal.Length ~ Species, data = iris)\nsummary(spec_model2)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.84333    0.04203 139.020   &lt;2e-16 ***\nSpecies1     0.09267    0.05944   1.559    0.121    \nSpecies2    -0.83733    0.05944 -14.086   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "1_b3_reading.html#interaction-models",
    "href": "1_b3_reading.html#interaction-models",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Interaction Models",
    "text": "Interaction Models\n\n Specifying Interaction Models\n\n\nInteraction models allow us to model the idea of “the association between \\(x_1\\) and \\(y\\) differs depending on the level of \\(x_2\\)” by including a product (multiplication) term between the two predictors.\nFormula:\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 (x_1 \\cdot x_2) + \\epsilon\n\\]\nIf we fit the interaction x1:x2, we almost always want to also fit the separate effects x1 and x2:\n\n“Except in special circumstances, a model including a product term for interaction between two explanatory variables should also include terms with each of the explanatory variables individually, even though their coefficients may not be significantly different from zero. Following this rule avoids the logical inconsistency of saying that the effect of \\(X_1\\) depends on the level of \\(X_2\\) but that there is no effect of \\(X_1\\).”\n— Ramsey and Schafer (2012)\n\n\nIn R:\nThere are basically two pieces of information that we need to pass to the lm() function:\n\nThe formula: The regression formula should be specified in the form y ~ x where \\(y\\) is the dependent variable (DV), \\(x_1\\) the first independent variable (IV1), and \\(x_2\\) the second independent variable (IV2). We then also need to include the interaction term between \\(x_1\\) and \\(x_2\\).\nThe data: Specify which dataframe (data =) contains the variables specified in the formula.\n\n\nrun interaction model via lm() function\n\n\nmodel_name &lt;- lm(DV ~ IV1*IV2, data = data_name)\n\nOR\n\nmodel_name &lt;- lm(DV ~ IV1 + IV2 + IV1:IV2, data = data_name)\n\n\n\n\n\n\n\n Interpreting Coefficients\n\n\n\n\nInterpreting coefficients for A and B in the presence of an interaction A:B\nInterpreting the interaction term A:B\n\n\n\nWhen you include an interaction between \\(x_1\\) and \\(x_2\\) in a regression model, you are estimating the extent to which the effect of \\(x_1\\) on \\(y\\) is different across the values of \\(x_2\\).\nWhat this means is that the effect of \\(x_1\\) on \\(y\\) depends on/is conditional upon the value of \\(x_2\\) (and vice versa, the effect of \\(x_2\\) on \\(y\\) is different across the values of \\(x_1\\)).\nThis means that we can no longer talk about the “effect of \\(x_1\\) holding \\(x_2\\) constant”. Instead we can talk about a marginal effect of \\(x_1\\) on \\(y\\) at a specific value of \\(x_2\\).\n\nWhen we fit the model \\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 (x_1 \\cdot x_2) + \\epsilon\\) using lm():\n\nthe parameter estimate \\(\\hat \\beta_1\\) is the marginal effect of \\(x_1\\) on \\(y\\) where \\(x_2 = 0\\)\n\nthe parameter estimate \\(\\hat \\beta_2\\) is the marginal effect of \\(x_2\\) on \\(y\\) where \\(x_1 = 0\\) In other words, when we fit a model with an interaction in R, we get out coefficients for both predictors, and for the interaction. The coefficients for each individual predictor reflect the effect on the outcome when the other predictor is zero.\n\n\n\n N.B. Regardless of whether or not there is an interaction term in our model, all parameter estimates in multiple regression are “conditional” in the sense that they are dependent upon the inclusion of other variables in the model. For instance, in \\(y = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon\\) the coefficient \\(\\hat \\beta_1\\) is conditional upon holding \\(x_2\\) constant. \n\n\n\nThe coefficient for an interaction term can be thought of as providing an adjustment to the slope.\nLet’s take the following model as an example:\nlm(formula = y ~ x1 * x2, data = df)\n...\n\n...\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  ...        ....       ...      ...  \nx1           ...        ....       ...      ...  \nx2           ...        ....       ...      ...  \nx1:x2        ...        ....       ...      ...  \n---\nThese coefficients can be interpreted, in turn as:\n\n\n\n\n\n\nCoefficient\nInterpretation\n\n\n\n(Intercept)\nthe estimated \\(y\\) when all predictors (\\(x_1\\) and \\(x_2\\)) are zero is [estimate]\n\n\nx1\n\nwhen \\(x_2\\) is zero, a 1 unit increase in \\(x_1\\) is associated with a [estimate] change in \\(y\\)\n\n\n\nx2\n\nwhen \\(x_1\\) is zero, a 1 unit increase in \\(x_2\\) is associated with a [estimate] change in \\(y\\).\n\n\nx1:x2\nas \\(x_2\\) increases by 1, the association between \\(x_1\\) and \\(y\\) changes by [estimate]oras \\(x_1\\) increases by 1, the association between \\(x_2\\) and \\(y\\) changes by [estimate]\n\n\n\n\n\n\n\n\n\n\n\n\nWhat if there are other things (e.g., other predictors/covatiates) in the model too?\n\n\n\nNote that the interaction x1:x2 changes how we interpret the individual coefficients for x1 and x2.\nIt does not change how we interpret coefficients for other predictors that might be in our model. For variables that aren’t involved in the interaction term, these are still held constant.\nFor example, suppose we also had another predictor \\(c_1\\) in our model:\nlm(y ~ c1 + x1 + x2 + x1:x2)\n\n\n\n\n\n\nCoefficient\nInterpretation\n\n\n\n(Intercept)\nthe estimated \\(y\\) when all predictors (\\(c_1\\), \\(x_1\\) and \\(x_2\\)) are zero is [estimate]\n\n\nc1\na 1 unit increase in \\(c_1\\) is associated with a [estimate] increase in \\(y\\), holding constant all other variables in the model (\\(x_1\\) and \\(x_2\\))\n\n\nx1\nholding \\(c_1\\) constant, when \\(x_2\\) is zero, a 1 unit increase in \\(x_1\\) is associated with a [estimate] change in \\(y\\)\n\n\n\nx2\nholding \\(c_1\\) constant, when \\(x_1\\) is zero, a 1 unit increase in \\(x_2\\) is associated with a [estimate] change in \\(y\\).\n\n\nx1:x2\nholding \\(c_1\\) constant, as \\(x_2\\) increases by 1, the association between \\(x_1\\) and \\(y\\) changes by [estimate]orholding \\(c_1\\) constant, as \\(x_1\\) increases by 1, the association between \\(x_2\\) and \\(y\\) changes by [estimate]\n\n\n\n\n\n\n\n\n\nNumeric x Categorical Example\n\nResearch Question\nDoes the association between body mass and flipper length differ between species of penguin?\n\n\n Overview\n\n\nHere we are using the palmer penguins dataset2. The dataset contains a variety of information for a total of 344 adult penguins, including body measurements (bill length (bill_length_mm; measured in mm)/depth (bill_length_mm; measured in mm), flipper length (flipper_length_mm; measured in mm), body mass (body_mass_g; measured in grams)) for male and female (sex) penguins from three species (species; categorised as Adelie, Chinstrap, or Gentoo) across three Antarctic islands (island; categorised as Biscoe, Dream, or Torgersen) from 2007-2009 (year).\n\n\n\n\n\n Visualise Data\n\n\nSince we have a continuous DV, one continuous IV and one categorical (with 3 levels) IV, one of the most appropriate visualisations would be a scatterplot where we have a separate line of best fit mapped for each level of species:\n\npenguins |&gt;\n  ggplot(aes(x = flipper_length_mm, y = body_mass_g, colour = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Flipper Length (in mm)\", y = \"Body Mass (in g)\")\n\n\n\n\n\n\n\nAlternatively, we could create the same above scatterplot, and then divide into different facets by species:\n\npenguins |&gt;\n  ggplot(aes(x = flipper_length_mm, y = body_mass_g, colour = species)) +\n  geom_point() +\n  facet_wrap(~species) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Flipper Length (in mm)\", y = \"Body Mass (in g)\")\n\n\n\n\n\n\n\n\n\n\n\n\n Model Specification\n\n\nBefore we specify our model, we must select (and provide justification for this choice) the reference group(s) for our categorical variable(s). In this specific example, there is no natural reference category, nor one that maps to our RQ, so we will go with R’s default coding and have Adelie as our reference group for species.\n\\[\n\\begin{align}\n\\text{Body Mass} ~=~ & \\beta_0 + \\beta_1 \\cdot \\text{Flipper Length} + \\beta_2 \\cdot \\text{Species}_\\text{Chinstrap} + \\beta_3 \\cdot \\text{Species}_\\text{Gentoo} \\\\\n& + \\beta_4 \\cdot (\\text{Flipper Length} \\cdot \\text{Species}_\\text{Chinstrap}) \\\\\n& + \\beta_5 \\cdot (\\text{Flipper Length} \\cdot \\text{Species}_\\text{Gentoo}) + \\epsilon \\\\\n\\end{align}\n\\quad\n\\]\n\n\n\n\n\n Model Building\n\n\nNo penguins in our dataset had a flipper length of zero mm. We might want to mean centre this predictor variable so that we can consider the difference in body mass between penguin species with average flipper lengths. Before we build our model, we should mean centre this IV:\n\npenguins &lt;- penguins |&gt;\n    mutate(\n   mc_flipper_length_mm = scale(flipper_length_mm, scale = FALSE)\n   )\n\nRecall that the default in R is to apply dummy coding, and thus R computes the dummy variables for us! Since we are using the default reference group, we can simply run our model (with our newly created mean centered flipper length variable):\n\nmdl_nc &lt;- lm(body_mass_g ~ mc_flipper_length_mm * species, data = penguins)\n\nEach row in the summary() output of the model will correspond to one of the estimated \\(\\beta\\)’s in the equation above.\n\nsummary(mdl_nc)\n\n\nCall:\nlm(formula = body_mass_g ~ mc_flipper_length_mm * species, data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-911.18 -251.93  -31.77  197.82 1144.81 \n\nCoefficients:\n                                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                           4060.549     59.010  68.811  &lt; 2e-16 ***\nmc_flipper_length_mm                    32.832      4.627   7.095 7.69e-12 ***\nspeciesChinstrap                      -151.424     80.912  -1.871  0.06215 .  \nspeciesGentoo                          126.662    108.104   1.172  0.24216    \nmc_flipper_length_mm:speciesChinstrap    1.742      7.856   0.222  0.82467    \nmc_flipper_length_mm:speciesGentoo      21.791      6.941   3.139  0.00184 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 370.6 on 336 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.7896,    Adjusted R-squared:  0.7864 \nF-statistic: 252.2 on 5 and 336 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\n(Intercept)\nmc_flipper_length_mm\nspeciesChinstrap\nspeciesGentoo\nmc_flipper_length_mm:speciesChinstrap\nmc_flipper_length_mm:speciesGentoo\n\n\n\n\\(\\beta_0\\) = (Intercept) = 4060.55\n\nThe intercept, or predicted body mass when flipper length was average and species was Adelie.\n\nAn Adelie penguin with an average flipper length was expected to have a body mass of \\(4060.55g\\).\n\n\n\n\n\n\\(\\beta_1\\) = mc_flipper_length_mm = 32.83\n\nThe simple slope of flipper length (in mm) for species reference group (Adelie).\n\nFor an Adelie penguin, every 1 additional mm in flipper length was associated with a significant \\(32.83g\\) increase in their body mass \\((p &lt; .001)\\).\n\n\n\n\n\n\\(\\beta_2\\) = speciesChinstrap = -151.42\n\nThe simple effect of species (or the difference in body mass between Adelie and Chinstrap penguins) when flipper length was average.\n\nA Chinstrap penguin with an average flipper length had a body mass \\(151.42g\\) lighter than an Adelie penguin with the same flipper length. Note that this difference was not statistically different from zero \\((p = .062)\\).\n\n\n\n\n\n\\(\\beta_3\\) = speciesGentoo = 126.66\n\nThe simple effect of species (or the difference in body mass between Adelie and Gentoo penguins) when flipper length was average.\n\nA Gentoo penguin with an average flipper length had a body mass \\(126.66g\\) heavier than an Adelie penguin with the same flipper length. Note that this difference was not statistically different from zero \\((p = .242)\\).\n\n\n\n\n\n\\(\\beta_4\\) = mc_flipper_length_mm:speciesChinstrap = 1.74\n\nThe interaction between flipper length (in mm; mean centered) and species (levels: Adelie/Chinstrap). This is the estimated difference in simple slopes of flipper length for Adelie vs. Chinstrap penguins.\n\nIn comparison to Adelie penguins, for a Chinstrap penguin every 1 additional mm in flipper length was associated with a \\(1.74g\\) point greater change in their body mass. Note that this adjustment was not statistically different from zero \\((p = .825)\\).\n\n\n\n\n\n\\(\\beta_5\\) = mc_flipper_length_mm:speciesGentoo = 21.79\n\nThe interaction between flipper length (in mm; mean centered) and species (levels: Adelie/Gentoo). This is the estimated difference in simple slopes of flipper length for Adelie vs. Gentoo penguins.\n\nIn comparison to Adelie penguins, for a Gentoo penguin every 1 additional mm in flipper length was associated with a \\(21.79g\\) greater increase in their body mass. Note that this adjustment was statistically significant \\((p = .002)\\).\n\n\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\nWe can do this using the probe_interaction() function from the interactions package.\nIn terms of of specification, it might be useful to look up the helper function (i.e., ?probe_interaction). As a quick guide:\n\n\nmodel =: The name model to be used\n\n\npred =: The continuous predictor variable that will appear on the x-axis\n\n\nmodx =: The categorical moderator variable\n\n\ninterval =: If we say TRUE, then confidence/prediction intervals will be plotted around the line\n\nRemember to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\na clear and concise title (specify main.title =)\n\naxis labels with units or scale included (specify x.label = and y.label =)\n\na legend title (specify legend.main =)\n\n\nlibrary(interactions)\n\nplt_mdl_nc &lt;- probe_interaction(model = mdl_nc,\n                                pred = mc_flipper_length_mm,\n                                modx = species,\n                                interval = T,\n                                main.title = \"Predicted Body Mass across Flipper Length by Species\",\n                                x.label = \"Flipper Length (in mm; Mean Centered)\",\n                                y.label = \"Body Mass (in g)\",\n                                legend.main = \"Penguin Species\")\nplt_mdl_nc$interactplot\n\n\n\n\n\n\n\n\n\n\n\nNumeric x Numeric Example\n\nResearch Question\nDoes the influence of bill length on body mass vary depending on flipper length?\n\n\n Overview\n\n\nHere we are using the palmer penguins dataset3. The dataset contains a variety of information for a total of 344 adult penguins, including body measurements (bill length (bill_length_mm; measured in mm)/depth (bill_length_mm; measured in mm), flipper length (flipper_length_mm; measured in mm), body mass (body_mass_g; measured in grams)) for male and female (sex) penguins from three species (species; categorised as Adelie, Chinstrap, or Gentoo) across three Antarctic islands (island; categorised as Biscoe, Dream, or Torgersen) from 2007-2009 (year).\n\n\n\n\n\n Visualise Data\n\n\nUsing pairs.panels() is likely the most useful way to visualise the associations among numeric variables. It returns a scatterplot of matrices (SPLOM) returning you (1) the marginal distribution of each variable via a histogram, (2) the correlation between variables, and (3) bivariate scatterplots.\n\npenguins |&gt;\n    select(body_mass_g, flipper_length_mm, bill_length_mm) |&gt;\n    pairs.panels()\n\n\n\n\n\n\n\nIf you really wanted to, you could create a 3D plot showing the associations among all three variables at once. We wouldn’t really recommend doing this - they can be very difficult to interpret correctly, and given their interactive nature, definitely NOT something that you’d want to include in a stats report. But, for demonstration purposes only, we could create one using the plotly package:\n\nlibrary(plotly)\nplot_ly(penguins, x = ~flipper_length_mm, y = ~body_mass_g, z = ~bill_length_mm, type = 'scatter3d', mode = 'markers+lines')\n\n\n\n\n\n\n\n\n\n\n Model Specification\n\n\n\\[\n\\begin{align}\n\\text{Body Mass} ~=~ & \\beta_0 + \\beta_1 \\cdot \\text{Flipper Length} + \\beta_2 \\cdot \\text{Bill Length} \\\\  \n& + \\beta_3 \\cdot (\\text{Flipper Length} \\cdot \\text{Bill Length}) + \\epsilon\n\\end{align}\n\\]\n\n\n\n\n\n Model Building\n\n\nNo penguins in our dataset had zero mm flipper or bill lengths. We might want to mean centre both of these predictor variables so that we can consider the difference in body mass between penguins with average flipper lengths and average bill lengths. Before we build our model, we should mean centre our two IVs:\n\npenguins &lt;- penguins |&gt;\n    mutate(\n   mc_flipper_length_mm = scale(flipper_length_mm, scale = FALSE),\n   mc_bill_length_mm = scale(bill_length_mm, scale = FALSE)\n   )\n\nWe can then specify our model using these two mean centred IVs:\n\nmdl_nn &lt;- lm(body_mass_g ~ mc_flipper_length_mm * mc_bill_length_mm, data = penguins)\nsummary(mdl_nn)\n\n\nCall:\nlm(formula = body_mass_g ~ mc_flipper_length_mm * mc_bill_length_mm, \n    data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1040.18  -283.07   -23.94   241.93  1241.40 \n\nCoefficients:\n                                        Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                            4141.4879    26.4532 156.559  &lt; 2e-16\nmc_flipper_length_mm                     45.3910     2.1082  21.531  &lt; 2e-16\nmc_bill_length_mm                        11.8249     5.3161   2.224 0.026785\nmc_flipper_length_mm:mc_bill_length_mm    1.1998     0.3224   3.721 0.000232\n                                          \n(Intercept)                            ***\nmc_flipper_length_mm                   ***\nmc_bill_length_mm                      *  \nmc_flipper_length_mm:mc_bill_length_mm ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 386.8 on 338 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.7694,    Adjusted R-squared:  0.7674 \nF-statistic: 375.9 on 3 and 338 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\n(Intercept)\nmc_flipper_length_mm\nmc_bill_length_mm\nmc_flipper_length_mm:mc_bill_length_mm\n\n\n\n\\(\\beta_0\\) = (Intercept) = 4141.49\n\nThe intercept, or predicted body mass of penguins for average flipper and bill length.\n\nA penguin with average flipper and bill length was expected to have a body mass of \\(4141.49g\\).\n\n\n\n\n\n\\(\\beta_1\\) = mc_flipper_length_mm = 45.39\n\nThe simple slope of flipper length (in mm) when bill length was average.\n\nFor a penguin with an average bill length, every 1mm increase in flipper length was associated with a significant \\((p &lt; .001)\\) increase of \\(45.39g\\) in their body mass.\n\n\n\n\n\n\\(\\beta_2\\) = mc_bill_length_mm = 11.82\n\nThe simple slope of bill length (in mm) when flipper length was average.\n\nFor a penguin with an average flipper length, every 1mm increase in bill length was associated with a significant \\((p &lt; .05)\\) increase in their body mass by \\(11.82g\\).\n\n\n\n\n\n\\(\\beta_3\\) = mc_flipper_length_mm:mc_bill_length_mm = 1.2\n\nThe interaction between flipper and bill length on body mass - the change in the slope of flipper length as a function of bill length.\n\nFor every 1mm increase in bill length, when flipper length increased by 1mm, the slope with body mass was adjusted by 1.20 \\((\\beta = 1.2,~p &lt; .001)\\).\n\n\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\nWe can do this using the probe_interaction() function from the interactions package.\nIn terms of of specification, it might be useful to look up the helper function (i.e., ?probe_interaction). As a quick guide:\n\n\nmodel =: The name model to be used\n\n\npred =: The continuous predictor variable that will appear on the x-axis\n\n\nmodx =: The continuous moderator variable\n\n\ninterval =: If we say TRUE, then confidence/prediction intervals will be plotted around the line\n\n\njnplot =: Since we are looking at a numeric x numeric interaction, we want to specify that this is TRUE\n\n\nRemember to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\na clear and concise title (specify main.title =)\n\naxis labels with units or scale included (specify x.label = and y.label =)\n\na legend title (specify legend.main =)\n\n\nlibrary(interactions)\n\nplt_mdl_nn &lt;- probe_interaction(model = mdl_nn,\n                                pred = mc_flipper_length_mm,\n                                modx = mc_bill_length_mm,\n                                cond.int = T,\n                                interval = T,\n                                jnplot = T,\n                                main.title = \"Bill Length Moderating the Effect of Flipper Length on Body Mass\",\n                                x.label = \"Flipper Length (in mm; Mean Centered)\",\n                                y.label = \"Body Mass (in g)\",\n                                legend.main = \"Bill Length (in mm; Mean Centered)\")\n\nFrom the above, we can choose to extract different information/visualisations of simple slopes (this will likely be dependent upon the question(s) you are trying to answer) - the interaction plot, simple slopes analysis only, johnson-neyman plot only, or both simple slopes and johnson-neyman plot:\n\n\nInteraction Plot\nSimple Slopes Only\nJohnson-Neyman Plot Only\nBoth Simple Slopes & Johnson-Neyman Plot\n\n\n\nThe default simple slopes analysis selects \\(z\\)-values for us at which to test the slope. The defaults are: the mean of \\(Z\\), and \\(+1~SD\\) and \\(-1~SD\\) from the mean:\n\nplt_mdl_nn$interactplot\n\n\n\n\n\n\n\n\n\nHere we can look a the significance of each slope:\n\nplt_mdl_nn$simslopes$slopes\n\n  Value of mc_bill_length_mm     Est.     S.E.     2.5%    97.5%   t val.\n1              -5.459584e+00 38.84037 3.185723 32.57403 45.10672 12.19201\n2               1.018029e-15 45.39104 2.108209 41.24417 49.53790 21.53061\n3               5.459584e+00 51.94170 2.222151 47.57071 56.31269 23.37452\n             p\n1 1.379943e-28\n2 2.378006e-65\n3 1.402468e-72\n\n\n\n\nThe Johnson-Neyman plot allows us to visualise the regions of significance - i.e., it identifies the range of the moderator variable \\((Z)\\) where the effect of the independent variable \\((X)\\) on the dependent variable \\((Y)\\) is statistically significant (e.g., \\(p &lt; .05\\)). Outwith these regions, the effect of the independent variable is not significant.\nPointers to help with interpretation of the plot:\n\nx-axis = Values of moderator variable \\((Z)\\)\n\ny-axis = The conditional effect (slope) of the independent variable \\((X)\\) on the dependent variable \\((Y)\\)\n\nBold black line (range of observed data) = The actual range of the moderator variable \\((Z)\\) values within the dataset. This helps with interpretation of results, and more importantly, avoid extrapolation - i.e., should help to ensure that the interpretations of the plot are data-driven and based on the actually observed data\n\nZero line = The horizontal line at \\(y = 0\\) indicates the point where the effect of the IV \\((X)\\) on the DV \\((Y)\\) is neither positive or negative\n\nShaded areas = Regions where the effect is significant (e.g., outside the bounds of 95% confidence intervals that include zero) are highlighted in blue. Regions where the effect is non-significant (e.g., crosses the zero line, inside the bounds of the 95% confidence intervals that include zero) are highlighted in red\n\n\nplt_mdl_nn$simslopes$jnplot\n\n\n\n\n\n\n\n\n\nWhen we return both the simple slopes analysis and Johnson-Neyman plot, we can see that some text is also provided to aid our interpretation of the plot:\n\nplt_mdl_nn$simslopes\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen mc_bill_length_mm is OUTSIDE the interval [-83.07, -23.71], the slope\nof mc_flipper_length_mm is p &lt; .05.\n\nNote: The range of observed values of mc_bill_length_mm is [-11.82, 15.68]\n\n\n\n\n\n\n\n\nSIMPLE SLOPES ANALYSIS \n\nWhen mc_bill_length_mm = -5.459584e+00 (- 1 SD): \n\n                                         Est.    S.E.   t val.      p\n----------------------------------- --------- ------- -------- ------\nSlope of mc_flipper_length_mm           38.84    3.19    12.19   0.00\nConditional intercept                 4076.93   42.62    95.65   0.00\n\nWhen mc_bill_length_mm =  1.018029e-15 (Mean): \n\n                                         Est.    S.E.   t val.      p\n----------------------------------- --------- ------- -------- ------\nSlope of mc_flipper_length_mm           45.39    2.11    21.53   0.00\nConditional intercept                 4141.49   26.45   156.56   0.00\n\nWhen mc_bill_length_mm =  5.459584e+00 (+ 1 SD): \n\n                                         Est.    S.E.   t val.      p\n----------------------------------- --------- ------- -------- ------\nSlope of mc_flipper_length_mm           51.94    2.22    23.37   0.00\nConditional intercept                 4206.05   35.60   118.14   0.00\n\n\nIn our example, we could say:\n\n\n\n\n\n\nExample Interpretation\nThe association between body mass (in g) and flipper length (in mm; mean centered) was significant when bill length (in mm; mean centered) was more than 83.07mm below the mean or greater than -23.71mm above the mean.\n\n\n\n\n\n\n\n\n\nCategorical x Categorical Example\n\nResearch Question\nDo differences in body mass between species differ by sex?\n\n\n Overview\n\n\nHere we are using the palmer penguins dataset4. The dataset contains a variety of information for a total of 344 adult penguins, including body measurements (bill length (bill_length_mm; measured in mm)/depth (bill_length_mm; measured in mm), flipper length (flipper_length_mm; measured in mm), body mass (body_mass_g; measured in grams)) for male and female (sex) penguins from three species (species; categorised as Adelie, Chinstrap, or Gentoo) across three Antarctic islands (island; categorised as Biscoe, Dream, or Torgersen) from 2007-2009 (year).\n\n\n\n\n\n Visualise Data\n\n\nSince we have a continuous DV, and we have two categorical IVs, the most appropriate visualisations would be a boxplot or violin plot:\n\npenguins |&gt;\n    drop_na() |&gt; #we need this here as we have some missing data for this particular example!\n    ggplot(aes(x = species, y = body_mass_g, fill = sex)) +\n    geom_violin() +\n    theme(legend.position = 'none') + \n  labs(x = \"Species\", y = \"Body Mass (in g)\")\n\n\n\n\n\n\n\n\n\n\n\n\n Model Specification\n\n\nBefore we specify our model, we must select (and provide justification for this choice) the reference group(s) for our categorical variable(s). In this specific example, there is no natural reference category, nor one that maps to our RQ, so we will go with R’s default coding and have Adelie as our reference group for species, and female for sex.\n\\[\n\\begin{aligned}\n\\text{Body Mass} &= \\beta_0 + \\beta_1 \\cdot \\text{Species}_\\text{Chinstrap} + \\beta_2 \\text{Species}_\\text{Gentoo} + \\beta_3 \\cdot \\text{Sex}_\\text{Male}  \\\\\n      &+ \\beta_4 \\cdot (\\text{Species}_\\text{Chinstrap} \\cdot \\text{Sex}_\\text{Male}) + \\beta_5 \\cdot (\\text{Species}_\\text{Gentoo} \\cdot \\text{Sex}_\\text{Male}) + \\epsilon\n\\end{aligned}\n\\]\n\n\n\n\n\n Model Building\n\n\nRecall that the default in R is to apply dummy coding, and thus R computes the dummy variables for us! Since we are using the default reference group, we can simply run our model.\nEach row in the summary() output of the model will correspond to one of the estimated \\(\\beta\\)’s in the equation above.\n\nmdl_cc &lt;- lm(body_mass_g ~ species * sex, data = penguins)\nsummary(mdl_cc)\n\n\nCall:\nlm(formula = body_mass_g ~ species * sex, data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-827.21 -213.97   11.03  206.51  861.03 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               3368.84      36.21  93.030  &lt; 2e-16 ***\nspeciesChinstrap           158.37      64.24   2.465  0.01420 *  \nspeciesGentoo             1310.91      54.42  24.088  &lt; 2e-16 ***\nsexmale                    674.66      51.21  13.174  &lt; 2e-16 ***\nspeciesChinstrap:sexmale  -262.89      90.85  -2.894  0.00406 ** \nspeciesGentoo:sexmale      130.44      76.44   1.706  0.08886 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 309.4 on 327 degrees of freedom\n  (11 observations deleted due to missingness)\nMultiple R-squared:  0.8546,    Adjusted R-squared:  0.8524 \nF-statistic: 384.3 on 5 and 327 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n Results Interpretation\n\n\n\n\n(Intercept)\nspeciesChinstrap\nspeciesGentoo\nsexmale\nspeciesChinstrap:sexmale\nspeciesGentoo:sexmale\n\n\n\n\\(\\beta_0\\) = (Intercept) = 3368.84\n\nThe intercept, or predicted body mass of a female Adelie (i.e., when both predictor variables are at their reference levels).\n\nA female Adelie penguin was expected to have a body mass of \\(3368.84g\\).\n\n\n\n\n\n\\(\\beta_1\\) = speciesChinstrap = 158.37\n\nThe difference in body mass between female Adelie and Chinstrap penguins.\n\nIn comparison to female Adelie penguins, Chinstrap penguins of the same sex were significantly \\((p &lt; .05)\\) heavier by \\(158.37g\\).\n\n\n\n\n\n\\(\\beta_2\\) = speciesGentoo = 1310.91\n\nThe difference in body mass between female Adelie and Gentoo penguins.\n\nIn comparison to female Adelie penguins, Gentoo penguins of the same sex were significantly \\((p &lt; .001)\\) heavier by \\(1310.91g\\).\n\n\n\n\n\n\\(\\beta_3\\) = sexmale = 674.66\n\nThe difference in body mass between female and male Adelie penguins.\n\nIn comparison to female Adelie penguins, male Adelie penguins were significantly heavier by \\(674.66g\\) \\((p &lt; .001)\\).\n\n\n\n\n\n\\(\\beta_4\\) = speciesChinstrap:sexmale = -262.89\n\nThe difference in body mass for Adelie and Chinstrap penguins between females and males differed by \\(-262.89g\\).\n\nThe difference in body mass between female and male penguins was \\(262.89g\\) less for Chinstrap penguins in comparison to Adele penguins. This difference was statistically significant \\(p &lt; .05\\).\nThe difference in body mass between female and male penguins was significantly less for the Chinstrap species in comparison to Adelie (where there was an additional \\(262.89g\\) lesser difference between the two sexes).\n\n\n\n\n\n\\(\\beta_5\\) = speciesGentoo:sexmale = 130.44\n\nThe difference in body mass for Adelie and Gentoo penguins between females and males differed by \\(130.44g\\).\n\nThe difference in body mass between female and male penguins was \\(130.45g\\) more for Gentoo penguins in comparison to Adele penguins. This difference was not statistically significant \\(p = .089\\).\n\nThe difference in body mass between female and male penguins was more for the Gentoo species in comparison to Adelie (where there was an additional \\(130.45g\\) greater difference between the two sexes), though this difference was not statistically significant.\n\n\n\n\n\n\n\n\n\n\n\n Model Visualisation\n\n\nWe can do this using the cat_plot() function from the interactions package.\nIn terms of of specification, it might be useful to look up the helper function (i.e., ?cat_plot). As a quick guide:\n\n\nmodel =: The name model to be used\n\n\npred =: The categorical predictor variable that will appear on the x-axis\n\n\nmodx =: The categorical moderator variable\n\nRemember to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\na clear and concise title (specify main.title =)\n\naxis labels with units or scale included (specify x.label = and y.label =)\n\na legend title (specify legend.main =)\n\n\nlibrary(interactions)\n\nplt_mdl_cc &lt;- cat_plot(model = mdl_cc,\n                                pred = species,\n                                modx = sex,\n                                main.title = \"Body Mass across Species and Sex\",\n                                x.label = \"Species\",\n                                y.label = \"Body Mass (in g)\",\n                                legend.main = \"Sex\")\nplt_mdl_cc\n\n\n\n\n\n\n\n\n\n\n\n\n Coding Constraints\n\n\nWhen we have categorical predictors, our choice of contrasts coding changes the bits that we’re getting our of our model.\nSuppose we have a 2x2 design (condition A and B, in groups 1 and 2):\n\n\n\n\nFigure 10: Categorical x Categorical Interaction plot\n\n\n\nWhen we are using the default contrasts coding (i.e., treatment or dummy) in R, then our coefficients for the individual predictors represent moving between the dots in Figure 10.\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            1.9098     0.1759  10.855  &lt; 2e-16 ***\nconditionB             1.1841     0.2488   4.759 5.65e-06 ***\ngrouping2             -1.6508     0.2488  -6.635 1.09e-09 ***\nconditionB:grouping2  -2.1627     0.3519  -6.146 1.15e-08 ***\n---\n\nThe intercept is the red circle in Figure 10.\n\nThe coefficient for condition is the difference between the red circle and the red triangle in Figure 10.\n\nThe coefficient for grouping is the difference between the red circle and the blue circle in Figure 10.\n\nThe interaction coefficient is the difference from the slope of the red line to the slope of the blue line.\n\nHowever, when we change to using effects (or sum-to-zero) coding, we’re switching where zero is in our model. So if we change to sum contrasts (here we’ve changed both predictors to using sum-to-zero coding), then we end up estimating the effect of each predictor averaged across the other.\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           1.13577    0.08796  12.912  &lt; 2e-16 ***\nconditionB            0.05141    0.08796   0.584     0.56    \ngrouping2            -1.36607    0.08796 -15.530  &lt; 2e-16 ***\nconditionB:grouping2 -0.54066    0.08796  -6.146 1.15e-08 ***\n---\n\nThe intercept is the grey X in Figure 11.\n\nThe coefficient for condition is the difference between the grey X and the grey triangle in Figure 11.\n\nThe coefficient for grouping is the difference between the grey X and the blue line in Figure 11.\n\nThe interaction coefficient is the difference from the slope of the grey line to slope of the blue line.\n\n\n\n\n\nFigure 11: Visualisation of sum-to-zero for categorical x categorical interaction plot\n\n\n\nIt can get quite confusing when we start switching up the contrasts, but it’s all just because we’re changing what “zero” means, and what “moving 1” means:\n\n\nDummy/Treatment Coding\nEffects/Sum-to-Zero Coding\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Simple Effects\n\n\nSimple effects involve examining the effect of one independent variable at a specific level of a second independent variable. This can allow us to better understand the nature of the interaction as we can examine group differences within one level of one of the independent variables.\nGoing back to our penguins example, we could ask:\n\nIs there an effect of sex for chinstrap penguins? Or in other words, is there a difference in body mass between male and female chinstrap penguins?\n\nTo test simple effects, we can use the emmeans package.\n\nIn R\n\n#load the emmeans package\nlibrary(emmeans)\n\n#obtain estimates of simple comparisons of cell means\nmdl_cc_emm &lt;- emmeans(mdl_cc, ~species*sex)\n\n#return cell means\nmdl_cc_emm\n\n species   sex    emmean   SE  df lower.CL upper.CL\n Adelie    female   3369 36.2 327     3298     3440\n Chinstrap female   3527 53.1 327     3423     3632\n Gentoo    female   4680 40.6 327     4600     4760\n Adelie    male     4043 36.2 327     3972     4115\n Chinstrap male     3939 53.1 327     3835     4043\n Gentoo    male     5485 39.6 327     5407     5563\n\nConfidence level used: 0.95 \n\n#specify that we want to compare sex for each species\nmdl_cc_simple &lt;- pairs(mdl_cc_emm, simple = \"sex\")\n\n#return comparison \nmdl_cc_simple\n\nspecies = Adelie:\n contrast      estimate   SE  df t.ratio p.value\n female - male     -675 51.2 327 -13.174  &lt;.0001\n\nspecies = Chinstrap:\n contrast      estimate   SE  df t.ratio p.value\n female - male     -412 75.0 327  -5.487  &lt;.0001\n\nspecies = Gentoo:\n contrast      estimate   SE  df t.ratio p.value\n female - male     -805 56.7 327 -14.188  &lt;.0001\n\n\n\nWe can also visualise the interaction using emmip(). Here we need to specify the model object, what we want on the x- and y-axis, and whether we want 95% CIs to be displayed.\n\nIn R\n\n## first argument is the model object we need to use to visualise the slopes\n## species is on the x axis\n## separate lines for each level of sex\n## return 95% CIs is set to true (default is false)\n\nemmip(mdl_cc, sex ~ species,\n      CIs = TRUE,\n      ylab = \"Predicted Weight (g)\",\n      xlab = \"Species\")\n\n\n\nFigure 12: Predicted Penguin Weight by Species and Sex\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nA simple effects analysis examined the whether there was a difference in body mass between male and female chinstrap penguins. Males \\((M = 3939~g)\\) were estimated to be heavier than females \\((M = 3527~g)\\) with an estimated difference of \\(412~g\\), and this difference was statistically significant \\(p &lt; .001\\). This difference is visually presented in Figure 12."
  },
  {
    "objectID": "1_b3_reading.html#general---extracting-information",
    "href": "1_b3_reading.html#general---extracting-information",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "General - Extracting Information",
    "text": "General - Extracting Information\nIt is important to have a good grasp of how to understand and interpret the key components of your model summary() output, including model coefficients, standard errors, \\(t\\)-values, \\(p\\)-values, etc., and how these can be used in further calculations (such as confidence intervals). As well as knowing how to extract from R, it is necessary to understand how to compute some of these statistics by hand too.\n\n Model Call\n\n\n\n\n\n\nMultiple regression output in R, model formula highlighted\n\n\n\nThe call section at the very top of the summary() output shows us the formula that was specified in R to fit the regression model.\nIn the above, we can see that recall accuracy is our DV, recall confidence and age were our two IVs, and our dataset was named recalldata.\n\n\n\n\n\n Residuals\n\n\n\n\n\n\nMultiple regression output in R, residuals highlighted\n\n\n\nResiduals are the difference between the observed values and model predicted values of the DV.\nIdeally, for the model to be unbiased, we want our median value (the middle value of the residuals when ordered) to be around 0, as this would show that the errors are random fluctuations around the true line. When this is the case, we know that our model is doing a good job predicting values at the high and low ends of our dataset, and that our residuals were somewhat symmetrical.\n\n\n\n\n\n Model Coefficients\n\n\n\n\n\n\nMultiple regression output in R, model coefficients highlighted\n\n\n\n\n\nEstimates\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\nOur model estimates help us to build our best fitting equation of the line that represents the association between our DV and our IV(s).\nIn the above example, we can build our equation for our model from this information:\n\\[\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Recall Confidence}_i + \\beta_2 \\cdot \\text{Age}_i + \\epsilon_i\n\\] \\[\n\\widehat{\\text{Recall Accuracy}} = 36.16 + 0.90 \\cdot \\text{Recall Confidence} - 0.34 \\cdot \\text{Age}\n\\]\nHow to calculate \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\)\n\n\nBy Hand\nUsing R\n\n\n\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nStep 1: Calculate mean of both \\(x\\) and \\(y\\)\n\\(\\bar x = {\\frac{1+2+3+4+5}{5}} = 3\\)\n\\(\\bar y = {\\frac{5+7+8+6+9}{5}} = 7\\)\nStep 2: Calculate \\(\\beta_0\\) and \\(\\beta_1\\)\nWe need to calculate the slope first, as we need to know the value of \\(\\beta_1\\) in order to calculate \\(\\beta_0\\)\nSlope (\\(\\beta_1\\))\n\\[\n\\begin{align}\n& \\hat \\beta_1 = \\frac{SP_{xy}}{SS_x} \\\\  \n\\\\\n\\\\\n& \\text{Where}: \\\\\n& \\text{SP}_\\text{xy} = \\text{sum of cross-products:} \\\\\n& \\text{SP}_\\text{xy} = \\sum_{i = 1}^{n}(x_i - \\bar{x})(y_i - \\bar{y}) \\\\  \n& \\text{and} \\\\\n& \\text{SS}_\\text{x} = \\text{sums of squared deviations of x:} \\\\    \n& \\text{SS}_\\text{x} = \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 \\\\  \n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\text{SP}_\\text{xy} =\\sum_{i = 1}^{n}(x_i - \\bar{x})(y_i - \\bar{y}) = \\\\\n& (1-3)(5-7) + (2-3)(7-7) + (3-3)(8-7) + (4-3)(6-7) + (5-3)(9-7) = \\\\\n& 4 + 0 + 0 + (-1) + 4 = \\\\\n& 7 \\\\\n\\\\  \n& \\text{SS}_\\text{x}= \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 = \\\\\n& (1-3)^2 + (2-3)^2 + (3-3)^22 + (4-3)^2 + (5-3)^2 = \\\\\n& 4 + 1 + 0 + 1 + 4 = \\\\\n& 10 \\\\\n\\\\  \n& \\hat \\beta_1 = \\frac{SP_{xy}}{SS_x} = \\frac{7}{10} = 0.7 \\\\\n\\end{align}\n\\]\nIntercept (\\(\\beta_0\\))\n\\[\n\\begin{align}\n&\\hat \\beta_0 = \\bar{y} - \\hat \\beta_1 \\bar{x} \\\\\n&\\hat \\beta_0 = 7 - 0.7 \\cdot 3 \\\\\n&\\hat \\beta_0 = 7 - 2.1 \\\\\n&\\hat \\beta_0 = 4.9\n\\end{align}\n\\]\n\n\n\nIn R\nThere are numerous equivalent ways to obtain the estimated regression coefficients — that is, \\(\\hat \\beta_0\\), \\(\\hat \\beta_1\\), …., \\(\\hat \\beta_k\\) — from the fitted model (for this below example, our fitted model has been named mdl):\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\n\n\n\n\n\n\n\nThe standard error of the coefficient is an estimate of the standard deviation of the coefficient (i.e., how much uncertainty there is in our estimated coefficient).\nThe formula for the standard error of the slope is:\n\\[\n\\begin{align}\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{\\text{SS}_\\text{Residual}/(n-k-1)}{\\sum(x_{ij} - \\bar{x_{j}})^2(1-R_{xj}^2)}} \\\\  \n\\\\  \n& \\text{Where}: \\\\  \n\\\\  \n& \\text{SS}_\\text{Residual} = \\text{ residual sum of squares} \\\\  \n& n = \\text{ sample size} \\\\  \n& k = \\text{ number of predictors} \\\\  \n& x_{ij} = \\text{ the observed value of a predictor (j) for an individual (i)} \\\\  \n& \\bar{x_{j}} = \\text{the mean of a predictor (j)} \\\\  \n& R_{xj}^2 = \\text{the multiple correlation coefficient of the predictors} \\\\  \n\\end{align}\n\\]\nLet’s apply to a straightforward example. Suppose you have a simple linear regression model (i.e., with only one IV, which means that \\(R_{xj}^2 = 0\\) since there is only one predictor) and the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nThere are a number of steps you need to take to calculate by hand:\n\nCalculate sum of the squared residuals\n\nCalculate predicted values\n\nCalculate residuals (i.e., the difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)) for each observation)\n\nSquare the residuals\n\nCalculate the Sum of Squared Residuals\n\n\n\nCalculate the sum of squared deviations of the (\\(x\\)) values from their mean\nUse values from 1 & 2 to calculate \\(SE(\\hat \\beta_j)\\)\n\n\nStep 1.1: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n4.9 + (0.7*1) = 5.6\n\n\n2\n7\n4.9 + (0.7*2) = 6.3\n\n\n3\n8\n4.9 + (0.7*3) = 7\n\n\n4\n6\n4.9 + (0.7*4) = 7.7\n\n\n5\n9\n4.9 + (0.7*5) = 8.4\n\n\n\nStep 1.2: Calculate residuals\n\n\\(\\epsilon_1 = 5 − 5.6 = -0.6\\)\n\\(\\epsilon_2 = 7 - 6.3 = 0.7\\)\n\\(\\epsilon_3 = 8 - 7 = 1\\)\n\\(\\epsilon_4 = 6 - 7.7 = -1.7\\)\n\\(\\epsilon_5 = 9 − 8.4 = 0.6\\)\n\nStep 1.3: Square the residuals\n\n\\(\\epsilon_1^2 = -0.6^2 = 0.36\\)\n\\(\\epsilon_2^2 = 0.7^2 = 0.49\\)\n\\(\\epsilon_3^2 = 1^2 = 1\\)\n\\(\\epsilon_4^2 = -1.7^2 = 2.89\\)\n\\(\\epsilon_5^2 = 0.6^2 = 0.36\\)\n\nStep 1.4: Calculate the Sum of Squared Residuals\n\\[\n\\sum \\epsilon_i^2 = 0.36 + 0.49 + 1 + 2.89 + 0.36 = 5.1\n\\]\nStep 2. Calculate the sum of squared deviations of the (\\(x\\)) values from their mean\nThe mean of \\(x\\) can be calculated as: \\(\\bar x = {\\frac{1+2+3+4+5}{5}} = 3\\). Using this, we can then calculate the sum of squared deviations of \\(x\\):\n\\[\n\\begin{align}\n& \\sum_{i = 1}^{n}(x_i - \\bar{x})^2 = \\\\\n& (1-3)^2 + (2-3)^2 + (3-3)^22 + (4-3)^2 + (5-3)^2 = \\\\\n& 4 + 1 + 0 + 1 + 4 = \\\\\n& 10 \\\\\n\\end{align}\n\\]\nStep 3: Calculate \\(SE(\\hat \\beta_j)\\)\nFrom this, we can finally calculate \\(SE(\\hat \\beta_j)\\):\n\\[\n\\begin{align}\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{\\text{SS}_\\text{Residual}/(n-k-1)}{\\sum(x_{ij} - \\bar{x_{j}})^2(1-R_{xj}^2)}} \\\\  \n& SE(\\hat \\beta_j) = \\sqrt{\\frac{5.1/(5-1-1)}{10 \\cdot (1-0)}} \\\\\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{5.1/3}{10}} \\\\\n& SE(\\hat \\beta_j) = \\sqrt{\\frac{1.7}{10}} \\\\\n& SE(\\hat \\beta_j) = \\sqrt{0.17} \\\\\n& SE(\\hat \\beta_j) = 0.4207\n\\\\\n\\end{align}\n\\]\n\nIn R\nIf you wanted to obtain just the standard error for each estimated regression coefficient, you could do the following (for this below example, our fitted model has been named mdl):\n\nsummary(mdl)$coefficients[,2]\n\n\n\n\nThe t-statistic is the \\(\\beta\\) coefficient divided by the standard error:\n\\[\nt = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)}\n\\]\nwhich follows a \\(t\\)-distribution with \\(n-k-1\\) degrees of freedom (where \\(k\\) = number of predictors and \\(n\\) = sample size).\nWith this, we can test the the null hypothesis \\(H_0: \\beta_j = 0\\).\nGenerally speaking, you want your model coefficients to have large \\(t\\)-statistics as this would indicate that the standard error was small in comparison to the coefficient. The larger our \\(t\\)-statistic, the more confident we can be that the coefficient is not 0.\nHow to calculate \\(t = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)}\\)\n\n\nBy Hand\nIn R\n\n\n\nWe can calculate the test statistic \\(t\\) for \\(\\beta_\\text{Age}\\) (or \\(\\beta_2\\)) by hand from our recall_multi model as follows:\n\\[\n\\begin{align}\n\\\\\n& t = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)} \\\\  \n\\\\  \n& t = \\frac{-0.3392 - 0}{0.1534} \\\\\n\\\\  \n& t = -2.211213 \\\\  \n\\\\  \n& t = -2.21 \\\\  \n\\end{align}\n\\]\nWe then need to calculate \\(t^*\\):\n\nn &lt;- nrow(recalldata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 2.109816\n\n\nAnd finally compare \\(|t|\\) to \\(t^*\\). Since \\(|t|\\) is larger than \\(t^*\\) (-2.21 &gt; 2.11), we can reject the null hypothesis.\n\n\n\nIn R\nIf you wanted to obtain just the \\(t\\)-values for each estimated regression coefficient, you could use the following:\n\ncoef(summary(mdl))[, \"t value\"]\nsummary(mdl)$coefficients[,3]\n\nFor example:\n\ncoef(summary(recall_multi))[, \"t value\"]\n\n      (Intercept) recall_confidence               age \n         2.815890          4.684654         -2.211515 \n\n\n\nsummary(recall_multi)$coefficients[,3]\n\n      (Intercept) recall_confidence               age \n         2.815890          4.684654         -2.211515 \n\n\n\n\n\n\n\n\nFrom our \\(t\\)-value, we can compute our \\(p\\)-value. The \\(p\\)-value help us to understand whether our coefficient(s) are statistically significant (i.e., that the coefficient is statistically different from 0). The \\(p\\)-value of each estimate indicates the probability of observing a \\(t\\)-value at least as extreme as, or more extreme than, the one calculated from the sample data when assuming the null hypothesis to be true.\nIn Psychology, a \\(p\\)-value &lt; .05 is usually used to make statements regarding statistical significance (it is important that you always state your \\(\\alpha\\) level to help your reader understand any statements regarding statistical significance).\nThe number of asterisks marks corresponds with the significance of the coefficient (see the ‘Signif. codes’ legend just under the coefficients section).\n\nIn R\nIf you wanted to obtain just the \\(p\\)-values for each estimated regression coefficient, you could do the following (for this below example, our fitted model has been named mdl):\n\nsummary(mdl)$coefficients[,4]\n\n\n\n\n\n\n\n\n\n\n Confidence Intervals\n\n\nUsing the estimate and standard error of a given \\(\\beta\\) coefficient, we can create confidence intervals to estimate a plausible range of values for the true population parameter. Recall the formula for obtaining a confidence interval for the population slope is:\n\\[\n\\hat \\beta_j \\pm t^* \\cdot SE(\\hat \\beta_j)\n\\]\nwhere \\(t^*\\) denotes the critical value chosen from \\(t\\)-distribution with \\(n-k-1\\) degrees of freedom (where \\(k\\) = number of predictors and \\(n\\) = sample size) for a desired \\(\\alpha\\) level of confidence.\nHow to calculate \\(\\hat \\beta_j \\pm t^* \\cdot SE(\\hat \\beta_j)\\)\n\n\nBy Hand\nUsing R\n\n\n\nTo calculate by hand for \\(\\hat \\beta_\\text{Age}\\) from our recall_multi model, we first need to calculate \\(t^*\\):\n\nn &lt;- nrow(recalldata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 2.109816\n\n\nFor 95% confidence intervals, we use \\(t^* = 2.1098\\), and can simply substitute into the formula:\n\\[\n\\begin{align}\n& \\text{Lower CI} = \\hat \\beta_\\text{Age} - t^* \\cdot SE(\\hat \\beta_\\text{Age}) \\\\  \n& \\text{Lower CI} = -0.3392 - (2.1098 \\cdot 0.1534) \\\\  \n& \\text{Lower CI} = -0.6628433 \\\\\n& \\text{Lower CI} = -0.663 \\\\\n\\\\    \n& \\text{Upper CI} = \\hat \\beta_\\text{Age} + t^* \\cdot SE(\\hat \\beta_\\text{Age}) \\\\  \n& \\text{Upper CI} = -0.3392 + (2.1098 \\cdot 0.1534) \\\\\n& \\text{Upper CI} = -0.01555668 \\\\\n& \\text{Upper CI} = -0.016 \\\\\n\\end{align}\n\\]\n\n\n\nIn R\nWe can obtain the confidence intervals for the regression coefficients using the command confint().\n\nconfint(recall_multi)\n\n                       2.5 %      97.5 %\n(Intercept)        9.0668871 63.25228524\nrecall_confidence  0.4923220  1.29913640\nage               -0.6627188 -0.01559663\n\n\nOr alternatively use R to compute using the manual process (though it makes more sense to use confint() given it is less prone to typos!):\n\ntibble(\n  b2_LowerCI = round(-0.3392 - (qt(0.975, n-3) * 0.1534), 3),\n  b2_UpperCI = round(-0.3392 + (qt(0.975, n-3) * 0.1534), 3)\n      )\n\n# A tibble: 1 × 2\n  b2_LowerCI b2_UpperCI\n       &lt;dbl&gt;      &lt;dbl&gt;\n1     -0.663     -0.016\n\n\n\n\n\n\n\n\n\n\n\n \\(\\sigma\\)\n\n\n\n\n\n\nMultiple regression output in R, model standard deviation of the errors highlighted\n\n\n\nThe standard deviation of the errors, denoted by \\(\\sigma\\), is an important quantity that our model estimates. It represents how much individual data points tend to deviate above and below the regression line - in other words, it tells us how well the model fits the data.\nA small \\(\\sigma\\) indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large \\(\\sigma\\) suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\nThe estimated standard deviation of the errors is denoted \\(\\hat \\sigma\\), and is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root:\n\\[\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{\\text{SS}_\\text{Residual}}{n - k - 1}} \\\\\n\\qquad \\\\\n& \\text{Where:}  \\\\\n& \\text{SS}_\\text{Residual} = \\textrm{Sum of Squared Residuals} = \\sum_{i=1}^n{(\\epsilon_i)^2} \\\\\n\\\\  \n\\\\  \n& \\text{and so, equivalently:} \\\\  \n\\\\  \n& \\hat \\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{n - k - 1}} \\\\\n\\end{align}\n\\]\nHow to calculate \\(\\hat \\sigma\\)\n\n\nBy Hand\nUsing R\n\n\n\nThere are a number of steps you need to take to calculate by hand:\n\nCalculate predicted values\nCalculate residuals (i.e., the difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)) for each observation)\n\nSquare the residuals\n\nCalculate the Sum of Squared Residuals\n\nDetermine the Residual Standard Deviation (\\(\\sigma\\))\n\nLet’s apply to a straightforward example. Suppose you have a simple linear regression model (i.e., with only one IV) and the following data points:\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nStep 1: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n4.9 + (0.7*1) = 5.6\n\n\n2\n7\n4.9 + (0.7*2) = 6.3\n\n\n3\n8\n4.9 + (0.7*3) = 7\n\n\n4\n6\n4.9 + (0.7*4) = 7.7\n\n\n5\n9\n4.9 + (0.7*5) = 8.4\n\n\n\nStep 2: Calculate residuals\n\n\\(\\epsilon_1 = 5 − 5.6 = -0.6\\)\n\\(\\epsilon_2 = 7 - 6.3 = 0.7\\)\n\\(\\epsilon_3 = 8 - 7 = 1\\)\n\\(\\epsilon_4 = 6 - 7.7 = -1.7\\)\n\\(\\epsilon_5 = 9 − 8.4 = 0.6\\)\n\nStep 3: Square the residuals\n\n\\(\\epsilon_1^2 = -0.6^2 = 0.36\\)\n\\(\\epsilon_2^2 = 0.7^2 = 0.49\\)\n\\(\\epsilon_3^2 = 1^2 = 1\\)\n\\(\\epsilon_4^2 = -1.7^2 = 2.89\\)\n\\(\\epsilon_5^2 = 0.6^2 = 0.36\\)\n\nStep 4: Calculate the Sum of Squared Residuals\n\\[\n\\sum \\epsilon_i^2 = 0.36 + 0.49 + 1 + 2.89 + 0.36 = 5.1\n\\]\nStep 5: Determine the Residual Standard Deviation (\\(\\sigma\\))\n\\[\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{\\text{SS}_\\text{Residual}}{n - k - 1}} \\\\  \n\\\\   \n& \\hat \\sigma = \\sqrt{\\frac{5.1}{5 - 1 - 1}}  \\\\  \n\\\\   \n& \\hat \\sigma = \\sqrt{\\frac{5.1}{3}}  \\\\  \n\\\\   \n& \\hat \\sigma = \\sqrt{1.70}  \\\\    \n\\\\  \n& \\hat \\sigma = 1.304  \\\\  \n\\end{align}\n\\]\n\n\n\nIn R\nThere are a couple of equivalent ways to obtain the estimated standard deviation of the errors — that is, \\(\\hat \\sigma\\) — from the fitted model (for this example, our fitted model has been named mdl):\n\nsigma(mdl)\nsummary(mdl)"
  },
  {
    "objectID": "1_b3_reading.html#additive-models",
    "href": "1_b3_reading.html#additive-models",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Additive Models",
    "text": "Additive Models\n\n Steps In R\n\n\nAfter specifying our hypotheses, to test our contrasts, we can use the emmeans package and follow the below structure:\n\n\nStep 1: Fit and run the model using lm()\n\n\nStep 2: Use the emmeans() function to obtain the estimated means of each group. You can visualise these by using plot() on the obtained estimated means of the groups\n\nStep 3: Check the order of your levels via levels()\n\n\nStep 4: Define the contrast by specifying the weights following the rules outlined above (as well as paying attention to the ordering of the levels)\n\nStep 5: Test the pre-specified group contrast(s) via contrast()\n\n\nStep 6: Obtain confidence intervals via confint()\n\n\nAfter completing these steps, the last task would be to interpret the results of the contrast analysis in the context of the hypothesis.\n\n\n\nExample\n\nResearch Question\nDoes the sepal length of an iris grown in Western states (i.e., iris setosa) differ from the sepal length of an Iris grown in Eastern states (i.e., iris versicolor and virginica)?\n\n\n Specify Hypotheses\n\n\nBased on the research question, we are asking whether there is a difference between the average sepal length of iris setosa (Western states), and the combined average sepal length of iris versicolor and iris virginica (Eastern state)s. To assess this for the Eastern states, we need to compute the average of the mean sepal lengths of the two species, iris versicolor and iris virginica.\nWith this in mind, we could specify our hypotheses as:\n\\[\n\\begin{aligned}\n    \\quad H_0 &: \\mu_\\text{Western} = \\mu_\\text{Eastern} \\\\\n    \\\\  \n    \\quad H_0 &: \\mu_\\text{Setosa} = \\frac{1}{2} (\\mu_\\text{Versicolor} + \\mu_\\text{Virginica}) \\\\\n\\\\  \n\\\\\n    \\quad H_1 &: \\mu_\\text{Western} \\neq \\mu_\\text{Eastern} \\\\\n    \\\\\n    \\quad H_1 &: \\mu_\\text{Setosa} \\neq \\frac{1}{2} (\\mu_\\text{Versicolor} + \\mu_\\text{Virginica}) \\\\\n\\\\\n\\end{aligned}\n\\]\n\n\n\n\n\n Conduct Contrast Analysis\n\n\nFollow steps 1-6 outlined above:\n\n# Step 1: Fit and run the model \nspec_model &lt;- lm(Sepal.Length ~ Species, data = iris)\n\n\n# Step 2: Use`emmeans()`& `plot()`\nlibrary(emmeans)\nseplength_mean &lt;- emmeans(spec_model, ~ Species)\nseplength_mean \n\n Species    emmean     SE  df lower.CL upper.CL\n setosa       5.01 0.0728 147     4.86     5.15\n versicolor   5.94 0.0728 147     5.79     6.08\n virginica    6.59 0.0728 147     6.44     6.73\n\nConfidence level used: 0.95 \n\nplot(seplength_mean)\n\n\n\n\n\n\n\n\n# Step 3: Check levels order via `levels()`\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\n\n# Step 4: Define contrast & weights - want to compare Iris setosa to iris versicolor and iris virginica\nseplength_comp &lt;- list(\"Western State Iris - Eastern State Iris\" = c(-1, 1/2, 1/2))\n\n\n# Step 5: run contrast analysis\nseplength_comp_test &lt;- contrast(seplength_mean, method = seplength_comp)\nseplength_comp_test\n\n contrast                                estimate     SE  df t.ratio p.value\n Western State Iris - Eastern State Iris     1.26 0.0892 147  14.086  &lt;.0001\n\n\n\n# Step 6: confidence intervals\nconfint(seplength_comp_test)\n\n contrast                                estimate     SE  df lower.CL upper.CL\n Western State Iris - Eastern State Iris     1.26 0.0892 147     1.08     1.43\n\nConfidence level used: 0.95 \n\n\n\n# Bonus Step: Run inferential test and return CIs in one command\nsummary(seplength_comp_test, infer = TRUE)\n\n contrast                                estimate     SE  df lower.CL upper.CL\n Western State Iris - Eastern State Iris     1.26 0.0892 147     1.08     1.43\n t.ratio p.value\n  14.086  &lt;.0001\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n Results Interpretation\n\n\nImportant to write up our findings in the context of the hypothesis / research question:\n\n\n\n\n\n\nWe performed a test against \\(H_0: \\mu_\\text{Setosa} = \\frac{1}{2} (\\mu_\\text{Versicolor} + \\mu_\\text{Virginica}) = 0\\). At the 5% significance level, there was evidence that iris sepal length significantly differed between Western and Eastern states in the US \\((t(147) = 14.09, p &lt; .001, \\text{two-sided})\\), and this difference was estimated to be \\(1.26~cm\\). We are 95% confident that an iris grown in an Eastern state, on average, would be between \\(1.08~cm\\) and \\(1.43~cm\\) longer than those grown in a Western state \\((CI_{95}[1.08, 1.43])\\)."
  },
  {
    "objectID": "1_b3_reading.html#interaction-models-1",
    "href": "1_b3_reading.html#interaction-models-1",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Interaction Models",
    "text": "Interaction Models\n\n Steps in R\n\n\nAfter specifying our hypotheses, to test our contrasts, we can use the emmeans package and follow the below structure:\n\n\nStep 1: Fit and run the model using lm()\n\n\nStep 2: Specify the coefficients to be used in the contrast analysis and present in a table\n\nStep 3: Use the emmeans() function to obtain the estimated means of each group. You can visualise these by using plot() on the obtained estimated means of the groups\n\nStep 4: Define the contrast by specifying the weights following the rules outlined above (as well as paying attention to the ordering of the groups as specified in the output of Step 3)\n\nStep 5: Test the pre-specified group contrast(s) via contrast()\n\n\nStep 6: Obtain confidence intervals via confint()\n\n\nAfter completing these steps, the last task would be to interpret the results of the contrast analysis in the context of the hypothesis.\n\n\n\nExample\n\nResearch Question\nDoes the difference in body mass between male and female penguins differ between those residing exclusively on the Antarctic Continent (i.e., Adelie) and those living in both Antarctica and the sub-Antarctic islands (i.e., Gentoo and Chinstrap)?\n\n\n Specify Hypotheses\n\n\nWe could specify our hypothesis as:\n\\[\n\\begin{aligned}\n    H_0 &: \\mu_\\text{(Male, Antarctic Continent)} - \\mu_\\text{(Female, Antarctic Continent)} = \\\\\n    &\\mu_\\text{(Male, Northern Antarctica | sub-Antarctic islands)} - \\mu_\\text{(Female, Northern Antarctica | sub-Antarctic islands)}\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n    H_1 &: \\mu_\\text{(Male, Antarctic Continent)} - \\mu_\\text{(Female, Antarctic Continent)} \\neq \\\\\n    &\\mu_\\text{(Male, Northern Antarctica | sub-Antarctic islands)}) - (\\mu_\\text{(Female, Northern Antarctica | sub-Antarctic islands)})\n\\end{aligned}\n\\]\nOr equivalently as:\n\\[\n\\begin{aligned}\nH_0 &: \\mu_\\text{(Male, Adelie)} - \\mu_\\text{(Female, Adelie)} = \\\\\n   & \\frac{1}{2} (\\mu_\\text{(Male, Gentoo)} + \\mu_\\text{(Male, Chinstrap)}) - \\frac{1}{2}(\\mu_\\text{(Female, Gentoo)} + \\mu_\\text{(Female, Chinstrap)}) \\\\\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nH_1 &: \\mu_\\text{(Male, Adelie)} - \\mu_\\text{(Female, Adelie)} \\neq \\\\\n    &\\frac{1}{2} (\\mu_\\text{(Male, Gentoo)} + \\mu_\\text{(Male, Chinstrap)}) - \\frac{1}{2}(\\mu_\\text{(Female, Gentoo)} + \\mu_\\text{(Female, Chinstrap)}) \\\\\n\\end{aligned}\n\\]\n\n\n\n\n\n Conduct Contrast Analysis\n\n\nFollow the steps as outlined above:\n\n# Step 1: Fit and run the model \nmdl_cc &lt;- lm(body_mass_g ~ species * sex, data = penguins)\n\n\n# Step 2: Specify the coefficients to be used in the contrast analysis, and present in a formatted table\n\n#TWO EQUALLY VALID WAYS TO DO THIS - SELECT ONLY ONE:\n#Option 1:\nspecies_coef  &lt;- c('Adelie' = -1, 'chinstrap' = 0.5, 'Gentoo' = 0.5)\nsex_coef  &lt;- c('male' = -1, 'female' = 1)\ncontr_coef &lt;- outer(species_coef, sex_coef)\ncontr_coef\n\n          male female\nAdelie     1.0   -1.0\nchinstrap -0.5    0.5\nGentoo    -0.5    0.5\n\n#Option 2:\nspecies_coef  &lt;- c('Adelie' = -1, 'chinstrap' = 0.5, 'Gentoo' = 0.5)\nsex_coef  &lt;- c('male' = -1, 'female' = 1)\ncontr_coef_2 &lt;- species_coef %o% sex_coef\ncontr_coef_2\n\n          male female\nAdelie     1.0   -1.0\nchinstrap -0.5    0.5\nGentoo    -0.5    0.5\n\n#Convert into a well-formatted table:\ncontr_coef |&gt; \n    kable(caption = \"Penguin Contrast Weights\") |&gt;\n    kable_styling(full_width = FALSE) \n\n\nPenguin Contrast Weights\n\n\nmale\nfemale\n\n\n\nAdelie\n1.0\n-1.0\n\n\nchinstrap\n-0.5\n0.5\n\n\nGentoo\n-0.5\n0.5\n\n\n\n\n\n\n# Step 3: Use`emmeans()`& `plot()`\nspecies_sex_mean &lt;- emmeans(mdl_cc, ~ species*sex)\nspecies_sex_mean\n\n species   sex    emmean   SE  df lower.CL upper.CL\n Adelie    female   3369 36.2 327     3298     3440\n Chinstrap female   3527 53.1 327     3423     3632\n Gentoo    female   4680 40.6 327     4600     4760\n Adelie    male     4043 36.2 327     3972     4115\n Chinstrap male     3939 53.1 327     3835     4043\n Gentoo    male     5485 39.6 327     5407     5563\n\nConfidence level used: 0.95 \n\nplot(species_sex_mean)\n\n\n\n\n\n\n\n\n# Step 4/5: Define contrast & weights, and give a name to this contrast \nspecies_sex_comp &lt;- contrast(species_sex_mean,\n                             method = list('Penguin Hyp' = c(-1, 0.5, 0.5, 1, -0.5, -0.5))\n                     )\n\n\n# Step 6: examine output and return inferential stats - CIs, t-ratio, p-value\n\n#OPTION 1:\n#examine output\nspecies_sex_comp\n\n contrast    estimate   SE  df t.ratio p.value\n Penguin Hyp     66.2 69.5 327   0.952  0.3416\n\n#obtain confidence intervals\nconfint(species_sex_comp)\n\n contrast    estimate   SE  df lower.CL upper.CL\n Penguin Hyp     66.2 69.5 327    -70.6      203\n\nConfidence level used: 0.95 \n\n#OPTION 2:\nsummary(species_sex_comp, infer = TRUE)\n\n contrast    estimate   SE  df lower.CL upper.CL t.ratio p.value\n Penguin Hyp     66.2 69.5 327    -70.6      203   0.952  0.3416\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n Results Interpretation\n\n\nImportant to write up our findings in the context of the hypothesis / research question:\n\n\n\n\n\n\nAt the 5% significance level, there was no evidence that the difference in body weight between male and female penguins differed by where the species was based geographically \\((t(327) = 0.95, p = .342, \\text{two-sided})\\)."
  },
  {
    "objectID": "1_b3_reading.html#multiple-comparisons",
    "href": "1_b3_reading.html#multiple-comparisons",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Multiple Comparisons",
    "text": "Multiple Comparisons\n\n Pairwise Comparisons\n\n\nWe can use pairwise comparisons when we want to compare all levels of an independent variable with all the levels of the other. In other words, we can compare all pairwise means between groups to determine whether there is a statistical difference between each pair of groups compared.\nFor example, let’s say that you had 2 categorical variables - Day (5 levels: Mon, Tue, Wed, Thurs, and Fri) and Time (3 levels: Morning, Afternoon, and Evening) where your outcome variable was productivity level (scored on a scale 0-50). If we were to conduct all possible pairwise comparisons, this would lead to the following pairs of groups being compared on productivity:\n\nMon - Morning\n\nMon - Afternoon\n\nMon - Evening\n\nTue - Morning\n\nTue - Afternoon\n\nTue - Evening\n\nWed - Morning\n\nWed - Afternoon\n\nWed - Evening\n\nThurs - Morning\n\nThurs - Afternoon\n\nThurs - Evening\n\nFri - Morning\n\nFri - Afternoon\n\nFri - Evening\n\n\nIn R\n\n#run comparisons\npair_comp &lt;- pairs(&lt;INSERT OBJECT NAME&gt;)\n\n#examine output\npair_comp\n\n#plot comparisons\nplot(pair_comp)\n\n\n\n\n\n\n\n Why does the Number of Tests Matter?\n\n\nIf we are conducting all possible pairwise comparisons, we can calculate how many tests are being conducted via the following rule:\n\\[\n_nC_r = \\frac{n!}{r!(n-r)!} \\\\\n\\] \\[\n\\begin{align} \\\\\n& \\text{Where:} \\\\\n& n = \\text{total number in the set} \\\\\n& r = \\text{number chosen} \\\\\n& _nC_r = \\text{number of combinations of r from n} \\\\\n\\end{align}\n\\]\nSo, why does the number of tests matter? First, think back to “Type 1 errors” from DAPR1 - when we conduct an hypothesis test, and we set \\(\\alpha = .05\\), we will reject the null hypothesis \\(H_0\\) when we find a \\(p &lt; .05\\). Now remember what a \\(p\\)-value represents - it is the chance of observing a statistic at least as extreme as the one we do have, assuming the null hypothesis to be true. This means that if \\(H_0\\) is true, then we will still observe a \\(p &lt; .05\\) 5% of the time. So our chance of making this error = the threshold (\\(\\alpha\\)) at which below a \\(p\\)-value results in us rejecting \\(H_0\\).\nBut this error-rate applies to each statistical hypothesis we test. So if we conduct an experiment in which we plan on conducting lots of tests of different comparisons, the chance of an error being made increases substantially. Across the family of tests performed that chance will be much higher than 5%.5\nEach test conducted at \\(\\alpha = .05\\) has a .05 (or 5%) probability of Type I error (wrongly rejecting the null hypothesis). If we do 9 tests, that experiment-wise error rate is \\(\\alpha_{ew} \\leq 9 \\times .05\\), where 9 is the number of comparisons made as part of the experiment.\nThus, if nine independent comparisons were made at the \\(\\alpha = .05\\) level, the experiment-wise Type I error rate \\(\\alpha_{ew}\\) would be at most \\(9 \\times .05 = 0.45\\). That is, we could wrongly reject the null hypothesis on average 45 times out of 100.\nTo make this more confusing, many of the tests in a family are not independent (see the lecture slides for the calculation of error rate for dependent tests).\n\n\n\n\n\n When to use Which Correction\n\n\nBonferroni\n\nCalculated as:\n\\(\\alpha_{Bonferroni} = \\frac{\\alpha}{m} \\qquad \\qquad p_{Bonferroni} = p \\cdot m\\)\nwhere \\(\\alpha\\) = alpha level, and \\(m\\) = number of tests\n\n\nUse Bonferroni’s method when you are interested in a small number of planned contrasts (or pairwise comparisons).\nBonferroni’s method is to divide alpha by the number of tests/confidence intervals.\nAssumes that all comparisons are independent of one another.\n\nIt sacrifices slightly more power than Tukey’s method (discussed below under Others), but it can be applied to any set of contrasts or linear combinations (i.e., it is useful in more situations than Tukey).\nIt is usually better than Tukey if we want to do a small number of planned comparisons.\n\n\n\n\n\n\n\nOptional (non-assessed): More Options!\n\n\n\n\n\nŠídák\n\nCalculated as:\n\\(\\alpha_{Sidák} = 1 - (1- \\alpha)^{\\frac{1}{m}}\\)\nwhere \\(\\alpha\\) = alpha level, and \\(m\\) = number of tests\n\n\n(A bit) more powerful than the Bonferroni method.\nAssumes that all comparisons are independent of one another.\nLess common than Bonferroni method, largely because it is more difficult to calculate (not a problem now we have computers).\n\nScheffe\n\nCalculated as:\n\\(\\sqrt{rF(\\alpha; r; d)}\\)\nwhere \\(\\alpha\\) = alpha level, \\(r\\) = number of restrictions (i.e., contrasts; calculated as number of means being compared - 1), \\(F\\) = \\(F\\) critical value, and \\(d\\) = \\(df_{error}\\) from linear model\n\n\nIt is the most conservative (least powerful) of all tests.\nIt controls the family alpha level for testing all possible contrasts.\nIt should be used if you have not planned contrasts in advance.\nFor testing pairs of treatment means it is too conservative (you should use Bonferroni or Šídák).\n\nOthers\n\nTukey is a very commonly used correction (how the formula is derived is quite complex and way beyond the content of DAPR2). It is helpful to know that it (1) specifies an exact family significance level for comparing all pairs of treatment means, and (2) it is most commonly used when you are interested in all (or most) pairwise comparisons of means.\n\nIn the wider literature, Holm’s step-down and Hochberg’s step-up mentioned. Do feel free to read about these in your spare time - there are lots of resources online.\n\n\n\n\n\nIn R\nYou can easily change which correction you are using via the adjust = argument. For example, using our categorical x categorical interaction model (mdl_cc) using the penguins dataset:\n\n\nNo Adjustment\nBonferroni\nScheffe\nŠídák\nTukey\n\n\n\n\nnone_pair_comp &lt;- pairs(mdl_cc_emm, adjust = \"none\")\n\nnone_pair_comp\n\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.0142\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  &lt;.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  &lt;.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  &lt;.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  &lt;.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  &lt;.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  &lt;.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  &lt;.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  &lt;.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  &lt;.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  &lt;.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  &lt;.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  0.1047\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  &lt;.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  &lt;.0001\n\nplot(none_pair_comp)\n\n\n\n\n\n\n\n\n\n\nbonf_pair_comp &lt;- pairs(mdl_cc_emm, adjust = \"bonferroni\")\n\nbonf_pair_comp\n\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.2131\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  &lt;.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  &lt;.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  &lt;.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  &lt;.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  &lt;.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  &lt;.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  &lt;.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  &lt;.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  &lt;.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  &lt;.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  &lt;.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  1.0000\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  &lt;.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  &lt;.0001\n\nP value adjustment: bonferroni method for 15 tests \n\nplot(bonf_pair_comp)\n\n\n\n\n\n\n\n\n\n\nscheffe_pair_comp &lt;- pairs(mdl_cc_emm, adjust = \"scheffe\")\n\nscheffe_pair_comp\n\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.3014\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  &lt;.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  &lt;.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  &lt;.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  &lt;.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  &lt;.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  &lt;.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  &lt;.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  &lt;.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  &lt;.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  &lt;.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  &lt;.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  0.7539\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  &lt;.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  &lt;.0001\n\nP value adjustment: scheffe method with rank 5 \n\nplot(scheffe_pair_comp)\n\n\n\n\n\n\n\n\n\n\nsidak_pair_comp &lt;- pairs(mdl_cc_emm, adjust = \"sidak\")\n\nsidak_pair_comp\n\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.1931\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  &lt;.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  &lt;.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  &lt;.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  &lt;.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  &lt;.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  &lt;.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  &lt;.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  &lt;.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  &lt;.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  &lt;.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  &lt;.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  0.8096\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  &lt;.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  &lt;.0001\n\nP value adjustment: sidak method for 15 tests \n\nplot(sidak_pair_comp)\n\n\n\n\n\n\n\n\n\n\ntukey_pair_comp &lt;- pairs(mdl_cc_emm, adjust = \"tukey\")\n\ntukey_pair_comp\n\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.1376\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  &lt;.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  &lt;.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  &lt;.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  &lt;.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  &lt;.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  &lt;.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  &lt;.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  &lt;.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  &lt;.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  &lt;.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  &lt;.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  0.5812\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  &lt;.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\nplot(tukey_pair_comp)"
  },
  {
    "objectID": "1_b3_reading.html#linear-models",
    "href": "1_b3_reading.html#linear-models",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Linear Models",
    "text": "Linear Models\nAssessing model fit involves examining metrics like the sum of squares to measure variability explained by the model, the \\(F\\)-ratio to evaluate the overall significance of the model by comparing explained variance to unexplained variance, and \\(R\\)-squared / Adjusted \\(R\\)-squared to quantify the proportion of variance in the dependent variable explained by the independent variable(s).\n\n Sums of Squares\n\n\nTo quantify and assess a model’s utility in explaining variance in an outcome variable, we can split the total variability of that outcome variable into two terms: the variability explained by the model plus the variability left unexplained in the residuals.\nThe sum of squares measures the deviation or variation of data points away from the mean (i.e., how spread out are the numbers in a given dataset). We are trying to find the equation/function that best fits our data by varying the least from our data points.\nTotal Sum of Squares\nFormula:\n\\[\n\\text{SS}_\\text{Total} = \\sum_{i=1}^{n}(y_i - \\bar{y})^2\n\\] Can also be derived from:\n\\[\n\\text{SS}_\\text{Total} = \\text{SS}_\\text{Model} + \\text{SS}_\\text{Residual}\n\\]\nIn words:\nSquared distance of each data point from the mean of \\(y\\).\nDescription:\nHow much variation there is in the DV.\nExample:\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nSteps:\n\nCalculate the mean of \\(y\\) (\\(\\bar y\\))\n\nCalculate for each observation \\(y_i\\) - \\(\\bar y\\)\n\nSquare each of the obtained \\(y_i\\) - \\(\\bar y\\) values\n\nSum squared values\n\nStep 1: Calculate the mean of \\(y_i\\)\n\\(\\bar y = {\\frac{5+7+8+6+9}{5}} = 7\\)\nStep 2 & 3: Calculate for each observation \\(y_i\\) - \\(\\bar y\\) & square values\n\n\nObserved \\(y_i\\)\n\n\n\\(y_i\\) - \\(\\bar y\\)\n\n\\((y_i - \\bar y)^2\\)\n\n\n\n5\n5 - 7 = -2\n\\(-2^2 = 4\\)\n\n\n7\n7 - 7 = 0\n\\(0^2 = 0\\)\n\n\n8\n8 - 7 = 1\n\\(1^2 = 1\\)\n\n\n6\n6 - 7 = -1\n\\(-1^2 = 1\\)\n\n\n9\n9 - 7 = 2\n\\(2^2 = 4\\)\n\n\n\nStep 4: Calculate sum squared values\n\\(\\text{SS}_\\text{Total} = 4 + 0 + 1 + 1 + 4 = 10\\)\nResidual Sum of Squares\nFormula:\n\\[\n\\text{SS}_\\text{Residual} = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n\\]\nIn words:\nSquared distance of each point from the predicted value.\nDescription:\nHow much of the variation in the DV the model did not explain - a measure that captures the unexplained variation in your regression model. Lower residual sum of squares suggests that your model fits the data well, and higher suggests that the model poorly explains the data (in other words, the lower the value, the better the regression model). If the value was zero here, it would suggest the model fits perfectly with no error.\nExample:\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nSteps:\n\nCalculate predicted values (\\(\\hat{y}_i\\))\n\nCalculate residuals (i.e., the difference between the observed value (\\(y_i\\)) and the predicted value (\\(\\hat{y}_i\\)) for each observation)\n\nSquare the residuals\n\nSum squared values\n\nStep 1: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n\\(4.9 + (0.7*1) = 5.6\\)\n\n\n2\n7\n\\(4.9 + (0.7*2) = 6.3\\)\n\n\n3\n8\n\\(4.9 + (0.7*3) = 7\\)\n\n\n4\n6\n\\(4.9 + (0.7*4) = 7.7\\)\n\n\n5\n9\n\\(4.9 + (0.7*5) = 8.4\\)\n\n\n\nStep 2: Calculate residuals\n\n\\(\\epsilon_1 = 5 − 5.6 = -0.6\\)\n\\(\\epsilon_2 = 7 - 6.3 = 0.7\\)\n\\(\\epsilon_3 = 8 - 7 = 1\\)\n\\(\\epsilon_4 = 6 - 7.7 = -1.7\\)\n\\(\\epsilon_5 = 9 − 8.4 = 0.6\\)\n\nStep 3: Square the residuals\n\n\\(\\epsilon_1^2 = -0.6^2 = 0.36\\)\n\\(\\epsilon_2^2 = 0.7^2 = 0.49\\)\n\\(\\epsilon_3^2 = 1^2 = 1\\)\n\\(\\epsilon_4^2 = -1.7^2 = 2.89\\)\n\\(\\epsilon_5^2 = 0.6^2 = 0.36\\)\n\nStep 4: Calculate sum of squared values\n\\(\\text{SS}_\\text{Residual} = 0.36 + 0.49 + 1 + 2.89 + 0.36 = 5.1\\)\nModel Sum of Squares\nFormula:\n\\[\n\\text{SS}_\\text{Model} = \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2\n\\]\nCan also be derived from:\n\\[\n\\text{SS}_\\text{Model} = \\text{SS}_\\text{Total} - \\text{SS}_\\text{Residual}\n\\]\nIn words:\nThe deviance of the predicted scores from the mean of \\(y\\).\nDescription:\nHow much of the variation in the DV your model explained - like a measure that captures how well the regression line fits your data.\nExample:\nLet’s apply to a straightforward example to try by-hand. Suppose you have a simple linear regression model (i.e., with only one IV) where you have the following data points:\n\n\nObserved \\(x_i\\)\n\nObserved \\(y_i\\)\n\n\n\n\n1\n5\n\n\n2\n7\n\n\n3\n8\n\n\n4\n6\n\n\n5\n9\n\n\n\nSteps:\n\nCalculate mean of \\(y\\) (\\(\\bar y\\))\n\nCalculate predicted values (\\(\\hat{y}_i\\))\n\nCalculate for each observation \\(\\hat{y}_i - \\bar y\\)\n\nSquaring each of the obtained \\(\\hat{y}_i - \\bar y\\) values\n\nSum squared values\n\nStep 1: Calculate the mean of \\(y_i\\) \n\\(\\bar y = {\\frac{5+7+8+6+9}{5}} = 7\\)\nStep 2: Calculate predicted values\nUsing \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\cdot x_i\\) and our model coefficients \\(\\beta_0 = 4.9\\) and \\(\\beta_1 = 0.7\\):\n\n\nObserved (\\(x_i\\))\nObserved (\\(y_i\\))\nPredicted (\\(\\hat{y}_i\\))\n\n\n\n1\n5\n\\(4.9 + (0.7*1) = 5.6\\)\n\n\n2\n7\n\\(4.9 + (0.7*2) = 6.3\\)\n\n\n3\n8\n\\(4.9 + (0.7*3) = 7\\)\n\n\n4\n6\n\\(4.9 + (0.7*4) = 7.7\\)\n\n\n5\n9\n\\(4.9 + (0.7*5) = 8.4\\)\n\n\n\nStep 3 & 4: Calculate for each observation \\(\\hat{y}_i\\) - \\(\\bar y\\) & square values\n\n\n\n\\(\\hat{y}_i\\) - \\(\\bar y\\)\n\n\\((\\hat{y}_i - \\bar y)^2\\)\n\n\n\n\\(5.6 - 7 = -1.4\\)\n\\((-1.4)^2 = 1.96\\)\n\n\n\\(6.3 - 7 = -0.7\\)\n\\((-0.7)^2 = 0.49\\)\n\n\n\\(7 - 7 = 0\\)\n\\((0)^2 = 0\\)\n\n\n\\(7.7 - 7 = 0.7\\)\n\\((0.7)^2 = 0.49\\)\n\n\n\\(8.4 - 7 = 1.4\\)\n\\((1.4)^2 = 1.96\\)\n\n\n\nStep 5: Calculate sum of squared values\n\\(\\text{SS}_\\text{Model} = 1.96 + 0.49 + 0 + 0.49 + 1.96 = 4.9\\)\nAlternatively:\n\\[\n\\begin{align}\n& \\text{SS}_\\text{Model} = \\text{SS}_\\text{Total} - \\text{SS}_\\text{Residual} \\\\\n& \\text{SS}_\\text{Model} = 10 - 5.1 \\\\  \n& \\text{SS}_\\text{Model} = 4.9 \\\\  \n\\end{align}\n\\]\n\n\n\n\n\n\n F-ratio\n\n\nOverview:\nWe can perform a test to investigate if a model is ‘useful’ — that is, a test to see if our explanatory variable explains more variance in our outcome than we would expect by just some random chance variable.\nWith one predictor, the \\(F\\)-statistic is used to test the null hypothesis that the regression slope for that predictor is zero:\n\\[\nH_0: \\text{the model is ineffective, }b_1 = 0 \\\\  \n\\] \\[\nH_1 : \\text{the model is effective, }b_1  \\neq 0 \\\\  \n\\]\nIn multiple regression, the logic is the same, but we are now testing against the null hypothesis that all regression slopes are zero. Our test is framed in terms of the following hypotheses:\n\\[\nH_0: \\text{the model is ineffective, }b_1,...., b_k = 0 \\\\    \n\\]\n\\[\nH_1 : \\text{the model is effective, }b_1,...., b_k  \\neq 0 \\\\  \n\\]\nThe relevant test-statistic is the \\(F\\)-statistic, which uses “Mean Squares” (these are Sums of Squares divided by the relevant degrees of freedom). We then compare that against (you guessed it) an \\(F\\)-distribution! \\(F\\)-distributions vary according to two parameters, which are both degrees of freedom.\nFormula:\n\\[\n\\text{F}_{(df_{model},~df_{residual})} = \\frac{\\text{MS}_\\text{Model}}{\\text{MS}_\\text{Residual}} = \\frac{\\text{SS}_\\text{Model}/\\text{df}_\\text{Model}}{\\text{SS}_\\text{Residual}/\\text{df}_\\text{Residual}} \\\\\n\\quad \\\\\n\\]\n\\[\n\\begin{align}\n& \\text{Where:} \\\\\n& df_{model} = k \\\\\n& df_{residual} = n-k-1 \\\\\n& n = \\text{sample size} \\\\\n& k  = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\nDescription:\nTo test the significance of an overall model, we can conduct an \\(F\\)-test. The \\(F\\)-test compares your model to a model containing zero predictor variables (i.e., the intercept only model), and tests whether your added predictor variables significantly improved the model.\nIt is called the \\(F\\)-ratio because it is the ratio of the how much of the variation is explained by the model (per parameter) versus how much of the variation is unexplained (per remaining degrees of freedom).\nThe \\(F\\)-test involves testing the statistical significance of the \\(F\\)-ratio.\nQ: What does the \\(F\\)-ratio test?A: The null hypothesis that all regression slopes in a model are zero (i.e., explain no variance in your outcome/DV). The alternative hypothesis is that at least one of the slopes is not zero.\nThe \\(F\\)-ratio you see at the bottom of summary(model) is actually a comparison between two models: your model (with some explanatory variables in predicting \\(y\\)) and the null model.\nIn regression, the null model can be thought of as the model in which all explanatory variables have zero regression coefficients. It is also referred to as the intercept-only model, because if all predictor variable coefficients are zero, then we are only estimating \\(y\\) via an intercept (which will be the mean - \\(\\bar y\\)).\nInterpretation:\nAlongside viewing the \\(F\\)-ratio, you can see the results from testing the null hypothesis that all of the coefficients are \\(0\\) (the alternative hypothesis is that at least one coefficient is \\(\\neq 0\\). Under the null hypothesis that all coefficients = 0, the ratio of explained:unexplained variance should be approximately 1)\nIf your model predictors do explain some variance, the \\(F\\)-ratio will be significant, and you would reject the null, as this would suggest that your predictor variables included in your model improved the model fit (in comparison to the intercept only model).\nPoints to note:\n\nThe larger your \\(F\\)-ratio, the better your model\nThe \\(F\\)-ratio will be close to 1 when the null is true (i.e., that all slopes are zero)\n\nHow to calculate \\(F\\)-ratio\n\n\nBy Hand\nUsing R\n\n\n\nSteps:\n\nCalculate model sum of squares\nCalculate residual sum of squares\nCalculate total sum of squares\nCalculate \\(df_{model}\\)\n\nCalculate \\(df_{residual}\\)\n\n\nStep 1, 2, & 3\nFollow steps above in the Sums of Squares flashcard:\n\\[\n\\begin{align}\n& \\text{SS}_\\text{Total} = 10  \\\\\n& \\text{SS}_\\text{Residual} = 5.1 \\\\  \n& \\text{SS}_\\text{Model} = 4.9 \\\\  \n\\end{align}\n\\]\nStep 4: Calculate \\(df_{model}\\)\n\\[\n\\begin{align}\n&df_{model} = k  \\\\  \n&df_{model} = 1\n\\end{align}\n\\]\nStep 5: Calculate \\(df_{residual}\\)\n\\[\n\\begin{align}\n&df_{residual} = n-k-1   \\\\  \n&df_{residual} = 5-1-1  \\\\  \n&df_{residual} = 3  \n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\text{F}_{(df_{model},~df_{residual})} = \\frac{\\text{MS}_\\text{Model}}{\\text{MS}_\\text{Residual}} = \\frac{\\text{SS}_\\text{Model}/\\text{df}_\\text{Model}}{\\text{SS}_\\text{Residual}/\\text{df}_\\text{Residual}} \\\\  \n\\\\  \n&\\text{F}_{(df_{model},~df_{residual})} = \\frac{4.9/1}{5.1/3} \\\\  \n\\\\  \n&\\text{F}_{(df_{model},~df_{residual})} = \\frac{4.9}{1.7} \\\\  \n\\\\  \n&\\text{F}_{(df_{model},~df_{residual})} = 2.88  \n\\end{align}\n\\]\n\n\n\nIn R\nWe can see the \\(F\\)-statistic and associated \\(p\\)-value at the bottom of the output of summary(&lt;modelname&gt;):\n\n\n\n\nMultiple regression output in R, F statistic highlighted\n\n\n\nAlternatively, you can extract this information as it is stored in the summary() of the model:\n\n#F-Statistic\nsummary(recall_multi)$fstatistic\n\n   value    numdf    dendf \n12.92426  2.00000 17.00000 \n\n#P-Value\npf(summary(recall_multi)$fstatistic[1], \n   summary(recall_multi)$fstatistic[2], \n   summary(recall_multi)$fstatistic[3], \n   lower.tail = FALSE)\n\n       value \n0.0003866881 \n\n\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nThe linear model with recall confidence and age explained a significant amount of variance in recall accuracy beyond what we would expect by chance \\(F(2, 17) = 12.92, p &lt; .001\\).\n\n\n\n\n\n\n\n\n R-squared and Adjusted R-squared\n\n\nOverview:\n\\(R^2\\) represents the proportion of variance in \\(Y\\) that is explained by the model predictor variables.\nFormula:\nThe \\(R^2\\) coefficient is defined as the proportion of the total variability in the outcome variable which is explained by our model:\n\\[\nR^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Residual}}{SS_{Total}}\n\\]\nThe Adjusted \\(R^2\\) coefficient is defined as:\n\\[\n\\hat R^2 = 1 - \\frac{(1 - R^2)(n-1)}{n-k-1}\n\\quad \\\\\n\\]\n\\[\n\\begin{align}\n& \\text{Where:} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\n\nWhen to report Multiple \\(R^2\\) vs. Adjusted \\(R^2\\):\nThe Multiple \\(R^2\\) value should be reported for a simple linear regression model (i.e., one predictor).\nUnlike \\(R^2\\), Adjusted-\\(R^2\\) does not necessarily increase with the addition of more explanatory variables, by the inclusion of a penalty according to the number of explanatory variables in the model. Since Adjusted-\\(R^2\\) is adjusted for the number of predictors in the model, this should be used when there are 2 or more predictors in the model. As a side note, the Adjusted-\\(R^2\\) should always be less than or equal to \\(R^2\\).\nHow to calculate Multiple \\(R^2\\) & Adjusted \\(R^2\\)\n\n\nBy Hand\nUsing R\n\n\n\nUsing the information calculated above in the Sums of Squares flashcard above, we can simply substitute values into the formula for \\(R^2\\):\n\\[\n\\begin{align}  \n& R^2 = \\frac{\\text{SS}_{\\text{Model}}}{\\text{SS}_{\\text{Total}}} = 1 - \\frac{\\text{SS}_{\\text{Residual}}}{\\text{SS}_{\\text{Total}}} \\\\\n\\\\  \n& R^2 = \\frac{4.9}{10} = 1 - \\frac{5.1}{10} \\\\  \n\\\\  \n& R^2 = 0.49 = 0.49\n\\end{align}  \n\\]\nAnd for Adjusted-\\(R^2\\):\n\\[\n\\begin{align}  \n& \\text{Adjusted-R}^2 = 1 - \\frac{(1 - R^2)(n-1)}{n-k-1} \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - \\frac{(1 - 0.49)(5-1)}{5-1-1} \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - \\frac{(0.51)(4)}{3} \\\\  \n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - \\frac{2.04}{3} \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 1 - 0.68 \\\\\n& \\quad \\\\  \n& \\text{Adjusted-R}^2 = 0.32 \\\\\n\\end{align}\n\\]\n\n\n\nIn R\nWe can see both \\(R^2\\) and Adjusted-\\(R^2\\) in the second bottom row of the summary(&lt;modelname&gt;):\n\n\n\n\nMultiple regression output in R, R^2 statistic highlighted\n\n\n\nAlternatively, you can extract this information as it is stored in the summary() of the model:\n\n#R-Squared\nsummary(recall_multi)$r.squared\n\n[1] 0.6032536\n\n#Adjusted R-Squared\nsummary(recall_multi)$adj.r.squared\n\n[1] 0.5565775\n\n\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nTogether, recall confidence and age explained approximately 55.66% of the variance in recall accuracy."
  },
  {
    "objectID": "1_b3_reading.html#linear-models-1",
    "href": "1_b3_reading.html#linear-models-1",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Linear Models",
    "text": "Linear Models\nOne useful thing we might want to do is compare our models with and without some predictor(s).There are numerous ways we can do this, but the method chosen depends on the models and underlying data:\n\n\n\n\n\n\n\n\n\n Nested vs Non-Nested Models\n\n\nNested Models\nConsider that you have two regression models where Model 1 contains a subset of the predictors contained in the other Model 2 and is fitted to the same data. More simply, Model 2 contains all of the predictors included in Model 1, plus additional predictor(s). This means that Model 1 is nested within Model 2, or that Model 1 is a submodel of Model 2. These two terms, at least in this setting, are interchangeable - it might be easier to think of Model 1 as your null and Model 2 as your alternative.\nNon-Nested Models\nConsider that you have two regression models where Model 1 contains different variables to those contained in Model 2, where both models are fitted to the same data. More simply, Model 1 and Model 2 contain unique variables that are not shared. This means that Model 1 and Model 2 are not nested.\n\n\n\n\n\n Incremental F-test\n\n\nIf (and only if) two models are nested, can we compare them using an incremental F-test.\nThis is a formal test of whether the additional predictors provide a better fitting model.\nFormally this is the test of:\n\n\\(H_0:\\) coefficients for the added/omitted variables are all zero.\n\\(H_1:\\) at least one of the added/omitted variables has a coefficient that is not zero.\n\nThe \\(F\\)-ratio for comparing the residual sums of squares between two models can be calculated as:\n\\[\nF_{(df_R-df_F),~df_F} = \\frac{(SSR_R-SSR_F)/(df_R-df_F)}{SSR_F / df_F} \\\\\n\\quad \\\\\n\\] \\[\n\\begin{align}\n& \\text{Where:} \\\\\n\\\\\n& SSR_R = \\text{residual sums of squares for the restricted model} \\\\\n& SSR_F = \\text{residual sums of squares for the full model} \\\\\n& df_R = \\text{residual degrees of freedom from the restricted model} \\\\\n& df_F = \\text{residual degrees of freedom from the full model} \\\\\n\\end{align}\n\\]\n\nIn R\nWe can conduct an incremental \\(F\\)-test to compare two models by fitting both models using lm(), and passing them to the anova() function:\n\nmodel1 &lt;- lm( ... )\nmodel2 &lt;- lm( ... )\nanova(model1, model2)\n\nIf we wanted to, for example, compare a model with just one predictor, \\(x1\\), to a model with 2 predictors: \\(x1\\), and \\(x2\\), we can assess the extent to which the variable \\(x2\\) improves model fit:\n\nmodel1 &lt;- lm(y ~ x1, data = data_name)\nmodel2 &lt;- lm(y ~ x1 + x2, data = data_name)\nanova(model1, model2)\n\nFor example:\n\n\n\n\nModel Comparisons using Incremental F-test\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nRecall confidence explained a significant amount of variance in recall accuracy beyond age \\((F(1, 17) = 21.95, p &lt; .001)\\).\n\n\n\n\n\n\n\n\n AIC & BIC\n\n\nAIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) combine information about the sample size, the number of model parameters, and the residual sums of squares (\\(SS_{residual}\\)). Models do not need to be nested to be compared via AIC and BIC, but they need to have been fit to the same dataset.\nAIC can be calculated as:\n\\[\n\\begin{align}\n& AIC = n\\,\\text{ln}\\left( \\frac{SS_{residual}}{n} \\right) + 2k \\\\\n\\end{align}\n\\quad \\\\\n\\]\nBIC can be calculated as:\n\\[\n\\begin{align}\n& BIC = n\\,\\text{ln}\\left( \\frac{SS_{residual}}{n} \\right) + k\\,\\text{ln}(n) \\\\\n\\end{align}\n\\quad \\\\\n\\]\nWhere for both AIC and BIC:\n\\[\n\\begin{align}\n& SS_{residual} = \\text{sum of squares residuals} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n& \\text{ln} = \\text{natural log function}\n\\end{align}\n\\]\nFor both of these fit indices, lower values are better, and both include a penalty for the number of predictors in the model (although BIC’s penalty is harsher).\nSo how do we determine whether there is a statistical difference between two models? To evaluate our model comparisons, we need to look at the difference (\\(\\Delta\\)) between the two values:\n\nAIC: There are no specific thresholds to suggest how big a difference in two models is needed to conclude that one is substantively better than the other\nBIC: Using the following \\(\\Delta BIC\\) cutoffs (Raftery, 1995):\n\n\n\nValue\nInterpretation of Difference between Models\n\n\n\n\\(\\Delta &lt; 2\\)\nNo evidence\n\n\n\\(2 &gt; \\Delta &lt; 6\\)\nPositive evidence\n\n\n\\(6 &gt; \\Delta &lt; 10\\)\nStrong evidence\n\n\n\\(\\Delta &gt; 10\\)\nVery strong evidence\n\n\n\n\nIn R\nWe can calculate AIC and BIC by using the AIC() and BIC() functions respectively:\n\n#AIC\nAIC(modelname)\n\n#BIC\nBIC(modelname)\n\nFor example, with AIC:\n\n\n\n\nModel Comparisons using AIC\n\n\n\nand BIC:\n\n\n\n\nModel Comparisons using BIC\n\n\n\n\n\n\n\n\n\n\nExample Interpretation\nBased on both AIC and BIC, the model predicting recall accuracy that included both recall confidence and age was better fitting \\((\\text{AIC} = 152.28; \\text{BIC} = 156.27)\\) than the model with age alone \\((\\text{AIC} = 166.86; \\text{BIC} = 169.85)\\)."
  },
  {
    "objectID": "1_b3_reading.html#linear-models-2",
    "href": "1_b3_reading.html#linear-models-2",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Linear Models",
    "text": "Linear Models\nLinear models rely on numerous underlying assumptions about the data. These assumptions ensure that the association between variables is appropriately captured, and that inferences drawn from the model are accurate and valid. Model diagnostics can help further assess whether these assumptions hold. When these assumptions are violated, there are numerous techniques that can be employed, such as through data transformations or using robust alternatives, to ensure reliable model interpretations.\n\n Linearity\n\n\nSimple Linear Regression\nIn simple linear regression with only one explanatory variable, we could assess linearity through a simple scatterplot of the outcome variable against the explanatory. This would allow us to check if the errors have a mean of zero. If this assumption was met, the residuals would appear to be randomly scattered around zero.\nThe rationale for this is that, once you remove from the data the linear trend, what’s left over in the residuals should not have any trend, i.e. have a mean of zero.\nMultiple Regression\nIn multiple regression, however, it becomes more necessary to rely on diagnostic plots of the model residuals. This is because we need to know whether the relations are linear between the outcome and each predictor after accounting for the other predictors in the model.\nIn order to assess this, we use partial-residual plots (also known as ‘component-residual plots’). This is a plot with each explanatory variable \\(x_j\\) on the x-axis, and partial residuals on the y-axis***.\nPartial residuals for a predictor \\(x_j\\) are calculated as: \\[\n\\hat \\epsilon + \\hat \\beta_j x_j\n\\]\n\nIn R\n\n\nSimple Linear Regression\nMultiple Linear Regression\n\n\n\n\n#specify model\nrecall_simp &lt;- lm(recall_accuracy ~ age, data = recalldata)\n\n#create plot\nggplot(recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE, colour = \"blue\") + #fit straight line to data\n    geom_smooth(method = \"loess\", se = FALSE, colour = \"red\") + #fit loess line to data\n    labs(x = \"Age\", y = \"Recall Accuracy\")\n\n\n\n\n\n\n\n\nInterpretation Guidance\nThe loess line should closely follow the data.\n\n\n\nWe can create these plots for all predictors in the model by using the crPlots() function from the car package:\n\n#specify model\nrecall_mdl &lt;- lm(recall_accuracy ~ recall_confidence + age, data = recalldata)\n\n#create plots\ncrPlots(recall_mdl)\n\n\n\n\n\n\n\n\nInterpretation Guidance\nYou are looking for the pink line to follow a linear trend line (i.e., follow the blue line). In other words, the loess line should closely follow the linear line.\n\n\n\n\n\n\nImportant to Note for Interaction Models\n***When there is an interaction in the model, assessing linearity becomes difficult. In fact, crPlots() will not work. To assess, you can create a residuals-vs-fitted plot.\n\n\n\n\n\n\n\n Independence (of errors)\n\n\nThe ‘independence of errors’ assumption is the condition that the errors do not have some underlying relationship which is causing them to influence one another. \nThere are many sources of possible dependence, and often these are issues of study design. For example, we may have groups of observations in our data which we would expect to be related (e.g., multiple trials from the same participant). Our modelling strategy would need to take this into account. \nTesting for the independence of errors can be pretty difficult, unless you know the potential source of correlation between cases (more on this in DAPR3!).\n\n\n\n\n\n Normality (of errors)\n\n\nThe normality assumption is the condition that the errors \\(\\epsilon\\) are normally distributed in the population.\nWe can visually assess this condition through histograms, density plots, and quantile-quantile plots (QQplots) of our residuals \\(\\hat \\epsilon\\).\n\n\nHistogram\nQQPlot\n\n\n\n\nhist(recall_mdl$residuals)\n\n\n\n\n\n\n\n\n\n\nplot(recall_mdl, which = 2)\n\n\n\n\n\n\n\n\n\n\n\nInterpretation Guidance\nRemember that departures from a linear trend in QQ plots indicate a lack of normality.\n\n\n\n\n\n\n Equal Variances (Homoscedasticity)\n\n\nThe equal variances assumption is that the error variance \\(\\sigma^2\\) is constant across values of the predictor(s) \\(x_1, \\dots, x_k\\), and across values of the fitted values \\(\\hat y\\). This sometimes gets termed “Constant” vs “Non-constant” variance. This is presented visually in Figure 13 and Figure 14.\n\n\n\n\nFigure 13: Non-constant variance for numeric and categorical X\n\n\n\n\n\n\n\nFigure 14: Constant variance for numeric and categorical X\n\n\n\n\nIn R\nWe can create plots of the Pearson residuals against the predicted values \\(\\hat y\\) and against the predictors \\(x_1\\), … \\(x_k\\) by using the residualPlots() function from the car package. This function also provides the results of a lack-of-fit test for each of these relationships (note when it is the fitted values \\(\\hat y\\) it gets called “Tukey’s test”).\n\nlibrary(car)\nresidualPlots(recall_mdl)\n\n\n\n\n\n\n\n                  Test stat Pr(&gt;|Test stat|)\nrecall_confidence    1.4473           0.1671\nage                 -0.0474           0.9627\nTukey test           0.8769           0.3805\n\n\nAlternatively, we can use:\n\nplot(recall_mdl, which = 1)\n\n\n\n\n\n\n\n\n\nInterpretation Guidance\nIf the assumption is met, you should see a random scatter of \\((x,y)\\) points with constant mean and variance functions i.e., the vertical spread of the residuals should roughly be the same everywhere.\n\n\n\n\n\n\n Useful Assumption Plots\n\n\n\n\nplot(modelname)\ncheck_model(modelname)\n\n\n\nWe can run plot(mymodel) which will cycle through these plots (asking us to press enter each time to move to the next plot), or we can arrange these plots in a matrix via par(mfrow), for example in a 2 x 2 matrix as shown below (make sure to always reset your graphical parameters! If needed, we could also extract specific plots using, for instance: plot(mymodel, which = 3) for the third plot.\n\nIn R\n\npar(mfrow=c(2,2))\nplot(recall_mdl)\n\n\n\n\n\n\npar(mfrow=c(1,1))\n\n\n\nInterpretation Guidance\n\nTop Left: For the Residuals vs Fitted plot, we want the red line to be horizontal at close to zero across the plot. We don’t want the residuals (the points) to be fanning in/out.\n\nTop Right: For the Normal Q-Q plot, we want the residuals (the points) to follow closely to the diagonal line, indicating that they are relatively normally distributed.6\n\nBottom Left: For the Scale-Location plot, we want the red line to be horizontal across the plot. These plots allow us to examine the extent to which the variance of the residuals changes across the fitted values. If it is angled, we are likely to see fanning in/out of the points in the residuals vs fitted plot.\nBottom Right: The Residuals vs Leverage plot indicates points that might be of individual interest as they may be unduly influencing the model. There are funnel-shaped lines on this plot (sometimes out of scope of the plotting window). Ideally, we want our residuals inside the funnel - the further the residual is to the right (the more leverage it has), the closer to the 0 we want it to be.\n\nNote, if we have only categorical predictors in our model, many of these will show vertical lines of points. This doesn’t indicate that anything is wrong, and the same principles described above continue to apply\n\n\n\nThe check_model() function from the performance package is a useful way to check the assumptions of models, as it also returns some useful notes to aid your interpretation. However, it is important to check each assumption individually with plots that are more suitable for a statistics report.\n\nIn R\n\nlibrary(performance)\ncheck_model(recall_mdl)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Multicollinearity\n\n\nFor the linear model with multiple explanatory variables, we need to also think about multicollinearity - this is when two (or more) of the predictors in our regression model are moderately or highly correlated.\nWe can assess multicollinearity using the variance inflation factor (VIF), which for a given predictor \\(x_j\\) is calculated as:\n\\[\nVIF_j = \\frac{1}{1-R_j^2} \\\\\n\\]\n\nInterpretation Guidance\nSuggested cut-offs for VIF are varied. Some suggest 10, others 5. Define what you will consider an acceptable value prior to calculating it. You could loosely interpret VIF values \\(&gt;5\\) as moderate multicollinearity and values \\(&gt;10\\) as severe multicollinearity.\n\n\nImportant to Note for Interaction Models\nInteraction terms often result in multicollinearity, because these terms are made up of the product of some ‘main effects’. Mean-centering the variables will help to reduce this source of structural multicollinearity (“structural” here refers to the fact that multicollinearity is due to our model specification, rather than the data itself).\n\n\nIn R\nThe vif() function from the car package will provide VIF values for each predictor in your model.\n\nvif(INSERT_MODEL_NAME)\n\n\n\n\n\n\n\n Individual Case Diagnostics\n\n\nWe have seen that some specific individual cases in our data can influence our model more than others. We can identify these as:\n\n\nRegression outliers: A large residual \\(\\hat \\epsilon_i\\) - i.e., a big discrepancy between their predicted y-value and their observed y-value.\n\n\nStandardised residuals: For residual \\(\\hat \\epsilon_i\\), divide by the estimate of the standard deviation of the residuals. In R, the rstandard() function will give you these\n\nStudentised residuals: For residual \\(\\hat \\epsilon_i\\), divide by the estimate of the standard deviation of the residuals excluding case \\(i\\). In R, the rstudent() function will give you these.\n\n\n\nHigh leverage cases: These are cases which have considerable potential to influence the regression model (e.g., cases with an unusual combination of predictor values).\n\n\nHat values: are used to assess leverage. In R, The hatvalues() function will retrieve these.\n\n\n\nHigh influence cases: When a case has high leverage and is an outlier, it will have a large influence on the regression model.\n\n\nCook’s Distance: combines leverage (hatvalues) with outlying-ness to capture influence: \\(D_i = \\text{Outlyingness} \\times \\text{Leverage}\\). Cook’s distance refers to the average distance the \\(\\hat{y}\\) values will move if a given case is removed. In R, the cooks.distance() function will provide these values. Alongside Cook’s Distance, we can examine the extent to which model estimates and predictions are affected when an entire case is dropped from the dataset and the model is refitted.\n\n\n\n\nDFFit: the change in the predicted value at the \\(i^{th}\\) observation with and without the \\(i^{th}\\) observation is included in the regression.\n\n\nDFbeta: the change in a specific coefficient with and without the \\(i^{th}\\) observation is included in the regression. DFbeta represents the difference in the beta coefficients when a case is excluded from the model versus when it’s included. A large DFbeta value would suggest that a case has a substantial impact on the estimated coefficients, and thus a high influence on the model results; a small DFbeta value would suggest that the case has less influence on the estimated coefficients. A commonly used cut-off or threshold to compare \\(|DFBETA|\\) values (absolute values) against is \\(\\frac{2}{\\sqrt{n}}\\) (see Belsley et al., (1980) p. 28 for more info)7.\n\nDFbetas: the change in a specific coefficient divided by the standard error, with and without the \\(i^{th}\\) observation is included in the regression.\n\n\nCOVRATIO: measures the effect of an observation on the covariance matrix of the parameter estimates. In simpler terms, it captures an observation’s influence on standard errors. Values which are \\(&gt;1+\\frac{3(k+1)}{n}\\) or \\(&lt;1-\\frac{3(k+1)}{n}\\) are considered as having strong influence.\n\n\nIn R, we can get lots of these measures with the influence.measures() function:\n\n\ninfluence.measures(my_model) will give you out a dataframe of the various measures.\n\nsummary(influence.measures(my_model)) will provide a nice summary of what R deems to be the influential points.\n\n\n\n\n\n\n\n Next Steps: What to do with Violations of Assumptions / Problematic Case Diagnostic Results\n\n\nThere are lots of different options available, and there is no one right answer. Assuming that we have no issues with model specification (i.e., are not missing variables, have modeled appropriately), then we may want to consider one of the below approaches (note: this is not an exhaustive list!)\n\n\nInvestigate Observations\nSensitivity Analysis\nBootstrapping\nOLS vs WLS Regression\nData Transformations\nUsing Non-Linear Models\nRemoving Observations\n\n\n\nThe first step is to re-examine your data. It is important to be familiar with your dataset, as you need to know what values are typical, normal, and possible. Could it be the case that you have missed some impossible values (e.g., a negative value of a persons height), values outwith the possible range (e.g., a score of 55 on a survey where scores can only range 10-50), values that don’t make any sense (e.g., an age of 200), or maybe there are even typos / data entry errors (e.g., forgetting to put a decimal point, so having a height of 152m instead of 1.52m)!\nIf there is a simple error in the data, it could be that you can fix the typo. If that is not possible (maybe you didn’t collect the data, so are unsure of what the value(s) should/could be), you will need to delete the value (i.e., set as an NA), because you know that it is incorrect.\nWe should aim to never change a legitimate value where possible (and remember that if you have a large dataset, a small number of extreme values will be unlikely to have a strong influence on your results).\nIf there is an extreme, but legitimate value that you have determined is adversely influencing your model (i.e., by examining the assumptions and diagnostics as outlined above), you may want to consider ways to reduce this influence (e.g., winsorizing - which essentially truncates or caps the identified extreme values to a specified percentile, in turn reducing their influence on the model without completely eliminating the observation(s). For example, you could replace values below the 5th percentile with the 5th percentile value, and values above the 95th percentile with the 95th percentile value).\nIf after re-examining your data you cannot identify any atypical, non-normal, or impossible values, you may need to select a different approach as outlined below.\n\n\nThis allows us to assess the sensitivity of our results (i.e., parameter estimates, p-values, confidence intervals) to changes in our modelling approach (i.e., the removal of observations).\nWe can re-fit our model after excluding our identified outliers and potentially influential observations, and compare these results to the original model.\n\n\n\n\n\n\nProcess of Removing Observations\n\n\n\n\n\nThe current example involves removing all identified outliers and potentially influential observations at the same time. Ideally, and to ensure a more thorough sensitivity analysis, you would remove each of these observations one at a time, assess the effects on the model by comparing to your original, reassessing the remaining pre-identified observations, and repeating the process if necessary.\n\n\n\n\n\nOriginal Model\nModel with Observations Removed\nCompare summary() output\n\n\n\n\n## wellbeing model\nwb_mdl1 &lt;- lm(wellbeing ~ outdoor_time + social_int, data = mwdata) \nsummary(wb_mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ outdoor_time + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n## wellbeing model\nwb_mdl2 &lt;- lm(wellbeing ~ outdoor_time + social_int, data = mwdata[-c(16, 25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, 101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, 173, 176, 179, 197), ])\nsummary(wb_mdl2)\n\n\nCall:\nlm(formula = wellbeing ~ outdoor_time + social_int, data = mwdata[-c(16, \n    25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, \n    101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, \n    173, 176, 179, 197), ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7700 -2.6445 -0.6073  2.8586  9.6605 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  27.91311    1.42612  19.573  &lt; 2e-16 ***\noutdoor_time  0.19356    0.04901   3.950 0.000116 ***\nsocial_int    0.39830    0.08964   4.443 1.62e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.044 on 165 degrees of freedom\nMultiple R-squared:  0.1774,    Adjusted R-squared:  0.1675 \nF-statistic:  17.8 on 2 and 165 DF,  p-value: 1.004e-07\n\n\n\n\n\ntab_model(wb_mdl1, wb_mdl2,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"outdoor_time\" = \"Outdoor Time (hours per week)\",\n                          \"social_int\" = \"Social Interactions (number per week)\"),\n          title = \"Regression Table for Wellbeing Models wb1 and wb2\")\n\n\nRegression Table for Wellbeing Models wb1 and wb2\n\n\n\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n28.62\n25.69 – 31.55\n&lt;0.001\n27.91\n25.10 – 30.73\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n0.20\n0.10 – 0.30\n&lt;0.001\n0.19\n0.10 – 0.29\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n0.33\n0.16 – 0.51\n&lt;0.001\n0.40\n0.22 – 0.58\n&lt;0.001\n\n\nObservations\n200\n168\n\n\nR2 / R2 adjusted\n0.126 / 0.118\n0.177 / 0.167\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe conducted a sensitivity analysis to assess how robust our conclusions were regarding outdoor time and the weekly number of social interactions in the presence of previously identified outliers and potentially influential observations. We re-fit the model, excluding these 28 observations (14% of our original sample), and compared these model results (wb_mdl2) to those of our original model (wb_mdl1).\nThere was little difference in the estimates from wb_mdl1 and wb_mdl2, and so we can conclude that after conducting a sensitivity analysis, there were no meaningful differences in our results, and hence our conclusions from our original model hold. Specifically:\n\nThe direction of all model estimates are the same in wb_mdl1 and wb_mdl2 (i.e., all positive)\nThere is no difference in statistical significance, and the p-values were of a similar magnitude (i.e., all &lt; .001)\nThe estimate and confidence intervals for outdoor_time are very similar\nThere are some quantitative differences in the estimate and confidence intervals for social_int. The estimate differs slightly in magnitude by 0.07), but given that this remains positive and significant, we do not need to be too concerned about this.\n\n\n\n\n\n\nThe bootstrap method is an alternative non-parametric method of constructing a standard error. Instead of having to rely on calculating the standard error with a formula and potentially applying fancy mathematical corrections, bootstrapping involves mimicking the idea of “repeatedly sampling from the population”. It does so by repeatedly resampling with replacement from our original sample.\nWhat this means is that we don’t have to rely on any assumptions about our model residuals, because we actually generate an actual distribution that we can take as an approximation of our sampling distribution, meaning that we can actually look at where 95% of the distribution falls, without having to rely on any summing of squared deviations.\nNote, the bootstrap may provide us with an alternative way of conducting inference, but our model may still be mis-specified. It is also very important to remember that bootstrapping is entirely reliant on utilising our original sample to pretend that it is a population (and mimic sampling from that population). If our original sample is not representative of the population that we’re interested in, bootstrapping doesn’t help us at all.\n\n\nThe method of ordinary least squares regression (OLS: i.e., the type of regression model you have been fitting on the course) assumes that there is constant variance in the errors (homoscedasticity). The method of weighted least squares (WLS) can be used when the ordinary least squares assumption of constant variance in the errors is violated (i.e., you have evidence of heteroscedasticity, like we do in Q3 of this lab).\nIf we have some specific belief that your non-constant variance is due to differences in the variances of the outcome between various groups, then it might be better to use Weighted Least Squares.\nAs an example, imagine we are looking at weight of different dog breeds (Figure 15). The weights of chihuahuas are all quite close together (between 2 to 5kg), but the weight of, for example, spaniels is anywhere from 8 to 25kg - a much bigger variance.\n\n\n\n\nFigure 15: The weights of 49 dogs, of 7 breeds\n\n\n\nRecall that the default way that lm() deals with categorical predictors such as dog breed, is to compare each one to a reference level. In this case, that reference level is “beagle” (first in the alphabet). Looking at Figure 15 above, which comparison do you feel more confident in?\n\n\nA: Beagles (14kg) vs Pugs (9.1kg). A difference of 4.9kg.\n\n\nB: Beagles (14kg) vs Spaniels (19kg). A difference of 5kg.\n\nHopefully, your intuition is that A looks like a clearer difference than B because there’s less overlap between Beagles and Pugs than between Beagles and Spaniels. Our standard linear model, however, assumes the standard errors are identical for each comparison:\n\n\n\nCall:\nlm(formula = weight ~ breed, data = dogdf)\n...\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             13.996      1.649   8.489 1.17e-10 ***\nbreedpug                -4.858      2.332  -2.084   0.0433 *  \nbreedspaniel             5.052      2.332   2.167   0.0360 *  \nbreedchihuahua         -10.078      2.332  -4.322 9.28e-05 ***\nbreedboxer              20.625      2.332   8.846 3.82e-11 ***\nbreedgolden retriever   17.923      2.332   7.687 1.54e-09 ***\nbreedlurcher             5.905      2.332   2.533   0.0151 *  \n---\n\n\nFurthermore, we can see that we have heteroscedasticity in our residuals - the variance is not constant across the model:\n\nplot(dogmodel, which=3)\n\n\n\n\n\n\n\nWeighted least squares is a method that allows us to apply weights to each observation, where the size of the weight indicates the precision of the information contained in that observation.\nWe can, in our dog-breeds example, allocate different weights to each breed. Accordingly, the Chihuahuas are given higher weights (and so Chihuahua comparisons result in a smaller SE), and Spaniels and Retrievers are given lower weights.\n\nlibrary(nlme)\nload(url(\"https://uoepsy.github.io/data/dogweight.RData\"))\ndogmod_wls = gls(weight ~ breed, data = dogdf, \n                 weights = varIdent(form = ~ 1 | breed))\nsummary(dogmod_wls)\n\n\n\nCoefficients:\n                           Value Std.Error   t-value p-value\n(Intercept)            13.995640  1.044722 13.396516  0.0000\nbreedpug               -4.858097  1.271562 -3.820576  0.0004\nbreedspaniel            5.051696  2.763611  1.827933  0.0747\nbreedchihuahua        -10.077615  1.095964 -9.195207  0.0000\nbreedboxer             20.625429  1.820370 11.330351  0.0000\nbreedgolden retriever  17.922779  2.976253  6.021927  0.0000\nbreedlurcher            5.905261  1.362367  4.334559  0.0001\n\n\nWe can also apply weights that change according to continuous predictors (e.g. observations with a smaller value of \\(x\\) are given more weight than observations with larger values).\n\n\nA data transformation involves the replacement of a variable (e.g., \\(y\\)) by a function of that variable in order to change the shape of a distribution or association (e.g., to help reduce skew). We can transform the outcome variable prior to fitting the model, using something such as log(y) or sqrt(y). This will sometimes allow us to estimate a model for which our assumptions are satisfied.\nSome of the most common (not an exhaustive list) transformations are:\n\n\nLog (log(y)): Often used for reducing right skewness. Note, this transformation cannot be applied to zero or negative values (make sure to check your data!)\n\nSquare root (sqrt(y)): Also often used for reducing right skewness. This transformation can be applied to zero values (but not negative), and is commonly applied to count data\n\n\n\n\n\nFigure 16: A model of a transformed outcome variable can sometimes avoid violations of assumptions that arise when modeling the outcome variable directly. Data from https://uoepsy.github.io/data/trouble1.csv\n\n\n\nThe major downside of this is that we are no longer modelling \\(y\\), but some transformation \\(f(y)\\) (\\(y\\) with some function \\(f\\) applied to it). Interpretation of the coefficients changes accordingly, such that we are no longer talking in terms of changes in y, but changes in \\(f(y)\\). When the transformation function used is non-linear (see the Right-Hand of Figure 17) a change in \\(f(y)\\) is not the same for every \\(y\\).\n\n\n\n\nFigure 17: The log transformation is non-linear\n\n\n\nFor certain transformations, we can re-express coefficients to be interpretable with respect to \\(y\\) itself. For instance, the model using a log transform \\(ln(y) = b_0 + b_1(x)\\) gives us a coefficient that represents statement A below. We can re-express this by taking the opposite function to logarithm, the exponent, exp(). Similar to how this works in logistic regression, the exponentiated coefficients obtained from exp(coef(model)) are multiplicative, meaning we can say something such as statement B\n\n\n\nA: “a 1 unit change in \\(x\\) is associated with a \\(b\\) unit change in \\(ln(y)\\)”.\n\n\nB: “a 1 unit change in \\(x\\) is associated with \\(e^b\\) percent change in \\(y\\).”\n\n\nFinding the optimal transformation to use can be difficult, but there are methods out there to help you. One such method is the BoxCox transformation, which can be conducted using BoxCox(variable, lambda=\"auto\"), from the forecast package.8\n\n\n\n\nGeneralized Linear Models\nHigher Order Terms\n\n\n\nGeneralized Linear Models (GLMs) can appropriately deal with data that do not follow a normal distribution (which is a requirement for traditional linear models). They can accommodate various types of distributions, including the Poisson, binomial, and gamma distributions. This makes them suitable for modelling count data (e.g., number of sunny days Edinburgh has per year - yes, count data can include 0!), binary data (where there are only two possible values e.g., doesn’t wear glasses vs wear glasses, smoker vs non-smoker, i.e., values that are yes/no or 0/1), and other types of non-normal data.\nWe will explore some GLMs later in the course (Semester 2 Block 4), where we will work with logistic regression models.\n\n\nHigher order regression terms refer to the inclusion of polynomial terms of degree higher than one in a regression model. In a linear regression model, the association between the dependent variable (\\(Y\\)) and the independent variable (\\(X\\)) is assumed to be linear, which means the association can be represented by a straight line. However, in many real-world scenarios, associations between variables are not strictly linear, and including higher order regression terms can help capture more complex relationships. Higher order terms that you could incorporate include quadratic, cubic, or higher degree polynomial terms.\nFor example, in a quadratic regression model, the relationship between \\(Y\\) and \\(X\\) can be represented as:\n\\[\nY = \\beta_0 + \\beta_1 \\cdot X + \\beta_2 \\cdot X^2 + \\epsilon\n\\] \\[\n\\begin{align}\n& \\text{Where:} \\\\\n& Y = \\text{Dependent Variable} \\\\\n& X = \\text{Independent Variable} \\\\\n\\end{align}\n\\]\nAs in our models we’ve seen so far, \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\) are the coefficients to be estimated in the above model. What is different from what we’ve seen in DAPR2 is the term \\(\\beta_2 \\cdot X^2\\), and this represents the quadratic term. This allows for a curved as opposed to straight line to represent the association between \\(Y\\) and \\(X\\), and hence can allow us to capture more complex relationships. For example, we can model the association between height and age:\n\n\n\n\nFigure 18: Two linear models, one with a quadratic term (right)\n\n\n\nPlease note that these types of models are beyond the scope of the DAPR2 course, but if you want to know more, please do read up on these in your own time.\n\n\n\n\n\nRemoving outliers and potentially influential observations should be a last resort - not all outliers are inherently ‘bad’ - we do expect natural variation in our population(s) of interest. Outliers can be informative about the topic under investigation, and this is why you need to be very careful about excluding outliers due only to their ‘extremeness’. In doing so, you can distort your results by removing variability - i.e., by forcing the data to be more normal and less variable than it actually is, and reduce statistical power by reducing the size of your sample.\nIf you do decide to remove observations, you will need to document what specific data points you excluded, and provide an explanation as to why these were excluded.\nTo set specific values to NA in our dataset (and save this updated dataset in a new object named mwdata2), we could use the following code. For the purpose of this demonstration, lets say that we wanted to set any age values of &lt;20 as NA. In the original dataset mwdata, we had 3 individuals aged 18, and 6 aged 19, so we should end up with 9 NA values in mwdata2 column age:\n\n#specify age column in original dataset, where age is &lt; 20, for values to be set to NA and save to new object named mwdata2 to avoid overwriting original data\nmwdata2 &lt;-  mwdata |&gt; \n    mutate(age = replace(age, age &lt; 20, NA))\n\n#check how many NA values we have - there should be 9 (so 9 TRUEs):\ntable(is.na(mwdata2$age))\n\n\nFALSE  TRUE \n  191     9 \n\n\nIf we wanted to remove a full row from the datset, we could use the following code. For the purpose of this demonstration, lets say that we wanted to remove all rows that were highlighted in the above assumption and diagnostic checks as potentially having an adverse influence on our model estimates:\n\n# create new dataset 'mwdata3' without (by specifying -) identified outliers and potentially influential observations\nmwdata3 &lt;- mwdata[-c(16, 25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, 101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, 173, 176, 179, 197), ]\n\n# check dimensions - should now have 32 rows less than original dataset 200 - 32 = 168\ndim(mwdata3)\n\n[1] 168   7"
  },
  {
    "objectID": "1_b3_reading.html#latex-symbols-equations",
    "href": "1_b3_reading.html#latex-symbols-equations",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "LaTeX Symbols & Equations",
    "text": "LaTeX Symbols & Equations\nBy embedding LaTeX into RMarkdown, you can accurately and precisely format mathematical expressions, ensuring that they are not only technically correct but also visually appealing and easy to interpret.\n\n LaTeX Guide\n\n\nFor an overview of how to integrate LaTeX symbols and equations, review Lesson 9 of the RMD bootcamp."
  },
  {
    "objectID": "1_b3_reading.html#apa-formatting",
    "href": "1_b3_reading.html#apa-formatting",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "APA Formatting",
    "text": "APA Formatting\nAPA format is a writing/presentation style that is often used in psychology to ensure consistency in communication. APA formatting applies to all aspects of writing - from formatting of papers (including tables and figures), citation of sources, and reference lists. This means that it also applies to how you present results in your Psychology courses, including DAPR2.\n\n APA Formatting Guides\n\n\nAll results should be presented following APA guidelines.\nYou also need to follow APA style rules for tables and figures.\nMake sure to familiarise yourself with the above guides, and practice presenting your results following these rules."
  },
  {
    "objectID": "1_b3_reading.html#tables",
    "href": "1_b3_reading.html#tables",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Tables",
    "text": "Tables\nWe want to ensure that we are presenting results in a well formatted table. To do so, there are lots of different packages available (see Lesson 4 of the RMD bootcamp).\nOne of the most convenient ways to present results from regression models is to use the tab_model() function from sjPlot.\n\n Creating tables via tab_model\n\n\nWithin tab_model(), there are lots of different ways that you can customise your table. The most common arguments that you should use are dv.labels, pred.labels, and title.\nYou can rename your DV and IV labels by specifying dv.labels and pred.labels. To do so, specify your variable name on the left, and what you would like this to be named in the table on the right. For title, you can simply specify in ““’s what you want your title to be e.g., title = \"This is my title\".\nHere’s an example if I had fitted a model with the following information:\n\nModel name = mdl_test\n\nModel DV = cognitive_score\n\nModel IVs = SES and age\n\n\n\nmdl_test &lt;- lm(cognitive_score ~ SES + age, data = data_name)\n\nI want to change the names of SES and age to be socio-economic status and age - in years respectively. What we need to pay attention to here is the ordering of the IVs - the ordering in our lm() must match that in tab_model(). I also want to name my table Regression Table for Cognitive Scores Model. Here is how we would do this in R:\n\nlibrary(sjPlot)\ntab_model(mdl_test,\n          pred.labels = c('Intercept', 'socio-economic status', 'age - in years'),\n          title = \"Regression Table for Cognitive Scores Model\")\n\nSee here for another short example."
  },
  {
    "objectID": "1_b3_reading.html#cross-referencing",
    "href": "1_b3_reading.html#cross-referencing",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Cross Referencing",
    "text": "Cross Referencing\nCross-referencing is a very helpful way to direct your reader through your document, and the good news is that this can be done automatically in RMarkdown.\n\n Cross Referencing\n\n\nThere are three key components to allow you to successfully cross-reference within your RMarkdown document:\n\nA bookdown output format\nA caption to your figure or table\nA named/labeled code chunk\n\nOnce you have the above, you will be able to cross-reference using the syntax @ref(type:label), where label is the chunk name/label, and type is the environment being referenced (e.g. tab for table, fig for figure, etc.).\nFor an in-depth overview and example of how to cross-reference, see Lesson 7 of the RMD bootcamp."
  },
  {
    "objectID": "1_b3_reading.html#footnotes",
    "href": "1_b3_reading.html#footnotes",
    "title": "Block 1, 2, & 3 Flash Cards",
    "section": "Footnotes",
    "text": "Footnotes\n\nYes, the error term is gone. This is because the line of best-fit gives you the prediction of the average recall accuracy for a given age, and not the individual recall accuracy of an individual person, which will almost surely be different from the prediction of the line.↩︎\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/ doi: 10.5281/zenodo.3960218↩︎\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/ doi: 10.5281/zenodo.3960218↩︎\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/ doi: 10.5281/zenodo.3960218↩︎\nwhat defines a ‘family’ of tests is debatable.↩︎\nQQplots plot the values against the associated percentiles of the normal distribution. So if we had ten values, it would order them lowest to highest, then plot them on the y against the 10th, 20th, 30th.. and so on percentiles of the standard normal distribution (mean 0, SD 1)↩︎\nBelsley, D. A., Kuh, E., & Welsch, R. E. (2005). Regression diagnostics: Identifying influential data and sources of collinearity. John Wiley & Sons. DOI: 10.1002/0471725153↩︎\nThis method finds an appropriate value for \\(\\lambda\\) such that the transformation \\((sign(x) |x|^{\\lambda}-1)/\\lambda\\) results in a close to normal distribution.↩︎"
  },
  {
    "objectID": "2_01_int1_nc.html",
    "href": "2_01_int1_nc.html",
    "title": "Interactions I: Num x Cat",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction\nBe able to interpret the meaning of a numeric \\(\\times\\) categorical interaction\nBe able to visualize and probe interactions\n\n\nBe up to date with lectures\nHave completed all labs from Semester 1\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nkableExtra\npsych\nsjPlot\npatchwork\nsandwich\ninteractions\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_location_rural.csv"
  },
  {
    "objectID": "2_01_int1_nc.html#study-analysis-plan-overview",
    "href": "2_01_int1_nc.html#study-analysis-plan-overview",
    "title": "Interactions I: Num x Cat",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\nWhen specifying your model, set ‘not rural’ as the reference group for location.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable - in this case, ‘not rural’)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\nThe statistical models flashcards may also be useful to refer to. Specifically the interaction models flashcards and numeric x categorical example flashcards might be of most use.\n\n\n\n\n\n\n\n Solution \n\n\nThe ruraldata dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants’ wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\nDensity plots and histograms will be used to visualise the marginal distributions of wellbeing and social interactions, and the strength of association between the two variables estimated via the correlation coefficient. To understand how these associations differ between rural and non-rural locations, scatterplots will be used.\nTo address the research question of whether the association between the number of social interactions and wellbeing differs between rural and non-rural residents, we are going to fit the following interaction model (where not rural will be specified as the reference group for location).\n\\[\n\\begin{align}\n\\text{Wellbeing} ~=~ & \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Location}_\\text{Rural} \\\\\n& + \\beta_3 \\cdot (\\text{Social Interactions} \\cdot \\text{Location}_\\text{Rural}) + \\epsilon \\\\\n\\end{align}\n\\quad\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_3 = 0\\)\nThe association between wellbeing and social interactions is not moderated by whether or not a person lives in a rural area.\n\\(H_1: \\beta_3 \\neq 0\\)\nThe association between wellbeing and social interactions is moderated by whether or not a person lives in a rural area.\n\n\n\n\n\nQuestion 2\n\n\nCheck coding of variables (e.g., that categorical variables are coded as factors).\nAs specified in Q1, we want ‘not rural’ as the reference group, so make sure to specify this.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the specifying reference levels flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nCheck coding of variables within ruraldata and ensure isRural is a factor with two levels, ‘rural’ and ‘not rural’:\n\n# check structure of dataset \nstr(ruraldata) \n\nspc_tbl_ [200 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ age         : num [1:200] 28 56 25 60 19 34 41 41 35 53 ...\n $ outdoor_time: num [1:200] 12 5 19 25 9 18 17 11 12 13 ...\n $ social_int  : num [1:200] 13 15 11 15 18 13 19 12 13 15 ...\n $ routine     : num [1:200] 1 1 1 0 1 1 1 1 0 1 ...\n $ wellbeing   : num [1:200] 36 41 35 35 32 34 39 43 35 37 ...\n $ isRural     : chr [1:200] \"rural\" \"rural\" \"rural\" \"rural\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   age = col_double(),\n  ..   outdoor_time = col_double(),\n  ..   social_int = col_double(),\n  ..   routine = col_double(),\n  ..   wellbeing = col_double(),\n  ..   isRural = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#alternatively run is.factor() for specific variable\nis.factor(ruraldata$isRural) \n\n[1] FALSE\n\n#set isRural as a factor\nruraldata &lt;- ruraldata |&gt;\n    mutate(\n        isRural = factor(isRural, \n                           levels = c('not rural', 'rural')))\n\n\n#check the levels, and make sure 'not rural' is first\nlevels(ruraldata$isRural)\n\n[1] \"not rural\" \"rural\""
  },
  {
    "objectID": "2_01_int1_nc.html#descriptive-statistics-visualisations",
    "href": "2_01_int1_nc.html#descriptive-statistics-visualisations",
    "title": "Interactions I: Num x Cat",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your findings in the context of the study (i.e., comment on any observed differences among groups).\nIn particular:\n\nExplore the associations among the variables included in your analysis\nProduce a visualisation of the association between weekly number of social interactions and well-being, with separate facets for rural vs non-rural respondents OR with different colours for each level of the isRural variable.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables - categorical and numeric values examples and numeric x categorical example - visualise data, paying particular attention to the type of data that you’re working with.\nFor your table of descriptive statistics, both the group_by() and summarise() functions will come in handy here.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nWe can present our summary statistics for wellbeing and social interactions grouped by location in a well formatted table using kable():\n\nruraldata |&gt;\n    group_by(isRural) |&gt;\n    summarise(Wellbeing_M = mean(wellbeing),\n              Wellbeing_SD = sd(wellbeing),\n              SocialInt_M = mean(social_int),\n              SocialInt_SD = sd(social_int)) |&gt;\n    kable(caption = \"Wellbeing, Social Interactions, and Location Descriptive Statistics\",digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Wellbeing, Social Interactions, and Location Descriptive Statistics\n\nisRural\nWellbeing_M\nWellbeing_SD\nSocialInt_M\nSocialInt_SD\n\n\n\nnot rural\n38.57\n5.66\n11.67\n3.95\n\n\nrural\n34.02\n3.99\n12.46\n4.08\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA quick non-APA style table - i.e., not for use in reports\n\n\n\n\n\nFor a quick overview of several summary statistics at once for all columns of our dataframe, but separately for each level of location (i.e.,rural and non-rural), you can use describeBy() from the psych package:\n\ndescribeBy(ruraldata, ruraldata$isRural)\n\n\n Descriptive statistics by group \ngroup: not rural\n             vars   n  mean    sd median trimmed   mad min max range  skew\nage             1 100 43.01 14.95   41.5   42.74 18.53  18  70    52  0.13\noutdoor_time    2 100 18.72  6.91   18.0   18.61  7.41   6  34    28  0.08\nsocial_int      3 100 11.67  3.95   12.0   11.51  3.71   3  24    21  0.37\nroutine         4 100  0.54  0.50    1.0    0.55  0.00   0   1     1 -0.16\nwellbeing       5 100 38.57  5.66   39.0   38.36  5.93  26  59    33  0.44\nisRural*        6 100  1.00  0.00    1.0    1.00  0.00   1   1     0   NaN\n             kurtosis   se\nage             -1.13 1.49\noutdoor_time    -0.87 0.69\nsocial_int       0.13 0.39\nroutine         -1.99 0.05\nwellbeing        0.38 0.57\nisRural*          NaN 0.00\n------------------------------------------------------------ \ngroup: rural\n             vars   n  mean    sd median trimmed   mad min max range  skew\nage             1 100 41.59 14.85     42   41.38 17.79  18  69    51  0.09\noutdoor_time    2 100 17.79  7.29     18   17.68  7.41   1  35    34  0.06\nsocial_int      3 100 12.46  4.08     12   12.41  4.45   4  21    17  0.05\nroutine         4 100  0.59  0.49      1    0.61  0.00   0   1     1 -0.36\nwellbeing       5 100 34.02  3.99     34   34.08  2.97  22  45    23 -0.07\nisRural*        6 100  2.00  0.00      2    2.00  0.00   2   2     0   NaN\n             kurtosis   se\nage             -1.18 1.49\noutdoor_time    -0.49 0.73\nsocial_int      -0.82 0.41\nroutine         -1.89 0.05\nwellbeing        0.40 0.40\nisRural*          NaN 0.00\n\n\n\n\n\n\n\nLet’s produce our plots with a facet for rural vs non-rural residents:\n\nggplot(data = ruraldata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method=\"lm\", se=FALSE) +\n  facet_wrap(~isRural, labeller = \"label_both\") + \n  labs(x = \"Social Interactions (number per week)\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\n\n\n\nOr instead of facets, we could use different colors for each location (rural vs non-rural):\n\nggplot(data = ruraldata, aes(x = social_int, y = wellbeing, colour = isRural)) +\n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE) +\n    scale_colour_discrete(\n    name =\"Location\",\n    labels=c(\"Not Rural\", \"Rural\")) + \n    labs(x = \"Social Interactions (number per week)\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nThose in non-rural locations appear to have higher wellbeing scores across almost all levels of social interactions. The slopes appear to be different for each location, where the greatest difference in wellbeing scores by location is most visible the highest number of social interactions. This suggests that there may be an interaction.\n\n\n\n\n\n\n\n\n\nHow do we know there might be an interaction?\n\n\n\n\n\nThe lines in the two plots above do not run in parallel - this suggested the presence of an interaction. Specifically in our example, the non-parallel lines suggested an interaction effect based on location, as the number of social interactions did not appear to have the same influence on rural and non-rural residents’ wellbeing scores.\nHowever, the only way we can determine whether there is actually an interaction is by including an interaction term in our model, and testing this."
  },
  {
    "objectID": "2_01_int1_nc.html#model-fitting-interpretation",
    "href": "2_01_int1_nc.html#model-fitting-interpretation",
    "title": "Interactions I: Num x Cat",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nFit the specified model, and assign it the name “rural_mod”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can fit interaction models using the lm() function.\nFor an overview, see the interaction models flashcards.\nFor an example, review the interaction models &gt; numeric x categorical example &gt; model building flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit model including interaction between social_int and isRural\nrural_mod &lt;- lm(wellbeing ~  social_int * isRural, data = ruraldata)\n\n#check model output\nsummary(rural_mod)\n\n\nCall:\nlm(formula = wellbeing ~ social_int * isRural, data = ruraldata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4845  -2.7975   0.0155   2.4539  15.6743 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              30.9986     1.4284  21.702  &lt; 2e-16 ***\nsocial_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural              1.3866     2.0510   0.676  0.49981    \nsocial_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.558 on 196 degrees of freedom\nMultiple R-squared:  0.2962,    Adjusted R-squared:  0.2854 \nF-statistic: 27.49 on 3 and 196 DF,  p-value: 6.97e-15\n\n\n\n\n\n\n\nQuestion 5\n\n\nLook at the parameter estimates from your model, and write a description of what each one corresponds to on the plot shown in Figure 1 (it may help to sketch out the plot yourself and annotate it, and refer to the drop down options below).\n\n\n\n\nFigure 1: Multiple regression model: Wellbeing ~ Social Interactions * is Rural\n\n\n\n\n Options for Mapping Parameter Estimates to Plot\n\n\nHere are some options to choose from:\n\nThe point at which the red line cuts the y-axis (where social_int = 0)\nThe point at which the blue line cuts the y-axis (where social_int = 0)\nThe vertical distance from the red to the blue line at the y-axis (where social_int = 0)\nThe vertical distance from the blue to the red line at the y-axis (where social_int = 0)\nThe vertical distance from the blue to the red line at the center of the plot\n\nThe vertical distance from the red to the blue line at the center of the plot\n\nThe slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the red line\nThe slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the blue line\nHow the slope of the line changes when you move from the red to the blue line\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\nFor an overview of how to interpret coefficients, review the interaction models &gt; interpreting coefficients flashcard.\nFor a specific example of coefficient interpretation, review the interaction models &gt; numeric x categorical example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nObtain parameter estimates:\n\ncoefficients(rural_mod)\n\n            (Intercept)              social_int            isRuralrural \n             30.9985688               0.6487945               1.3865688 \nsocial_int:isRuralrural \n             -0.5175856 \n\n\n\n\n(Intercept)\nsocial_int\nisRuralrural\nsocial_int:isRuralrural\n\n\n\n\\(\\beta_0\\) = (Intercept) = 31\n\nOn plot: The point at which the red line cuts the y-axis.\n\nInterpretation: The intercept, or predicted wellbeing score when the number of social interactions per week was 0, and when location was not rural.\n\nA non-rural resident who had zero social interactions per week was expected to have a wellbeing score of 31.\n\n\n\n\n\n\\(\\beta_1\\) = social_int = 0.65\n\nOn plot: The slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the red line.\n\nInterpretation: The simple slope of social interactions (number per week) for location reference group (not rural).\n\nFor someone who lives in a non-rural location, every 1 additional social interaction per week was associated with a 0.65 point change in their wellbeing score.\n\n\n\n\n\n\\(\\beta_2\\) = isRuralrural = 1.39\n\nOn plot: The vertical distance from the red to the blue line at the y-axis (where social_int = 0).\n\nInterpretation: The simple effect of location (or the difference in wellbeing scores between rural and non rural residents) when number of social interactions was 0.\n\nFor residents who had zero social interactions per week, living in a rural location was associated with wellbeing scores 1.39 points higher than living in non-rural locations (note that this difference was not significantly different from zero).\n\n\n\n\n\n\\(\\beta_3\\) = social_int:isRuralrural = -0.52\n\nOn plot: How the slope of the line differs when you move from the red to the blue line.\n\nInterpretation: The interaction between social interactions (number per week) and location (rural/not rural). This is the estimated difference in simple slopes of social interactions for rural vs non-rural residents.\n\nCompared to living in non-rural locations, living in a rural location was associated with a 0.52 lesser increase in wellbeing scores for every every 1 additional social interaction per week. Specifically, (1) for those in non-rural locations the association between wellbeing and social interactions had a slope of 0.65 (as we can see in \\(\\beta_1\\); the social_int coefficient), and (2) for those in rural locations, the association between wellbeing and social interactions has a slope of 0.13 (calculated as 0.65 + (–0.52); or \\(\\beta_1\\) the social_int coefficient + \\(\\beta_3\\) the social_int:isRuralruralcoefficient)\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nNo participants in our dataset had zero hours of social interactions per week (the lowest was 3), and we’re likely not interested in differences between rural and non-rural residents who have never interacted with others.\nMean center the continuous IV(s), and re-run your model with mean centered variable(s).\n\n\n\n\n\n\nHint\n\n\n\n\n\nThere are a couple of different ways that we can re-centre. See the data transformations &gt; centering flashcards for a recap. Note, it would be best to create a new mean-centered variable to then use within the model in this instance.\n\n\n\n\n\n\n\n Solution \n\n\nCreate mean centered variable for ‘social_int’, named ‘mc_social_int’:\n\nruraldata &lt;-\n ruraldata |&gt;\n  mutate(\n   mc_social_int = social_int - mean(social_int)\n    )\n\nRe-run model with ‘mc_social_int’:\n\n#fit model including interaction between social_int and isRural\nrural_mod1 &lt;- lm(wellbeing ~  mc_social_int * isRural, data = ruraldata)\n\n#check model output\nsummary(rural_mod1)\n\n\nCall:\nlm(formula = wellbeing ~ mc_social_int * isRural, data = ruraldata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4845  -2.7975   0.0155   2.4539  15.6743 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 38.8263     0.4581  84.754  &lt; 2e-16 ***\nmc_social_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural                -4.8581     0.6478  -7.500 2.17e-12 ***\nmc_social_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.558 on 196 degrees of freedom\nMultiple R-squared:  0.2962,    Adjusted R-squared:  0.2854 \nF-statistic: 27.49 on 3 and 196 DF,  p-value: 6.97e-15\n\n\n\n\n\n\n\nQuestion 7\n\n\nNote any differences between the summary() output between the original (“rural_mod”) and mean centred (“rural_mod1”) models. Pay particular attention to your coefficients and their significance values. How have your coefficients changed? Why do you think these differences have been observed?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThese plots illustrate the difference between the “rural_mod” and “rural_mod1” models.\n\n\n\n\nFigure 2: Difference when social interactions is not vs is mean centered.Note that the lines without SE intervals on the left plot represent predicted values below the minimum observed number of social interactions, to ensure that zero on the x-axis is visible\n\n\n\n\n\n\n\n\n\n\n Solution \n\n\nBy comparing the summary() outputs, you should see that the coefficients for (Intercept) and isRuralrural differed between the two models, whilst the coefficients for social_int and mc_social_int were the same, as were the interaction estimates social_int:isRuralrural.\n\n\n\n\n\n\nCompare Model Estimates\n\n\n\n\n\nOriginal Model - rural_mod:\nCall:\nlm(formula = wellbeing ~ social_int * isRural, data = ruraldata)\n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              30.9986     1.4284  21.702  &lt; 2e-16 ***\nsocial_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural              1.3866     2.0510   0.676  0.49981    \nsocial_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \nModel with mean centered social interactions - rural_mod1:\nCall:\nlm(formula = wellbeing ~ mc_social_int * isRural, data = ruraldata)\n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 38.8263     0.4581  84.754  &lt; 2e-16 ***\nmc_social_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural                -4.8581     0.6478  -7.500 2.17e-12 ***\nmc_social_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n\n\n\nRecall that when there is an interaction A\\(\\times\\)B, the coefficients A and B are no longer main effects. Instead, they are conditional effects upon the other being zero.\nIf we have the interaction y ~ x1 + x2 + x1:x2 (where \\(y\\) = wellbeing; \\(x_1\\) = social interactions; and \\(x_2\\) = whether or not the respondent lives in a rural location.), then:\n\nIn our “rural_mod”, the coefficient for x2 represents the association between \\(y\\) and \\(x_2\\) for someone with a score of 0 on \\(x_1\\)\n\nIn our “rural_mod1”, where x1 is mean centered, this will now make the coefficient for x2 represent the association between \\(y\\) and \\(x_2\\) for someone at the average of \\(x_1\\) (i.e., in our current example, 12.06)\n\nWhilst the difference in rural vs non-rural may not have been significantly different when the number of weekly social interactions is zero, there did appear to be a significant difference at the average number of social interactions (as you can see from the plot below - note that this is the same plot as in the hint). Note that we can see that the model doesn’t change, it is just extracting different information (the distance to move from the blue dot to the red dot is different):\n\n\n\n\nFigure 3: Difference when social interactions is not vs is mean centered"
  },
  {
    "objectID": "2_01_int1_nc.html#visualise-interaction-model",
    "href": "2_01_int1_nc.html#visualise-interaction-model",
    "title": "Interactions I: Num x Cat",
    "section": "Visualise Interaction Model",
    "text": "Visualise Interaction Model\n\nQuestion 8\n\n\nUsing the probe_interaction() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a short and concise sentence.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; numeric x categorical example &gt; model visualisation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_rural_mod &lt;- probe_interaction(model = rural_mod1, \n                  pred = mc_social_int, \n                  modx = isRural, \n                  interval = T,\n                  main.title = \"Predicted Wellbeing Scores across \\n Social Interactions by Location\",\n                  x.label = \"Number of Social Interactions per Week (Mean Centred)\",\n                  y.label = \"Wellbeing (WEMWBS Scores)\",\n                  legend.main = \"Location\")\n\nLet’s look at our plot:\n\nplt_rural_mod$interactplot\n\n\n\nFigure 4: Predicted Wellbeing Scores across Social Interactions by Location\n\n\n\n\n\n\n\n\n\nOptional: More Informative Plot\n\n\n\n\n\nTo make the plot a little more informative, we could add the data points by first creating a new dataset where we name mc_social_int as pred and isRural as modx_group (we need to do this so that the data is formatted/named in the way interactplot expects):\n\nwellbeing_probedat &lt;- ruraldata |&gt;\n  mutate(\n    pred = mc_social_int,\n    modx_group = isRural\n  )\n\nand then add geom_point() with our new dataset to our original interaction plot (to avoid overwriting our original plot, this one is being saved in a new object named plt_rural_mod2) to superimpose the data points:\n\nplt_rural_mod2 &lt;- plt_rural_mod$interactplot +\n    geom_point(data = wellbeing_probedat)\n\nplt_rural_mod2\n\n\n\nFigure 5: Predicted Wellbeing Scores across Social Interactions by Location with Data Points\n\n\n\n\n\n\n\n\n\n\n\n\nThis suggested that for individuals living in rural locations, wellbeing scores increased at a slower rate across the number of weekly social interactions in comparison to those in non-rural locations. In other words, for each additional social interaction per week, wellbeing scores of those living in non-rural locations increased at a greater rate than those in rural."
  },
  {
    "objectID": "2_01_int1_nc.html#writing-up-presenting-results",
    "href": "2_01_int1_nc.html#writing-up-presenting-results",
    "title": "Interactions I: Num x Cat",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(rural_mod1,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"mc_social_int\" = \"Social Interactions (number per week; mean centred)\",\n                          \"isRuralrural\" = \"Location - Rural\",\n                          \"mc_social_int:isRuralrural\" = \"Social Interactions (number per week; mean centred) * Location - Rural\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\nTable 2: Regression Table for Wellbeing Model\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n38.83\n37.92 – 39.73\n&lt;0.001\n\n\nSocial Interactions\n(number per week; mean\ncentred)\n0.65\n0.42 – 0.88\n&lt;0.001\n\n\nLocation - Rural\n-4.86\n-6.14 – -3.58\n&lt;0.001\n\n\nSocial Interactions\n(number per week; mean\ncentred) * Location -\nRural\n-0.52\n-0.84 – -0.20\n0.002\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.296 / 0.285\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an example of coefficient interpretation, review the interaction models &gt; numeric x categorical example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(3,196) = 27.49, p &lt; .001)\\), and the model explained approximately 28.54% of the variability in wellbeing (WEMWBS Scores).\nThere was a significant conditional association between wellbeing (WEMWBS Scores) and the number of weekly social interactions \\((\\beta = 0.65,~ SE = 0.12,~ t(196) = 5.59,~ p &lt; .001)\\), which suggested that for those living in non-rural locations, wellbeing scores increased by 0.65 for every additional social interaction per week. A significant conditional association was also evident between wellbeing and location \\((\\beta = -4.86,~ SE = 0.65,~ t(196) = -7.50,~ p &lt; .001)\\), which suggested that for those who have the average number of social interactions per week \\((M = 12.06)\\), wellbeing scores were 4.86 points lower for those in rural areas in comparison to those in non-rural.\nThe association between wellbeing (WEMWBS Scores) and social interactions was found to be dependent upon location (rural/non-rural), and this was significant \\((\\beta = -0.52,~ SE = 0.16,~ t(196) = -3.21, ~p = .002)\\). The expected increase in wellbeing (WEMWBS Scores) for every additional social interaction per week was 0.52 points less for those living in rural locations in comparison to those in non-rural. This interaction is visually presented in Figure 5. Therefore, we have evidence to reject the null hypothesis (that the association between wellbeing and social interactions is not moderated by whether or not a person lives in a rural area)."
  },
  {
    "objectID": "2_01_int1_nc_burt.html",
    "href": "2_01_int1_nc_burt.html",
    "title": "Interactions I: Num x Cat",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction\nBe able to interpret the meaning of a numeric \\(\\times\\) categorical interaction\nBe able to visualize and probe interactions\n\n\nBe up to date with lectures\nHave completed all labs from Semester 1\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nkableExtra\npsych\nsjPlot\npatchwork\nsandwich\ninteractions\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_location_rural.csv"
  },
  {
    "objectID": "2_01_int1_nc_burt.html#study-analysis-plan-overview",
    "href": "2_01_int1_nc_burt.html#study-analysis-plan-overview",
    "title": "Interactions I: Num x Cat",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\nWhen specifying your model, set ‘not rural’ as the reference group for location.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable - in this case, ‘not rural’)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\nThe statistical models flashcards may also be useful to refer to. Specifically the interaction models flashcards and numeric x categorical example flashcards might be of most use.\n\n\n\n\n\n\n\n Solution \n\n\nThe ruraldata dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants’ wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\nDensity plots and histograms will be used to visualise the marginal distributions of wellbeing and social interactions, and the strength of association between the two variables estimated via the correlation coefficient. To understand how these associations differ between rural and non-rural locations, scatterplots will be used.\nTo address the research question of whether the association between the number of social interactions and wellbeing differs between rural and non-rural residents, we are going to fit the following interaction model (where not rural will be specified as the reference group for location).\n\\[\n\\begin{align}\n\\text{Wellbeing} ~=~ & \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Location}_\\text{Rural} \\\\\n& + \\beta_3 \\cdot (\\text{Social Interactions} \\cdot \\text{Location}_\\text{Rural}) + \\epsilon \\\\\n\\end{align}\n\\quad\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_3 = 0\\)\nThe association between wellbeing and social interactions is not moderated by whether or not a person lives in a rural area.\n\\(H_1: \\beta_3 \\neq 0\\)\nThe association between wellbeing and social interactions is moderated by whether or not a person lives in a rural area.\n\n\n\n\n\nQuestion 2\n\n\nCheck coding of variables (e.g., that categorical variables are coded as factors).\nAs specified in Q1, we want ‘not rural’ as the reference group, so make sure to specify this.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the specifying reference levels flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nCheck coding of variables within ruraldata and ensure isRural is a factor with two levels, ‘rural’ and ‘not rural’:\n\n# check structure of dataset \nstr(ruraldata) \n\nspc_tbl_ [200 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ age         : num [1:200] 28 56 25 60 19 34 41 41 35 53 ...\n $ outdoor_time: num [1:200] 12 5 19 25 9 18 17 11 12 13 ...\n $ social_int  : num [1:200] 13 15 11 15 18 13 19 12 13 15 ...\n $ routine     : num [1:200] 1 1 1 0 1 1 1 1 0 1 ...\n $ wellbeing   : num [1:200] 36 41 35 35 32 34 39 43 35 37 ...\n $ isRural     : chr [1:200] \"rural\" \"rural\" \"rural\" \"rural\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   age = col_double(),\n  ..   outdoor_time = col_double(),\n  ..   social_int = col_double(),\n  ..   routine = col_double(),\n  ..   wellbeing = col_double(),\n  ..   isRural = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#alternatively run is.factor() for specific variable\nis.factor(ruraldata$isRural) \n\n[1] FALSE\n\n#set isRural as a factor\nruraldata &lt;- ruraldata |&gt;\n    mutate(\n        isRural = factor(isRural, \n                           levels = c('not rural', 'rural')))\n\n\n#check the levels, and make sure 'not rural' is first\nlevels(ruraldata$isRural)\n\n[1] \"not rural\" \"rural\""
  },
  {
    "objectID": "2_01_int1_nc_burt.html#descriptive-statistics-visualisations",
    "href": "2_01_int1_nc_burt.html#descriptive-statistics-visualisations",
    "title": "Interactions I: Num x Cat",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your findings in the context of the study (i.e., comment on any observed differences among groups).\nIn particular:\n\nExplore the associations among the variables included in your analysis\nProduce a visualisation of the association between weekly number of social interactions and well-being, with separate facets for rural vs non-rural respondents OR with different colours for each level of the isRural variable.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables - categorical and numeric values examples and numeric x categorical example - visualise data, paying particular attention to the type of data that you’re working with.\nFor your table of descriptive statistics, both the group_by() and summarise() functions will come in handy here.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nWe can present our summary statistics for wellbeing and social interactions grouped by location in a well formatted table using kable():\n\nruraldata |&gt;\n    group_by(isRural) |&gt;\n    summarise(Wellbeing_M = mean(wellbeing),\n              Wellbeing_SD = sd(wellbeing),\n              SocialInt_M = mean(social_int),\n              SocialInt_SD = sd(social_int)) |&gt;\n    kable(caption = \"Wellbeing, Social Interactions, and Location Descriptive Statistics\", digits = 2) |&gt;\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Wellbeing, Social Interactions, and Location Descriptive Statistics\n\nisRural\nWellbeing_M\nWellbeing_SD\nSocialInt_M\nSocialInt_SD\n\n\n\nnot rural\n38.57\n5.66\n11.67\n3.95\n\n\nrural\n34.02\n3.99\n12.46\n4.08\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA quick non-APA style table - i.e., not for use in reports\n\n\n\n\n\nFor a quick overview of several summary statistics at once for all columns of our dataframe, but separately for each level of location (i.e.,rural and non-rural), you can use describeBy() from the psych package:\n\ndescribeBy(ruraldata, ruraldata$isRural)\n\n\n Descriptive statistics by group \ngroup: not rural\n             vars   n  mean    sd median trimmed   mad min max range  skew\nage             1 100 43.01 14.95   41.5   42.74 18.53  18  70    52  0.13\noutdoor_time    2 100 18.72  6.91   18.0   18.61  7.41   6  34    28  0.08\nsocial_int      3 100 11.67  3.95   12.0   11.51  3.71   3  24    21  0.37\nroutine         4 100  0.54  0.50    1.0    0.55  0.00   0   1     1 -0.16\nwellbeing       5 100 38.57  5.66   39.0   38.36  5.93  26  59    33  0.44\nisRural*        6 100  1.00  0.00    1.0    1.00  0.00   1   1     0   NaN\n             kurtosis   se\nage             -1.13 1.49\noutdoor_time    -0.87 0.69\nsocial_int       0.13 0.39\nroutine         -1.99 0.05\nwellbeing        0.38 0.57\nisRural*          NaN 0.00\n------------------------------------------------------------ \ngroup: rural\n             vars   n  mean    sd median trimmed   mad min max range  skew\nage             1 100 41.59 14.85     42   41.38 17.79  18  69    51  0.09\noutdoor_time    2 100 17.79  7.29     18   17.68  7.41   1  35    34  0.06\nsocial_int      3 100 12.46  4.08     12   12.41  4.45   4  21    17  0.05\nroutine         4 100  0.59  0.49      1    0.61  0.00   0   1     1 -0.36\nwellbeing       5 100 34.02  3.99     34   34.08  2.97  22  45    23 -0.07\nisRural*        6 100  2.00  0.00      2    2.00  0.00   2   2     0   NaN\n             kurtosis   se\nage             -1.18 1.49\noutdoor_time    -0.49 0.73\nsocial_int      -0.82 0.41\nroutine         -1.89 0.05\nwellbeing        0.40 0.40\nisRural*          NaN 0.00\n\n\n\n\n\n\n\nLet’s produce our plots with a facet for rural vs non-rural residents:\n\nggplot(data = ruraldata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method=\"lm\", se=FALSE) +\n  facet_wrap(~isRural, labeller = \"label_both\") + \n  labs(x = \"Social Interactions (number per week)\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\n\n\n\nOr instead of facets, we could use different colors for each location (rural vs non-rural):\n\nggplot(data = ruraldata, aes(x = social_int, y = wellbeing, colour = isRural)) +\n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE) +\n    scale_colour_discrete(\n    name =\"Location\",\n    labels=c(\"Not Rural\", \"Rural\")) + \n    labs(x = \"Social Interactions (number per week)\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nThose in non-rural locations appear to have higher wellbeing scores across almost all levels of social interactions. The slopes appear to be different for each location, where the greatest difference in wellbeing scores by location is most visible the highest number of social interactions. This suggests that there may be an interaction.\n\n\n\n\n\n\n\n\n\nHow do we know there might be an interaction?\n\n\n\n\n\nThe lines in the two plots above do not run in parallel - this suggested the presence of an interaction. Specifically in our example, the non-parallel lines suggested an interaction effect based on location, as the number of social interactions did not appear to have the same influence on rural and non-rural residents’ wellbeing scores.\nHowever, the only way we can determine whether there is actually an interaction is by including an interaction term in our model, and testing this."
  },
  {
    "objectID": "2_01_int1_nc_burt.html#model-fitting-interpretation",
    "href": "2_01_int1_nc_burt.html#model-fitting-interpretation",
    "title": "Interactions I: Num x Cat",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nFit the specified model, and assign it the name “rural_mod”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can fit interaction models using the lm() function.\nFor an overview, see the interaction models flashcards.\nFor an example, review the interaction models &gt; numeric x categorical example &gt; model building flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit model including interaction between social_int and isRural\nrural_mod &lt;- lm(wellbeing ~  social_int * isRural, data = ruraldata)\n\n#check model output\nsummary(rural_mod)\n\n\nCall:\nlm(formula = wellbeing ~ social_int * isRural, data = ruraldata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4845  -2.7975   0.0155   2.4539  15.6743 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              30.9986     1.4284  21.702  &lt; 2e-16 ***\nsocial_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural              1.3866     2.0510   0.676  0.49981    \nsocial_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.558 on 196 degrees of freedom\nMultiple R-squared:  0.2962,    Adjusted R-squared:  0.2854 \nF-statistic: 27.49 on 3 and 196 DF,  p-value: 6.97e-15\n\n\n\n\n\n\n\nQuestion 5\n\n\nLook at the parameter estimates from your model, and write a description of what each one corresponds to on the plot shown in Figure 1 (it may help to sketch out the plot yourself and annotate it, and refer to the drop down options below).\n\n\n\n\nFigure 1: Multiple regression model: Wellbeing ~ Social Interactions * is Rural\n\n\n\n\n Options for Mapping Parameter Estimates to Plot\n\n\nHere are some options to choose from:\n\nThe point at which the red line cuts the y-axis (where social_int = 0)\nThe point at which the blue line cuts the y-axis (where social_int = 0)\nThe vertical distance from the red to the blue line at the y-axis (where social_int = 0)\nThe vertical distance from the blue to the red line at the y-axis (where social_int = 0)\nThe vertical distance from the blue to the red line at the center of the plot\n\nThe vertical distance from the red to the blue line at the center of the plot\n\nThe slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the red line\nThe slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the blue line\nHow the slope of the line changes when you move from the red to the blue line\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\nFor an overview of how to interpret coefficients, review the interaction models &gt; interpreting coefficients flashcard.\nFor a specific example of coefficient interpretation, review the interaction models &gt; numeric x categorical example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nObtain parameter estimates:\n\ncoefficients(rural_mod)\n\n            (Intercept)              social_int            isRuralrural \n             30.9985688               0.6487945               1.3865688 \nsocial_int:isRuralrural \n             -0.5175856 \n\n\n\n\n(Intercept)\nsocial_int\nisRuralrural\nsocial_int:isRuralrural\n\n\n\n\\(\\beta_0\\) = (Intercept) = 31\n\nOn plot: The point at which the red line cuts the y-axis.\n\nInterpretation: The intercept, or predicted wellbeing score when the number of social interactions per week was 0, and when location was not rural.\n\nA non-rural resident who had zero social interactions per week was expected to have a wellbeing score of 31.\n\n\n\n\n\n\\(\\beta_1\\) = social_int = 0.65\n\nOn plot: The slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the red line.\n\nInterpretation: The simple slope of social interactions (number per week) for location reference group (not rural).\n\nFor someone who lives in a non-rural location, every 1 additional social interaction per week was associated with a 0.65 point change in their wellbeing score.\n\n\n\n\n\n\\(\\beta_2\\) = isRuralrural = 1.39\n\nOn plot: The vertical distance from the red to the blue line at the y-axis (where social_int = 0).\n\nInterpretation: The simple effect of location (or the difference in wellbeing scores between rural and non rural residents) when number of social interactions was 0.\n\nFor residents who had zero social interactions per week, living in a rural location was associated with wellbeing scores 1.39 points higher than living in non-rural locations (note that this difference was not significantly different from zero).\n\n\n\n\n\n\\(\\beta_3\\) = social_int:isRuralrural = -0.52\n\nOn plot: How the slope of the line differs when you move from the red to the blue line.\n\nInterpretation: The interaction between social interactions (number per week) and location (rural/not rural). This is the estimated difference in simple slopes of social interactions for rural vs non-rural residents.\n\nCompared to living in non-rural locations, living in a rural location was associated with a 0.52 lesser increase in wellbeing scores for every every 1 additional social interaction per week. Specifically, (1) for those in non-rural locations the association between wellbeing and social interactions had a slope of 0.65 (as we can see in \\(\\beta_1\\); the social_int coefficient), and (2) for those in rural locations, the association between wellbeing and social interactions has a slope of 0.13 (calculated as 0.65 + (–0.52); or \\(\\beta_1\\) the social_int coefficient + \\(\\beta_3\\) the social_int:isRuralruralcoefficient)\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nNo participants in our dataset had zero hours of social interactions per week (the lowest was 3), and we’re likely not interested in differences between rural and non-rural residents who have never interacted with others.\nMean center the continuous IV(s), and re-run your model with mean centered variable(s).\n\n\n\n\n\n\nHint\n\n\n\n\n\nThere are a couple of different ways that we can re-centre. See the data transformations &gt; centering flashcards for a recap. Note, it would be best to create a new mean-centered variable to then use within the model in this instance.\n\n\n\n\n\n\n\n Solution \n\n\nCreate mean centered variable for ‘social_int’, named ‘mc_social_int’:\n\nruraldata &lt;-\n ruraldata |&gt;\n  mutate(\n   mc_social_int = social_int - mean(social_int)\n    )\n\nRe-run model with ‘mc_social_int’:\n\n#fit model including interaction between social_int and isRural\nrural_mod1 &lt;- lm(wellbeing ~  mc_social_int * isRural, data = ruraldata)\n\n#check model output\nsummary(rural_mod1)\n\n\nCall:\nlm(formula = wellbeing ~ mc_social_int * isRural, data = ruraldata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4845  -2.7975   0.0155   2.4539  15.6743 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 38.8263     0.4581  84.754  &lt; 2e-16 ***\nmc_social_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural                -4.8581     0.6478  -7.500 2.17e-12 ***\nmc_social_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.558 on 196 degrees of freedom\nMultiple R-squared:  0.2962,    Adjusted R-squared:  0.2854 \nF-statistic: 27.49 on 3 and 196 DF,  p-value: 6.97e-15\n\n\n\n\n\n\n\nQuestion 7\n\n\nNote any differences between the summary() output between the original (“rural_mod”) and mean centred (“rural_mod1”) models. Pay particular attention to your coefficients and their significance values. How have your coefficients changed? Why do you think these differences have been observed?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThese plots illustrate the difference between the “rural_mod” and “rural_mod1” models.\n\n\n\n\nFigure 2: Difference when social interactions is not vs is mean centered.Note that the lines without SE intervals on the left plot represent predicted values below the minimum observed number of social interactions, to ensure that zero on the x-axis is visible\n\n\n\n\n\n\n\n\n\n\n Solution \n\n\nBy comparing the summary() outputs, you should see that the coefficients for (Intercept) and isRuralrural differed between the two models, whilst the coefficients for social_int and mc_social_int were the same, as were the interaction estimates social_int:isRuralrural.\n\n\n\n\n\n\nCompare Model Estimates\n\n\n\n\n\nOriginal Model - rural_mod:\nCall:\nlm(formula = wellbeing ~ social_int * isRural, data = ruraldata)\n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              30.9986     1.4284  21.702  &lt; 2e-16 ***\nsocial_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural              1.3866     2.0510   0.676  0.49981    \nsocial_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \nModel with mean centered social interactions - rural_mod1:\nCall:\nlm(formula = wellbeing ~ mc_social_int * isRural, data = ruraldata)\n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 38.8263     0.4581  84.754  &lt; 2e-16 ***\nmc_social_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural                -4.8581     0.6478  -7.500 2.17e-12 ***\nmc_social_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n\n\n\nRecall that when there is an interaction A\\(\\times\\)B, the coefficients A and B are no longer main effects. Instead, they are conditional effects upon the other being zero.\nIf we have the interaction y ~ x1 + x2 + x1:x2 (where \\(y\\) = wellbeing; \\(x_1\\) = social interactions; and \\(x_2\\) = whether or not the respondent lives in a rural location.), then:\n\nIn our “rural_mod”, the coefficient for x2 represents the association between \\(y\\) and \\(x_2\\) for someone with a score of 0 on \\(x_1\\)\n\nIn our “rural_mod1”, where x1 is mean centered, this will now make the coefficient for x2 represent the association between \\(y\\) and \\(x_2\\) for someone at the average of \\(x_1\\) (i.e., in our current example, 12.06)\n\nWhilst the difference in rural vs non-rural may not have been significantly different when the number of weekly social interactions is zero, there did appear to be a significant difference at the average number of social interactions (as you can see from the plot below - note that this is the same plot as in the hint). Note that we can see that the model doesn’t change, it is just extracting different information (the distance to move from the blue dot to the red dot is different):\n\n\n\n\nFigure 3: Difference when social interactions is not vs is mean centered"
  },
  {
    "objectID": "2_01_int1_nc_burt.html#visualise-interaction-model",
    "href": "2_01_int1_nc_burt.html#visualise-interaction-model",
    "title": "Interactions I: Num x Cat",
    "section": "Visualise Interaction Model",
    "text": "Visualise Interaction Model\n\nQuestion 8\n\n\nUsing the probe_interaction() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a short and concise sentence.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; numeric x categorical example &gt; model visualisation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_rural_mod &lt;- probe_interaction(model = rural_mod1, \n                  pred = mc_social_int, \n                  modx = isRural, \n                  interval = T,\n                  main.title = \"Predicted Wellbeing Scores across \\n Social Interactions by Location\",\n                  x.label = \"Number of Social Interactions per Week (Mean Centred)\",\n                  y.label = \"Wellbeing (WEMWBS Scores)\",\n                  legend.main = \"Location\")\n\nLet’s look at our plot:\n\nplt_rural_mod$interactplot\n\n\n\nFigure 4: Predicted Wellbeing Scores across Social Interactions by Location\n\n\n\n\n\n\n\n\n\nOptional: More Informative Plot\n\n\n\n\n\nTo make the plot a little more informative, we could add the data points by first creating a new dataset where we name mc_social_int as pred and isRural as modx_group (we need to do this so that the data is formatted/named in the way interactplot expects):\n\nwellbeing_probedat &lt;- ruraldata |&gt;\n  mutate(\n    pred = mc_social_int,\n    modx_group = isRural\n  )\n\nand then add geom_point() with our new dataset to our original interaction plot (to avoid overwriting our original plot, this one is being saved in a new object named plt_rural_mod2) to superimpose the data points:\n\nplt_rural_mod2 &lt;- plt_rural_mod$interactplot +\n    geom_point(data = wellbeing_probedat)\n\nplt_rural_mod2\n\n\n\nFigure 5: Predicted Wellbeing Scores across Social Interactions by Location with Data Points\n\n\n\n\n\n\n\n\n\n\n\n\nThis suggested that for individuals living in rural locations, wellbeing scores increased at a slower rate across the number of weekly social interactions in comparison to those in non-rural locations. In other words, for each additional social interaction per week, wellbeing scores of those living in non-rural locations increased at a greater rate than those in rural."
  },
  {
    "objectID": "2_01_int1_nc_burt.html#writing-up-presenting-results",
    "href": "2_01_int1_nc_burt.html#writing-up-presenting-results",
    "title": "Interactions I: Num x Cat",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(rural_mod1,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"mc_social_int\" = \"Social Interactions (number per week; mean centred)\",\n                          \"isRuralrural\" = \"Location - Rural\",\n                          \"mc_social_int:isRuralrural\" = \"Social Interactions (number per week; mean centred) * Location - Rural\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\nTable 2: Regression Table for Wellbeing Model\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n38.83\n37.92 – 39.73\n&lt;0.001\n\n\nSocial Interactions\n(number per week; mean\ncentred)\n0.65\n0.42 – 0.88\n&lt;0.001\n\n\nLocation - Rural\n-4.86\n-6.14 – -3.58\n&lt;0.001\n\n\nSocial Interactions\n(number per week; mean\ncentred) * Location -\nRural\n-0.52\n-0.84 – -0.20\n0.002\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.296 / 0.285\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an example of coefficient interpretation, review the interaction models &gt; numeric x categorical example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(3,196) = 27.49, p &lt; .001)\\), and the model explained approximately 28.54% of the variability in wellbeing (WEMWBS Scores).\nThere was a significant conditional association between wellbeing (WEMWBS Scores) and the number of weekly social interactions \\((\\beta = 0.65,~ SE = 0.12,~ t(196) = 5.59,~ p &lt; .001)\\), which suggested that for those living in non-rural locations, wellbeing scores increased by 0.65 for every additional social interaction per week. A significant conditional association was also evident between wellbeing and location \\((\\beta = -4.86,~ SE = 0.65,~ t(196) = -7.50,~ p &lt; .001)\\), which suggested that for those who have the average number of social interactions per week \\((M = 12.06)\\), wellbeing scores were 4.86 points lower for those in rural areas in comparison to those in non-rural.\nThe association between wellbeing (WEMWBS Scores) and social interactions was found to be dependent upon location (rural/non-rural), and this was significant \\((\\beta = -0.52,~ SE = 0.16,~ t(196) = -3.21, ~p = .002)\\). The expected increase in wellbeing (WEMWBS Scores) for every additional social interaction per week was 0.52 points less for those living in rural locations in comparison to those in non-rural. This interaction is visually presented in Figure 5. Therefore, we have evidence to reject the null hypothesis (that the association between wellbeing and social interactions is not moderated by whether or not a person lives in a rural area)."
  },
  {
    "objectID": "2_02_int2_nn.html",
    "href": "2_02_int2_nn.html",
    "title": "Interactions II: Num x Num",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction\nBe able to interpret the meaning of a numeric \\(\\times\\) numeric interaction\nUnderstand the principle of marginality and why this impacts modelling choices with interactions\nBe able to visualize and probe interactions\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nsjPlot\nkableExtra\nsandwich\ninteractions\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/scs_study.csv"
  },
  {
    "objectID": "2_02_int2_nn.html#study-analysis-plan-overview",
    "href": "2_02_int2_nn.html#study-analysis-plan-overview",
    "title": "Interactions II: Num x Num",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\nThe statistical models flashcards may also be useful to refer to. Specifically the interaction models flashcards and numeric x numeric example flashcards might be of most use.\n\n\n\n\n\n\n\n Solution \n\n\nThe scs_study dataset contained information on 656 participants, including \\(z\\)-scores on 5 personality traits assessed by the Big-Five Aspects Scale (BFAS; Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism). Participants were also assessed on the Social Comparison Scale (SCS), which is an 11-item scale measuring self-perception (relative to others) of social rank, attractiveness and belonging, and the Depression Anxiety and Stress Scale (DASS-21) - a 21 item measure with higher scores indicating higher severity of symptoms. For both of these measures, only total scores were available. Items in the SCS were measured on a 5-point scale, giving minimum and maximum possible scores of 11 and 55 respectively. Items in the DASS-21 were measured on a 4-point scale, meaning that scores could range from 21 to 84.\nDensity plots and histograms will be used to visualise the marginal distributions of DASS-21 Scores, SCS Scores, and Neuroticism. To understand the strength of association among the variables, we will estimate the correlation coefficients; and to visualise these associations scatterplots will be used. To address the research question of whether Neuroticism moderated the effect of social comparison on depression and anxiety, we are going to fit the following interaction model:\n\\[\n\\begin{align}\n\\text{DASS-21 Score} ~=~ & \\beta_0 + \\beta_1 \\cdot \\text{SCS Score} + \\beta_2 \\cdot \\text{Neuroticism} \\\\  \n& + \\beta_3 \\cdot (\\text{Neuroticism} \\cdot \\text{SCS Score}) + \\epsilon\n\\end{align}\n\\] Effects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_3 = 0\\)\nThe effect of social comparison on symptoms of depression, anxiety and stress does not vary depending on level of Neuroticism.\n\\(H_1: \\beta_3 \\neq 0\\)\nThe effect of social comparison on symptoms of depression, anxiety and stress does vary depending on level of Neuroticism."
  },
  {
    "objectID": "2_02_int2_nn.html#descriptive-statistics-visualisations",
    "href": "2_02_int2_nn.html#descriptive-statistics-visualisations",
    "title": "Interactions II: Num x Num",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 2\n\n\nProvide a table of descriptive statistics and visualise your data. You may also want to consider estimating the associations among the variables of interest.\nRemember to interpret these in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables - numeric values only examples and numeric x numeric example - visualise data.\nThe pairs.panels() function may come in handy here to complete multiple tasks at once!\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\n# note that we are selecting only our three variables of interest (dass, scs, zn)\n\nscs_study |&gt;\n    select(dass, scs, zn) |&gt; \n    describe() |&gt;\n    kable(caption = \"Descriptive Statistics - DASS-21, SCS, and Neuroticism (Z-Scored)\", digits = 2) |&gt;\n    kable_styling()\n\n\n\nTable 1: Descriptive Statistics - DASS-21, SCS, and Neuroticism (Z-Scored)\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\ndass\n1\n656\n44.72\n6.76\n44.00\n44.62\n5.93\n23.00\n68.00\n45.0\n0.18\n0.33\n0.26\n\n\nscs\n2\n656\n35.77\n3.53\n35.00\n35.59\n2.97\n27.00\n54.00\n27.0\n0.60\n0.96\n0.14\n\n\nzn\n3\n656\n0.00\n1.00\n-0.21\n-0.10\n1.00\n-1.45\n3.35\n4.8\n0.80\n0.04\n0.04\n\n\n\n\n\n\n\n\n\n\nVisualise associations among variables of interest:\n\nscs_study |&gt;\n  ggplot(aes(x = scs, y = dass, colour = zn)) +\n  geom_point()\n\n\n\n\n\n\n\n\nscs_study |&gt; \n  select(dass, scs, zn) |&gt;\n  pairs.panels()\n\n\n\n\n\n\n\n\n\n\nDescription of individual variables:\n\n\n\n\n\n\n\nThe marginal distribution of scores on the Depression, Anxiety and Stress Scale (DASS-21) was unimodal with a mean of 44.72 and a standard deviation of 6.76.\nThe marginal distribution of scores on the Social Comparison Scale (SCS) was unimodal with a mean of 35.77 and a standard deviation of 3.53.\nThe marginal distribution of Neuroticism (Z-scored) was positively skewed.\n\n\n\n\nDescription of correlations:\n\n\n\n\n\n\n\nThere was a weak, negative association between scores on the Depression Anxiety and Stress Scale and scores on the Social Comparison Scale for the participants in the sample \\((r = -.23)\\)\n\nSeverity of symptoms measured on the DASS-21 were lower, on average, for those who more favorably perceived their social rank\n\n\n\nThere was a weak, positive association between DASS-21 Scores and levels of Neuroticism \\((r = .20)\\)\n\nParticipants who were more neurotic tended to, on average, display a higher severity of symptoms of depression, anxiety and stress\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nFor demonstration purposes only\nTo help us visualise and understand the associations among our variables a little better, copy and run the two code chunks below. It takes the dataset, and uses the cut() function to add a new variable called “zn_group”, which is the “zn” variable split into 4 groups.\n\nscs_study &lt;-\n  scs_study |&gt;\n  mutate(\n    zn_group = cut(zn, 4)\n  )\n\nWe can see how it has split the “zn” variable by plotting the two against one another (note that the levels of the new variable are named according to the cut-points):\n\nggplot(data = scs_study, aes(x = zn_group, y = zn)) + \n  geom_point()\n\n\n\n\n\n\n\nPlot the association between scores on the SCS and scores on the DASS-21, for each group of the variable we just created.\nHow does the pattern differ across groups? Does it suggest an interaction?\n\n\n\n\n\n\nHint\n\n\n\n\n\nRather than creating four separate plots, you might want to map some feature of the plot to the variable we created in the data, or make use of facet_wrap() / facet_grid().\nRemember that you can specify geom_smooth() to add a trend line. For a recap, review the facet examples contained within the visual exploration flashcards. Alternatively, review the numeric x numeric example - visualise data flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\nggplot(data = scs_study, aes(x = scs, y = dass, col = zn_group)) + \n  geom_point() + \n  geom_smooth(method='lm', se = FALSE) +\n  facet_grid(~zn_group) +\n  labs(x = \"SCS Scores \", y = \"DASS-21 Scores\") +\n  theme(legend.position = \"none\") # removes the legend\n\n\n\n\n\n\n\nThe association between DASS-21 scores and SCS scores appears to be different across these groups. For those with a relatively high Neuroticism score, the association seems stronger, while for those with a low Neuroticism score there is almost no discernible association.\nThis does suggest an interaction - the association of DASS-21 ~ SCS differed across the values of Neuroticism.\n\n\n\n\n\nVisualising Interaction Terms\nCutting one of the explanatory variables up into groups essentially turns a numeric variable into a categorical one. We did this just to make it easier to visualise how an association differs across the values of another variable, because we can imagine a separate line for the association between SCS and DASS-21 scores for each of the groups of Neuroticism. However, in grouping a numeric variable like this we lose information. Neuroticism is measured on a continuous scale, and we want to capture how the association between SCS and DASS-21 differs across that continuum (rather than cutting it into chunks).\nWe could imagine cutting it into more and more chunks (see Figure 1), until what we end up with is an infinite number of lines - i.e., a three-dimensional plane/surface (recall that in for a multiple regression model with 2 explanatory variables, we can think of the model as having three-dimensions). The inclusion of the interaction term simply results in this surface no longer being necessarily flat. You can see this in Figure 2.\n\n\n\n\nFigure 1: Separate regression lines DASS ~ SCS for Neuroticism when cut into 4 (left) or 6 (center) or 12 (right) groups.\n\n\n\n\n\n\nFigure 2: 3D plot of regression surface with interaction. You can explore the plot in the figure below from different angles by moving it around with your mouse."
  },
  {
    "objectID": "2_02_int2_nn.html#model-fitting-interpretation",
    "href": "2_02_int2_nn.html#model-fitting-interpretation",
    "title": "Interactions II: Num x Num",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nConsider that Neuroticism has already been \\(z\\)-scored, but scs has not. To ensure that we can compare the effects of our estimates (and so they are both on meaningful scales), standardize the scs variable.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the standardisation flashcards for a recap if needed. Note, it would be best to create a new z-scored variable to then use within the model in this instance.\n\n\n\n\n\n\n\n Solution \n\n\n\n# standardize scs score\nscs_study &lt;- \n  scs_study |&gt; \n    mutate(\n      zscs = (scs-mean(scs))/sd(scs)\n    )\n\n\n\n\n\n\nQuestion 5\n\n\nFit your model (including the standardized predictor variables) using lm(), and assign it the name “dass_mdl”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can fit interaction models using the lm() function.\nFor an overview, see the interaction models flashcards.\nFor an example, review the interaction models &gt; numeric x numeric example &gt; model building flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit interaction model\ndass_mdl &lt;- lm(dass ~  zn*zscs, data = scs_study)\n\n#check model output\nsummary(dass_mdl)\n\n\nCall:\nlm(formula = dass ~ zn * zscs, data = scs_study)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.301  -3.825  -0.173   3.733  45.777 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  44.9324     0.2405 186.807  &lt; 2e-16 ***\nzn            1.5798     0.2409   6.559 1.11e-10 ***\nzscs         -1.5691     0.2416  -6.495 1.64e-10 ***\nzn:zscs      -1.8332     0.2316  -7.915 1.06e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.123 on 652 degrees of freedom\nMultiple R-squared:  0.1825,    Adjusted R-squared:  0.1787 \nF-statistic:  48.5 on 3 and 652 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\nQuestion 6\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\nFor an overview of how to interpret coefficients, review the interaction models &gt; interpreting coefficients flashcard. It is important to remember that you have standardised the variables in your model, and this will affect your interpretation. For a recap on what standardisation is and how it affects the scales of your variables, review the standardisation flashcard.\nFor a specific example of coefficient interpretation, review the interaction models &gt; numeric x numeric example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nObtain parameter estimates:\n\ncoefficients(dass_mdl)\n\n(Intercept)          zn        zscs     zn:zscs \n  44.932448    1.579769   -1.569097   -1.833169 \n\n\n\n\n(Intercept)\nzn\nzscs\nzscs:zn\n\n\n\n\\(\\beta_0\\) = (Intercept) = 44.93\n\nThe intercept, or predicted DASS-21 score for an individual with an average SCS score and average Neuroticism score. In this case, the mean scores of SCS and Neuroticism are both 0 (since both have been standardised).\n\nAn individual with a Neuroticism score of 0 (\\(Z\\)-scored) and an SCS score of 0 (\\(Z\\)-scored) was expected to have a DASS-21 score of 44.93 points.\n\n\n\n\n\n\\(\\beta_1\\) = zn = 1.58\n\nThe simple slope of Neuroticism on DASS-21 scores with average SCS scores (0; \\(Z\\)-scored).\n\nSpecifically for an individual with an average SCS score (0; \\(Z\\)-scored), every 1 standard deviation increase in Neuroticism score was associated with a 1.58 point increase in DASS-21 scores.\n\n\n\n\n\n\\(\\beta_2\\) = zscs = -1.57\n\nThe simple slope of SCS scores on DASS-21 scores with average Neuroticism scores (0; \\(Z\\)-scored).\n\nSpecifically for an individual with an average Neuroticism score (0; \\(Z\\)-scored), every 1 standard deviation increase in SCS score was associated with a 1.57 decrease in DASS-21 scores.\n\n\n\n\n\n\\(\\beta_3\\) = zscs:zn = -1.83\n\nThe interaction between SCS score and Neuroticism on DASS-21 Scores - the change in the slope of SCS Scores as a function of Neuroticism.\n\nFor every 1 standard deviation increase in SCS scores, when Neuroticism scores increased by 1 standard deviation, the slope with DASS-21 scores was adjusted by -1.83 points. Equivalently, the higher Neuroticism scores, the stronger the negative association between SCS Scores and DASS-21 scores."
  },
  {
    "objectID": "2_02_int2_nn.html#visualise-interaction-model",
    "href": "2_02_int2_nn.html#visualise-interaction-model",
    "title": "Interactions II: Num x Num",
    "section": "Visualise Interaction Model",
    "text": "Visualise Interaction Model\n\nQuestion 7\n\n\nUsing the probe_interaction() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a short and concise sentence.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; numeric x numeric example &gt; model visualisation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_dass_mdl &lt;- probe_interaction(model = dass_mdl, \n                  pred = zscs, \n                  modx = zn, \n                  cond.int = T,\n                  interval = T, \n                  jnplot = T,\n                  main.title = \"Neuroticism moderating the effect of\\nsocial comparison on depression and anxiety\",\n                  x.label = \"Social Comparison Scale (Z-scored)\",\n                  y.label = \"DASS-21 Scores\",\n                  legend.main = \"Neuroticism (Z-scored)\")\n\nLet’s look at the plot - to do so you need to call interactplot from your object plt_dass_mdl:\n\nplt_dass_mdl$interactplot\n\n\n\nFigure 3: Simple Slopes for +/- 1 SD and Mean Neuroticism Scores\n\n\n\n\n\n\n\n\n\nRecall that higher DASS-21 scores indicate higher severity of symptoms. Based on this, we can state:\n\nFor individuals 1 SD below the sample mean on Neuroticism, as their SCS Score increases, it appears that their DASS-21 scores remain flat / there is a very slight increase\n\nFor individuals with average levels of Neuroticism, as their SCS Score increases, it appears that their DASS-21 scores decreases\n\nFor individuals 1 SD above the sample mean on Neuroticism, as their SCS Score increases, it appears that their DASS-21 scores more steeply decreases\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nConduct a simple slopes and regions of significance analysis.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; numeric x numeric example &gt; model visualisation flashcards. Pay particular attention to how you can extract specific parts of output.\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_dass_mdl$simslopes\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen zn is OUTSIDE the interval [-1.28, -0.55], the slope of zscs is p &lt;\n.05.\n\nNote: The range of observed values of zn is [-1.45, 3.35]\n\n\nSIMPLE SLOPES ANALYSIS \n\nWhen zn = -1.000000e+00 (- 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                  0.26   0.35     0.76   0.45\nConditional intercept         43.35   0.34   127.47   0.00\n\nWhen zn = -8.610271e-16 (Mean): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -1.57   0.24    -6.50   0.00\nConditional intercept         44.93   0.24   186.81   0.00\n\nWhen zn =  1.000000e+00 (+ 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -3.40   0.32   -10.59   0.00\nConditional intercept         46.51   0.34   136.52   0.00\n\n\n\n\nFigure 4: Johnson-Neyman Plot\n\n\n\n\n\n\n\n\n\nThe Johnson-Neyman technique (see Figure 4) indicated that the association between DASS-21 scores and SCS was not significant when Neuroticism scores between -0.55 and -1.28 standard deviations below the mean."
  },
  {
    "objectID": "2_02_int2_nn.html#writing-up-presenting-results",
    "href": "2_02_int2_nn.html#writing-up-presenting-results",
    "title": "Interactions II: Num x Num",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(dass_mdl,\n          dv.labels = \"DASS-21 Scores\",\n          pred.labels = c(\"zscs\" = \"Social Comparison Scale (Z-scored)\",\n                          \"zn\" = \"Neuroticism (Z-scored)\",\n                          \"zn:zscs\" = \"Social Comparison Scale (Z-scored): Neutoricism (Z-scored)\"),\n          title = \"Regression Table for DASS-21 Model\")\n\n\n\nTable 2: Regression table for DASS-21 model\n\n\n\n\n\n\n\n\n \nDASS-21 Scores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n44.93\n44.46 – 45.40\n&lt;0.001\n\n\nNeuroticism (Z-scored)\n1.58\n1.11 – 2.05\n&lt;0.001\n\n\nSocial Comparison Scale\n(Z-scored)\n-1.57\n-2.04 – -1.09\n&lt;0.001\n\n\nSocial Comparison Scale\n(Z-scored): Neutoricism\n(Z-scored)\n-1.83\n-2.29 – -1.38\n&lt;0.001\n\n\nObservations\n656\n\n\nR2 / R2 adjusted\n0.182 / 0.179\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an example of coefficient interpretation, review the interaction models &gt; numeric x numeric example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nFull regression results including 95% confidence intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(3,652) = 48.50, p &lt; .001)\\), and the model explained approximately 17.87% of the variability in DASS-21 scores.\nThere was a significant conditional association between DASS-21 Scores and SCS scores (\\(z\\)-scored) \\((\\beta = -1.57, SE = 0.24, p &lt; .001)\\). This suggested that for those with Neuroticism scores of 0, DASS-21 scores decreased by 1.57 points for every 1 standard deviation increase in SCS scores.\nA significant conditional association was also evident between DASS-21 Scores and Neuroticism (\\(z\\)-scored) \\((\\beta = 1.58, SE = 0.24, p &lt; .001)\\). This suggested that for those with SCS scores of 0, DASS-21 scores increased by 1.58 points for every 1 standard deviation increase in Neuroticism.\nThe association between symptoms of depression and anxiety (DASS-21 scores) and social comparison was found to be dependent upon the level of Neuroticism, with a greater negative association between the two for those with higher levels of Neuroticism \\((\\beta = -1.83, SE = 0.23, p &lt; .001)\\). For every standard deviation increase in SCS Scores, the change in DASS-21 scores associated with an increase of 1 SD in Neuroticism was adjusted by -1.83 points (see Figure Figure 3). We further used the Johnson-Neyman technique to probe the interaction, and to identify regions of significance. We identified that Neuroticism values (\\(z\\)-scored) outside the range of -1.28 to -0.55 standard deviations below the mean were significant (see Figure 4).\nTherefore, we have evidence to reject the null hypothesis (that the effect of social comparison on symptoms of depression, anxiety and stress does not vary depending on level of Neuroticism)."
  },
  {
    "objectID": "2_02_int2_nn_ivy.html",
    "href": "2_02_int2_nn_ivy.html",
    "title": "Interactions II: Num x Num",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction\nBe able to interpret the meaning of a numeric \\(\\times\\) numeric interaction\nUnderstand the principle of marginality and why this impacts modelling choices with interactions\nBe able to visualize and probe interactions\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nsjPlot\nkableExtra\nsandwich\ninteractions\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/scs_study.csv"
  },
  {
    "objectID": "2_02_int2_nn_ivy.html#study-analysis-plan-overview",
    "href": "2_02_int2_nn_ivy.html#study-analysis-plan-overview",
    "title": "Interactions II: Num x Num",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\nThe statistical models flashcards may also be useful to refer to. Specifically the interaction models flashcards and numeric x numeric example flashcards might be of most use.\n\n\n\n\n\n\n\n Solution \n\n\nThe scs_study dataset contained information on 656 participants, including \\(z\\)-scores on 5 personality traits assessed by the Big-Five Aspects Scale (BFAS; Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism). Participants were also assessed on the Social Comparison Scale (SCS), which is an 11-item scale measuring self-perception (relative to others) of social rank, attractiveness and belonging, and the Depression Anxiety and Stress Scale (DASS-21) - a 21 item measure with higher scores indicating higher severity of symptoms. For both of these measures, only total scores were available. Items in the SCS were measured on a 5-point scale, giving minimum and maximum possible scores of 11 and 55 respectively. Items in the DASS-21 were measured on a 4-point scale, meaning that scores could range from 21 to 84.\nDensity plots and histograms will be used to visualise the marginal distributions of DASS-21 Scores, SCS Scores, and Neuroticism. To understand the strength of association among the variables, we will estimate the correlation coefficients; and to visualise these associations scatterplots will be used. To address the research question of whether Neuroticism moderated the effect of social comparison on depression and anxiety, we are going to fit the following interaction model:\n\\[\n\\begin{align}\n\\text{DASS-21 Score} ~=~ & \\beta_0 + \\beta_1 \\cdot \\text{SCS Score} + \\beta_2 \\cdot \\text{Neuroticism} \\\\  \n& + \\beta_3 \\cdot (\\text{Neuroticism} \\cdot \\text{SCS Score}) + \\epsilon\n\\end{align}\n\\] Effects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_3 = 0\\)\nThe effect of social comparison on symptoms of depression, anxiety and stress does not vary depending on level of Neuroticism.\n\\(H_1: \\beta_3 \\neq 0\\)\nThe effect of social comparison on symptoms of depression, anxiety and stress does vary depending on level of Neuroticism."
  },
  {
    "objectID": "2_02_int2_nn_ivy.html#descriptive-statistics-visualisations",
    "href": "2_02_int2_nn_ivy.html#descriptive-statistics-visualisations",
    "title": "Interactions II: Num x Num",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 2\n\n\nProvide a table of descriptive statistics and visualise your data. You may also want to consider estimating the associations among the variables of interest.\nRemember to interpret these in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables - numeric values only examples and numeric x numeric example - visualise data.\nThe pairs.panels() function may come in handy here to complete multiple tasks at once!\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\n# note that we are selecting only our three variables of interest (dass, scs, zn)\n\nscs_study |&gt;\n    select(dass, scs, zn) |&gt; \n    describe() |&gt;\n    kable(caption = \"Descriptive Statistics - DASS-21, SCS, and Neuroticism (Z-Scored)\", digits = 2) |&gt;\n    kable_styling()\n\n\n\nTable 1: Descriptive Statistics - DASS-21, SCS, and Neuroticism (Z-Scored)\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\ndass\n1\n656\n44.72\n6.76\n44.00\n44.62\n5.93\n23.00\n68.00\n45.0\n0.18\n0.33\n0.26\n\n\nscs\n2\n656\n35.77\n3.53\n35.00\n35.59\n2.97\n27.00\n54.00\n27.0\n0.60\n0.96\n0.14\n\n\nzn\n3\n656\n0.00\n1.00\n-0.21\n-0.10\n1.00\n-1.45\n3.35\n4.8\n0.80\n0.04\n0.04\n\n\n\n\n\n\n\n\n\n\nVisualise associations among variables of interest:\n\nscs_study |&gt;\n  ggplot(aes(x = scs, y = dass, colour = zn)) +\n  geom_point()\n\n\n\n\n\n\n\n\nscs_study |&gt; \n  select(dass, scs, zn) |&gt;\n  pairs.panels()\n\n\n\n\n\n\n\n\n\n\nDescription of individual variables:\n\n\n\n\n\n\n\nThe marginal distribution of scores on the Depression, Anxiety and Stress Scale (DASS-21) was unimodal with a mean of 44.72 and a standard deviation of 6.76.\nThe marginal distribution of scores on the Social Comparison Scale (SCS) was unimodal with a mean of 35.77 and a standard deviation of 3.53.\nThe marginal distribution of Neuroticism (Z-scored) was positively skewed.\n\n\n\n\nDescription of correlations:\n\n\n\n\n\n\n\nThere was a weak, negative association between scores on the Depression Anxiety and Stress Scale and scores on the Social Comparison Scale for the participants in the sample \\((r = -.23)\\)\n\nSeverity of symptoms measured on the DASS-21 were lower, on average, for those who more favorably perceived their social rank\n\n\n\nThere was a weak, positive association between DASS-21 Scores and levels of Neuroticism \\((r = .20)\\)\n\nParticipants who were more neurotic tended to, on average, display a higher severity of symptoms of depression, anxiety and stress\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nFor demonstration purposes only\nTo help us visualise and understand the associations among our variables a little better, copy and run the two code chunks below. It takes the dataset, and uses the cut() function to add a new variable called “zn_group”, which is the “zn” variable split into 4 groups.\n\nscs_study &lt;-\n  scs_study |&gt;\n  mutate(\n    zn_group = cut(zn, 4)\n  )\n\nWe can see how it has split the “zn” variable by plotting the two against one another (note that the levels of the new variable are named according to the cut-points):\n\nggplot(data = scs_study, aes(x = zn_group, y = zn)) + \n  geom_point()\n\n\n\n\n\n\n\nPlot the association between scores on the SCS and scores on the DASS-21, for each group of the variable we just created.\nHow does the pattern differ across groups? Does it suggest an interaction?\n\n\n\n\n\n\nHint\n\n\n\n\n\nRather than creating four separate plots, you might want to map some feature of the plot to the variable we created in the data, or make use of facet_wrap() / facet_grid().\nRemember that you can specify geom_smooth() to add a trend line. For a recap, review the facet examples contained within the visual exploration flashcards. Alternatively, review the numeric x numeric example - visualise data flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\nggplot(data = scs_study, aes(x = scs, y = dass, col = zn_group)) + \n  geom_point() + \n  geom_smooth(method='lm', se = FALSE) +\n  facet_grid(~zn_group) +\n  labs(x = \"SCS Scores \", y = \"DASS-21 Scores\") +\n  theme(legend.position = \"none\") # removes the legend\n\n\n\n\n\n\n\nThe association between DASS-21 scores and SCS scores appears to be different across these groups. For those with a relatively high Neuroticism score, the association seems stronger, while for those with a low Neuroticism score there is almost no discernible association.\nThis does suggest an interaction - the association of DASS-21 ~ SCS differed across the values of Neuroticism.\n\n\n\n\n\nVisualising Interaction Terms\nCutting one of the explanatory variables up into groups essentially turns a numeric variable into a categorical one. We did this just to make it easier to visualise how an association differs across the values of another variable, because we can imagine a separate line for the association between SCS and DASS-21 scores for each of the groups of Neuroticism. However, in grouping a numeric variable like this we lose information. Neuroticism is measured on a continuous scale, and we want to capture how the association between SCS and DASS-21 differs across that continuum (rather than cutting it into chunks).\nWe could imagine cutting it into more and more chunks (see Figure 1), until what we end up with is an infinite number of lines - i.e., a three-dimensional plane/surface (recall that in for a multiple regression model with 2 explanatory variables, we can think of the model as having three-dimensions). The inclusion of the interaction term simply results in this surface no longer being necessarily flat. You can see this in Figure 2.\n\n\n\n\nFigure 1: Separate regression lines DASS ~ SCS for Neuroticism when cut into 4 (left) or 6 (center) or 12 (right) groups.\n\n\n\n\n\n\nFigure 2: 3D plot of regression surface with interaction. You can explore the plot in the figure below from different angles by moving it around with your mouse."
  },
  {
    "objectID": "2_02_int2_nn_ivy.html#model-fitting-interpretation",
    "href": "2_02_int2_nn_ivy.html#model-fitting-interpretation",
    "title": "Interactions II: Num x Num",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nConsider that Neuroticism has already been \\(z\\)-scored, but scs has not. To ensure that we can compare the effects of our estimates (and so they are both on meaningful scales), standardize the scs variable.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the standardisation flashcards for a recap if needed. Note, it would be best to create a new z-scored variable to then use within the model in this instance.\n\n\n\n\n\n\n\n Solution \n\n\n\n# standardize scs score\nscs_study &lt;- \n  scs_study |&gt; \n    mutate(\n      zscs = (scs-mean(scs))/sd(scs)\n    )\n\n\n\n\n\n\nQuestion 5\n\n\nFit your model (including the standardized predictor variables) using lm(), and assign it the name “dass_mdl”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can fit interaction models using the lm() function.\nFor an overview, see the interaction models flashcards.\nFor an example, review the interaction models &gt; numeric x numeric example &gt; model building flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit interaction model\ndass_mdl &lt;- lm(dass ~  zn*zscs, data = scs_study)\n\n#check model output\nsummary(dass_mdl)\n\n\nCall:\nlm(formula = dass ~ zn * zscs, data = scs_study)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.301  -3.825  -0.173   3.733  45.777 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  44.9324     0.2405 186.807  &lt; 2e-16 ***\nzn            1.5798     0.2409   6.559 1.11e-10 ***\nzscs         -1.5691     0.2416  -6.495 1.64e-10 ***\nzn:zscs      -1.8332     0.2316  -7.915 1.06e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.123 on 652 degrees of freedom\nMultiple R-squared:  0.1825,    Adjusted R-squared:  0.1787 \nF-statistic:  48.5 on 3 and 652 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\nQuestion 6\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\nFor an overview of how to interpret coefficients, review the interaction models &gt; interpreting coefficients flashcard. It is important to remember that you have standardised the variables in your model, and this will affect your interpretation. For a recap on what standardisation is and how it affects the scales of your variables, review the standardisation flashcard.\nFor a specific example of coefficient interpretation, review the interaction models &gt; numeric x numeric example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nObtain parameter estimates:\n\ncoefficients(dass_mdl)\n\n(Intercept)          zn        zscs     zn:zscs \n  44.932448    1.579769   -1.569097   -1.833169 \n\n\n\n\n(Intercept)\nzn\nzscs\nzscs:zn\n\n\n\n\\(\\beta_0\\) = (Intercept) = 44.93\n\nThe intercept, or predicted DASS-21 score for an individual with an average SCS score and average Neuroticism score. In this case, the mean scores of SCS and Neuroticism are both 0 (since both have been standardised).\n\nAn individual with a Neuroticism score of 0 (\\(Z\\)-scored) and an SCS score of 0 (\\(Z\\)-scored) was expected to have a DASS-21 score of 44.93 points.\n\n\n\n\n\n\\(\\beta_1\\) = zn = 1.58\n\nThe simple slope of Neuroticism on DASS-21 scores with average SCS scores (0; \\(Z\\)-scored).\n\nSpecifically for an individual with an average SCS score (0; \\(Z\\)-scored), every 1 standard deviation increase in Neuroticism score was associated with a 1.58 point increase in DASS-21 scores.\n\n\n\n\n\n\\(\\beta_2\\) = zscs = -1.57\n\nThe simple slope of SCS scores on DASS-21 scores with average Neuroticism scores (0; \\(Z\\)-scored).\n\nSpecifically for an individual with an average Neuroticism score (0; \\(Z\\)-scored), every 1 standard deviation increase in SCS score was associated with a 1.57 decrease in DASS-21 scores.\n\n\n\n\n\n\\(\\beta_3\\) = zscs:zn = -1.83\n\nThe interaction between SCS score and Neuroticism on DASS-21 Scores - the change in the slope of SCS Scores as a function of Neuroticism.\n\nFor every 1 standard deviation increase in SCS scores, when Neuroticism scores increased by 1 standard deviation, the slope with DASS-21 scores was adjusted by -1.83 points. Equivalently, the higher Neuroticism scores, the stronger the negative association between SCS Scores and DASS-21 scores."
  },
  {
    "objectID": "2_02_int2_nn_ivy.html#visualise-interaction-model",
    "href": "2_02_int2_nn_ivy.html#visualise-interaction-model",
    "title": "Interactions II: Num x Num",
    "section": "Visualise Interaction Model",
    "text": "Visualise Interaction Model\n\nQuestion 7\n\n\nUsing the probe_interaction() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a short and concise sentence.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; numeric x numeric example &gt; model visualisation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_dass_mdl &lt;- probe_interaction(model = dass_mdl, \n                  pred = zscs, \n                  modx = zn, \n                  cond.int = T,\n                  interval = T, \n                  jnplot = T,\n                  main.title = \"Neuroticism moderating the effect of\\nsocial comparison on depression and anxiety\",\n                  x.label = \"Social Comparison Scale (Z-scored)\",\n                  y.label = \"DASS-21 Scores\",\n                  legend.main = \"Neuroticism (Z-scored)\")\n\nLet’s look at the plot - to do so you need to call interactplot from your object plt_dass_mdl:\n\nplt_dass_mdl$interactplot\n\n\n\nFigure 3: Simple Slopes for +/- 1 SD and Mean Neuroticism Scores\n\n\n\n\n\n\n\n\n\nRecall that higher DASS-21 scores indicate higher severity of symptoms. Based on this, we can state:\n\nFor individuals 1 SD below the sample mean on Neuroticism, as their SCS Score increases, it appears that their DASS-21 scores remain flat / there is a very slight increase\n\nFor individuals with average levels of Neuroticism, as their SCS Score increases, it appears that their DASS-21 scores decreases\n\nFor individuals 1 SD above the sample mean on Neuroticism, as their SCS Score increases, it appears that their DASS-21 scores more steeply decreases\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nConduct a simple slopes and regions of significance analysis.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; numeric x numeric example &gt; model visualisation flashcards. Pay particular attention to how you can extract specific parts of output.\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_dass_mdl$simslopes\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen zn is OUTSIDE the interval [-1.28, -0.55], the slope of zscs is p &lt;\n.05.\n\nNote: The range of observed values of zn is [-1.45, 3.35]\n\n\nSIMPLE SLOPES ANALYSIS \n\nWhen zn = -1.000000e+00 (- 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                  0.26   0.35     0.76   0.45\nConditional intercept         43.35   0.34   127.47   0.00\n\nWhen zn = -8.610271e-16 (Mean): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -1.57   0.24    -6.50   0.00\nConditional intercept         44.93   0.24   186.81   0.00\n\nWhen zn =  1.000000e+00 (+ 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -3.40   0.32   -10.59   0.00\nConditional intercept         46.51   0.34   136.52   0.00\n\n\n\n\nFigure 4: Johnson-Neyman Plot\n\n\n\n\n\n\n\n\n\nThe Johnson-Neyman technique (see Figure 4) indicated that the association between DASS-21 scores and SCS was not significant when Neuroticism scores between -0.55 and -1.28 standard deviations below the mean."
  },
  {
    "objectID": "2_02_int2_nn_ivy.html#writing-up-presenting-results",
    "href": "2_02_int2_nn_ivy.html#writing-up-presenting-results",
    "title": "Interactions II: Num x Num",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(dass_mdl,\n          dv.labels = \"DASS-21 Scores\",\n          pred.labels = c(\"zscs\" = \"Social Comparison Scale (Z-scored)\",\n                          \"zn\" = \"Neuroticism (Z-scored)\",\n                          \"zn:zscs\" = \"Social Comparison Scale (Z-scored): Neutoricism (Z-scored)\"),\n          title = \"Regression Table for DASS-21 Model\")\n\n\n\nTable 2: Regression table for DASS-21 model\n\n\n\n\n\n\n\n\n \nDASS-21 Scores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n44.93\n44.46 – 45.40\n&lt;0.001\n\n\nNeuroticism (Z-scored)\n1.58\n1.11 – 2.05\n&lt;0.001\n\n\nSocial Comparison Scale\n(Z-scored)\n-1.57\n-2.04 – -1.09\n&lt;0.001\n\n\nSocial Comparison Scale\n(Z-scored): Neutoricism\n(Z-scored)\n-1.83\n-2.29 – -1.38\n&lt;0.001\n\n\nObservations\n656\n\n\nR2 / R2 adjusted\n0.182 / 0.179\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an example of coefficient interpretation, review the interaction models &gt; numeric x numeric example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nFull regression results including 95% confidence intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(3,652) = 48.50, p &lt; .001)\\), and the model explained approximately 17.87% of the variability in DASS-21 scores.\nThere was a significant conditional association between DASS-21 Scores and SCS scores (\\(z\\)-scored) \\((\\beta = -1.57, SE = 0.24, p &lt; .001)\\). This suggested that for those with Neuroticism scores of 0, DASS-21 scores decreased by 1.57 points for every 1 standard deviation increase in SCS scores.\nA significant conditional association was also evident between DASS-21 Scores and Neuroticism (\\(z\\)-scored) \\((\\beta = 1.58, SE = 0.24, p &lt; .001)\\). This suggested that for those with SCS scores of 0, DASS-21 scores increased by 1.58 points for every 1 standard deviation increase in Neuroticism.\nThe association between symptoms of depression and anxiety (DASS-21 scores) and social comparison was found to be dependent upon the level of Neuroticism, with a greater negative association between the two for those with higher levels of Neuroticism \\((\\beta = -1.83, SE = 0.23, p &lt; .001)\\). For every standard deviation increase in SCS Scores, the change in DASS-21 scores associated with an increase of 1 SD in Neuroticism was adjusted by -1.83 points (see Figure Figure 3). We further used the Johnson-Neyman technique to probe the interaction, and to identify regions of significance. We identified that Neuroticism values (\\(z\\)-scored) outside the range of -1.28 to -0.55 standard deviations below the mean were significant (see Figure 4).\nTherefore, we have evidence to reject the null hypothesis (that the effect of social comparison on symptoms of depression, anxiety and stress does not vary depending on level of Neuroticism)."
  },
  {
    "objectID": "2_03_int3_cc.html",
    "href": "2_03_int3_cc.html",
    "title": "Interactions III: Cat x Cat",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction\nBe able to interpret a categorical \\(\\times\\) categorical interaction\nBe able to visualize and probe interactions\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1 and Week 2\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nsjPlot\nkableExtra\nsandwich\ninteractions\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/cognitive_experiment_3_by_2.csv"
  },
  {
    "objectID": "2_03_int3_cc.html#study-analysis-plan-overview",
    "href": "2_03_int3_cc.html#study-analysis-plan-overview",
    "title": "Interactions III: Cat x Cat",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe str() function will return the overall structure of the dataset, this can be quite handy to look at\n\nConvert categorical variables to factors, and if needed, provide better variable names*\nLabel factors and levels appropriately to aid with your model interpretations if required*\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\n\nNote that all of these steps can be done in combination - the mutate() and factor() functions will likely be useful here.\n*See the numeric outcomes & categorical predictors flashcard.\n\n\n\n\n\n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(cog)\n\nspc_tbl_ [30 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diagnosis: num [1:30] 1 1 1 1 1 1 1 1 1 1 ...\n $ Task     : num [1:30] 1 1 1 1 1 2 2 2 2 2 ...\n $ Y        : num [1:30] 44 63 76 72 45 70 51 82 66 56 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diagnosis = col_double(),\n  ..   Task = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis  Task     Y\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1         1     1    44\n2         1     1    63\n3         1     1    76\n4         1     1    72\n5         1     1    45\n6         1     2    70\n\n\nThe columns Diagnosis and Task should be coded into factors with better labels, as currently, without making reference to the codebook, it is not clear what “1” and “2” represent. It is also unclear what the Y column represents - this should be renamed.\n\n#We can make all of the changes noted above in one (long) command. \n#First we can use the function `factor()` by specifying the current levels and what labels each level should map to. \n#We can also simply rename the Y column to score. \n\ncog &lt;- cog |&gt;\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('Amnesic', 'Huntingtons', 'Control')),\n        Task = factor(Task, \n                      levels = c(1, 2),\n                      labels = c('Grammar', 'Recognition'))) |&gt;\n    rename(Score = Y)\n\n#Use head() function to check renaming\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis Task        Score\n  &lt;fct&gt;     &lt;fct&gt;       &lt;dbl&gt;\n1 Amnesic   Grammar        44\n2 Amnesic   Grammar        63\n3 Amnesic   Grammar        76\n4 Amnesic   Grammar        72\n5 Amnesic   Grammar        45\n6 Amnesic   Recognition    70\n\n\n\n\n\n\n\nQuestion 2\n\n\nChoose appropriate reference levels for the Diagnosis and Task variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRead the Study Overview codebook carefully.\nReview the specifying reference levels flashcard.\n\n\n\n\n\n\n\n\n\nDiagnosis\nTask\n\n\n\nThe Diagnosis factor has a group coded ‘Control’ which lends itself naturally to be the reference category, since it is the only group of participants with no known neurological disorder.\n\ncog$Diagnosis &lt;- relevel(cog$Diagnosis, 'Control')\n\nlevels(cog$Diagnosis)\n\n[1] \"Control\"     \"Amnesic\"     \"Huntingtons\"\n\n\n\n\nThere is no natural reference category for the Task factor, so we will leave it unaltered. However, if you are of a different opinion, please note that there is no absolute correct answer. As long as you describe and interpret the model correctly, you will reach to the same conclusions as someone that has chosen a different baseline category.\nWe can see what the reference group is below (first in list):\n\nlevels(cog$Task)\n\n[1] \"Grammar\"     \"Recognition\"\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable(s))\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\nThe statistical models flashcards may also be useful to refer to. Specifically the interaction models flashcards and categorical x categorical example flashcards might be of most use.\n\n\n\n\n\n\n\nThe cog dataset contained information on 30 hypothetical participants from a between-subjects study. Participants belonged to one of three ‘Diagnosis’ groups, which had 10 participants in each - Control, Amnesic, or Huntingtons. Participants from each of the Diagnosis groups were randomly assigned to one of two ‘Tasks’ to measure different memory processes - Grammar or Recognition. For the purpose of this analysis, ‘Control’ was designated as the reference group for Diagnosis, since it was the only group of participants with no known neurological disorder, and as there is no natural reference group for Diagnosis, we chose to leave this as ‘Grammar’.\nBoxplots will be used to visualise the associations among Diagnosis and Task conditions. To address the research question of whether the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls, we first need to define the dummy variables for both\nDiagnosis:\n\\[\n\\begin{align}\n& D_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\\n& D_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\\n\\\\  \n& (\\text{Control is base level})\n\\end{align}\n\\]\nand for Task:\n\\[\n\\begin{align}\n& \\text{T}_\\text{Recognition} = \\begin{cases}\n1 & \\text{if Task is Recognition} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad\n\\\\\n\\\\\n& (\\text{Grammar is base level})\n\\end{align}\n\\]\nBased on the above dummy coding, we are going to fit the following interaction model:\n\\[\n\\begin{aligned}\n\\text{Score} &= \\beta_0 \\\\\n      &+ \\beta_1 \\cdot \\text{D}_\\text{Amnesic} + \\beta_2 \\cdot \\text{D}_\\text{Huntingtons}  \\\\\n      &+ \\beta_3 \\cdot \\text{T}_\\text{Recognition}  \\\\\n      &+ \\beta_4 \\cdot (\\text{D}_\\text{Amnesic} \\cdot \\text{T}_\\text{Recognition}) + \\beta_5 \\cdot (\\text{D}_\\text{Huntingtons} \\cdot \\text{T}_\\text{Recognition})  \\\\\n      &+ \\epsilon\n\\end{aligned}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_5 = 0\\)\nThe difference in performance between explicit and implicit memory tasks does not significantly differ between patients with Huntingtons in comparison to Controls.\n\\(H_1: \\beta_5 \\neq 0\\)\nThe difference in performance between explicit and implicit memory tasks does significantly differ between patients with Huntingtons in comparison to Controls."
  },
  {
    "objectID": "2_03_int3_cc.html#descriptive-statistics-visualisations",
    "href": "2_03_int3_cc.html#descriptive-statistics-visualisations",
    "title": "Interactions III: Cat x Cat",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 4\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables - categorical and numeric values examples and categorical x categorical example - visualise data.\n\n\n\n\n\n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\ncog_desc &lt;- cog |&gt; \n            group_by(Diagnosis, Task) |&gt;\n            summarise(M = mean(Score),\n                      SD = sd(Score),\n                      Min = min(Score),\n                      Max = max(Score)) |&gt; \n            kable(caption = \"Descriptive Statistics\", digits = 2) |&gt;\n            kable_styling()\n\ncog_desc\n\n\n\nTable 1: Descriptive Statistics\n\nDiagnosis\nTask\nM\nSD\nMin\nMax\n\n\n\nControl\nGrammar\n80\n11.68\n70\n98\n\n\nControl\nRecognition\n95\n12.98\n80\n107\n\n\nAmnesic\nGrammar\n60\n14.92\n44\n76\n\n\nAmnesic\nRecognition\n65\n12.17\n51\n82\n\n\nHuntingtons\nGrammar\n40\n13.25\n24\n55\n\n\nHuntingtons\nRecognition\n95\n13.38\n80\n108\n\n\n\n\n\n\n\n\n\n\nVisualise associations among variables of interest either by using a boxplot:\n\ncog_plt &lt;- ggplot(cog, aes(x = Diagnosis, y = Score, fill = Task)) + \n  geom_boxplot() \ncog_plt\n\n\n\nFigure 1: Associations among Score, Diagnosis, and Task\n\n\n\nOr violin plot:\n\ncog |&gt;\n  ggplot(aes(x = Task, y = Score, fill = Task, colour = Task)) + \n  geom_violin(alpha = 0.5) +\n  geom_jitter(alpha = 0.5) +\n  facet_wrap(~ Diagnosis) +\n  theme(legend.position = 'none')\n\n\n\nFigure 2: Associations among Score, Diagnosis, and Task\n\n\n\n\n\n\n\n\n\n\n\n\n\nScores on Recognition tasks appear to be higher than those on Grammar across Diagnosis conditions\n\nParticipants with Amnesia do not appear to differ in Score for Recognition or Grammar tasks\n\nIn comparison to Controls, Amnesic patients score lower on both tasks, but not considerably so\n\nParticipants with Huntingtons do differ in Score for Recognition and Grammar tasks, with higher scores on Recognition tasks\n\nIn comparison to Controls, Huntingtons patients score similarly on Recognition tasks, but considerably lower on Grammar tasks"
  },
  {
    "objectID": "2_03_int3_cc.html#model-fitting-interpretation",
    "href": "2_03_int3_cc.html#model-fitting-interpretation",
    "title": "Interactions III: Cat x Cat",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nFit the specified model using lm(), and assign it the name “cog_mdl”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can fit interaction models using the lm() function.\nFor an overview, see the interaction models flashcards.\nFor an example, review the interaction models &gt; categorical x categorical example &gt; model building flashcards.\n\n\n\n\n\n\n\n\n#fit interaction model\ncog_mdl &lt;- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(cog_mdl)\n\n\nCall:\nlm(formula = Score ~ Diagnosis * Task, data = cog)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-16.00 -12.25   2.00  11.75  18.00 \n\nCoefficients:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                            80.000      5.859  13.653 8.27e-13 ***\nDiagnosisAmnesic                      -20.000      8.287  -2.414  0.02379 *  \nDiagnosisHuntingtons                  -40.000      8.287  -4.827 6.45e-05 ***\nTaskRecognition                        15.000      8.287   1.810  0.08281 .  \nDiagnosisAmnesic:TaskRecognition      -10.000     11.719  -0.853  0.40192    \nDiagnosisHuntingtons:TaskRecognition   40.000     11.719   3.413  0.00228 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.1 on 24 degrees of freedom\nMultiple R-squared:  0.7394,    Adjusted R-squared:  0.6851 \nF-statistic: 13.62 on 5 and 24 DF,  p-value: 2.359e-06\n\n\n\n\n\n\n\nQuestion 6\n\n\nRecall your table of descriptive statistics - map each coefficient from the summary() output from “cog_mdl” to the group means.\n\n\n\n\n\n\n\n\n\n\nNote - \\(\\beta\\) Coefficient Order\n\n\n\n\n\nThe ordering of the \\(\\beta\\) coefficients follows the specification of the model in Q5. Yours might be different (e.g., if you specified lm(Score ~ Task * Diagnosis, data = cog) instead of lm(Score ~ Diagnosis * Task, data = cog).\n\n\n\n\n\n\nDescriptive Statistics\n\nDiagnosis\nTask\nM\nSD\nMin\nMax\n\n\n\nControl\nGrammar\n80\n11.68\n70\n98\n\n\nControl\nRecognition\n95\n12.98\n80\n107\n\n\nAmnesic\nGrammar\n60\n14.92\n44\n76\n\n\nAmnesic\nRecognition\n65\n12.17\n51\n82\n\n\nHuntingtons\nGrammar\n40\n13.25\n24\n55\n\n\nHuntingtons\nRecognition\n95\n13.38\n80\n108\n\n\n\n\n\n\n\n\n\n\n\n\nCoefficient\nValue\nMapping to Group Means              \n\n\n\n\\(\\hat{\\beta}_0\\)\n80\nMean(Control, Grammar)\n\n\n\\(\\hat{\\beta}_1\\)\n-20\nMean(Amnesic, Grammar) - Mean(Control, Grammar) = 60-80\n\n\n\\(\\hat{\\beta}_2\\)\n-40\nMean(Huntingtons, Grammar) - Mean(Control, Grammar) = 40-80\n\n\n\\(\\hat{\\beta}_3\\)\n15\nMean(Control, Recognition) - Mean(Control, Grammar) = 95-80\n\n\n\\(\\hat{\\beta}_4\\)\n-10\n[Mean(Amnesic, Recognition) - Mean(Control, Recognition)] - [Mean(Amnesic, Grammar) - Mean(Control, Grammar)] = [65-95] - [60-80] = [-30] – [-20] = -10\n\n\n\\(\\hat{\\beta}_5\\)\n40\n[Mean(Huntingtons, Recognition) - Mean(Control, Recognition)] - [Mean(Huntingtons, Grammar) - Mean(Control, Grammar)] = [95-95] - [40-80] = [0] – [-40] = 40\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\nYou may find it helpful to review your descriptive statistics from Q4, or the findings from your mapping exercise in Q6.\nFor an overview of how to interpret coefficients, review the interaction models &gt; interpreting coefficients flashcard.\nFor a specific example of coefficient interpretation, review the interaction models &gt; categorical x categorical example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote - \\(\\beta\\) Coefficient Order\n\n\n\n\n\nThe ordering of the \\(\\beta\\) coefficients follows the specification of the model in Q5. Yours might be different (e.g., if you specified lm(Score ~ Task * Diagnosis, data = cog) instead of lm(Score ~ Diagnosis * Task, data = cog).\n\n\n\nObtain parameter estimates:\n\ncoefficients(cog_mdl)\n\n                         (Intercept)                     DiagnosisAmnesic \n                                  80                                  -20 \n                DiagnosisHuntingtons                      TaskRecognition \n                                 -40                                   15 \n    DiagnosisAmnesic:TaskRecognition DiagnosisHuntingtons:TaskRecognition \n                                 -10                                   40 \n\n\n\n\n(Intercept)\nDiagnosisAmnesic\nDiagnosisHuntingtons\nTaskRecognition\nDiagnosisAmnesic:TaskRecognition\nDiagnosisHuntingtons:TaskRecognition\n\n\n\n\\(\\beta_0\\) = (Intercept) = 80\n\nThe intercept, or predicted scores for those in the Control diagnosis condition on the Grammar task.\n\nA Control participant completing the Grammar task was expected to score 80.\n\nControl participants completing the Grammar task scored significantly different from 0 \\((\\beta = 80, ~SE = 5.86,~ p &lt; .001)\\).\n\n\n\n\n\n\\(\\beta_1\\) = DiagnosisAmnesic = -20\n\nThe difference in scores between Amnesic and Control conditions on the Grammar task.\n\nWhen completing the Grammar task, individuals with Amnesia were estimated to score 20 points lower than Control participants.\nThis difference between Control and Amnesia participants completing the Grammar task was statistically significant \\((\\beta = -20, ~SE = 8.29,~ p = .024)\\).\n\n\n\n\n\n\\(\\beta_2\\) = DiagnosisHuntingtons = -40\n\nThe difference in score between Huntingtons and Control conditions on the Grammar task.\n\nWhen completing the Grammar task, individuals with Huntingtons were estimated to score 40 points lower than Control participants.\nThis difference between Control and Huntingtons participants completing the Grammar task was statistically significant \\((\\beta = -40, ~SE = 8.29,~ p &lt; .001)\\).\n\n\n\n\n\n\\(\\beta_3\\) = TaskRecognition = 15\n\nThe difference in score between individuals in the Control diagnosis condition completing Recognition and Grammar tasks\n\nControl participants were estimated to score 15 points higher when completing Recognition tasks in comparison to Grammar tasks.\n\nThis difference between Recognition and Grammar task performance for Control patients was not statistically significant \\((\\beta = 15, ~SE = 8.29,~ p = .083)\\).\n\n\n\n\n\n\\(\\beta_4\\) = DiagnosisAmnesic:TaskRecognition = -10\n\nThe difference in scores among those in Amnesia and Control diagnosis conditions between the Grammar and Recognition tasks\n\nThe difference between scores for Amnesic and Control patients between Grammar and Recognition tasks differed by -10 points. The difference between Amnesics and controls was greater in the Recognition task, where in comparison to the Grammar task (where Amnesic were estimated to score 20 points lower than controls), there was an additional -10 difference between the two diagnosis groups.\nThis difference between scores for Amnesic and Control patients between Grammar and Recognition tasks was not statistically significant \\((\\beta = -10, ~SE = 11.72,~ p = .402)\\).\n\n\n\n\n\n\\(\\beta_5\\) = DiagnosisHuntingtons:TaskRecognition = 40\n\nThe difference in scores among those in Huntingtons and Control diagnosis conditions between the Grammar and Recognition tasks\n\nThe difference between scores for Huntingtons and Control patients between Grammar and Recognition tasks differed by 40 points. In comparison to the Grammar task (where Huntingtons patients were expected to score 40 points lower than controls), there was no difference between Huntingtons and controls in the Recognition task.\nThis difference between scores for Huntingtons and Control patients between Grammar and Recognition tasks was statistically significant \\((\\beta = 40, ~SE = 11.72,~ p = .002)\\)."
  },
  {
    "objectID": "2_03_int3_cc.html#visualise-interaction-model",
    "href": "2_03_int3_cc.html#visualise-interaction-model",
    "title": "Interactions III: Cat x Cat",
    "section": "Visualise Interaction Model",
    "text": "Visualise Interaction Model\n\nQuestion 8\n\n\nUsing the cat_plot() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a few short and concise sentences.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; categorical x categorical example &gt; model visualisation flashcards.\n\n\n\n\n\n\n\n\nplt_cog_mdl1 &lt;- cat_plot(model = cog_mdl, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl1\n\n\n\nFigure 3: Interaction Plot\n\n\n\nOr the the symmetrical way of plotting the interaction (note we’ve just switched the order of pred and modx):\n\nplt_cog_mdl2 &lt;- cat_plot(model = cog_mdl, \n                  pred = Task, \n                  modx = Diagnosis, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Task\",\n                  y.label = \"Score\",\n                  legend.main = \"Diagnosis\")\nplt_cog_mdl2\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe effect of Task on Scores did appear to vary depending on Diagnosis.\nThere was very little difference in scores between Control and Amnesic groups for Grammar and Recognition tasks (given the overlapping intervals).\nThere was a large difference in scores between Huntingtons and Control groups for Grammar tasks, but no difference in score on Recognition tasks. Thus, the difference of scores between tasks did differ by Diagnosis group.\n\n\n\n\n\n\n\n\n\nHow do we know there is an interaction?\n\n\n\n\n\nIf you imagine connecting the dots of the same color with a line (you could specify geom = \"line\" in a new line in the code chunk above to do this), you can see that the two virtual lines are not parallel (see below plot), suggesting the presence of an interaction. The difference in score between recognition and grammar tasks for Huntingtons patients (consider the vertical difference) is larger than the difference in score between recognition and grammar tasks for the Control patients. If those vertical differences were the same, there would be no interaction.\n\n\n\n\nFigure 4: Interaction Plot with Connected Lines"
  },
  {
    "objectID": "2_03_int3_cc.html#writing-up-presenting-results",
    "href": "2_03_int3_cc.html#writing-up-presenting-results",
    "title": "Interactions III: Cat x Cat",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n\n#create table for results\ntab_model(cog_mdl, \n          show.stat = TRUE,\n          dv.labels = \"Scores\",\n          title = \"Regression Table for Scores Model\")\n\n\n\nTable 2: Regression Table for Scores Model\n\n\n\n\n\n\n\n\n\n \nScores\n\n\nPredictors\nEstimates\nCI\nStatistic\np\n\n\n(Intercept)\n80.00\n67.91 – 92.09\n13.65\n&lt;0.001\n\n\nDiagnosis [Amnesic]\n-20.00\n-37.10 – -2.90\n-2.41\n0.024\n\n\nDiagnosis [Huntingtons]\n-40.00\n-57.10 – -22.90\n-4.83\n&lt;0.001\n\n\nTask [Recognition]\n15.00\n-2.10 – 32.10\n1.81\n0.083\n\n\nDiagnosis [Amnesic] ×\nTask [Recognition]\n-10.00\n-34.19 – 14.19\n-0.85\n0.402\n\n\nDiagnosis [Huntingtons] ×\nTask [Recognition]\n40.00\n15.81 – 64.19\n3.41\n0.002\n\n\nObservations\n30\n\n\nR2 / R2 adjusted\n0.739 / 0.685\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an example of coefficient interpretation, review the interaction models &gt; categorical x categorical example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(5,24) = 13.62, p &lt;.001)\\), and the model explained approximately 68.5% of the variability in Scores. The interaction between Task and Diagnosis is visually presented in Figure 3.\nAmnesic patients were found to score significantly lower on the grammar task compared to controls \\((\\beta = -20, ~SE = 8.29,~ t(24) = -2.41,~ p = .024)\\). However, their relative performance on recognition vs grammar tasks was not found to significantly differ from that of controls \\((\\beta = -10, ~SE = 11.72,~ t(24) = -0.85,~ p = .402)\\), suggesting that Amnesia affects both types of memory to a similar extent.\nHuntingons patients were found to score significantly lower on the grammar task compared to controls \\((\\beta = -40, ~SE = 8.29,~ t(24) = -4.83,~ p &lt;.001)\\). However, the difference in performance on the recognition task compared to the grammar was significantly larger for Huntingtons patients than it was for controls \\((\\beta = 40, ~SE = 11.72,~ t(24) = 3.41,~ p = .002)\\), suggesting that Huntingtons affects implicit memory to a greater extent than it does explicit memory.\nTherefore, we have evidence to reject the null hypothesis (the difference in performance between explicit and implicit memory tasks does not significantly differ between patients with Huntingtons in comparison to Controls)."
  },
  {
    "objectID": "2_03_int3_cc.html#footnotes",
    "href": "2_03_int3_cc.html#footnotes",
    "title": "Interactions III: Cat x Cat",
    "section": "Footnotes",
    "text": "Footnotes\n\nSome researchers may point out that a design where each person was assessed on both tasks might have been more efficient. However, the task factor in such design would then be within-subjects, meaning that the scores corresponding to the same person would be correlated. To analyse such design we will need a different method which (spoiler alert!) will be discussed next year in DAPR3.↩︎"
  },
  {
    "objectID": "2_03_int3_cc_mulberry.html",
    "href": "2_03_int3_cc_mulberry.html",
    "title": "Interactions III: Cat x Cat",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction\nBe able to interpret a categorical \\(\\times\\) categorical interaction\nBe able to visualize and probe interactions\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1 and Week 2\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nsjPlot\nkableExtra\nsandwich\ninteractions\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/cognitive_experiment_3_by_2.csv"
  },
  {
    "objectID": "2_03_int3_cc_mulberry.html#study-analysis-plan-overview",
    "href": "2_03_int3_cc_mulberry.html#study-analysis-plan-overview",
    "title": "Interactions III: Cat x Cat",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe str() function will return the overall structure of the dataset, this can be quite handy to look at\n\nConvert categorical variables to factors, and if needed, provide better variable names*\nLabel factors and levels appropriately to aid with your model interpretations if required*\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\n\nNote that all of these steps can be done in combination - the mutate() and factor() functions will likely be useful here.\n*See the numeric outcomes & categorical predictors flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(cog)\n\nspc_tbl_ [30 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diagnosis: num [1:30] 1 1 1 1 1 1 1 1 1 1 ...\n $ Task     : num [1:30] 1 1 1 1 1 2 2 2 2 2 ...\n $ Y        : num [1:30] 44 63 76 72 45 70 51 82 66 56 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diagnosis = col_double(),\n  ..   Task = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis  Task     Y\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1         1     1    44\n2         1     1    63\n3         1     1    76\n4         1     1    72\n5         1     1    45\n6         1     2    70\n\n\nThe columns Diagnosis and Task should be coded into factors with better labels, as currently, without making reference to the codebook, it is not clear what “1” and “2” represent. It is also unclear what the Y column represents - this should be renamed.\n\n#We can make all of the changes noted above in one (long) command. \n#First we can use the function `factor()` by specifying the current levels and what labels each level should map to. \n#We can also simply rename the Y column to score. \n\ncog &lt;- cog |&gt;\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('Amnesic', 'Huntingtons', 'Control')),\n        Task = factor(Task, \n                      levels = c(1, 2),\n                      labels = c('Grammar', 'Recognition'))) |&gt;\n    rename(Score = Y)\n\n#Use head() function to check renaming\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis Task        Score\n  &lt;fct&gt;     &lt;fct&gt;       &lt;dbl&gt;\n1 Amnesic   Grammar        44\n2 Amnesic   Grammar        63\n3 Amnesic   Grammar        76\n4 Amnesic   Grammar        72\n5 Amnesic   Grammar        45\n6 Amnesic   Recognition    70\n\n\n\n\n\n\n\nQuestion 2\n\n\nChoose appropriate reference levels for the Diagnosis and Task variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRead the Study Overview codebook carefully.\nReview the specifying reference levels flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nDiagnosis\nTask\n\n\n\nThe Diagnosis factor has a group coded ‘Control’ which lends itself naturally to be the reference category, since it is the only group of participants with no known neurological disorder.\n\ncog$Diagnosis &lt;- relevel(cog$Diagnosis, 'Control')\n\nlevels(cog$Diagnosis)\n\n[1] \"Control\"     \"Amnesic\"     \"Huntingtons\"\n\n\n\n\nThere is no natural reference category for the Task factor, so we will leave it unaltered. However, if you are of a different opinion, please note that there is no absolute correct answer. As long as you describe and interpret the model correctly, you will reach to the same conclusions as someone that has chosen a different baseline category.\nWe can see what the reference group is below (first in list):\n\nlevels(cog$Task)\n\n[1] \"Grammar\"     \"Recognition\"\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable(s))\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\nThe statistical models flashcards may also be useful to refer to. Specifically the interaction models flashcards and categorical x categorical example flashcards might be of most use.\n\n\n\n\n\n\n\n Solution \n\n\nThe cog dataset contained information on 30 hypothetical participants from a between-subjects study. Participants belonged to one of three ‘Diagnosis’ groups, which had 10 participants in each - Control, Amnesic, or Huntingtons. Participants from each of the Diagnosis groups were randomly assigned to one of two ‘Tasks’ to measure different memory processes - Grammar or Recognition. For the purpose of this analysis, ‘Control’ was designated as the reference group for Diagnosis, since it was the only group of participants with no known neurological disorder, and as there is no natural reference group for Diagnosis, we chose to leave this as ‘Grammar’.\nBoxplots will be used to visualise the associations among Diagnosis and Task conditions. To address the research question of whether the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls, we first need to define the dummy variables for both\nDiagnosis:\n\\[\n\\begin{align}\n& D_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\\n& D_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\\n\\\\  \n& (\\text{Control is base level})\n\\end{align}\n\\]\nand for Task:\n\\[\n\\begin{align}\n& \\text{T}_\\text{Recognition} = \\begin{cases}\n1 & \\text{if Task is Recognition} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad\n\\\\\n\\\\\n& (\\text{Grammar is base level})\n\\end{align}\n\\]\nBased on the above dummy coding, we are going to fit the following interaction model:\n\\[\n\\begin{aligned}\n\\text{Score} &= \\beta_0 \\\\\n      &+ \\beta_1 \\cdot \\text{D}_\\text{Amnesic} + \\beta_2 \\cdot \\text{D}_\\text{Huntingtons}  \\\\\n      &+ \\beta_3 \\cdot \\text{T}_\\text{Recognition}  \\\\\n      &+ \\beta_4 \\cdot (\\text{D}_\\text{Amnesic} \\cdot \\text{T}_\\text{Recognition}) + \\beta_5 \\cdot (\\text{D}_\\text{Huntingtons} \\cdot \\text{T}_\\text{Recognition})  \\\\\n      &+ \\epsilon\n\\end{aligned}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_5 = 0\\)\nThe difference in performance between explicit and implicit memory tasks does not significantly differ between patients with Huntingtons in comparison to Controls.\n\\(H_1: \\beta_5 \\neq 0\\)\nThe difference in performance between explicit and implicit memory tasks does significantly differ between patients with Huntingtons in comparison to Controls."
  },
  {
    "objectID": "2_03_int3_cc_mulberry.html#descriptive-statistics-visualisations",
    "href": "2_03_int3_cc_mulberry.html#descriptive-statistics-visualisations",
    "title": "Interactions III: Cat x Cat",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 4\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables - categorical and numeric values examples and categorical x categorical example - visualise data.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\ncog_desc &lt;- cog |&gt; \n            group_by(Diagnosis, Task) |&gt;\n            summarise(M = mean(Score),\n                      SD = sd(Score),\n                      Min = min(Score),\n                      Max = max(Score)) |&gt; \n            kable(caption = \"Descriptive Statistics\", digits = 2) |&gt;\n            kable_styling()\n\ncog_desc\n\n\n\nTable 1: Descriptive Statistics\n\nDiagnosis\nTask\nM\nSD\nMin\nMax\n\n\n\nControl\nGrammar\n80\n11.68\n70\n98\n\n\nControl\nRecognition\n95\n12.98\n80\n107\n\n\nAmnesic\nGrammar\n60\n14.92\n44\n76\n\n\nAmnesic\nRecognition\n65\n12.17\n51\n82\n\n\nHuntingtons\nGrammar\n40\n13.25\n24\n55\n\n\nHuntingtons\nRecognition\n95\n13.38\n80\n108\n\n\n\n\n\n\n\n\n\n\nVisualise associations among variables of interest either by using a boxplot:\n\ncog_plt &lt;- ggplot(cog, aes(x = Diagnosis, y = Score, fill = Task)) + \n  geom_boxplot() \ncog_plt\n\n\n\nFigure 1: Associations among Score, Diagnosis, and Task\n\n\n\nOr violin plot:\n\ncog |&gt;\n  ggplot(aes(x = Task, y = Score, fill = Task, colour = Task)) + \n  geom_violin(alpha = 0.5) +\n  geom_jitter(alpha = 0.5) +\n  facet_wrap(~ Diagnosis) +\n  theme(legend.position = 'none')\n\n\n\nFigure 2: Associations among Score, Diagnosis, and Task\n\n\n\n\n\n\n\n\n\n\n\n\n\nScores on Recognition tasks appear to be higher than those on Grammar across Diagnosis conditions\n\nParticipants with Amnesia do not appear to differ in Score for Recognition or Grammar tasks\n\nIn comparison to Controls, Amnesic patients score lower on both tasks, but not considerably so\n\nParticipants with Huntingtons do differ in Score for Recognition and Grammar tasks, with higher scores on Recognition tasks\n\nIn comparison to Controls, Huntingtons patients score similarly on Recognition tasks, but considerably lower on Grammar tasks"
  },
  {
    "objectID": "2_03_int3_cc_mulberry.html#model-fitting-interpretation",
    "href": "2_03_int3_cc_mulberry.html#model-fitting-interpretation",
    "title": "Interactions III: Cat x Cat",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nFit the specified model using lm(), and assign it the name “cog_mdl”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can fit interaction models using the lm() function.\nFor an overview, see the interaction models flashcards.\nFor an example, review the interaction models &gt; categorical x categorical example &gt; model building flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit interaction model\ncog_mdl &lt;- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(cog_mdl)\n\n\nCall:\nlm(formula = Score ~ Diagnosis * Task, data = cog)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-16.00 -12.25   2.00  11.75  18.00 \n\nCoefficients:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                            80.000      5.859  13.653 8.27e-13 ***\nDiagnosisAmnesic                      -20.000      8.287  -2.414  0.02379 *  \nDiagnosisHuntingtons                  -40.000      8.287  -4.827 6.45e-05 ***\nTaskRecognition                        15.000      8.287   1.810  0.08281 .  \nDiagnosisAmnesic:TaskRecognition      -10.000     11.719  -0.853  0.40192    \nDiagnosisHuntingtons:TaskRecognition   40.000     11.719   3.413  0.00228 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.1 on 24 degrees of freedom\nMultiple R-squared:  0.7394,    Adjusted R-squared:  0.6851 \nF-statistic: 13.62 on 5 and 24 DF,  p-value: 2.359e-06\n\n\n\n\n\n\n\nQuestion 6\n\n\nRecall your table of descriptive statistics - map each coefficient from the summary() output from “cog_mdl” to the group means.\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nNote - \\(\\beta\\) Coefficient Order\n\n\n\n\n\nThe ordering of the \\(\\beta\\) coefficients follows the specification of the model in Q5. Yours might be different (e.g., if you specified lm(Score ~ Task * Diagnosis, data = cog) instead of lm(Score ~ Diagnosis * Task, data = cog).\n\n\n\n\n\n\nDescriptive Statistics\n\nDiagnosis\nTask\nM\nSD\nMin\nMax\n\n\n\nControl\nGrammar\n80\n11.68\n70\n98\n\n\nControl\nRecognition\n95\n12.98\n80\n107\n\n\nAmnesic\nGrammar\n60\n14.92\n44\n76\n\n\nAmnesic\nRecognition\n65\n12.17\n51\n82\n\n\nHuntingtons\nGrammar\n40\n13.25\n24\n55\n\n\nHuntingtons\nRecognition\n95\n13.38\n80\n108\n\n\n\n\n\n\n\n\n\n\n\n\nCoefficient\nValue\nMapping to Group Means              \n\n\n\n\\(\\hat{\\beta}_0\\)\n80\nMean(Control, Grammar)\n\n\n\\(\\hat{\\beta}_1\\)\n-20\nMean(Amnesic, Grammar) - Mean(Control, Grammar) = 60-80\n\n\n\\(\\hat{\\beta}_2\\)\n-40\nMean(Huntingtons, Grammar) - Mean(Control, Grammar) = 40-80\n\n\n\\(\\hat{\\beta}_3\\)\n15\nMean(Control, Recognition) - Mean(Control, Grammar) = 95-80\n\n\n\\(\\hat{\\beta}_4\\)\n-10\n[Mean(Amnesic, Recognition) - Mean(Control, Recognition)] - [Mean(Amnesic, Grammar) - Mean(Control, Grammar)] = [65-95] - [60-80] = [-30] – [-20] = -10\n\n\n\\(\\hat{\\beta}_5\\)\n40\n[Mean(Huntingtons, Recognition) - Mean(Control, Recognition)] - [Mean(Huntingtons, Grammar) - Mean(Control, Grammar)] = [95-95] - [40-80] = [0] – [-40] = 40\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\nYou may find it helpful to review your descriptive statistics from Q4, or the findings from your mapping exercise in Q6.\nFor an overview of how to interpret coefficients, review the interaction models &gt; interpreting coefficients flashcard.\nFor a specific example of coefficient interpretation, review the interaction models &gt; categorical x categorical example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nNote - \\(\\beta\\) Coefficient Order\n\n\n\n\n\nThe ordering of the \\(\\beta\\) coefficients follows the specification of the model in Q5. Yours might be different (e.g., if you specified lm(Score ~ Task * Diagnosis, data = cog) instead of lm(Score ~ Diagnosis * Task, data = cog).\n\n\n\nObtain parameter estimates:\n\ncoefficients(cog_mdl)\n\n                         (Intercept)                     DiagnosisAmnesic \n                                  80                                  -20 \n                DiagnosisHuntingtons                      TaskRecognition \n                                 -40                                   15 \n    DiagnosisAmnesic:TaskRecognition DiagnosisHuntingtons:TaskRecognition \n                                 -10                                   40 \n\n\n\n\n(Intercept)\nDiagnosisAmnesic\nDiagnosisHuntingtons\nTaskRecognition\nDiagnosisAmnesic:TaskRecognition\nDiagnosisHuntingtons:TaskRecognition\n\n\n\n\\(\\beta_0\\) = (Intercept) = 80\n\nThe intercept, or predicted scores for those in the Control diagnosis condition on the Grammar task.\n\nA Control participant completing the Grammar task was expected to score 80.\n\nControl participants completing the Grammar task scored significantly different from 0 \\((\\beta = 80, ~SE = 5.86,~ p &lt; .001)\\).\n\n\n\n\n\n\\(\\beta_1\\) = DiagnosisAmnesic = -20\n\nThe difference in scores between Amnesic and Control conditions on the Grammar task.\n\nWhen completing the Grammar task, individuals with Amnesia were estimated to score 20 points lower than Control participants.\nThis difference between Control and Amnesia participants completing the Grammar task was statistically significant \\((\\beta = -20, ~SE = 8.29,~ p = .024)\\).\n\n\n\n\n\n\\(\\beta_2\\) = DiagnosisHuntingtons = -40\n\nThe difference in score between Huntingtons and Control conditions on the Grammar task.\n\nWhen completing the Grammar task, individuals with Huntingtons were estimated to score 40 points lower than Control participants.\nThis difference between Control and Huntingtons participants completing the Grammar task was statistically significant \\((\\beta = -40, ~SE = 8.29,~ p &lt; .001)\\).\n\n\n\n\n\n\\(\\beta_3\\) = TaskRecognition = 15\n\nThe difference in score between individuals in the Control diagnosis condition completing Recognition and Grammar tasks\n\nControl participants were estimated to score 15 points higher when completing Recognition tasks in comparison to Grammar tasks.\n\nThis difference between Recognition and Grammar task performance for Control patients was not statistically significant \\((\\beta = 15, ~SE = 8.29,~ p = .083)\\).\n\n\n\n\n\n\\(\\beta_4\\) = DiagnosisAmnesic:TaskRecognition = -10\n\nThe difference in scores among those in Amnesia and Control diagnosis conditions between the Grammar and Recognition tasks\n\nThe difference between scores for Amnesic and Control patients between Grammar and Recognition tasks differed by -10 points. The difference between Amnesics and controls was greater in the Recognition task, where in comparison to the Grammar task (where Amnesic were estimated to score 20 points lower than controls), there was an additional -10 difference between the two diagnosis groups.\nThis difference between scores for Amnesic and Control patients between Grammar and Recognition tasks was not statistically significant \\((\\beta = -10, ~SE = 11.72,~ p = .402)\\).\n\n\n\n\n\n\\(\\beta_5\\) = DiagnosisHuntingtons:TaskRecognition = 40\n\nThe difference in scores among those in Huntingtons and Control diagnosis conditions between the Grammar and Recognition tasks\n\nThe difference between scores for Huntingtons and Control patients between Grammar and Recognition tasks differed by 40 points. In comparison to the Grammar task (where Huntingtons patients were expected to score 40 points lower than controls), there was no difference between Huntingtons and controls in the Recognition task.\nThis difference between scores for Huntingtons and Control patients between Grammar and Recognition tasks was statistically significant \\((\\beta = 40, ~SE = 11.72,~ p = .002)\\)."
  },
  {
    "objectID": "2_03_int3_cc_mulberry.html#visualise-interaction-model",
    "href": "2_03_int3_cc_mulberry.html#visualise-interaction-model",
    "title": "Interactions III: Cat x Cat",
    "section": "Visualise Interaction Model",
    "text": "Visualise Interaction Model\n\nQuestion 8\n\n\nUsing the cat_plot() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a few short and concise sentences.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; categorical x categorical example &gt; model visualisation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_cog_mdl &lt;- cat_plot(model = cog_mdl, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl\n\n\n\nFigure 3: Interaction Plot\n\n\n\nOr the the symmetrical way of plotting the interaction (note we’ve just switched the order of pred and modx):\n\nplt_cog_mdl2 &lt;- cat_plot(model = cog_mdl, \n                  pred = Task, \n                  modx = Diagnosis, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Task\",\n                  y.label = \"Score\",\n                  legend.main = \"Diagnosis\")\nplt_cog_mdl2\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe effect of Task on Scores did appear to vary depending on Diagnosis.\nThere was very little difference in scores between Control and Amnesic groups for Grammar and Recognition tasks (given the overlapping intervals).\nThere was a large difference in scores between Huntingtons and Control groups for Grammar tasks, but no difference in score on Recognition tasks. Thus, the difference of scores between tasks did differ by Diagnosis group.\n\n\n\n\n\n\n\n\n\nHow do we know there is an interaction?\n\n\n\n\n\nIf you imagine connecting the dots of the same color with a line (you could specify geom = \"line\" in a new line in the code chunk above to do this), you can see that the two virtual lines are not parallel (see below plot), suggesting the presence of an interaction. The difference in score between recognition and grammar tasks for Huntingtons patients (consider the vertical difference) is larger than the difference in score between recognition and grammar tasks for the Control patients. If those vertical differences were the same, there would be no interaction.\n\n\n\n\nFigure 4: Interaction Plot with Connected Lines"
  },
  {
    "objectID": "2_03_int3_cc_mulberry.html#writing-up-presenting-results",
    "href": "2_03_int3_cc_mulberry.html#writing-up-presenting-results",
    "title": "Interactions III: Cat x Cat",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(cog_mdl, \n          show.stat = TRUE,\n          dv.labels = \"Scores\",\n          title = \"Regression Table for Scores Model\")\n\n\n\nTable 2: Regression Table for Scores Model\n\n\n\n\n\n\n\n\n\n \nScores\n\n\nPredictors\nEstimates\nCI\nStatistic\np\n\n\n(Intercept)\n80.00\n67.91 – 92.09\n13.65\n&lt;0.001\n\n\nDiagnosis [Amnesic]\n-20.00\n-37.10 – -2.90\n-2.41\n0.024\n\n\nDiagnosis [Huntingtons]\n-40.00\n-57.10 – -22.90\n-4.83\n&lt;0.001\n\n\nTask [Recognition]\n15.00\n-2.10 – 32.10\n1.81\n0.083\n\n\nDiagnosis [Amnesic] ×\nTask [Recognition]\n-10.00\n-34.19 – 14.19\n-0.85\n0.402\n\n\nDiagnosis [Huntingtons] ×\nTask [Recognition]\n40.00\n15.81 – 64.19\n3.41\n0.002\n\n\nObservations\n30\n\n\nR2 / R2 adjusted\n0.739 / 0.685\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an example of coefficient interpretation, review the interaction models &gt; categorical x categorical example &gt; results interpretation flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(5,24) = 13.62, p &lt;.001)\\), and the model explained approximately 68.5% of the variability in Scores. The interaction between Task and Diagnosis is visually presented in Figure 3.\nAmnesic patients were found to score significantly lower on the grammar task compared to controls \\((\\beta = -20, ~SE = 8.29,~ t(24) = -2.41,~ p = .024)\\). However, their relative performance on recognition vs grammar tasks was not found to significantly differ from that of controls \\((\\beta = -10, ~SE = 11.72,~ t(24) = -0.85,~ p = .402)\\), suggesting that Amnesia affects both types of memory to a similar extent.\nHuntingons patients were found to score significantly lower on the grammar task compared to controls \\((\\beta = -40, ~SE = 8.29,~ t(24) = -4.83,~ p &lt;.001)\\). However, the difference in performance on the recognition task compared to the grammar was significantly larger for Huntingtons patients than it was for controls \\((\\beta = 40, ~SE = 11.72,~ t(24) = 3.41,~ p = .002)\\), suggesting that Huntingtons affects implicit memory to a greater extent than it does explicit memory.\nTherefore, we have evidence to reject the null hypothesis (the difference in performance between explicit and implicit memory tasks does not significantly differ between patients with Huntingtons in comparison to Controls)."
  },
  {
    "objectID": "2_03_int3_cc_mulberry.html#footnotes",
    "href": "2_03_int3_cc_mulberry.html#footnotes",
    "title": "Interactions III: Cat x Cat",
    "section": "Footnotes",
    "text": "Footnotes\n\nSome researchers may point out that a design where each person was assessed on both tasks might have been more efficient. However, the task factor in such design would then be within-subjects, meaning that the scores corresponding to the same person would be correlated. To analyse such design we will need a different method which (spoiler alert!) will be discussed next year in DAPR3.↩︎"
  },
  {
    "objectID": "2_04_simp_pair.html",
    "href": "2_04_simp_pair.html",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to interpret simple effects for experimental designs\nUnderstand how to conduct pairwise comparisons\nUnderstand how to apply corrections available for multiple comparisons\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Semester 1 Week 7, Semester 1 Week 8, Semester 1 Week 11, Semester 2 Week 1, Semester 2 Week 2, and Semester 2 Week 3.\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nsjPlot\ninteractions\npatchwork\nemmeans\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/cognitive_experiment.csv\nNote, you have already worked with some of this data last week - see Semester 2 Week 3 lab, but we now have a third Task condition - Classification."
  },
  {
    "objectID": "2_04_simp_pair.html#study-analysis-plan-overview",
    "href": "2_04_simp_pair.html#study-analysis-plan-overview",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nFirstly, examine the dataset, and perform any necessary and appropriate data management steps.\nNext, consider what would be the most appropriate coding constraint to apply in order to best address the research question - i.e., are we interested in whether group X (e.g., Amnesic) differed from group Y (e.g., Huntingtons), or whether group X (e.g., Amnesic) differed from the grand mean?\nChoose appropriate reference levels for the Diagnosis and Task variables based on your decision above.\n\n\n\n\n\n\nHint\n\n\n\n\n\nData Management\n\nThe str() function will return the overall structure of the dataset, this can be quite handy to look at\n\nConvert categorical variables to factors, and if needed, provide better variable names*\n\nLabel factors appropriately to aid with your model interpretations if required*\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\n\nNote that all of these steps can be done in combination - the mutate() and factor() functions will likely be useful here.\nCoding Constraints\n\nIf you think you’d benefit from a refresher on coding constraints, it might be best to revisit the materials from Semester 1 Block 2 (especially the dummy vs effects coding flashcard).\n\nIf you would like an overview of coding constraints in the context of interaction models, review the categorical x categorical example &gt; coding constraints flashcard.\n\nReference Levels\n\nReview the specifying reference levels flashcard.\n\n*See the numeric outcomes & categorical predictors flashcard.\n\n\n\n\n\n\n\nLet’s have a look at the data to see what we’re working with - str() or head() are a good place to start - and then we should check for any missing data (NA values):\n\n#first look at dataset structure\nstr(cog)\n\nspc_tbl_ [45 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diagnosis: num [1:45] 1 1 1 1 1 1 1 1 1 1 ...\n $ Task     : num [1:45] 1 1 1 1 1 2 2 2 2 2 ...\n $ Y        : num [1:45] 44 63 76 72 45 72 66 55 82 75 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diagnosis = col_double(),\n  ..   Task = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis  Task     Y\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1         1     1    44\n2         1     1    63\n3         1     1    76\n4         1     1    72\n5         1     1    45\n6         1     2    72\n\n#check for NAs \ntable(is.na(cog))\n\n\nFALSE \n  135 \n\n# there are none - all FALSE\n\nNext, lets convert Diagnosis and Task into factors, making the labels of each factor level more meaningful. According to the data description, the encoding of the factor Diagnosis is: 1 = amnesic patients, 2 = Huntingtons patients, and 3 = control patients. The encoding for the factor Task is: 1 = grammar task, 2 = classification task, and 3 = recognition task.\n\ncog &lt;- cog |&gt;\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('amnesic', 'huntingtons', 'control'),\n                           ordered = FALSE),\n        Task = factor(Task, \n                      levels = c(1, 2, 3),\n                      labels = c('grammar', 'classification', 'recognition'),\n                      ordered = FALSE)) |&gt;\n    rename(Score = Y)\n\nSince we are interested in comparing groups, we should use dummy coding. By default, R uses dummy coding, so we do not need to make any changes to the coding constraint.\nHowever, for our reference groups, we’re likely to want it to be the Control group for Diagnosis, and recognition for Task:\n\ncog$Diagnosis &lt;- fct_relevel(cog$Diagnosis, \"control\")\ncog$Task &lt;- fct_relevel(cog$Task, \"recognition\")\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study (you might be able to re-use some of the content you wrote for Semester 2 Week 3 lab here, but note that we now have an extra condition within Task)\nOutline data checks / data cleaning\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variables. This will be somewhat similar to last week, but with the addition of Classification in Task, our model will contain a different number of parameters)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\nThe statistical models flashcards may also be useful to refer to. Specifically the interaction models flashcards and categorical x categorical example flashcards might be of most use.\n\n\n\n\n\n\n\nThe cog dataset contained information on 45 hypothetical participants from a between-subjects study. Participants belonged to one of three ‘Diagnosis’ groups, which had 15 participants in each - Control, Amnesic, or Huntingtons. Participants from each of the Diagnosis groups were equally and randomly assigned to one of three ‘Tasks’ to measure different memory processes - Grammar, Classification, or Recognition - the former two measuring implicit memory and the latter explicit. This resulted in 5 participants from each Diagnosis group in each of the three Task conditions.\nAll participant data was complete, and categorical variables were coded as factors. For the purpose of this analysis, ‘Control’ was designated as the reference group for Diagnosis, since it was the only group of participants with no known neurological disorder. For Task, the recognition task measures explicit memory whereas the other two measure implicit memory, so this was specified as the reference group.\nBoxplots will be used to visualise the associations among Diagnosis and Task conditions. To address the research question of whether the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls, we first need to define the dummy variables for both\nDiagnosis:\n\\[\n\\begin{gather*}\n\\text{D}_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic}\\\\  \n0 & \\text{otherwise}\n\\end{cases}\n\\\\  \n\\\\  \n\\text{D}_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons}\\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad   \n\\\\  \n\\\\  \n(\\text{Control is base level})  \n\\end{gather*}\n\\]\nand for Task:\n\\[\n\\begin{gather*}    \n\\text{T}_\\text{Grammar} = \\begin{cases}\n1 & \\text{if Task is Grammar}\\\\\n0 & \\text{otherwise}\\\\  \n\\end{cases}\\\n\\\\  \n\\\\\n\\text{T}_\\text{Classification} = \\begin{cases}  \n1 & \\text{if Task is Classification}\\\\   \n0 & \\text{otherwise}\\\\\n\\end{cases}\\\\\\  \n\\quad    \n\\\\    \n\\\\  \n(\\text{Recognition is base level})\\\\\n\\end{gather*}   \n\\]\nBased on the above dummy coding, we are going to fit the following interaction model:\n\\[\n\\begin{align}\n\\text{Interaction Model}: \\text{Score} &= \\beta_0  \\\\\n      &+ \\beta_1 \\cdot \\text{D}_\\text{Amnesic} + \\beta_2 \\cdot  \\text{D}_\\text{Huntingtons}  \\\\\n      &+ \\beta_3 \\cdot  \\text{T}_\\text{Grammar}  + \\beta_4 \\cdot  \\text{T}_\\text{Classification}  \\\\\n      &+ \\beta_5 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_6 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_7 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\beta_8 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\epsilon  \n\\end{align}\n\\]\nEffects will be considered statistically significant at \\(\\alpha = .05\\)\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 5, 6, 7, 8\\))\nThere are no significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s).\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 5, 6, 7, 8\\))\nThere are significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s)."
  },
  {
    "objectID": "2_04_simp_pair.html#descriptive-statistics-visualisations",
    "href": "2_04_simp_pair.html#descriptive-statistics-visualisations",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nInterpret the descriptive statistics and visualisations in the context of the study (i.e., comment on any observed differences among groups).\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables - categorical and numeric values examples and categorical x categorical example - visualise data.\nMake sure to comment on any observed differences among the sample means of the different conditions.\n\n\n\n\n\n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\ncog_stats &lt;- cog |&gt; \n    group_by(Diagnosis, Task) |&gt;\n    summarise(\n        Mean = mean(Score), \n        SD = sd(Score),\n        SE = sd(Score) / sqrt(n()),\n        Min = min(Score),\n        Max = max(Score)) |&gt;\n    kable(caption = \"Descriptive Statistics of Score\", digits = 2) |&gt;\n    kable_styling()\n\ncog_stats\n\n\n\nTable 1: Descriptive Statistics\n\nDiagnosis\nTask\nMean\nSD\nSE\nMin\nMax\n\n\n\ncontrol\nrecognition\n95\n12.98\n5.81\n80\n107\n\n\ncontrol\ngrammar\n80\n11.68\n5.22\n70\n98\n\n\ncontrol\nclassification\n80\n12.98\n5.81\n65\n92\n\n\namnesic\nrecognition\n65\n12.17\n5.44\n51\n82\n\n\namnesic\ngrammar\n60\n14.92\n6.67\n44\n76\n\n\namnesic\nclassification\n70\n10.17\n4.55\n55\n82\n\n\nhuntingtons\nrecognition\n95\n13.38\n5.98\n80\n108\n\n\nhuntingtons\ngrammar\n40\n13.25\n5.92\n24\n55\n\n\nhuntingtons\nclassification\n45\n10.86\n4.86\n33\n59\n\n\n\n\n\n\n\n\n\n\nSince we have a continuous outcome and 2 categorical predictors - a boxplot would be most appropriate for visualisations:\n\ncog_plt &lt;- ggplot(data = cog, aes(x = Diagnosis, y = Score, color = Task)) +\n  geom_boxplot() +\n  labs(x = 'Diagnosis', y = 'Score')\ncog_plt\n\n\n\nFigure 1: Association between Task Condition, Diagnosis, and Score\n\n\n\n\n\n\n\n\n\n\n\n\n\nControl patients consistently performed best across all tasks. They did not appear to differ substantially in their scores between grammar and classification tasks, but they clearly performed better in the recognition task in comparison to both the grammar and classification ones.\nAmnesic patients appeared to perform better than Huntingtons patients in grammar and classification tasks (reflecting intrinsic memory processes), and performed worse than Huntingtons patients in the recognition task (reflecting extrinsic memory processes)."
  },
  {
    "objectID": "2_04_simp_pair.html#model-fitting-interpretation",
    "href": "2_04_simp_pair.html#model-fitting-interpretation",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nFit the specified model using lm(), and assign it the name “mdl_int”.\nProvide key model results in a formatted table and plot the interaction model before reporting in-text the overall model fit.\n\n\n\n\n\n\nHint\n\n\n\n\n\nModel Building\n\nWe can fit interaction models using the lm() function.\n\nFor an overview, see the interaction models flashcards.\nFor an example, review the interaction models &gt; categorical x categorical example &gt; model building flashcards.\n\nResults Table\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\nPlot Model\n\nUsing the cat_plot() function from the interactions package, visualise the interaction effects from your model.\nFor an overview and example, review the interaction models &gt; categorical x categorical example &gt; model visualisation flashcards.\n\n\n\n\n\n\n\n\n\n\nBuild & Check Model\nResults Table\nInteraction Plot\n\n\n\n\n#fit interaction model\nmdl_int &lt;- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(mdl_int)\n\n\nCall:\nlm(formula = Score ~ Diagnosis * Task, data = cog)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n   -16    -12      2     11     18 \n\nCoefficients:\n                                          Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                              9.500e+01  5.617e+00  16.912  &lt; 2e-16\nDiagnosisamnesic                        -3.000e+01  7.944e+00  -3.776 0.000576\nDiagnosishuntingtons                     2.960e-14  7.944e+00   0.000 1.000000\nTaskgrammar                             -1.500e+01  7.944e+00  -1.888 0.067085\nTaskclassification                      -1.500e+01  7.944e+00  -1.888 0.067085\nDiagnosisamnesic:Taskgrammar             1.000e+01  1.123e+01   0.890 0.379329\nDiagnosishuntingtons:Taskgrammar        -4.000e+01  1.123e+01  -3.560 0.001063\nDiagnosisamnesic:Taskclassification      2.000e+01  1.123e+01   1.780 0.083490\nDiagnosishuntingtons:Taskclassification -3.500e+01  1.123e+01  -3.115 0.003597\n                                           \n(Intercept)                             ***\nDiagnosisamnesic                        ***\nDiagnosishuntingtons                       \nTaskgrammar                             .  \nTaskclassification                      .  \nDiagnosisamnesic:Taskgrammar               \nDiagnosishuntingtons:Taskgrammar        ** \nDiagnosisamnesic:Taskclassification     .  \nDiagnosishuntingtons:Taskclassification ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.56 on 36 degrees of freedom\nMultiple R-squared:  0.7318,    Adjusted R-squared:  0.6722 \nF-statistic: 12.28 on 8 and 36 DF,  p-value: 2.844e-08\n\n\n\n\n\ntab_model(mdl_int,\n          dv.labels = \"Scores\",\n          pred.labels = c(\"Diagnosisamnesic\" = \"Diagnosis - Amnesic\",\n                          \"Diagnosishuntingtons\" = \"Diagnosis - Huntingtons\",\n                          \"Taskgrammar\" = \"Task - Grammar\",\n                          \"Taskclassification\" = \"Task - Classification\",\n                          \"Diagnosisamnesic:Taskgrammar\" = \"Diagnosis - Amnesic : Task - Grammar\",\n                          \"Diagnosishuntingtons:Taskgrammar\" = \"Diagnosis - Huntingtons : Task - Grammar\",\n                          \"Diagnosisamnesic:Taskclassification\" = \"Diagnosis - Amnesic : Task - Classification\",\n                          \"Diagnosishuntingtons:Taskclassification\" = \"Diagnosis - Huntingtons : Task - Classification\"),\n          title = \"Regression Table for Scores Model\")\n\n\n\nTable 2: Regression Table for Scores Model\n\n\n\n\n\n\n\n\n \nScores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n95.00\n83.61 – 106.39\n&lt;0.001\n\n\nDiagnosis - Amnesic\n-30.00\n-46.11 – -13.89\n0.001\n\n\nDiagnosis - Huntingtons\n0.00\n-16.11 – 16.11\n1.000\n\n\nTask - Grammar\n-15.00\n-31.11 – 1.11\n0.067\n\n\nTask - Classification\n-15.00\n-31.11 – 1.11\n0.067\n\n\nDiagnosis - Amnesic :\nTask - Grammar\n10.00\n-12.79 – 32.79\n0.379\n\n\nDiagnosis - Huntingtons :\nTask - Grammar\n-40.00\n-62.79 – -17.21\n0.001\n\n\nDiagnosis - Amnesic :\nTask - Classification\n20.00\n-2.79 – 42.79\n0.083\n\n\nDiagnosis - Huntingtons :\nTask - Classification\n-35.00\n-57.79 – -12.21\n0.004\n\n\nObservations\n45\n\n\nR2 / R2 adjusted\n0.732 / 0.672\n\n\n\n\n\n\n\n\n\n\n\nplt_cog_mdl &lt;- cat_plot(model = mdl_int, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl\n\n\n\nFigure 2: Interaction Plot\n\n\n\n\n\n\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2, and the interaction model is visually presented in Figure 2. The \\(F\\)-test for model utility was significant \\((F(8, 36) = 12.28, p &lt; .001)\\), and the model explained approximately 67% of the variability in Scores."
  },
  {
    "objectID": "2_04_simp_pair.html#contrast-analysis",
    "href": "2_04_simp_pair.html#contrast-analysis",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Contrast Analysis",
    "text": "Contrast Analysis\nLet’s move onto testing differences between specific group means.\n\nQuestion 5\n\n\nIn terms of the diagnostic groups, we want to compare the individuals with amnesia to those with Huntingtons. This corresponds to a contrast with coefficients of 0, 1, and −1, for control, amnesic, and Huntingtons, respectively.\nSimilarly, in terms of the tasks, we want to compare the average of the two implicit memory tasks with the explicit memory task. This corresponds to a contrast with coefficients of 0.5, 0.5, and −1 for the three tasks.\nWhen we are in presence of a significant interaction, the coefficients for a contrast between the means are found by multiplying each row coefficient with all column coefficients as shown below:\n\n\n\n\n\n\n\n\nSpecify the coefficients to be used in the contrast analysis, and present in a table.\nNext, formally state the contrast that the researchers were interested in as testable hypotheses.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the manual contrasts flashcards &gt; interaction models.\n\n\n\n\n\n\n\nWe can specify the coefficients to be used in the contrast analysis in R using either:\n\n\nOption 1\nOption 2\n\n\n\n\ndiag_coef  &lt;- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  &lt;- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef &lt;- outer(diag_coef, task_coef)\ncontr_coef\n\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n\n\n\n\n\ndiag_coef  &lt;- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  &lt;- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef &lt;- diag_coef %o% task_coef\ncontr_coef\n\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n\n\n\n\n\nUsing either approach, we can then convert into a well-formatted table:\n\ncontr_coef |&gt; \n    kable(caption = \"Contrast Weights\") |&gt;\n    kable_styling(full_width = FALSE) \n\n\n\nTable 3: Contrast Weights\n\n\ngrammar\nclassification\nrecognition\n\n\n\ncontrol\n0.0\n0.0\n0\n\n\namnesic\n0.5\n0.5\n-1\n\n\nhuntingtons\n-0.5\n-0.5\n1\n\n\n\n\n\n\n\n\nThe above coefficients correspond to the following hypotheses:\n\\[\nH_0: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) = 0\n\\]\n\\[\nH_1: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) \\neq 0\n\\]\nwhich can be equivalently specified as:\n\\[\nH_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n\\]\n\\[  \nH_1: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad \\neq \\quad  \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n\\]\nboth statements state that, in the population, the difference between the mean implicit memory and the explicit memory score is the same for individuals with amnesia and Huntingtons.\nNote that the scores for the grammar and classification tasks have been averaged to obtain a single measure of ‘implicit memory’ score.\n\n\n\n\n\nQuestion 6\n\n\nFirstly, use emmeans() to obtain the estimated means and uncertainties for your factors.\nNext, specify the coefficients of the comparison and run the contrast analysis, obtaining 95% confidence intervals.\nReport the results of the contrast analysis in full.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the manual contrasts flashcards &gt; interaction models.\n\n\n\n\n\n\n\nNow that we have the coefficients, let’s firstly call the emmeans function to get the estimated means of our groups (this is also helpful to look at the ordering of the groups):\n\ndiag_task_mean &lt;- emmeans(mdl_int, ~ Diagnosis*Task)\ndiag_task_mean\n\n Diagnosis   Task           emmean   SE df lower.CL upper.CL\n control     recognition        95 5.62 36     83.6    106.4\n amnesic     recognition        65 5.62 36     53.6     76.4\n huntingtons recognition        95 5.62 36     83.6    106.4\n control     grammar            80 5.62 36     68.6     91.4\n amnesic     grammar            60 5.62 36     48.6     71.4\n huntingtons grammar            40 5.62 36     28.6     51.4\n control     classification     80 5.62 36     68.6     91.4\n amnesic     classification     70 5.62 36     58.6     81.4\n huntingtons classification     45 5.62 36     33.6     56.4\n\nConfidence level used: 0.95 \n\n\nNext, from contr_coef, insert the coefficients following the order specified by the rows of diag_task_mean above. That is, the first one should be for control recognition and have a value of 0, the second for amnesic recognition with a value of -1, and so on…\nLet’s specify our weights, and give a name to this contrast (in this example ‘Research Hyp’):\n\ndiag_task_comp &lt;- contrast(diag_task_mean, \n                     method = list('Research Hyp' = c(0, -1, 1, 0, 0.5, -0.5, 0, 0.5, -0.5))\n                     )\n\nNext, let’s look at the output via one of two ways:\n\n\nOption 1\nOption 2\n\n\n\n\n#examine output\ndiag_task_comp\n\n contrast     estimate   SE df t.ratio p.value\n Research Hyp     52.5 9.73 36   5.396  &lt;.0001\n\n#obtain confidence intervals\nconfint(diag_task_comp)\n\n contrast     estimate   SE df lower.CL upper.CL\n Research Hyp     52.5 9.73 36     32.8     72.2\n\nConfidence level used: 0.95 \n\n\n\n\n\n#examine summary output and state `infer = TRUE` to include confidence intervals\nsummary(diag_task_comp, infer = TRUE)\n\n contrast     estimate   SE df lower.CL upper.CL t.ratio p.value\n Research Hyp     52.5 9.73 36     32.8     72.2   5.396  &lt;.0001\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n\n\n\n\nWe performed a test against \\(H_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\\). At the 5% significance level, there was evidence that individuals with Amnesia and Huntingtons did differ in the difference between implicit and explicit memory tasks \\((t(36) = 5.40, p &lt; .001, \\text{two-sided})\\), and this difference was estimated to be 52.50. We are 95% confident that the difference in implicit and explicit memory scores between individuals with Amnesia and Huntingtons was between 32.80 to 72.20 points. Therefore, we can reject the null hypothesis that the difference in differences was equal to zero."
  },
  {
    "objectID": "2_04_simp_pair.html#simple-effects",
    "href": "2_04_simp_pair.html#simple-effects",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Simple Effects",
    "text": "Simple Effects\n\nQuestion 7\n\n\nExamine the simple effects for Task at each level of Diagnosis; and then the simple effects for Diagnosis at each level of Task.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; categorical x categorical example &gt; simple effects flashcards.\n\n\n\n\n\n\n\n\n\nSimple Effects of Task\nSimple Effects of Diagnosis\n\n\n\nFrom mdl_int_simple1 we can see the differences between tasks for each diagnosis group:\n\nmdl_int_simple1 &lt;- pairs(diag_task_mean, simple = \"Task\")\nmdl_int_simple1\n\nDiagnosis = control:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              15 7.94 36   1.888  0.1567\n recognition - classification       15 7.94 36   1.888  0.1567\n grammar - classification            0 7.94 36   0.000  1.0000\n\nDiagnosis = amnesic:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar               5 7.94 36   0.629  0.8050\n recognition - classification       -5 7.94 36  -0.629  0.8050\n grammar - classification          -10 7.94 36  -1.259  0.4273\n\nDiagnosis = huntingtons:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              55 7.94 36   6.923  &lt;.0001\n recognition - classification       50 7.94 36   6.294  &lt;.0001\n grammar - classification           -5 7.94 36  -0.629  0.8050\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n\n\nFrom mdl_int_simple2 we can see the differences between diagnoses for each task group:\n\nmdl_int_simple2 &lt;- pairs(diag_task_mean, simple = \"Diagnosis\")\nmdl_int_simple2\n\nTask = recognition:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           30 7.94 36   3.776  0.0016\n control - huntingtons        0 7.94 36   0.000  1.0000\n amnesic - huntingtons      -30 7.94 36  -3.776  0.0016\n\nTask = grammar:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           20 7.94 36   2.518  0.0424\n control - huntingtons       40 7.94 36   5.035  &lt;.0001\n amnesic - huntingtons       20 7.94 36   2.518  0.0424\n\nTask = classification:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           10 7.94 36   1.259  0.4273\n control - huntingtons       35 7.94 36   4.406  0.0003\n amnesic - huntingtons       25 7.94 36   3.147  0.0091\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nVisualise the interaction, displaying two plots - one with Diagnosis on the x-axis, and the other with Task on the x-axis.\nConsidering the simple effects that you noted above, identify the significant effects and match them to the corresponding points of your interaction plot.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; categorical x categorical example &gt; simple effects flashcards.\nRecall that the patchwork package allows us to arrange multiple plots using either / or | or +.\n\n\n\n\n\n\n\n\n\nSimple Effects of Task\nSimple Effects of Diagnosis\n\n\n\n\nplt_1 &lt;- emmip(mdl_int, Diagnosis ~ Task, CIs = TRUE)\nplt_1\n\n\n\n\n\n\n\nFor the simple effects of task (see plt_1), we saw the significant differences (those for which \\(p&lt;.05\\)):\n\nOnly in the Huntingtons group, between recognition & grammar and recognition & classification tasks\n\nleft-most blue point compared to the middle blue point, and then compared to the right-most blue point\n\n\n\n\n\n\nplt_2 &lt;- emmip(mdl_int, Task ~ Diagnosis, CIs = TRUE)\nplt_2\n\n\n\n\n\n\n\nFor the simple effects of Diagnosis (see plt_2), we saw significant differences (those for which \\(p&lt;.05\\)):\n\nin the recognition task, between control & amnesic\n\nleft-most red point to middle red point\n\n\nin the recognition task, between amnesic & huntingtons\n\nmiddle red-point to right-most red point\n\n\nin the grammar task, between control & amnesic\n\nleft-most green point to middle green point\n\n\nin the grammar task, between control & huntingtons\n\nleft-most green point to right-most green point\n\n\nin the grammar task, between amnesic & huntingtons\n\nmiddle green point to right-most green point\n\n\nin the classification task, between control & huntingtons\n\nleft-most blue point to right-most blue point\n\n\nin the classification task, between amnesic & huntingtons\n\nmiddle blue point to right-most blue point"
  },
  {
    "objectID": "2_04_simp_pair.html#pairwise-comparisons-multiple-corrections",
    "href": "2_04_simp_pair.html#pairwise-comparisons-multiple-corrections",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Pairwise Comparisons & Multiple Corrections",
    "text": "Pairwise Comparisons & Multiple Corrections\n\nQuestion 9\n\n\nConduct exploratory pairwise comparisons to compare all levels of Diagnosis with all levels of Task, applying no correction (note that Tukey will be automatically applied since we are comparing groups of means, so you will need to overwrite this).\nWithout adjusting our \\(\\alpha\\) (or \\(p\\)-value), why might any inferences drawn from your output be problematic?\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview, review the multiple comparisons flashcards.\n\n\n\n\n\n\n\n\npairs_res &lt;- pairs(diag_task_mean, adjust = \"none\")\npairs_res\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0006\n  1.0000\n  0.0671\n  0.0001\n  &lt;.0001\n  0.0671\n  0.0033\n  &lt;.0001\n  0.0006\n  0.0671\n  0.5331\n  0.0033\n  0.0671\n  0.5331\n  0.0164\n  0.0671\n  0.0001\n  &lt;.0001\n  0.0671\n  0.0033\n  &lt;.0001\n  0.0164\n  &lt;.0001\n  1.0000\n  0.2162\n  0.0001\n  0.0164\n  0.0164\n  0.2162\n  0.0671\n  &lt;.0001\n  0.0006\n  0.5331\n  0.2162\n  0.0001\n  0.0033\n\n#can also plot if you'd like:\nplot(pairs_res)\n\n\n\n\n\n\n\nFrom the above, we can see comparisons for all different possible pairs of diagnosis-task combinations1.\nIn total, there are 9 different estimates, but comparing them all means that we have 36 comparisons being tested! By not adjusting our \\(p\\)-value, we are increasing the experiment-wise Type I error rate - we could wrongly reject the null hypothesis at a much higher rate than 5/100 (or 1/20 as is assumed when \\(\\alpha = .05\\)). To overcome this, we might adjust and determine a result to be statistically significant if \\(p &lt; .005\\), as opposed to \\(p &lt; .05\\), depending on how many tests are in our family of tests.\n\n\n\n\n\nQuestion 10\n\n\nSelect an appropriate method to adjust for multiple comparisons, and then obtain confidence intervals.\nComment on how these \\(p\\)-values differ from your raw (i.e., unadjusted) \\(p\\)-values.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview, review the multiple comparisons flashcards.\n\n\n\n\n\n\n\nNote what the functions in R do is adjust the \\(p\\)-value, rather than the \\(\\alpha\\).\nSince we’re interested in all pairwise comparisons of means, the Tukey adjustment might be a sensible approach. However, we’ll also show the Bonferroni to show how it differs (note, in practice you would only apply one correction and justify this choice based on your design - we are only applying two to note how they differ!)\n\n\nTukey\nBonferroni\n\n\n\n\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"Tukey\")\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0149\n  1.0000\n  0.6257\n  0.0026\n  &lt;.0001\n  0.6257\n  0.0711\n  &lt;.0001\n  0.0149\n  0.6257\n  0.9993\n  0.0711\n  0.6257\n  0.9993\n  0.2575\n  0.6257\n  0.0026\n  &lt;.0001\n  0.6257\n  0.0711\n  &lt;.0001\n  0.2575\n  0.0004\n  1.0000\n  0.9367\n  0.0026\n  0.2575\n  0.2575\n  0.9367\n  0.6257\n  0.0004\n  0.0149\n  0.9993\n  0.9367\n  0.0026\n  0.0711\n\nP value adjustment: tukey method for comparing a family of 9 estimates \n\n\nNote that 8 of the comparisons are no longer significant when using Tukey’s adjustment, suggesting that these might have been (when using no adjustment) Type I errors!\n\n\n\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"bonferroni\")\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  &lt;.0001\n  1.0000\n  0.1190\n  &lt;.0001\n  0.0207\n  1.0000\n  1.0000\n  0.1190\n  1.0000\n  1.0000\n  0.5907\n  1.0000\n  0.0033\n  &lt;.0001\n  1.0000\n  0.1190\n  &lt;.0001\n  0.5907\n  0.0005\n  1.0000\n  1.0000\n  0.0033\n  0.5907\n  0.5907\n  1.0000\n  1.0000\n  0.0005\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  0.1190\n\nP value adjustment: bonferroni method for 36 tests \n\n\nThe first Bonferroni adjusted \\(p\\)-value is 0.0207.\nThe raw (unadjusted) \\(p\\)-value from the previous question was 0.0005759265.\nThe Bonferroni method simply multiplies the ‘raw’ \\(p\\)-value by the number of the tests, which we know is 36.\n\n0.0005759265 * 36\n\n[1] 0.02073335\n\n\nIn terms of differences in Bonferroni to raw \\(p\\)-values, they are thus 36 times the size.\nOne benefit of Bonferroni is that it can be applied to any set of \\(p\\)-values, whereas Tukey only applies when comparing the means of levels of a factor. The downside, however, is that it may be overly conservative (i.e. reduce our power to detect an effect that is truly there)."
  },
  {
    "objectID": "2_04_simp_pair.html#footnotes",
    "href": "2_04_simp_pair.html#footnotes",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Footnotes",
    "text": "Footnotes\n\nthe differences between the group means for the comparison as labelled↩︎"
  },
  {
    "objectID": "2_04_simp_pair_broom.html",
    "href": "2_04_simp_pair_broom.html",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to interpret simple effects for experimental designs\nUnderstand how to conduct pairwise comparisons\nUnderstand how to apply corrections available for multiple comparisons\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Semester 1 Week 7, Semester 1 Week 8, Semester 1 Week 11, Semester 2 Week 1, Semester 2 Week 2, and Semester 2 Week 3.\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nsjPlot\ninteractions\npatchwork\nemmeans\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/cognitive_experiment.csv\nNote, you have already worked with some of this data last week - see Semester 2 Week 3 lab, but we now have a third Task condition - Classification."
  },
  {
    "objectID": "2_04_simp_pair_broom.html#study-analysis-plan-overview",
    "href": "2_04_simp_pair_broom.html#study-analysis-plan-overview",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nFirstly, examine the dataset, and perform any necessary and appropriate data management steps.\nNext, consider what would be the most appropriate coding constraint to apply in order to best address the research question - i.e., are we interested in whether group X (e.g., Amnesic) differed from group Y (e.g., Huntingtons), or whether group X (e.g., Amnesic) differed from the grand mean?\nChoose appropriate reference levels for the Diagnosis and Task variables based on your decision above.\n\n\n\n\n\n\nHint\n\n\n\n\n\nData Management\n\nThe str() function will return the overall structure of the dataset, this can be quite handy to look at\n\nConvert categorical variables to factors, and if needed, provide better variable names*\n\nLabel factors appropriately to aid with your model interpretations if required*\n\nCheck that the dataset is complete (i.e., are there any NA values?). We can check this using is.na()\n\n\nNote that all of these steps can be done in combination - the mutate() and factor() functions will likely be useful here.\nCoding Constraints\n\nIf you think you’d benefit from a refresher on coding constraints, it might be best to revisit the materials from Semester 1 Block 2 (especially the dummy vs effects coding flashcard).\n\nIf you would like an overview of coding constraints in the context of interaction models, review the categorical x categorical example &gt; coding constraints flashcard.\n\nReference Levels\n\nReview the specifying reference levels flashcard.\n\n*See the numeric outcomes & categorical predictors flashcard.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with - str() or head() are a good place to start - and then we should check for any missing data (NA values):\n\n#first look at dataset structure\nstr(cog)\n\nspc_tbl_ [45 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diagnosis: num [1:45] 1 1 1 1 1 1 1 1 1 1 ...\n $ Task     : num [1:45] 1 1 1 1 1 2 2 2 2 2 ...\n $ Y        : num [1:45] 44 63 76 72 45 72 66 55 82 75 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diagnosis = col_double(),\n  ..   Task = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis  Task     Y\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1         1     1    44\n2         1     1    63\n3         1     1    76\n4         1     1    72\n5         1     1    45\n6         1     2    72\n\n#check for NAs \ntable(is.na(cog))\n\n\nFALSE \n  135 \n\n# there are none - all FALSE\n\nNext, lets convert Diagnosis and Task into factors, making the labels of each factor level more meaningful. According to the data description, the encoding of the factor Diagnosis is: 1 = amnesic patients, 2 = Huntingtons patients, and 3 = control patients. The encoding for the factor Task is: 1 = grammar task, 2 = classification task, and 3 = recognition task.\n\ncog &lt;- cog |&gt;\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('amnesic', 'huntingtons', 'control'),\n                           ordered = FALSE),\n        Task = factor(Task, \n                      levels = c(1, 2, 3),\n                      labels = c('grammar', 'classification', 'recognition'),\n                      ordered = FALSE)) |&gt;\n    rename(Score = Y)\n\nSince we are interested in comparing groups, we should use dummy coding. By default, R uses dummy coding, so we do not need to make any changes to the coding constraint.\nHowever, for our reference groups, we’re likely to want it to be the Control group for Diagnosis, and recognition for Task:\n\ncog$Diagnosis &lt;- fct_relevel(cog$Diagnosis, \"control\")\ncog$Task &lt;- fct_relevel(cog$Task, \"recognition\")\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study (you might be able to re-use some of the content you wrote for Semester 2 Week 3 lab here, but note that we now have an extra condition within Task)\nOutline data checks / data cleaning\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variables. This will be somewhat similar to last week, but with the addition of Classification in Task, our model will contain a different number of parameters)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\nThe statistical models flashcards may also be useful to refer to. Specifically the interaction models flashcards and categorical x categorical example flashcards might be of most use.\n\n\n\n\n\n\n\n Solution \n\n\nThe cog dataset contained information on 45 hypothetical participants from a between-subjects study. Participants belonged to one of three ‘Diagnosis’ groups, which had 15 participants in each - Control, Amnesic, or Huntingtons. Participants from each of the Diagnosis groups were equally and randomly assigned to one of three ‘Tasks’ to measure different memory processes - Grammar, Classification, or Recognition - the former two measuring implicit memory and the latter explicit. This resulted in 5 participants from each Diagnosis group in each of the three Task conditions.\nAll participant data was complete, and categorical variables were coded as factors. For the purpose of this analysis, ‘Control’ was designated as the reference group for Diagnosis, since it was the only group of participants with no known neurological disorder. For Task, the recognition task measures explicit memory whereas the other two measure implicit memory, so this was specified as the reference group.\nBoxplots will be used to visualise the associations among Diagnosis and Task conditions. To address the research question of whether the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls, we first need to define the dummy variables for both\nDiagnosis:\n\\[\n\\begin{gather*}\n\\text{D}_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic}\\\\  \n0 & \\text{otherwise}\n\\end{cases}\n\\\\  \n\\\\  \n\\text{D}_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons}\\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad   \n\\\\  \n\\\\  \n(\\text{Control is base level})  \n\\end{gather*}\n\\]\nand for Task:\n\\[\n\\begin{gather*}    \n\\text{T}_\\text{Grammar} = \\begin{cases}\n1 & \\text{if Task is Grammar}\\\\\n0 & \\text{otherwise}\\\\  \n\\end{cases}\\\n\\\\  \n\\\\\n\\text{T}_\\text{Classification} = \\begin{cases}  \n1 & \\text{if Task is Classification}\\\\   \n0 & \\text{otherwise}\\\\\n\\end{cases}\\\\\\  \n\\quad    \n\\\\    \n\\\\  \n(\\text{Recognition is base level})\\\\\n\\end{gather*}   \n\\]\nBased on the above dummy coding, we are going to fit the following interaction model:\n\\[\n\\begin{align}\n\\text{Interaction Model}: \\text{Score} &= \\beta_0  \\\\\n      &+ \\beta_1 \\cdot \\text{D}_\\text{Amnesic} + \\beta_2 \\cdot  \\text{D}_\\text{Huntingtons}  \\\\\n      &+ \\beta_3 \\cdot  \\text{T}_\\text{Grammar}  + \\beta_4 \\cdot  \\text{T}_\\text{Classification}  \\\\\n      &+ \\beta_5 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_6 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_7 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\beta_8 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\epsilon  \n\\end{align}\n\\]\nEffects will be considered statistically significant at \\(\\alpha = .05\\)\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 5, 6, 7, 8\\))\nThere are no significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s).\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 5, 6, 7, 8\\))\nThere are significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s)."
  },
  {
    "objectID": "2_04_simp_pair_broom.html#descriptive-statistics-visualisations",
    "href": "2_04_simp_pair_broom.html#descriptive-statistics-visualisations",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nInterpret the descriptive statistics and visualisations in the context of the study (i.e., comment on any observed differences among groups).\n\n\n\n\n\n\nHint\n\n\n\n\n\nReview the many ways to numerically and visually explore your data by reading over the data exploration flashcards.\nFor examples, see flashcards on descriptives statistics tables - categorical and numeric values examples and categorical x categorical example - visualise data.\nMake sure to comment on any observed differences among the sample means of the different conditions.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\ncog_stats &lt;- cog |&gt; \n    group_by(Diagnosis, Task) |&gt;\n    summarise(\n        Mean = mean(Score), \n        SD = sd(Score),\n        SE = sd(Score) / sqrt(n()),\n        Min = min(Score),\n        Max = max(Score)) |&gt;\n    kable(caption = \"Descriptive Statistics of Score\", digits = 2) |&gt;\n    kable_styling()\n\ncog_stats\n\n\n\nTable 1: Descriptive Statistics\n\nDiagnosis\nTask\nMean\nSD\nSE\nMin\nMax\n\n\n\ncontrol\nrecognition\n95\n12.98\n5.81\n80\n107\n\n\ncontrol\ngrammar\n80\n11.68\n5.22\n70\n98\n\n\ncontrol\nclassification\n80\n12.98\n5.81\n65\n92\n\n\namnesic\nrecognition\n65\n12.17\n5.44\n51\n82\n\n\namnesic\ngrammar\n60\n14.92\n6.67\n44\n76\n\n\namnesic\nclassification\n70\n10.17\n4.55\n55\n82\n\n\nhuntingtons\nrecognition\n95\n13.38\n5.98\n80\n108\n\n\nhuntingtons\ngrammar\n40\n13.25\n5.92\n24\n55\n\n\nhuntingtons\nclassification\n45\n10.86\n4.86\n33\n59\n\n\n\n\n\n\n\n\n\n\nSince we have a continuous outcome and 2 categorical predictors - a boxplot would be most appropriate for visualisations:\n\ncog_plt &lt;- ggplot(data = cog, aes(x = Diagnosis, y = Score, color = Task)) +\n  geom_boxplot() +\n  labs(x = 'Diagnosis', y = 'Score')\ncog_plt\n\n\n\nFigure 1: Association between Task Condition, Diagnosis, and Score\n\n\n\n\n\n\n\n\n\n\n\n\n\nControl patients consistently performed best across all tasks. They did not appear to differ substantially in their scores between grammar and classification tasks, but they clearly performed better in the recognition task in comparison to both the grammar and classification ones.\nAmnesic patients appeared to perform better than Huntingtons patients in grammar and classification tasks (reflecting intrinsic memory processes), and performed worse than Huntingtons patients in the recognition task (reflecting extrinsic memory processes)."
  },
  {
    "objectID": "2_04_simp_pair_broom.html#model-fitting-interpretation",
    "href": "2_04_simp_pair_broom.html#model-fitting-interpretation",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nFit the specified model using lm(), and assign it the name “mdl_int”.\nProvide key model results in a formatted table and plot the interaction model before reporting in-text the overall model fit.\n\n\n\n\n\n\nHint\n\n\n\n\n\nModel Building\n\nWe can fit interaction models using the lm() function.\n\nFor an overview, see the interaction models flashcards.\nFor an example, review the interaction models &gt; categorical x categorical example &gt; model building flashcards.\n\nResults Table\n\nUse tab_model() from the sjPlot package. For a quick guide, review the tables flashcard.\n\nPlot Model\n\nUsing the cat_plot() function from the interactions package, visualise the interaction effects from your model.\nFor an overview and example, review the interaction models &gt; categorical x categorical example &gt; model visualisation flashcards.\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nBuild & Check Model\nResults Table\nInteraction Plot\n\n\n\n\n#fit interaction model\nmdl_int &lt;- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(mdl_int)\n\n\nCall:\nlm(formula = Score ~ Diagnosis * Task, data = cog)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n   -16    -12      2     11     18 \n\nCoefficients:\n                                          Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                              9.500e+01  5.617e+00  16.912  &lt; 2e-16\nDiagnosisamnesic                        -3.000e+01  7.944e+00  -3.776 0.000576\nDiagnosishuntingtons                     2.960e-14  7.944e+00   0.000 1.000000\nTaskgrammar                             -1.500e+01  7.944e+00  -1.888 0.067085\nTaskclassification                      -1.500e+01  7.944e+00  -1.888 0.067085\nDiagnosisamnesic:Taskgrammar             1.000e+01  1.123e+01   0.890 0.379329\nDiagnosishuntingtons:Taskgrammar        -4.000e+01  1.123e+01  -3.560 0.001063\nDiagnosisamnesic:Taskclassification      2.000e+01  1.123e+01   1.780 0.083490\nDiagnosishuntingtons:Taskclassification -3.500e+01  1.123e+01  -3.115 0.003597\n                                           \n(Intercept)                             ***\nDiagnosisamnesic                        ***\nDiagnosishuntingtons                       \nTaskgrammar                             .  \nTaskclassification                      .  \nDiagnosisamnesic:Taskgrammar               \nDiagnosishuntingtons:Taskgrammar        ** \nDiagnosisamnesic:Taskclassification     .  \nDiagnosishuntingtons:Taskclassification ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.56 on 36 degrees of freedom\nMultiple R-squared:  0.7318,    Adjusted R-squared:  0.6722 \nF-statistic: 12.28 on 8 and 36 DF,  p-value: 2.844e-08\n\n\n\n\n\ntab_model(mdl_int,\n          dv.labels = \"Scores\",\n          pred.labels = c(\"Diagnosisamnesic\" = \"Diagnosis - Amnesic\",\n                          \"Diagnosishuntingtons\" = \"Diagnosis - Huntingtons\",\n                          \"Taskgrammar\" = \"Task - Grammar\",\n                          \"Taskclassification\" = \"Task - Classification\",\n                          \"Diagnosisamnesic:Taskgrammar\" = \"Diagnosis - Amnesic : Task - Grammar\",\n                          \"Diagnosishuntingtons:Taskgrammar\" = \"Diagnosis - Huntingtons : Task - Grammar\",\n                          \"Diagnosisamnesic:Taskclassification\" = \"Diagnosis - Amnesic : Task - Classification\",\n                          \"Diagnosishuntingtons:Taskclassification\" = \"Diagnosis - Huntingtons : Task - Classification\"),\n          title = \"Regression Table for Scores Model\")\n\n\n\nTable 2: Regression Table for Scores Model\n\n\n\n\n\n\n\n\n \nScores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n95.00\n83.61 – 106.39\n&lt;0.001\n\n\nDiagnosis - Amnesic\n-30.00\n-46.11 – -13.89\n0.001\n\n\nDiagnosis - Huntingtons\n0.00\n-16.11 – 16.11\n1.000\n\n\nTask - Grammar\n-15.00\n-31.11 – 1.11\n0.067\n\n\nTask - Classification\n-15.00\n-31.11 – 1.11\n0.067\n\n\nDiagnosis - Amnesic :\nTask - Grammar\n10.00\n-12.79 – 32.79\n0.379\n\n\nDiagnosis - Huntingtons :\nTask - Grammar\n-40.00\n-62.79 – -17.21\n0.001\n\n\nDiagnosis - Amnesic :\nTask - Classification\n20.00\n-2.79 – 42.79\n0.083\n\n\nDiagnosis - Huntingtons :\nTask - Classification\n-35.00\n-57.79 – -12.21\n0.004\n\n\nObservations\n45\n\n\nR2 / R2 adjusted\n0.732 / 0.672\n\n\n\n\n\n\n\n\n\n\n\nplt_cog_mdl &lt;- cat_plot(model = mdl_int, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl\n\n\n\nFigure 2: Interaction Plot\n\n\n\n\n\n\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2, and the interaction model is visually presented in Figure 2. The \\(F\\)-test for model utility was significant \\((F(8, 36) = 12.28, p &lt; .001)\\), and the model explained approximately 67% of the variability in Scores."
  },
  {
    "objectID": "2_04_simp_pair_broom.html#contrast-analysis",
    "href": "2_04_simp_pair_broom.html#contrast-analysis",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Contrast Analysis",
    "text": "Contrast Analysis\nLet’s move onto testing differences between specific group means.\n\nQuestion 5\n\n\nIn terms of the diagnostic groups, we want to compare the individuals with amnesia to those with Huntingtons. This corresponds to a contrast with coefficients of 0, 1, and −1, for control, amnesic, and Huntingtons, respectively.\nSimilarly, in terms of the tasks, we want to compare the average of the two implicit memory tasks with the explicit memory task. This corresponds to a contrast with coefficients of 0.5, 0.5, and −1 for the three tasks.\nWhen we are in presence of a significant interaction, the coefficients for a contrast between the means are found by multiplying each row coefficient with all column coefficients as shown below:\n\n\n\n\n\n\n\n\nSpecify the coefficients to be used in the contrast analysis, and present in a table.\nNext, formally state the contrast that the researchers were interested in as testable hypotheses.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the manual contrasts flashcards &gt; interaction models.\n\n\n\n\n\n\n\n Solution \n\n\nWe can specify the coefficients to be used in the contrast analysis in R using either:\n\n\nOption 1\nOption 2\n\n\n\n\ndiag_coef  &lt;- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  &lt;- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef &lt;- outer(diag_coef, task_coef)\ncontr_coef\n\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n\n\n\n\n\ndiag_coef  &lt;- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  &lt;- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef &lt;- diag_coef %o% task_coef\ncontr_coef\n\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n\n\n\n\n\nUsing either approach, we can then convert into a well-formatted table:\n\ncontr_coef |&gt; \n    kable(caption = \"Contrast Weights\") |&gt;\n    kable_styling(full_width = FALSE) \n\n\n\nTable 3: Contrast Weights\n\n\ngrammar\nclassification\nrecognition\n\n\n\ncontrol\n0.0\n0.0\n0\n\n\namnesic\n0.5\n0.5\n-1\n\n\nhuntingtons\n-0.5\n-0.5\n1\n\n\n\n\n\n\n\n\nThe above coefficients correspond to the following hypotheses:\n\\[\nH_0: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) = 0\n\\]\n\\[\nH_1: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) \\neq 0\n\\]\nwhich can be equivalently specified as:\n\\[\nH_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n\\]\n\\[  \nH_1: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad \\neq \\quad  \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n\\]\nboth statements state that, in the population, the difference between the mean implicit memory and the explicit memory score is the same for individuals with amnesia and Huntingtons.\nNote that the scores for the grammar and classification tasks have been averaged to obtain a single measure of ‘implicit memory’ score.\n\n\n\n\n\nQuestion 6\n\n\nFirstly, use emmeans() to obtain the estimated means and uncertainties for your factors.\nNext, specify the coefficients of the comparison and run the contrast analysis, obtaining 95% confidence intervals.\nReport the results of the contrast analysis in full.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the manual contrasts flashcards &gt; interaction models.\n\n\n\n\n\n\n\n Solution \n\n\nNow that we have the coefficients, let’s firstly call the emmeans function to get the estimated means of our groups (this is also helpful to look at the ordering of the groups):\n\ndiag_task_mean &lt;- emmeans(mdl_int, ~ Diagnosis*Task)\ndiag_task_mean\n\n Diagnosis   Task           emmean   SE df lower.CL upper.CL\n control     recognition        95 5.62 36     83.6    106.4\n amnesic     recognition        65 5.62 36     53.6     76.4\n huntingtons recognition        95 5.62 36     83.6    106.4\n control     grammar            80 5.62 36     68.6     91.4\n amnesic     grammar            60 5.62 36     48.6     71.4\n huntingtons grammar            40 5.62 36     28.6     51.4\n control     classification     80 5.62 36     68.6     91.4\n amnesic     classification     70 5.62 36     58.6     81.4\n huntingtons classification     45 5.62 36     33.6     56.4\n\nConfidence level used: 0.95 \n\n\nNext, from contr_coef, insert the coefficients following the order specified by the rows of diag_task_mean above. That is, the first one should be for control recognition and have a value of 0, the second for amnesic recognition with a value of -1, and so on…\nLet’s specify our weights, and give a name to this contrast (in this example ‘Research Hyp’):\n\ndiag_task_comp &lt;- contrast(diag_task_mean, \n                     method = list('Research Hyp' = c(0, -1, 1, 0, 0.5, -0.5, 0, 0.5, -0.5))\n                     )\n\nNext, let’s look at the output via one of two ways:\n\n\nOption 1\nOption 2\n\n\n\n\n#examine output\ndiag_task_comp\n\n contrast     estimate   SE df t.ratio p.value\n Research Hyp     52.5 9.73 36   5.396  &lt;.0001\n\n#obtain confidence intervals\nconfint(diag_task_comp)\n\n contrast     estimate   SE df lower.CL upper.CL\n Research Hyp     52.5 9.73 36     32.8     72.2\n\nConfidence level used: 0.95 \n\n\n\n\n\n#examine summary output and state `infer = TRUE` to include confidence intervals\nsummary(diag_task_comp, infer = TRUE)\n\n contrast     estimate   SE df lower.CL upper.CL t.ratio p.value\n Research Hyp     52.5 9.73 36     32.8     72.2   5.396  &lt;.0001\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n\n\n\n\nWe performed a test against \\(H_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\\). At the 5% significance level, there was evidence that individuals with Amnesia and Huntingtons did differ in the difference between implicit and explicit memory tasks \\((t(36) = 5.40, p &lt; .001, \\text{two-sided})\\), and this difference was estimated to be 52.50. We are 95% confident that the difference in implicit and explicit memory scores between individuals with Amnesia and Huntingtons was between 32.80 to 72.20 points. Therefore, we can reject the null hypothesis that the difference in differences was equal to zero."
  },
  {
    "objectID": "2_04_simp_pair_broom.html#simple-effects",
    "href": "2_04_simp_pair_broom.html#simple-effects",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Simple Effects",
    "text": "Simple Effects\n\nQuestion 7\n\n\nExamine the simple effects for Task at each level of Diagnosis; and then the simple effects for Diagnosis at each level of Task.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; categorical x categorical example &gt; simple effects flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nSimple Effects of Task\nSimple Effects of Diagnosis\n\n\n\nFrom mdl_int_simple1 we can see the differences between tasks for each diagnosis group:\n\nmdl_int_simple1 &lt;- pairs(diag_task_mean, simple = \"Task\")\nmdl_int_simple1\n\nDiagnosis = control:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              15 7.94 36   1.888  0.1567\n recognition - classification       15 7.94 36   1.888  0.1567\n grammar - classification            0 7.94 36   0.000  1.0000\n\nDiagnosis = amnesic:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar               5 7.94 36   0.629  0.8050\n recognition - classification       -5 7.94 36  -0.629  0.8050\n grammar - classification          -10 7.94 36  -1.259  0.4273\n\nDiagnosis = huntingtons:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              55 7.94 36   6.923  &lt;.0001\n recognition - classification       50 7.94 36   6.294  &lt;.0001\n grammar - classification           -5 7.94 36  -0.629  0.8050\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n\n\nFrom mdl_int_simple2 we can see the differences between diagnoses for each task group:\n\nmdl_int_simple2 &lt;- pairs(diag_task_mean, simple = \"Diagnosis\")\nmdl_int_simple2\n\nTask = recognition:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           30 7.94 36   3.776  0.0016\n control - huntingtons        0 7.94 36   0.000  1.0000\n amnesic - huntingtons      -30 7.94 36  -3.776  0.0016\n\nTask = grammar:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           20 7.94 36   2.518  0.0424\n control - huntingtons       40 7.94 36   5.035  &lt;.0001\n amnesic - huntingtons       20 7.94 36   2.518  0.0424\n\nTask = classification:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           10 7.94 36   1.259  0.4273\n control - huntingtons       35 7.94 36   4.406  0.0003\n amnesic - huntingtons       25 7.94 36   3.147  0.0091\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nVisualise the interaction, displaying two plots - one with Diagnosis on the x-axis, and the other with Task on the x-axis.\nConsidering the simple effects that you noted above, identify the significant effects and match them to the corresponding points of your interaction plot.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview and example, review the interaction models &gt; categorical x categorical example &gt; simple effects flashcards.\nRecall that the patchwork package allows us to arrange multiple plots using either / or | or +.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nSimple Effects of Task\nSimple Effects of Diagnosis\n\n\n\n\nplt_1 &lt;- emmip(mdl_int, Diagnosis ~ Task, CIs = TRUE)\nplt_1\n\n\n\n\n\n\n\nFor the simple effects of task (see plt_1), we saw the significant differences (those for which \\(p&lt;.05\\)):\n\nOnly in the Huntingtons group, between recognition & grammar and recognition & classification tasks\n\nleft-most blue point compared to the middle blue point, and then compared to the right-most blue point\n\n\n\n\n\n\nplt_2 &lt;- emmip(mdl_int, Task ~ Diagnosis, CIs = TRUE)\nplt_2\n\n\n\n\n\n\n\nFor the simple effects of Diagnosis (see plt_2), we saw significant differences (those for which \\(p&lt;.05\\)):\n\nin the recognition task, between control & amnesic\n\nleft-most red point to middle red point\n\n\nin the recognition task, between amnesic & huntingtons\n\nmiddle red-point to right-most red point\n\n\nin the grammar task, between control & amnesic\n\nleft-most green point to middle green point\n\n\nin the grammar task, between control & huntingtons\n\nleft-most green point to right-most green point\n\n\nin the grammar task, between amnesic & huntingtons\n\nmiddle green point to right-most green point\n\n\nin the classification task, between control & huntingtons\n\nleft-most blue point to right-most blue point\n\n\nin the classification task, between amnesic & huntingtons\n\nmiddle blue point to right-most blue point"
  },
  {
    "objectID": "2_04_simp_pair_broom.html#pairwise-comparisons-multiple-corrections",
    "href": "2_04_simp_pair_broom.html#pairwise-comparisons-multiple-corrections",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Pairwise Comparisons & Multiple Corrections",
    "text": "Pairwise Comparisons & Multiple Corrections\n\nQuestion 9\n\n\nConduct exploratory pairwise comparisons to compare all levels of Diagnosis with all levels of Task, applying no correction (note that Tukey will be automatically applied since we are comparing groups of means, so you will need to overwrite this).\nWithout adjusting our \\(\\alpha\\) (or \\(p\\)-value), why might any inferences drawn from your output be problematic?\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview, review the multiple comparisons flashcards.\n\n\n\n\n\n\n\n Solution \n\n\n\npairs_res &lt;- pairs(diag_task_mean, adjust = \"none\")\npairs_res\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0006\n  1.0000\n  0.0671\n  0.0001\n  &lt;.0001\n  0.0671\n  0.0033\n  &lt;.0001\n  0.0006\n  0.0671\n  0.5331\n  0.0033\n  0.0671\n  0.5331\n  0.0164\n  0.0671\n  0.0001\n  &lt;.0001\n  0.0671\n  0.0033\n  &lt;.0001\n  0.0164\n  &lt;.0001\n  1.0000\n  0.2162\n  0.0001\n  0.0164\n  0.0164\n  0.2162\n  0.0671\n  &lt;.0001\n  0.0006\n  0.5331\n  0.2162\n  0.0001\n  0.0033\n\n#can also plot if you'd like:\nplot(pairs_res)\n\n\n\n\n\n\n\nFrom the above, we can see comparisons for all different possible pairs of diagnosis-task combinations1.\nIn total, there are 9 different estimates, but comparing them all means that we have 36 comparisons being tested! By not adjusting our \\(p\\)-value, we are increasing the experiment-wise Type I error rate - we could wrongly reject the null hypothesis at a much higher rate than 5/100 (or 1/20 as is assumed when \\(\\alpha = .05\\)). To overcome this, we might adjust and determine a result to be statistically significant if \\(p &lt; .005\\), as opposed to \\(p &lt; .05\\), depending on how many tests are in our family of tests.\n\n\n\n\n\nQuestion 10\n\n\nSelect an appropriate method to adjust for multiple comparisons, and then obtain confidence intervals.\nComment on how these \\(p\\)-values differ from your raw (i.e., unadjusted) \\(p\\)-values.\n\n\n\n\n\n\nHint\n\n\n\n\n\nFor an overview, review the multiple comparisons flashcards.\n\n\n\n\n\n\n\n Solution \n\n\nNote what the functions in R do is adjust the \\(p\\)-value, rather than the \\(\\alpha\\).\nSince we’re interested in all pairwise comparisons of means, the Tukey adjustment might be a sensible approach. However, we’ll also show the Bonferroni to show how it differs (note, in practice you would only apply one correction and justify this choice based on your design - we are only applying two to note how they differ!)\n\n\nTukey\nBonferroni\n\n\n\n\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"Tukey\")\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0149\n  1.0000\n  0.6257\n  0.0026\n  &lt;.0001\n  0.6257\n  0.0711\n  &lt;.0001\n  0.0149\n  0.6257\n  0.9993\n  0.0711\n  0.6257\n  0.9993\n  0.2575\n  0.6257\n  0.0026\n  &lt;.0001\n  0.6257\n  0.0711\n  &lt;.0001\n  0.2575\n  0.0004\n  1.0000\n  0.9367\n  0.0026\n  0.2575\n  0.2575\n  0.9367\n  0.6257\n  0.0004\n  0.0149\n  0.9993\n  0.9367\n  0.0026\n  0.0711\n\nP value adjustment: tukey method for comparing a family of 9 estimates \n\n\nNote that 8 of the comparisons are no longer significant when using Tukey’s adjustment, suggesting that these might have been (when using no adjustment) Type I errors!\n\n\n\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"bonferroni\")\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  &lt;.0001\n  1.0000\n  0.1190\n  &lt;.0001\n  0.0207\n  1.0000\n  1.0000\n  0.1190\n  1.0000\n  1.0000\n  0.5907\n  1.0000\n  0.0033\n  &lt;.0001\n  1.0000\n  0.1190\n  &lt;.0001\n  0.5907\n  0.0005\n  1.0000\n  1.0000\n  0.0033\n  0.5907\n  0.5907\n  1.0000\n  1.0000\n  0.0005\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  0.1190\n\nP value adjustment: bonferroni method for 36 tests \n\n\nThe first Bonferroni adjusted \\(p\\)-value is 0.0207.\nThe raw (unadjusted) \\(p\\)-value from the previous question was 0.0005759265.\nThe Bonferroni method simply multiplies the ‘raw’ \\(p\\)-value by the number of the tests, which we know is 36.\n\n0.0005759265 * 36\n\n[1] 0.02073335\n\n\nIn terms of differences in Bonferroni to raw \\(p\\)-values, they are thus 36 times the size.\nOne benefit of Bonferroni is that it can be applied to any set of \\(p\\)-values, whereas Tukey only applies when comparing the means of levels of a factor. The downside, however, is that it may be overly conservative (i.e. reduce our power to detect an effect that is truly there)."
  },
  {
    "objectID": "2_04_simp_pair_broom.html#footnotes",
    "href": "2_04_simp_pair_broom.html#footnotes",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Footnotes",
    "text": "Footnotes\n\nthe differences between the group means for the comparison as labelled↩︎"
  },
  {
    "objectID": "2_05_writeup_recap3.html",
    "href": "2_05_writeup_recap3.html",
    "title": "Block 3 Analysis & Write-Up Example",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to write-up and provide interpretation of a 4x2 factorial ANOVA1\n\n\n\nBe up to date with lectures\nHave completed Labs Semester 2 Weeks 1-4\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nsjPlot\ninteractions\nemmeans\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/laptop_vs_longhand.csv"
  },
  {
    "objectID": "2_05_writeup_recap3.html#study-overview",
    "href": "2_05_writeup_recap3.html#study-overview",
    "title": "Block 3 Analysis & Write-Up Example",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Aim\nExplore the associations among study time and note-taking medium on test scores.\n\n\nResearch Questions\n\nRQ1: Do differences in test scores between study conditions differ by the note-taking medium used?\nRQ2: Are there differences in test scores between participants when comparing pairs of study and note-taking conditions? If so, what are these specific differences?\n\n\n\n Note Taking: Data Codebook\n\n\nDescription\nThe data used for this write-up exercise are simulated, drawing on a research paper that explored the association between student note taking, and performance when answering different types of questions. The simulated data are loosely based on the findings of this work, and acted to expand upon the methods and results reported in the paper:\nMueller, P. A., & Oppenheimer, D. M. (2014). The pen is mightier than the keyboard: Advantages of longhand over laptop note taking. Psychological Science, 25(6), 1159–1168. https://doi.org/10.1177/0956797614524581\nIn the current study, participants were invited to take part in a study investigating the the medium of note taking and study time on test scores. The sample comprised of 160 students who took notes on a lecture via one of two mediums - either on a laptop or longhand (i.e., using pen and paper). After watching the lecture and taking notes, they then randomly allocated to one of four study time conditions, either engaging in no, minimal, moderate, or extensive study of the notes taken on their assigned medium. After engaging in study for their allocated time, participants took a test on the lecture content. The test involved a series of questions, where participants could score a maximum of 100 points.\nData Dictionary\nThe data in laptop_vs_longhand.csv contain three attributes collected from a simulated sample of \\(n=160\\) hypothetical individuals, and includes:\n\n\n\n\n\n\n\nVariable\n      Description\n    \n\n\ntest_score\nTest Score (0-100)\n\n\nmedium\nMedium of note-taking (levels = Longhand, Laptop)\n\n\nstudy\nStudy time (levels = No, Minimal, Moderate, Extensive)\n\n\n\n\n\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\ntest_score\n      medium\n      study\n    \n\n\n47.47812\nLaptop\nNo\n\n\n50.41772\nLaptop\nNo\n\n\n49.88763\nLaptop\nNo\n\n\n48.47961\nLaptop\nNo\n\n\n48.44368\nLaptop\nNo\n\n\n48.02715\nLaptop\nNo\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the laptop_vs_longhand dataset into R, assigning it to an object named notes\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(psych) \nlibrary(kableExtra)\nlibrary(sjPlot)\nlibrary(interactions)\nlibrary(emmeans)\n\n#read in data\nnotes &lt;- read_csv(\"https://uoepsy.github.io/data/laptop_vs_longhand.csv\")\n\n\n\n\nAnalysis Code\nTry to answer the research question above without referring to the provided analysis code below, and then check how your script matches up - is there anything you missed or done differently? If so, discuss the differences with a tutor - there are lots of ways to code to the same solution!\n\n Provided Analysis Code\n\n\n\n######Step 1 is always to read in the data, then to explore, check, describe, and visualise it.\n\n#check coding of variables - are they coded as they should be?\nstr(notes)\n\nspc_tbl_ [160 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ test_score: num [1:160] 47.5 50.4 49.9 48.5 48.4 ...\n $ medium    : chr [1:160] \"Laptop\" \"Laptop\" \"Laptop\" \"Laptop\" ...\n $ study     : chr [1:160] \"No\" \"No\" \"No\" \"No\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   test_score = col_double(),\n  ..   medium = col_character(),\n  ..   study = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nhead(notes)\n\n# A tibble: 6 × 3\n  test_score medium study\n       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;\n1       47.5 Laptop No   \n2       50.4 Laptop No   \n3       49.9 Laptop No   \n4       48.5 Laptop No   \n5       48.4 Laptop No   \n6       48.0 Laptop No   \n\n#check for NAs - none in dataset, so no missing values\ntable(is.na(notes))\n\n\nFALSE \n  480 \n\n#make variables factors\nnotes &lt;- notes |&gt;\n    mutate(medium = as_factor(medium),\n           study = as_factor(study))\n\n#create descriptives table\ndescript &lt;- notes |&gt; \n    group_by(study, medium) |&gt;\n   summarise(\n       M_Score = round(mean(test_score), 2),\n       SD_Score = round(sd(test_score), 2),\n       SE_Score = round(sd(test_score)/sqrt(n()), 2),\n       Min_Score = round(min(test_score), 2),\n       Max_Score = round(max(test_score), 2)\n    )\ndescript\n\n# A tibble: 8 × 7\n# Groups:   study [4]\n  study     medium   M_Score SD_Score SE_Score Min_Score Max_Score\n  &lt;fct&gt;     &lt;fct&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 No        Laptop      48.1        2     0.45      44.9      51.2\n2 No        Longhand    51.0        2     0.45      48.0      54.9\n3 Minimal   Laptop      55.6        2     0.45      52.1      60.1\n4 Minimal   Longhand    60.9        2     0.45      57.8      65.3\n5 Moderate  Laptop      59.3        2     0.45      55.8      63.0\n6 Moderate  Longhand    80.7        2     0.45      76.3      84.6\n7 Extensive Laptop      61.2        2     0.45      56.9      64.3\n8 Extensive Longhand    90.6        2     0.45      86.8      94.3\n\n#boxplot\np1 &lt;- ggplot(data = notes, aes(x = study, y = test_score, color = medium)) + \n  geom_boxplot() + \n    ylim(0,100) +\n    labs(x = \"Study Condition\", y = \"Test Score\")\np1\n\n\n\n\n\n\n#plot showing the mean score for each condition\n# p2 is useful to notice that lines do not run in parallel - suggests interaction\np2 &lt;- ggplot(descript, aes(x = study, y = M_Score, color = medium)) + \n  geom_point(size = 3) +\n  geom_linerange(aes(ymin = M_Score - 2 * SE_Score, ymax = M_Score + 2 * SE_Score)) +\n  geom_path(aes(x = as.numeric(study)))\np2\n\n\n\n\n\n\n######Step 2 is to run your model(s) of interest to answer your research question, and make sure that the data meet the assumptions of your chosen test\n\n#set reference levels\nnotes$medium &lt;- fct_relevel(notes$medium , \"Longhand\")\nnotes$study &lt;- fct_relevel(notes$study , \"No\")\n\n#build model\nnotes_mdl &lt;- lm(test_score ~ study*medium, data = notes)\n\n#check assumptions - note should check diagnostics here too!\npar(mfrow=c(2,2))\nplot(notes_mdl)\n\n\n\n\n\n\npar(mfrow=c(1,1))\n\n# look at model output - summary()\nsummary(notes_mdl)\n\n\nCall:\nlm(formula = test_score ~ study * medium, data = notes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3485 -1.4764 -0.1018  1.4039  4.5321 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  51.0200     0.4472 114.084  &lt; 2e-16 ***\nstudyMinimal                  9.8900     0.6325  15.637  &lt; 2e-16 ***\nstudyModerate                29.6700     0.6325  46.912  &lt; 2e-16 ***\nstudyExtensive               39.5600     0.6325  62.550  &lt; 2e-16 ***\nmediumLaptop                 -2.9000     0.6325  -4.585 9.41e-06 ***\nstudyMinimal:mediumLaptop    -2.4400     0.8944  -2.728  0.00712 ** \nstudyModerate:mediumLaptop  -18.4900     0.8944 -20.672  &lt; 2e-16 ***\nstudyExtensive:mediumLaptop -26.5200     0.8944 -29.650  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2 on 152 degrees of freedom\nMultiple R-squared:  0.9803,    Adjusted R-squared:  0.9794 \nF-statistic:  1081 on 7 and 152 DF,  p-value: &lt; 2.2e-16\n\n#table results\ntab_model(notes_mdl, \n          pred.labels = c('Intercept', 'Study - Minimal', 'Study - Moderate', 'Study - Extensive', 'Medium - Laptop', 'Study - Minimal : Medium - Laptop', 'Study - Moderate : Medium - Laptop', 'Study - Extensive : Medium - Laptop'),\n          title = 'RQ1 - Regression Table for Total Scores Model')\n\n\nRQ1 - Regression Table for Total Scores Model\n\n\n \ntest score\n\n\nPredictors\nEstimates\nCI\np\n\n\nIntercept\n51.02\n50.14 – 51.90\n&lt;0.001\n\n\nStudy - Minimal\n9.89\n8.64 – 11.14\n&lt;0.001\n\n\nStudy - Moderate\n29.67\n28.42 – 30.92\n&lt;0.001\n\n\nStudy - Extensive\n39.56\n38.31 – 40.81\n&lt;0.001\n\n\nMedium - Laptop\n-2.90\n-4.15 – -1.65\n&lt;0.001\n\n\nStudy - Minimal : Medium - Laptop\n-2.44\n-4.21 – -0.67\n0.007\n\n\nStudy - Moderate : Medium - Laptop\n-18.49\n-20.26 – -16.72\n&lt;0.001\n\n\nStudy - Extensive : Medium - Laptop\n-26.52\n-28.29 – -24.75\n&lt;0.001\n\n\nObservations\n160\n\n\nR2 / R2 adjusted\n0.980 / 0.979\n\n\n\n\n#int model plot\nplt_notes_mdl &lt;- cat_plot(model = notes_mdl, \n                  pred = study, \n                  modx = medium, \n                  main.title = \"Scores across Study and Medium\",\n                  x.label = \"Study\",\n                  y.label = \"Score\",\n                  legend.main = \"Medium\")\nplt_notes_mdl\n\n\n\n\n\n\n#####Step 3 somewhat depends on the outcomes of step 2. Here, you may need to consider conducting further analyses before writing up / describing your results in relation to the research question. \n\n#Perform a pairwise comparison of the mean accuracy (as measured by points accrued) across the 2×2 factorial design, making sure to adjust for multiple comparisons. \n\nm1_emm &lt;- emmeans(notes_mdl, ~study*medium)\n\npairs_res &lt;- pairs(m1_emm)\npairs_res \n\n contrast                               estimate    SE  df t.ratio p.value\n No Longhand - Minimal Longhand            -9.89 0.632 152 -15.637  &lt;.0001\n No Longhand - Moderate Longhand          -29.67 0.632 152 -46.912  &lt;.0001\n No Longhand - Extensive Longhand         -39.56 0.632 152 -62.550  &lt;.0001\n No Longhand - No Laptop                    2.90 0.632 152   4.585  0.0002\n No Longhand - Minimal Laptop              -4.55 0.632 152  -7.194  &lt;.0001\n No Longhand - Moderate Laptop             -8.28 0.632 152 -13.092  &lt;.0001\n No Longhand - Extensive Laptop           -10.14 0.632 152 -16.033  &lt;.0001\n Minimal Longhand - Moderate Longhand     -19.78 0.632 152 -31.275  &lt;.0001\n Minimal Longhand - Extensive Longhand    -29.67 0.632 152 -46.912  &lt;.0001\n Minimal Longhand - No Laptop              12.79 0.632 152  20.223  &lt;.0001\n Minimal Longhand - Minimal Laptop          5.34 0.632 152   8.443  &lt;.0001\n Minimal Longhand - Moderate Laptop         1.61 0.632 152   2.546  0.1847\n Minimal Longhand - Extensive Laptop       -0.25 0.632 152  -0.395  0.9999\n Moderate Longhand - Extensive Longhand    -9.89 0.632 152 -15.637  &lt;.0001\n Moderate Longhand - No Laptop             32.57 0.632 152  51.498  &lt;.0001\n Moderate Longhand - Minimal Laptop        25.12 0.632 152  39.718  &lt;.0001\n Moderate Longhand - Moderate Laptop       21.39 0.632 152  33.821  &lt;.0001\n Moderate Longhand - Extensive Laptop      19.53 0.632 152  30.880  &lt;.0001\n Extensive Longhand - No Laptop            42.46 0.632 152  67.135  &lt;.0001\n Extensive Longhand - Minimal Laptop       35.01 0.632 152  55.356  &lt;.0001\n Extensive Longhand - Moderate Laptop      31.28 0.632 152  49.458  &lt;.0001\n Extensive Longhand - Extensive Laptop     29.42 0.632 152  46.517  &lt;.0001\n No Laptop - Minimal Laptop                -7.45 0.632 152 -11.779  &lt;.0001\n No Laptop - Moderate Laptop              -11.18 0.632 152 -17.677  &lt;.0001\n No Laptop - Extensive Laptop             -13.04 0.632 152 -20.618  &lt;.0001\n Minimal Laptop - Moderate Laptop          -3.73 0.632 152  -5.898  &lt;.0001\n Minimal Laptop - Extensive Laptop         -5.59 0.632 152  -8.839  &lt;.0001\n Moderate Laptop - Extensive Laptop        -1.86 0.632 152  -2.941  0.0717\n\nP value adjustment: tukey method for comparing a family of 8 estimates \n\n#plot\nplot(pairs_res)\n\n\n\n\n\n\n\n\n\n\nThe 3-Act Structure\nWe need to present our report in three clear sections - think of your sections like the 3 key parts of a play or story - we need to (1) provide some background and scene setting for the reader, (2) present our results in the context of the research question, and (3) present a resolution to our story - relate our findings back to the question we were asked and provide our answer.\nAct I: Analysis Strategy\n\nQuestion 1\n\n\nAttempt to draft an analysis strategy section based on the above research question and analysis provided.\n\n\n\n\n\n\n\n\n\nAnalysis Strategy - What to Include*\n\n\n\n\n\nYour analysis strategy will contain a number of different elements detailing plans and changes to your plan. Remember, your analysis strategy should not contain any results. You may wish to include the following sections:\n\nVery brief data and design description:\n\nGive the reader some background on the context of your write-up. For example, you may wish to describe the data source, data collection strategy, study design, number of observational units.\nSpecify the variables of interest in relation to the research question, including their unit of measurement, the allowed range (e.g., for Likert scales), and how they are scored. If you have categorical data, you will need to specify the levels and coding of your variables, and what was specified as your reference level and the justification for this choice.\n\n\nData management:\n\nDescribe any data cleaning and/or recoding.\nAre there any observations that have been excluded based on pre-defined criteria? How/why, and how many?\nDescribe any transformations performed to aid your interpretation (i.e., mean centering, standardisation, etc.)\n\n\nModel specification:\n\nClearly state your hypotheses and specify your chosen significance level.\nWhat type of statistical analysis do you plan to use to answer the research question? (e.g., simple linear regression, multiple linear regression, binary logistic regression, etc.)\nIn some cases, you may wish to include some visualisations and descriptive tables to motivate your model specification.\nSpecify the model(s) to be fitted to answer your given research question and analysis structure. Clearly specify the response and explanatory variables included in your model(s). This includes specifying the type of coding scheme applied if using categorical data.\n* Specify the assumption and diagnostic checks that you will conduct. Specify what plots you will use, and how you will evaluate these.\n\n\n\n\n*Note, given time constraints in lab, we have not included any reference to diagnostic checks in this write-up example - you would be expected to include this in your report. You can find more information on diagnostic checks in the S1 Week 9 Lab and S1 Week 9 Lectures.\n\nAs noted and encouraged throughout the course, one of the main benefits of using RMarkdown is the ability to include inline R code in your document. Try to incorporate this in your write up so you can automatically pull the specified values from your code. If you need a reminder on how to do this, see Lesson 3 of the Rmd Bootcamp.\n\n\n\n\nThe notes dataset contained information on 160 participants who took part in a study concerning the role(s) of note taking and study time on test scores. Participants took notes on a lecture via one of two mediums - either on a laptop \\((n = 80)\\) or long-hand using pen and paper \\((n = 80)\\). They were then randomly allocated to one of four study time conditions, either engaging in no \\((n = 40)\\), minimal \\((n = 40)\\), moderate \\((n = 40)\\), or extensive \\((n = 40)\\) study of the notes taken on their assigned medium. Participants then answered a series of questions based on the lecture content. The maximum score was 100, where higher scores reflected better test performance.\nThe aim of this report was to address the following two research questions:\n\nDo differences in test scores between study conditions differ by the note-taking medium used?\nAre there differences in test scores between participants when comparing pairs of study and note-taking conditions? If so, what are these specific differences?\n\nAll participant data was complete, and test scores within range i.e., 0-100. Categorical variables were coded as factors, and dummy coding applied where ‘No’ was designated as the reference level for study condition, and ‘Longhand’ as the reference level for medium.\nTo address RQ1 and investigate whether study condition (No, Minimal, Moderate, Extensive) and note-taking medium (Longhand, Laptop) interacted to influence test scores, the following 4 \\(\\times\\) 2 model specification was used:\n\\[\n\\begin{align}\n\\text{Test Score} &= \\beta_0  \\\\\n      &+ \\beta_1 \\cdot \\text{S}_\\text{Minimal} \\\\\n      &+ \\beta_2 \\cdot \\text{S}_\\text{Moderate} \\\\\n      &+ \\beta_3 \\cdot \\text{S}_\\text{Extensive} \\\\\n      &+ \\beta_4 \\cdot \\text{M}_\\text{Laptop} \\\\        \n      &+ \\beta_5 \\cdot  (\\text{S}_\\text{Minimal} \\cdot \\text{M}_\\text{Laptop})  \\\\\n      &+ \\beta_6 \\cdot  (\\text{S}_\\text{Moderate} \\cdot \\text{M}_\\text{Laptop})  \\\\\n      &+ \\beta_7 \\cdot  (\\text{S}_\\text{Extensive} \\cdot \\text{M}_\\text{Laptop})  \\\\\n      &+ \\epsilon  \n\\end{align}\n\\]\nwhere we tested whether there was a significant interaction between study condition and note-taking medium:\n\\[\nH_0: \\text{All}~~ \\beta_j = 0 ~\\text{(for j = 5, 6, 7)}\n\\]\n\\[\nH_1: \\text{At least one}~ \\beta_j \\neq \\text{(for j = 5, 6, 7)}\n\\]\nEffects were considered statistically significant at \\(\\alpha = .05\\). As we were using between-subjects datasets, we assumed independence of our error terms. We assumed linearity as all predictor variables were categorical. Equal variances was assessed via partial residual plots (residuals should be evenly spread across the range of fitted values, where the spread should be constant across the range of fitted values), and normality was assessed via a qqplot of the residuals (points should follow along the diagonal line).\nTo address RQ2 and explore if there are pairwise differences and determine which conditions significantly differed from each other, we will conduct a series of pairwise comparisons. Since we are interested in all pairwise comparisons of means, we will apply a Tukey correction.\n\n\n\nAct II: Results\n\nQuestion 2\n\n\nAttempt to draft a results section based on your detailed analysis strategy and the analysis provided.\n\n\n\n\n\n\n\n\n\nResults - What To Include*\n\n\n\n\n\nThe results section should follow from your analysis strategy. This is where you would present the evidence and results that will be used to answer the research questions and can support your conclusions. Make sure that you address all aspects of the approach you outlined in the analysis strategy (including the evaluation of assumptions and diagnostics).\nIn this section, it is useful to include tables and/or plots to clearly present your findings to your reader. It is important, however, to carefully select what is the key information that should be presented. You do not want to overload the reader with unnecessary or duplicate information (e.g., do not present print outs of the head of a dataset, or the same information in tables and plots, etc.), and you also want to save space in case there is a page limit. Make use of figures with multiple panels where you can. You can also make use of an Appendix to present your assumption and diagnostic* plots/tables, but remember that you must evaluate these in-text within the results section and clearly refer the reader to the relevant plots within the Appendix.\nAs a broad guideline, you want to start with the results of any exploratory data analysis, presenting tables of summary statistics and exploratory plots. You may also want to visualise associations between/among variables and report covariances or correlations. Then, you should move on to the results from your model.\n\n*Note, given time constraints in lab, we have not included any reference to diagnostic checks in this write-up example - you would be expected to include this in your report. You can find more information on diagnostic checks in the S1 Week 9 Lab and S1 Week 9 Lectures.\n\n\n\n\n\nDescriptive statistics are displayed in Table 1.\n\n\n\n\nTable 1: Descriptive Statistics\n\nstudy\nmedium\nM_Score\nSD_Score\nSE_Score\nMin_Score\nMax_Score\n\n\n\nNo\nLonghand\n51.02\n2\n0.45\n48.02\n54.92\n\n\nNo\nLaptop\n48.12\n2\n0.45\n44.86\n51.16\n\n\nMinimal\nLonghand\n60.91\n2\n0.45\n57.84\n65.29\n\n\nMinimal\nLaptop\n55.57\n2\n0.45\n52.07\n60.10\n\n\nModerate\nLonghand\n80.69\n2\n0.45\n76.34\n84.64\n\n\nModerate\nLaptop\n59.30\n2\n0.45\n55.77\n62.98\n\n\nExtensive\nLonghand\n90.58\n2\n0.45\n86.82\n94.32\n\n\nExtensive\nLaptop\n61.16\n2\n0.45\n56.93\n64.32\n\n\n\n\n\n\n\n\nIn the No and Minimal study conditions, there did not appear to be differences in test score between those using a laptop or longhand when note-taking. However, those in the longhand note-taking condition scored higher than those using laptops in the moderate and extensive study conditions. This suggested that there may be an interaction (see Figure 1).\n\n\n\n\nFigure 1: Association between Test Score and Medium / Study Conditions\n\n\n\nTest scores were analysed with a 4 (study: no vs minimal vs moderate vs extensive) \\(\\times\\) 2 (medium: longhand vs laptop) categorical interaction model.\nThe model met assumptions of linearity and independence (see Appendix A, top left panel of Figure 4; residuals were randomly scattered with a mean of zero and there was no clear dependence), homoscedasticity (see Appendix A, bottom left panel of Figure 4; there was a constant spread of residuals), and normality (see Appendix A, top right panel of Figure 4; the QQplot showed very little deviation from the diagonal line).\nThere was a significant interaction between study condition and note-taking medium \\(F(7, 152) = 1081, p &lt; . 001\\). Full regression results, including 95% Confidence Intervals, are shown in Table 2.\n\n\n\n\nTable 2: RQ1 - Regression Table for Total Scores Model\n\n\n \ntest score\n\n\nPredictors\nEstimates\nCI\np\n\n\nIntercept\n51.02\n50.14 – 51.90\n&lt;0.001\n\n\nStudy - Minimal\n9.89\n8.64 – 11.14\n&lt;0.001\n\n\nStudy - Moderate\n29.67\n28.42 – 30.92\n&lt;0.001\n\n\nStudy - Extensive\n39.56\n38.31 – 40.81\n&lt;0.001\n\n\nMedium - Laptop\n-2.90\n-4.15 – -1.65\n&lt;0.001\n\n\nStudy - Minimal : Medium - Laptop\n-2.44\n-4.21 – -0.67\n0.007\n\n\nStudy - Moderate : Medium - Laptop\n-18.49\n-20.26 – -16.72\n&lt;0.001\n\n\nStudy - Extensive : Medium - Laptop\n-26.52\n-28.29 – -24.75\n&lt;0.001\n\n\nObservations\n160\n\n\nR2 / R2 adjusted\n0.980 / 0.979\n\n\n\n\n\n\n\n\nAs displayed in Figure 2, results suggested that the difference in scores did differ significantly across the note-taking medium and study conditions, where scores differences appeared to get larger as the period of study increased (i.e., there was little difference between longhand and laptop note-taking conditions when participants engaged in no study, but the gap in test scores seemed to grow as the length of study time increased).\n\n\n\n\nFigure 2: Interaction Plot\n\n\n\nTo explore the interaction further, and address RQ2, pairwise comparisons were conducted. Tukey’s Honestly Significant Difference comparisons (see Figure 3) indicated that the vast majority of pairwise comparisons were statistically significant. There were only three pairs of comparisons that were not - those in the minimal longhand condition did not significantly differ from those in either the moderate laptop (95% CI [-0.33 - 3.55]) or extensive laptop (95% CI [-2.19 - 1.69]) conditions; and there was no difference between those in the laptop condition who studied either for a moderate or extensive period of time (95% CI [-3.80 - 0.08]). Overall, test differences appeared more pronounced when using the longhand note-taking medium across study conditions.\n\n\n\n\nFigure 3: Tukey HSD Pairwise Comparisons\n\n\n\n\n\n\nAct III: Discussion\n\nQuestion 3\n\n\nAttempt to draft a discussion section based on your results and the analysis provided.\n\n\n\n\n\n\n\n\n\nDiscussion - What To Include\n\n\n\n\n\nIn the discussion section, you should summarise the key findings from the results section and provide the reader with a few take-home sentences drawing the analysis together and relating it back to the original question.\nThe discussion should be relatively brief, and should not include any statistical analysis - instead think of the discussion as a conclusion, providing an answer to the research question(s).\n\n\n\n\nThe findings indicated that, in general, people who engaged in no study regardless of note-taking medium performed at chance level. Overall, participants who had taken notes with laptops performed worse on tests regardless of study time in comparison to those who took notes by hand. Our results led us to reject the null hypothesis, as the results indicated that the association between study condition and note-taking medium did interact to influence test scores. The direction of this association was somewhat surprising, as it suggested that laptop use can negatively influence performance on educational tests, and that engaging in hours of study is not enough to mitigate these effects.\n\n\n\nAssumptions & Diagnostics Appendix\n\nQuestion 4\n\n\nGiven that the report should be kept as concise as possible, you may wish to utilize the appendix to present assumption and diagnostic plots. You must however ensure that you have:\n\nDescribed what assumptions you will check in the analysis strategy, including how you will evaluate them.\nSummarized the evaluations of your assumptions and diagnostic checks in the results section of the main report.\nAccurately referred to the figures and tables labels presented in the appendix in the main report (if you don’t refer to them, the reader won’t know what they are relevant to!).\n\n\n\n\nAppendix A\n\n\n\n\nFigure 4: Assumption Plots"
  },
  {
    "objectID": "2_05_writeup_recap3.html#footnotes",
    "href": "2_05_writeup_recap3.html#footnotes",
    "title": "Block 3 Analysis & Write-Up Example",
    "section": "Footnotes",
    "text": "Footnotes\n\nA factorial ANOVA compares means across two or more independent variables (each with two or more levels) and their interaction.↩︎"
  },
  {
    "objectID": "2_05_writeup_recap3_fir.html",
    "href": "2_05_writeup_recap3_fir.html",
    "title": "Block 3 Analysis & Write-Up Example",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to write-up and provide interpretation of a 4x2 factorial ANOVA1\n\n\n\nBe up to date with lectures\nHave completed Labs Semester 2 Weeks 1-4\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nsjPlot\ninteractions\nemmeans\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/laptop_vs_longhand.csv"
  },
  {
    "objectID": "2_05_writeup_recap3_fir.html#study-overview",
    "href": "2_05_writeup_recap3_fir.html#study-overview",
    "title": "Block 3 Analysis & Write-Up Example",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Aim\nExplore the associations among study time and note-taking medium on test scores.\n\n\nResearch Questions\n\nRQ1: Do differences in test scores between study conditions differ by the note-taking medium used?\nRQ2: Are there differences in test scores between participants when comparing pairs of study and note-taking conditions? If so, what are these specific differences?\n\n\n\n Note Taking: Data Codebook\n\n\nDescription\nThe data used for this write-up exercise are simulated, drawing on a research paper that explored the association between student note taking, and performance when answering different types of questions. The simulated data are loosely based on the findings of this work, and acted to expand upon the methods and results reported in the paper:\nMueller, P. A., & Oppenheimer, D. M. (2014). The pen is mightier than the keyboard: Advantages of longhand over laptop note taking. Psychological Science, 25(6), 1159–1168. https://doi.org/10.1177/0956797614524581\nIn the current study, participants were invited to take part in a study investigating the the medium of note taking and study time on test scores. The sample comprised of 160 students who took notes on a lecture via one of two mediums - either on a laptop or longhand (i.e., using pen and paper). After watching the lecture and taking notes, they then randomly allocated to one of four study time conditions, either engaging in no, minimal, moderate, or extensive study of the notes taken on their assigned medium. After engaging in study for their allocated time, participants took a test on the lecture content. The test involved a series of questions, where participants could score a maximum of 100 points.\nData Dictionary\nThe data in laptop_vs_longhand.csv contain three attributes collected from a simulated sample of \\(n=160\\) hypothetical individuals, and includes:\n\n\n\n\n\n\n\nVariable\n      Description\n    \n\n\ntest_score\nTest Score (0-100)\n\n\nmedium\nMedium of note-taking (levels = Longhand, Laptop)\n\n\nstudy\nStudy time (levels = No, Minimal, Moderate, Extensive)\n\n\n\n\n\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\ntest_score\n      medium\n      study\n    \n\n\n47.47812\nLaptop\nNo\n\n\n50.41772\nLaptop\nNo\n\n\n49.88763\nLaptop\nNo\n\n\n48.47961\nLaptop\nNo\n\n\n48.44368\nLaptop\nNo\n\n\n48.02715\nLaptop\nNo\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the laptop_vs_longhand dataset into R, assigning it to an object named notes\n\n\n\n\n\n\n Solution \n\n\n\nlibrary(tidyverse)\nlibrary(psych) \nlibrary(kableExtra)\nlibrary(sjPlot)\nlibrary(interactions)\nlibrary(emmeans)\n\n#read in data\nnotes &lt;- read_csv(\"https://uoepsy.github.io/data/laptop_vs_longhand.csv\")\n\n\n\n\nAnalysis Code\nTry to answer the research question above without referring to the provided analysis code below, and then check how your script matches up - is there anything you missed or done differently? If so, discuss the differences with a tutor - there are lots of ways to code to the same solution!\n\n Provided Analysis Code\n\n\n\n######Step 1 is always to read in the data, then to explore, check, describe, and visualise it.\n\n#check coding of variables - are they coded as they should be?\nstr(notes)\n\nspc_tbl_ [160 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ test_score: num [1:160] 47.5 50.4 49.9 48.5 48.4 ...\n $ medium    : chr [1:160] \"Laptop\" \"Laptop\" \"Laptop\" \"Laptop\" ...\n $ study     : chr [1:160] \"No\" \"No\" \"No\" \"No\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   test_score = col_double(),\n  ..   medium = col_character(),\n  ..   study = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nhead(notes)\n\n# A tibble: 6 × 3\n  test_score medium study\n       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;\n1       47.5 Laptop No   \n2       50.4 Laptop No   \n3       49.9 Laptop No   \n4       48.5 Laptop No   \n5       48.4 Laptop No   \n6       48.0 Laptop No   \n\n#check for NAs - none in dataset, so no missing values\ntable(is.na(notes))\n\n\nFALSE \n  480 \n\n#make variables factors\nnotes &lt;- notes |&gt;\n    mutate(medium = as_factor(medium),\n           study = as_factor(study))\n\n#create descriptives table\ndescript &lt;- notes |&gt; \n    group_by(study, medium) |&gt;\n   summarise(\n       M_Score = round(mean(test_score), 2),\n       SD_Score = round(sd(test_score), 2),\n       SE_Score = round(sd(test_score)/sqrt(n()), 2),\n       Min_Score = round(min(test_score), 2),\n       Max_Score = round(max(test_score), 2)\n    )\ndescript\n\n# A tibble: 8 × 7\n# Groups:   study [4]\n  study     medium   M_Score SD_Score SE_Score Min_Score Max_Score\n  &lt;fct&gt;     &lt;fct&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 No        Laptop      48.1        2     0.45      44.9      51.2\n2 No        Longhand    51.0        2     0.45      48.0      54.9\n3 Minimal   Laptop      55.6        2     0.45      52.1      60.1\n4 Minimal   Longhand    60.9        2     0.45      57.8      65.3\n5 Moderate  Laptop      59.3        2     0.45      55.8      63.0\n6 Moderate  Longhand    80.7        2     0.45      76.3      84.6\n7 Extensive Laptop      61.2        2     0.45      56.9      64.3\n8 Extensive Longhand    90.6        2     0.45      86.8      94.3\n\n#boxplot\np1 &lt;- ggplot(data = notes, aes(x = study, y = test_score, color = medium)) + \n  geom_boxplot() + \n    ylim(0,100) +\n    labs(x = \"Study Condition\", y = \"Test Score\")\np1\n\n\n\n\n\n\n#plot showing the mean score for each condition\n# p2 is useful to notice that lines do not run in parallel - suggests interaction\np2 &lt;- ggplot(descript, aes(x = study, y = M_Score, color = medium)) + \n  geom_point(size = 3) +\n  geom_linerange(aes(ymin = M_Score - 2 * SE_Score, ymax = M_Score + 2 * SE_Score)) +\n  geom_path(aes(x = as.numeric(study)))\np2\n\n\n\n\n\n\n######Step 2 is to run your model(s) of interest to answer your research question, and make sure that the data meet the assumptions of your chosen test\n\n#set reference levels\nnotes$medium &lt;- fct_relevel(notes$medium , \"Longhand\")\nnotes$study &lt;- fct_relevel(notes$study , \"No\")\n\n#build model\nnotes_mdl &lt;- lm(test_score ~ study*medium, data = notes)\n\n#check assumptions - note should check diagnostics here too!\npar(mfrow=c(2,2))\nplot(notes_mdl)\n\n\n\n\n\n\npar(mfrow=c(1,1))\n\n# look at model output - summary()\nsummary(notes_mdl)\n\n\nCall:\nlm(formula = test_score ~ study * medium, data = notes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3485 -1.4764 -0.1018  1.4039  4.5321 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  51.0200     0.4472 114.084  &lt; 2e-16 ***\nstudyMinimal                  9.8900     0.6325  15.637  &lt; 2e-16 ***\nstudyModerate                29.6700     0.6325  46.912  &lt; 2e-16 ***\nstudyExtensive               39.5600     0.6325  62.550  &lt; 2e-16 ***\nmediumLaptop                 -2.9000     0.6325  -4.585 9.41e-06 ***\nstudyMinimal:mediumLaptop    -2.4400     0.8944  -2.728  0.00712 ** \nstudyModerate:mediumLaptop  -18.4900     0.8944 -20.672  &lt; 2e-16 ***\nstudyExtensive:mediumLaptop -26.5200     0.8944 -29.650  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2 on 152 degrees of freedom\nMultiple R-squared:  0.9803,    Adjusted R-squared:  0.9794 \nF-statistic:  1081 on 7 and 152 DF,  p-value: &lt; 2.2e-16\n\n#table results\ntab_model(notes_mdl, \n          pred.labels = c('Intercept', 'Study - Minimal', 'Study - Moderate', 'Study - Extensive', 'Medium - Laptop', 'Study - Minimal : Medium - Laptop', 'Study - Moderate : Medium - Laptop', 'Study - Extensive : Medium - Laptop'),\n          title = 'RQ1 - Regression Table for Total Scores Model')\n\n\nRQ1 - Regression Table for Total Scores Model\n\n\n \ntest score\n\n\nPredictors\nEstimates\nCI\np\n\n\nIntercept\n51.02\n50.14 – 51.90\n&lt;0.001\n\n\nStudy - Minimal\n9.89\n8.64 – 11.14\n&lt;0.001\n\n\nStudy - Moderate\n29.67\n28.42 – 30.92\n&lt;0.001\n\n\nStudy - Extensive\n39.56\n38.31 – 40.81\n&lt;0.001\n\n\nMedium - Laptop\n-2.90\n-4.15 – -1.65\n&lt;0.001\n\n\nStudy - Minimal : Medium - Laptop\n-2.44\n-4.21 – -0.67\n0.007\n\n\nStudy - Moderate : Medium - Laptop\n-18.49\n-20.26 – -16.72\n&lt;0.001\n\n\nStudy - Extensive : Medium - Laptop\n-26.52\n-28.29 – -24.75\n&lt;0.001\n\n\nObservations\n160\n\n\nR2 / R2 adjusted\n0.980 / 0.979\n\n\n\n\n#int model plot\nplt_notes_mdl &lt;- cat_plot(model = notes_mdl, \n                  pred = study, \n                  modx = medium, \n                  main.title = \"Scores across Study and Medium\",\n                  x.label = \"Study\",\n                  y.label = \"Score\",\n                  legend.main = \"Medium\")\nplt_notes_mdl\n\n\n\n\n\n\n#####Step 3 somewhat depends on the outcomes of step 2. Here, you may need to consider conducting further analyses before writing up / describing your results in relation to the research question. \n\n#Perform a pairwise comparison of the mean accuracy (as measured by points accrued) across the 2×2 factorial design, making sure to adjust for multiple comparisons. \n\nm1_emm &lt;- emmeans(notes_mdl, ~study*medium)\n\npairs_res &lt;- pairs(m1_emm)\npairs_res \n\n contrast                               estimate    SE  df t.ratio p.value\n No Longhand - Minimal Longhand            -9.89 0.632 152 -15.637  &lt;.0001\n No Longhand - Moderate Longhand          -29.67 0.632 152 -46.912  &lt;.0001\n No Longhand - Extensive Longhand         -39.56 0.632 152 -62.550  &lt;.0001\n No Longhand - No Laptop                    2.90 0.632 152   4.585  0.0002\n No Longhand - Minimal Laptop              -4.55 0.632 152  -7.194  &lt;.0001\n No Longhand - Moderate Laptop             -8.28 0.632 152 -13.092  &lt;.0001\n No Longhand - Extensive Laptop           -10.14 0.632 152 -16.033  &lt;.0001\n Minimal Longhand - Moderate Longhand     -19.78 0.632 152 -31.275  &lt;.0001\n Minimal Longhand - Extensive Longhand    -29.67 0.632 152 -46.912  &lt;.0001\n Minimal Longhand - No Laptop              12.79 0.632 152  20.223  &lt;.0001\n Minimal Longhand - Minimal Laptop          5.34 0.632 152   8.443  &lt;.0001\n Minimal Longhand - Moderate Laptop         1.61 0.632 152   2.546  0.1847\n Minimal Longhand - Extensive Laptop       -0.25 0.632 152  -0.395  0.9999\n Moderate Longhand - Extensive Longhand    -9.89 0.632 152 -15.637  &lt;.0001\n Moderate Longhand - No Laptop             32.57 0.632 152  51.498  &lt;.0001\n Moderate Longhand - Minimal Laptop        25.12 0.632 152  39.718  &lt;.0001\n Moderate Longhand - Moderate Laptop       21.39 0.632 152  33.821  &lt;.0001\n Moderate Longhand - Extensive Laptop      19.53 0.632 152  30.880  &lt;.0001\n Extensive Longhand - No Laptop            42.46 0.632 152  67.135  &lt;.0001\n Extensive Longhand - Minimal Laptop       35.01 0.632 152  55.356  &lt;.0001\n Extensive Longhand - Moderate Laptop      31.28 0.632 152  49.458  &lt;.0001\n Extensive Longhand - Extensive Laptop     29.42 0.632 152  46.517  &lt;.0001\n No Laptop - Minimal Laptop                -7.45 0.632 152 -11.779  &lt;.0001\n No Laptop - Moderate Laptop              -11.18 0.632 152 -17.677  &lt;.0001\n No Laptop - Extensive Laptop             -13.04 0.632 152 -20.618  &lt;.0001\n Minimal Laptop - Moderate Laptop          -3.73 0.632 152  -5.898  &lt;.0001\n Minimal Laptop - Extensive Laptop         -5.59 0.632 152  -8.839  &lt;.0001\n Moderate Laptop - Extensive Laptop        -1.86 0.632 152  -2.941  0.0717\n\nP value adjustment: tukey method for comparing a family of 8 estimates \n\n#plot\nplot(pairs_res)\n\n\n\n\n\n\n\n\n\n\nThe 3-Act Structure\nWe need to present our report in three clear sections - think of your sections like the 3 key parts of a play or story - we need to (1) provide some background and scene setting for the reader, (2) present our results in the context of the research question, and (3) present a resolution to our story - relate our findings back to the question we were asked and provide our answer.\nAct I: Analysis Strategy\n\nQuestion 1\n\n\nAttempt to draft an analysis strategy section based on the above research question and analysis provided.\n\n\n\n\n\n\n\n\n\nAnalysis Strategy - What to Include*\n\n\n\n\n\nYour analysis strategy will contain a number of different elements detailing plans and changes to your plan. Remember, your analysis strategy should not contain any results. You may wish to include the following sections:\n\nVery brief data and design description:\n\nGive the reader some background on the context of your write-up. For example, you may wish to describe the data source, data collection strategy, study design, number of observational units.\nSpecify the variables of interest in relation to the research question, including their unit of measurement, the allowed range (e.g., for Likert scales), and how they are scored. If you have categorical data, you will need to specify the levels and coding of your variables, and what was specified as your reference level and the justification for this choice.\n\n\nData management:\n\nDescribe any data cleaning and/or recoding.\nAre there any observations that have been excluded based on pre-defined criteria? How/why, and how many?\nDescribe any transformations performed to aid your interpretation (i.e., mean centering, standardisation, etc.)\n\n\nModel specification:\n\nClearly state your hypotheses and specify your chosen significance level.\nWhat type of statistical analysis do you plan to use to answer the research question? (e.g., simple linear regression, multiple linear regression, binary logistic regression, etc.)\nIn some cases, you may wish to include some visualisations and descriptive tables to motivate your model specification.\nSpecify the model(s) to be fitted to answer your given research question and analysis structure. Clearly specify the response and explanatory variables included in your model(s). This includes specifying the type of coding scheme applied if using categorical data.\n* Specify the assumption and diagnostic checks that you will conduct. Specify what plots you will use, and how you will evaluate these.\n\n\n\n\n*Note, given time constraints in lab, we have not included any reference to diagnostic checks in this write-up example - you would be expected to include this in your report. You can find more information on diagnostic checks in the S1 Week 9 Lab and S1 Week 9 Lectures.\n\nAs noted and encouraged throughout the course, one of the main benefits of using RMarkdown is the ability to include inline R code in your document. Try to incorporate this in your write up so you can automatically pull the specified values from your code. If you need a reminder on how to do this, see Lesson 3 of the Rmd Bootcamp.\n\n\n\n\n Solution : Example Write-Up of Analysis Strategy Section\n\n\nThe notes dataset contained information on 160 participants who took part in a study concerning the role(s) of note taking and study time on test scores. Participants took notes on a lecture via one of two mediums - either on a laptop \\((n = 80)\\) or long-hand using pen and paper \\((n = 80)\\). They were then randomly allocated to one of four study time conditions, either engaging in no \\((n = 40)\\), minimal \\((n = 40)\\), moderate \\((n = 40)\\), or extensive \\((n = 40)\\) study of the notes taken on their assigned medium. Participants then answered a series of questions based on the lecture content. The maximum score was 100, where higher scores reflected better test performance.\nThe aim of this report was to address the following two research questions:\n\nDo differences in test scores between study conditions differ by the note-taking medium used?\nAre there differences in test scores between participants when comparing pairs of study and note-taking conditions? If so, what are these specific differences?\n\nAll participant data was complete, and test scores within range i.e., 0-100. Categorical variables were coded as factors, and dummy coding applied where ‘No’ was designated as the reference level for study condition, and ‘Longhand’ as the reference level for medium.\nTo address RQ1 and investigate whether study condition (No, Minimal, Moderate, Extensive) and note-taking medium (Longhand, Laptop) interacted to influence test scores, the following 4 \\(\\times\\) 2 model specification was used:\n\\[\n\\begin{align}\n\\text{Test Score} &= \\beta_0  \\\\\n      &+ \\beta_1 \\cdot \\text{S}_\\text{Minimal} \\\\\n      &+ \\beta_2 \\cdot \\text{S}_\\text{Moderate} \\\\\n      &+ \\beta_3 \\cdot \\text{S}_\\text{Extensive} \\\\\n      &+ \\beta_4 \\cdot \\text{M}_\\text{Laptop} \\\\        \n      &+ \\beta_5 \\cdot  (\\text{S}_\\text{Minimal} \\cdot \\text{M}_\\text{Laptop})  \\\\\n      &+ \\beta_6 \\cdot  (\\text{S}_\\text{Moderate} \\cdot \\text{M}_\\text{Laptop})  \\\\\n      &+ \\beta_7 \\cdot  (\\text{S}_\\text{Extensive} \\cdot \\text{M}_\\text{Laptop})  \\\\\n      &+ \\epsilon  \n\\end{align}\n\\]\nwhere we tested whether there was a significant interaction between study condition and note-taking medium:\n\\[\nH_0: \\text{All}~~ \\beta_j = 0 ~\\text{(for j = 5, 6, 7)}\n\\]\n\\[\nH_1: \\text{At least one}~ \\beta_j \\neq \\text{(for j = 5, 6, 7)}\n\\]\nEffects were considered statistically significant at \\(\\alpha = .05\\). As we were using between-subjects datasets, we assumed independence of our error terms. We assumed linearity as all predictor variables were categorical. Equal variances was assessed via partial residual plots (residuals should be evenly spread across the range of fitted values, where the spread should be constant across the range of fitted values), and normality was assessed via a qqplot of the residuals (points should follow along the diagonal line).\nTo address RQ2 and explore if there are pairwise differences and determine which conditions significantly differed from each other, we will conduct a series of pairwise comparisons. Since we are interested in all pairwise comparisons of means, we will apply a Tukey correction.\n\n\n\nAct II: Results\n\nQuestion 2\n\n\nAttempt to draft a results section based on your detailed analysis strategy and the analysis provided.\n\n\n\n\n\n\n\n\n\nResults - What To Include*\n\n\n\n\n\nThe results section should follow from your analysis strategy. This is where you would present the evidence and results that will be used to answer the research questions and can support your conclusions. Make sure that you address all aspects of the approach you outlined in the analysis strategy (including the evaluation of assumptions and diagnostics).\nIn this section, it is useful to include tables and/or plots to clearly present your findings to your reader. It is important, however, to carefully select what is the key information that should be presented. You do not want to overload the reader with unnecessary or duplicate information (e.g., do not present print outs of the head of a dataset, or the same information in tables and plots, etc.), and you also want to save space in case there is a page limit. Make use of figures with multiple panels where you can. You can also make use of an Appendix to present your assumption and diagnostic* plots/tables, but remember that you must evaluate these in-text within the results section and clearly refer the reader to the relevant plots within the Appendix.\nAs a broad guideline, you want to start with the results of any exploratory data analysis, presenting tables of summary statistics and exploratory plots. You may also want to visualise associations between/among variables and report covariances or correlations. Then, you should move on to the results from your model.\n\n*Note, given time constraints in lab, we have not included any reference to diagnostic checks in this write-up example - you would be expected to include this in your report. You can find more information on diagnostic checks in the S1 Week 9 Lab and S1 Week 9 Lectures.\n\n\n\n\n\n Solution : Example Write-Up of Results Section\n\n\nDescriptive statistics are displayed in Table 1.\n\n\n\n\nTable 1: Descriptive Statistics\n\nstudy\nmedium\nM_Score\nSD_Score\nSE_Score\nMin_Score\nMax_Score\n\n\n\nNo\nLonghand\n51.02\n2\n0.45\n48.02\n54.92\n\n\nNo\nLaptop\n48.12\n2\n0.45\n44.86\n51.16\n\n\nMinimal\nLonghand\n60.91\n2\n0.45\n57.84\n65.29\n\n\nMinimal\nLaptop\n55.57\n2\n0.45\n52.07\n60.10\n\n\nModerate\nLonghand\n80.69\n2\n0.45\n76.34\n84.64\n\n\nModerate\nLaptop\n59.30\n2\n0.45\n55.77\n62.98\n\n\nExtensive\nLonghand\n90.58\n2\n0.45\n86.82\n94.32\n\n\nExtensive\nLaptop\n61.16\n2\n0.45\n56.93\n64.32\n\n\n\n\n\n\n\n\nIn the No and Minimal study conditions, there did not appear to be differences in test score between those using a laptop or longhand when note-taking. However, those in the longhand note-taking condition scored higher than those using laptops in the moderate and extensive study conditions. This suggested that there may be an interaction (see Figure 1).\n\n\n\n\nFigure 1: Association between Test Score and Medium / Study Conditions\n\n\n\nTest scores were analysed with a 4 (study: no vs minimal vs moderate vs extensive) \\(\\times\\) 2 (medium: longhand vs laptop) categorical interaction model.\nThe model met assumptions of linearity and independence (see Appendix A, top left panel of Figure 4; residuals were randomly scattered with a mean of zero and there was no clear dependence), homoscedasticity (see Appendix A, bottom left panel of Figure 4; there was a constant spread of residuals), and normality (see Appendix A, top right panel of Figure 4; the QQplot showed very little deviation from the diagonal line).\nThere was a significant interaction between study condition and note-taking medium \\(F(7, 152) = 1081, p &lt; . 001\\). Full regression results, including 95% Confidence Intervals, are shown in Table 2.\n\n\n\n\nTable 2: RQ1 - Regression Table for Total Scores Model\n\n\n \ntest score\n\n\nPredictors\nEstimates\nCI\np\n\n\nIntercept\n51.02\n50.14 – 51.90\n&lt;0.001\n\n\nStudy - Minimal\n9.89\n8.64 – 11.14\n&lt;0.001\n\n\nStudy - Moderate\n29.67\n28.42 – 30.92\n&lt;0.001\n\n\nStudy - Extensive\n39.56\n38.31 – 40.81\n&lt;0.001\n\n\nMedium - Laptop\n-2.90\n-4.15 – -1.65\n&lt;0.001\n\n\nStudy - Minimal : Medium - Laptop\n-2.44\n-4.21 – -0.67\n0.007\n\n\nStudy - Moderate : Medium - Laptop\n-18.49\n-20.26 – -16.72\n&lt;0.001\n\n\nStudy - Extensive : Medium - Laptop\n-26.52\n-28.29 – -24.75\n&lt;0.001\n\n\nObservations\n160\n\n\nR2 / R2 adjusted\n0.980 / 0.979\n\n\n\n\n\n\n\n\nAs displayed in Figure 2, results suggested that the difference in scores did differ significantly across the note-taking medium and study conditions, where scores differences appeared to get larger as the period of study increased (i.e., there was little difference between longhand and laptop note-taking conditions when participants engaged in no study, but the gap in test scores seemed to grow as the length of study time increased).\n\n\n\n\nFigure 2: Interaction Plot\n\n\n\nTo explore the interaction further, and address RQ2, pairwise comparisons were conducted. Tukey’s Honestly Significant Difference comparisons (see Figure 3) indicated that the vast majority of pairwise comparisons were statistically significant. There were only three pairs of comparisons that were not - those in the minimal longhand condition did not significantly differ from those in either the moderate laptop (95% CI [-0.33 - 3.55]) or extensive laptop (95% CI [-2.19 - 1.69]) conditions; and there was no difference between those in the laptop condition who studied either for a moderate or extensive period of time (95% CI [-3.80 - 0.08]). Overall, test differences appeared more pronounced when using the longhand note-taking medium across study conditions.\n\n\n\n\nFigure 3: Tukey HSD Pairwise Comparisons\n\n\n\n\n\n\nAct III: Discussion\n\nQuestion 3\n\n\nAttempt to draft a discussion section based on your results and the analysis provided.\n\n\n\n\n\n\n\n\n\nDiscussion - What To Include\n\n\n\n\n\nIn the discussion section, you should summarise the key findings from the results section and provide the reader with a few take-home sentences drawing the analysis together and relating it back to the original question.\nThe discussion should be relatively brief, and should not include any statistical analysis - instead think of the discussion as a conclusion, providing an answer to the research question(s).\n\n\n\n\n Solution : Example Write-Up of Discussion Section\n\n\nThe findings indicated that, in general, people who engaged in no study regardless of note-taking medium performed at chance level. Overall, participants who had taken notes with laptops performed worse on tests regardless of study time in comparison to those who took notes by hand. Our results led us to reject the null hypothesis, as the results indicated that the association between study condition and note-taking medium did interact to influence test scores. The direction of this association was somewhat surprising, as it suggested that laptop use can negatively influence performance on educational tests, and that engaging in hours of study is not enough to mitigate these effects.\n\n\n\nAssumptions & Diagnostics Appendix\n\nQuestion 4\n\n\nGiven that the report should be kept as concise as possible, you may wish to utilize the appendix to present assumption and diagnostic plots. You must however ensure that you have:\n\nDescribed what assumptions you will check in the analysis strategy, including how you will evaluate them.\nSummarized the evaluations of your assumptions and diagnostic checks in the results section of the main report.\nAccurately referred to the figures and tables labels presented in the appendix in the main report (if you don’t refer to them, the reader won’t know what they are relevant to!).\n\n\n\n\n\n Solution : Example Assumptions & Diagnostics Appendix\n\n\nAppendix A\n\n\n\n\nFigure 4: Assumption Plots"
  },
  {
    "objectID": "2_05_writeup_recap3_fir.html#footnotes",
    "href": "2_05_writeup_recap3_fir.html#footnotes",
    "title": "Block 3 Analysis & Write-Up Example",
    "section": "Footnotes",
    "text": "Footnotes\n\nA factorial ANOVA compares means across two or more independent variables (each with two or more levels) and their interaction.↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Dr Umberto Noe\nDr Josiah King\nDr Emma Waterston\nDepartment of Psychology, The University of Edinburgh"
  },
  {
    "objectID": "about.html#the-team",
    "href": "about.html#the-team",
    "title": "About",
    "section": "",
    "text": "Dr Umberto Noe\nDr Josiah King\nDr Emma Waterston\nDepartment of Psychology, The University of Edinburgh"
  },
  {
    "objectID": "csstests.html",
    "href": "csstests.html",
    "title": "Tests",
    "section": "",
    "text": "learning obj\n\n\nimportant\n\n\nsticky\n\n\n\n\n\nr tips\n\n\nstatbox\n\n\ninterprtation interprtation interprtation\n\n\nQuestion\n\n\nquestion\nwhat is your name?\nwhat is your favourite colour?\n\n\n\n\n Solution \n\n\nsolution\nhello\n\n2+2\n\n[1] 4\n\n\n\n\n\n\n Optional hello my optional friend\n\n\nit’s nice to see you again\n\n\n\n\n\nthis is not a panel\n\n\nthis is a panel\n\n\nthis is a panel"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to the Data Analysis for Psychology in R 2 (DAPR2) lab workbook. Using the menu on the left, you can find lab materials for each week."
  },
  {
    "objectID": "index.html#group-work",
    "href": "index.html#group-work",
    "title": "Home",
    "section": "Group Work",
    "text": "Group Work\nYou are expected to work through the lab tasks in groups of up to 6 students. You can either:\n\nOption 1: work independently on your own device and discuss lab exercises with your fellow group members.\nOption 2: follow a similar structure as you did in DAPR1 where in each group, one person is the driver and the rest are navigators (each week the driver must rotate so that everyone experiences being a driver at least once). Please note that as you will be using a local version of R and RStudio, you will need to share the file with your group members each week. If you select this option, the roles are defined as follows - drivers are responsible for typing the code and written solutions for their designated week, and sharing the resulting RMarkdown file with the group via the Learn group discussion space or via email; and navigators are responsible for suggesting and commenting on the code, spotting typos, fixing errors, and generating the text-based solutions."
  },
  {
    "objectID": "index.html#help-support-feedback",
    "href": "index.html#help-support-feedback",
    "title": "Home",
    "section": "Help, Support & Feedback",
    "text": "Help, Support & Feedback\n\nWithin Lab Workbook\n\nHints, Notes, and Example Write-Up / Interpretation\nHints are shown in a green box, with the title ‘Hint’. If you are unsure what to do, check the collapsible hint provided.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is an example of a hint. They will usually link you to the course flashcards page that we will build on as we progress throughout the course.\n\n\n\nNotes are displayed in blue boxes, with the title ‘Note’. These are occasionally used to draw your attention to a specific point.\n\n\n\n\n\n\nNote\n\n\n\nThis is an example of a note.\n\n\nExample write-ups and/or interpretations are shown with a red right border. These are helpful to check your interpretation against, and a useful guide to use in future when interpreting and/or writing up results.\n\n\n\n\n\n\nThis is an example write-up / interpretation block.\n\n\n\n\n\nFlashcards\nThe purpose of the flashcards is to complement your core learning materials i.e., your lecture and lab materials, by offering additional guidance and examples on key concepts/topics. They are designed to deepen your understanding, clarify complex concepts, and help you make connections between different areas of study. Think of it as an extra resource that supports what you’re learning in the classroom.\nYou may want to consider using these as a supporting document whilst your work through lab exercises, and/or refer to in order to aid revision.\n\n\nSolutions\nSolutions are made available each Friday (usually around 12 noon). To view solutions, click the drop down ‘Solution’ button within the lab sheet.\nImportant  Before checking the solution you should review the lecture slides and lab hints. You should also avoid copying and pasting code from previous solutions.\nInstead, you should:\n\nTry to figure out the answer yourself in collaboration with your peers (and/or ask for help from a staff member if needed).\nType the code out yourself if adapting from previous exercises (and annotate your R code chunks so you know what your code is doing & why - future you will thank you for this).\n\n\n\n\nAsking Questions\n\nDuring labs, if you have a question, please ask one of the Tutors for support.\nOutside of labs, we encourage you to use the various support options, details of which can be found on the course Learn page."
  },
  {
    "objectID": "index.html#feedback-on-labs",
    "href": "index.html#feedback-on-labs",
    "title": "Home",
    "section": "Feedback on Labs",
    "text": "Feedback on Labs\nIf you wish to make suggestions for improvements to these workbooks (or if you spot any typos!), please email ppls.psych.stats@ed.ac.uk making sure to include the course name in the subject."
  }
]