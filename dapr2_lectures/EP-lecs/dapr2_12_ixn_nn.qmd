---
title: "Numeric/numeric interactions"
editor_options: 
  chunk_output_type: console
format:
  revealjs:
    smaller: true
---

```{r}
#| label: setup
#| include: false
library(tidyverse)
library(interactions)  # for probe_interactions() plot
dapr2red <- "#BF1932" 

theme_set(
  theme_minimal(
    base_size = 28
  )
)

outdoors <- read_csv("data/salary2.csv", show_col_types = FALSE) |>
  rename(
    wellbeing = salary,
    outdoor_time = serv,
    hrs_sun = perf  # hrs sun in a day
  )

palette_probe <- c('#4ab8fc', '#ff7b01')
```



# Course Overview

<br>

:::: {.columns}

::: {.column width="50%"}

```{r echo = FALSE, results='asis', warning = FALSE}
block1_name = "Introduction to linear Models"
block1_lecs = c("Intro to linear regression",
                "Interpreting linear models",
                "Testing individual predictors",
                "Model testing & comparison",
                "Linear model analysis")
block2_name = "Analysing Experimental Studies"
block2_lecs = c("Categorical predictors and dummy coding",
                "Effect coding and manual post-hoc contrasts",
                "Assumptions and diagnostics",
                "Bootstrapping and confidence intervals",
                "Categorical predictors: Practice analysis")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")

course_table(block1_name,block2_name,block1_lecs,block2_lecs,week = 0)
```

:::

::: {.column width="50%"}

```{r echo = FALSE, results='asis', warning = FALSE}
block3_name = "Interactions"
block3_lecs = c("Mean-centering and numeric/categorical interactions",
                "Numeric/numeric interactions",
                "Categorical/categorical interactions",
                "Manual contrast interactions and multiple comparisons",
                "Interactions: Practice analysis")
block4_name = "Advanced Topics"
block4_lecs = c("Power analysis",
                "Binary logistic regression I",
                "Binary logistic regression II",
                "Logistic regression: Practice analysis",
                "Exam prep and course Q&A")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")

course_table(block3_name,block4_name,block3_lecs,block4_lecs,week = 2)
```

:::

::::


## This week's learning objectives

<br>

::::: {style="font-size: 125%;"}

::: {.dapr2callout .fragment}
How do we specify an interaction between two numeric predictors?
:::

::: {.dapr2callout .fragment}
What does it mean when we say "interactions are symmetrical"?
:::

::: {.dapr2callout .fragment}
What is a simple slope?
:::

::: {.dapr2callout .fragment}
When we have an interaction between two numeric predictors, what values do we typically use to compute simple slopes?
:::

:::::


## Where we are in the analysis plan today

![](figs/block3-flowchart-03.svg){height="925" fig-align="center"}


## What's an interaction again?

An interaction is how we allow a model to estimate that **the association between one predictor and the outcome is different, _depending on_ the value of another predictor**.

![](figs/depends-on-11.svg){fig-align="center"}


## Today's data


<br>

:::: {.columns}
::: {.column width="60%"}
```{r echo=F, fig.align = 'center', fig.dim = c(10, 8)}
outdoors |>
  mutate() |>
  ggplot(aes(x = outdoor_time, y = wellbeing, colour = hrs_sun, size = hrs_sun)) +
  geom_point() +
  scale_colour_viridis_c(guide = "legend") +
  scale_size_continuous(range = c(3, 15), transform = "exp")
```
:::

::: {.column width="40%"}

::::{ style="font-size:85%;"}
```{r}
outdoors |>
  head(12)
```
::::

:::

::::

:::{.hcenter style="font-size:125%;"}
How does the association between **outdoor time** and people's **wellbeing** change, <br> _depending on_ the **number of hours of sunlight** in a day?
:::


## A plot to make interaction more obvious

```{r echo=F, fig.align = 'center', fig.dim = c(16, 8), warning = F}
p_sun_panel <- outdoors |>
  ggplot(aes(x = outdoor_time, y = wellbeing, colour = hrs_sun)) +
  geom_point(aes(size = hrs_sun))+#, alpha = .5) +
  facet_wrap(~ hrs_sun, nrow = 1, labeller = label_both) +
  geom_smooth(se = F, method = 'lm', colour = 'black', show.legend = F) +
  scale_colour_viridis_c(guide = "legend") +
  scale_size_continuous(range = c(3, 15), transform = "exp") +
  theme(
    legend.position = 'none',
    panel.grid.minor = element_blank()
  )
p_sun_panel
```


<br>


:::{style="font-size:125%;"}
Different slopes in different panels $\rightarrow$ The **association** between outdoor time and wellbeing appears **different for different amounts of sunlight.**
:::


# Specifying the interaction model

## <img style="vertical-align: text-bottom; width: 1.5em;" src="figs/icon-park-twotone--brain.svg"> Retrieval practice: Specifying the interaction model

<br>

:::{.hcenter style="font-size: 125%;"}
`wooclap.com`, enter code `BIAHTI`
:::


## Specifying the interaction model

<br>

**In mathematical notation:**

$$
\text{wellbeing} = \beta_0 + (\beta_1 \cdot \text{outdoor_time}) +
(\beta_2 \cdot \text{hrs_sun}) +
(\beta_3 \cdot \text{outdoor_time} \cdot \text{hrs_sun}) +
\epsilon
$$

<br>

**In R,** where both of these options have the same result:

<br>

```{r eval=F}
lm(wellbeing ~ outdoor_time + hrs_sun + outdoor_time:hrs_sun, data = outdoors)

lm(wellbeing ~ outdoor_time * hrs_sun, data = outdoors)
```

<br>

:::{.dapr2callout .fragment}
**Does an interaction model need to contain each of the interacting predictors on their own, too?**
Yes—otherwise we'd only see how one predictor's effect depends on another predictor, with no idea how they behave individually.

- Better: `Y ~ A + B + A:B`
- Worse: `Y ~ A:B`

Including each interacting predictor as well as the interaction (the "Better" example above) is an example of the **"principle of marginality"** ... yet another terrible name for a stats concept :( 
:::


## Think ahead, using our key points about multiple regression/interactions (1)

<br>

:::{.hcenter style="font-size: 125%;"}
`wooclap.com`, enter code `BIAHTI`
:::

<br>

:::{.dapr2callout .fragment}
**For every predictor that goes into your model, know what zero represents.**

- What does `outdoor_time = 0` represent?
- What does `hrs_sun = 0` represent?
:::


:::{.dapr2callout .fragment}

A model's intercept is the estimated mean outcome **when every predictor in the model is at zero.**

- What will the intercept represent for `wellbeing ~ outdoor_time * hrs_sun`?
:::



## Think ahead, using our key points about multiple regression/interactions (2)

<br>

:::{.hcenter style="font-size: 125%;"}
`wooclap.com`, enter code `BIAHTI`
:::

<br>

:::{.dapr2callout .fragment}

Each predictor's slope represents the association of the given predictor with the outcome **when every other predictor is at zero.** 

If predictors interact, then slope estimates are **conditional** on the other predictor being zero. (In other words, each predictor's slope estimate **is _only_ true when the other interacting predictor is zero.**)

- What will the slope of `outdoor_time` represent?
- What will the slope of `hrs_sun` represent?

:::



:::{.dapr2callout .fragment}

The interaction term tells us **how much the association between _one_ predictor and the outcome changes, when the _other_ predictor moves from 0 to 1.**

- What will the interaction term `outdoor_time:hrs_sun` represent?

:::



## Fitting the model

```{r}
m1 <- lm(wellbeing ~ outdoor_time * hrs_sun, data = outdoors)
summary(m1)
```



## Interpreting the model (1)

:::: {.columns}
::: {.column width="60%"}
```{r echo=F, fig.align='center', fig.dim=c(10, 8)}
p_sun_panel +
  facet_wrap(~ hrs_sun, nrow = 1)
```

::::{ style="font-size:80%;"}
```{r echo=F}
cat(paste0(capture.output(summary(m1)), '\n')[10:14])
```
::::
:::
::: {.column width="40%"}

:::{.fragment}

**`Intercept`**

- When `outdoor_time = 0` hours outdoors and `hrs_sun = 0` sunlight hours, the estimated average `wellbeing` is 87.9.

:::

:::{.fragment}

**`outdoor_time`**

- Specifically when `hrs_sun = 0` sunlight hours, spending an additional hour outdoors is associated with a decrease in wellbeing of 10.9 points.

:::

:::{.fragment}

**`hrs_sun`**

- Specifically when `outdoor_time = 0` hours spent outdoors, the sun shining for an extra hour is associated with an increase in wellbeing of 3.2 points.

:::

:::

::::


## Interpreting the model (2)

:::: {.columns}
::: {.column width="60%"}
```{r echo=F, fig.align='center', fig.dim=c(10, 8)}
p_sun_panel +
  facet_wrap(~ hrs_sun, nrow = 1)
```

::::{ style="font-size:80%;"}
```{r echo=F}
cat(paste0(capture.output(summary(m1)), '\n')[10:14])
```
::::
:::
::: {.column width="40%"}

**`outdoor_time:hrs_sun`**

- Increasing sunlight hours by 1 changes the association of `outdoor_time` with `wellbeing` by 3.3.

- So, the association of `outdoor_time` with `wellbeing` when ...
  - `hrs_sun = 0` is –10.9
  - `hrs_sun = 1` is –10.9 + 3.3 = –7.6
  - `hrs_sun = 2` is –10.9 + 3.3 + 3.3 = –4.3
  - ...
  

:::
::::


## But wait! There's another way to interpret the interaction term

<!-- **Interpretation 1 (what we just saw):** -->

<!-- ```{r echo=F, fig.align='center', fig.dim=c(16, 4)} -->
<!-- p_sun_panel -->
<!-- ``` -->

<!-- - Increasing sunlight hours by 1 changes the association of `outdoor_time` with `wellbeing` by about 3. -->


```{r echo=F, fig.align='center', fig.dim=c(16, 8)}
p_out_panel <- outdoors |>
  mutate(
    out_time_bin = cut(outdoor_time, 3)
  ) |>
  ggplot(aes(x = hrs_sun, y = wellbeing, colour = hrs_sun)) +
  geom_point(aes(size = hrs_sun))+#, alpha = .5) +
  facet_wrap(~ out_time_bin, nrow = 1, labeller = label_both) +
  geom_smooth(se = F, method = 'lm', colour = 'black', show.legend = F) +
  scale_colour_viridis_c(guide = "legend") +
  scale_size_continuous(range = c(3, 15), transform = "exp") +
  theme(
    legend.position = 'none',
    panel.grid.minor = element_blank()
  )

p_out_panel
```

Now the x axis shows hours of sunlight, and each panel shows a group of similar `outdoor_time`s.

<!-- We've flipped the interacting variables, but the pattern of the interaction is still there. -->

This plot shows that **the association between sunlight hours and wellbeing is different, when different amounts of time are spent outdoors.** The interacting variables are flipped, but the interaction is still there.


## Both ways of interpreting the interaction term

**Interpretation 1:**

:::: {.columns}
::: {.column width="60%"}
```{r echo=F, fig.dim = c(10, 4)}
p_sun_panel +
  facet_wrap(~ hrs_sun, nrow = 1)
```
:::

::: {.column width="40%"}

<br>

Increasing `hrs_sun` by 1 means that the association between `outdoor_time` and `wellbeing` changes by about 3.
:::
::::


**Interpretation 2 flips the two interacting variables and is still true:**

:::: {.columns}
::: {.column width="60%"}
```{r echo=F, fig.dim = c(10, 4)}
p_out_panel +
  facet_wrap(~ out_time_bin, nrow = 1)
```
:::

::: {.column width="40%"}

<br>

Increasing `outdoor_time` by 1 means that the association between `sun_hrs` and `wellbeing` changes by about 3.
:::
::::



## Interactions are symmetrical

A common example of symmetry: **When a shape looks the same, even when it is mirrored.**

![Image from Wikimedia Commons](figs/Asymmetric_(PSF).png){fig-align="center"}


<br>

**If we have an interaction between predictors A and B, then both "mirror images" are always true:**

- The association between **A** and the outcome is different for different values of **B**.
- The association between **B** and the outcome is different for different values of **A**.

**So we say that interactions are symmetrical.**

<br>

In practice, usually we choose the interpretation that's narratively simpler or makes more intuitive sense (like I secretly did last week!)


## Back to interpreting the interaction term

:::: {.columns}
::: {.column width="60%"}
```{r echo=F, fig.align='center', fig.dim=c(10, 8)}
p_sun_panel +
  facet_wrap(~ hrs_sun, nrow = 1)
```

::::{ style="font-size:80%;"}
```{r echo=F}
cat(paste0(capture.output(summary(m1)), '\n')[10:14])
```
::::
:::
::: {.column width="40%"}

**`outdoor_time:hrs_sun`**

- Increasing sunlight hours by 1 changes the association of `outdoor_time` with `wellbeing` by 3.3.

- So, the association of `outdoor_time` with `wellbeing` when ...
  - `hrs_sun = 0` is –10.9
  - `hrs_sun = 1` is –10.9 + 3.3 = –7.6
  - `hrs_sun = 2` is –10.9 + 3.3 + 3.3 = –4.3
  - ...
  
:::{.fragment}

- **Equivalently:** Increasing outdoor time by 1 changes the association of `hrs_sun` with `wellbeing` by 3.3.

- So, the association of `hrs_sun` with `wellbeing` when ...
  - `outd_time = 0` is 3.2
  - `outd_time = 1` is 3.2 + 3.3 = 6.5
  - `outd_time = 2` is 3.2 + 3.3 + 3.3 = 9.8
  - ...
  
:::

:::
::::


# Simple slopes

## Simple slopes

One of the best ways to understand an interaction is to figure out **what the model thinks the values of these different slopes are:**

```{r echo=F, fig.dim = c(16, 6), fig.align = 'center'}
p_sun_panel
```


Specifically, we want to know the **slopes of the associations that the model estimates** between `outdoor_time` and `wellbeing` for particular values of `hrs_sun`.
We call these **simple slopes**.

:::{.fragment}
**A simple slope is the slope of the association between one predictor and the outcome, at a specific value of another predictor.**

I've been showing you simple slopes when interpreting interaction coefficients. But now let's calculate them formally!

What we need to know:

- The model's linear expression
- The values of each $\beta$ coefficient
:::


## Calculating simple slopes by hand (Example 1)

<br>

**The model's linear expression** (where w stands for wellbeing):
 
$$
\text{w} = \beta_0 + (\beta_1 \cdot \text{outdoor_time}) +
(\beta_2 \cdot \text{hrs_sun}) +
(\beta_3 \cdot \text{outdoor_time} \cdot \text{hrs_sun}) +
\epsilon
$$ 

**The model's coefficients:**

```{r echo=F}
m1_coef_tab <- coef(m1) |> 
  round(2) |> 
  as.data.frame() |> 
  cbind(paste0('beta', 0:3)) |>
  rownames_to_column()
names(m1_coef_tab) <- c('parameter', 'estim', 'beta')
select(m1_coef_tab, parameter, beta, estim) |>
  kableExtra::kable()
```



<br>

:::{.dapr2callout}

**Step 1:** Substitute the estimated coefficients into the linear expression.

$$
\text{w} = 87.92 + (-10.94 \cdot \text{outdoor_time}) +
(3.15 \cdot \text{hrs_sun}) +
(3.25 \cdot \text{outdoor_time} \cdot \text{hrs_sun}) +
\epsilon
$$ 

:::

## Calculating simple slopes by hand (Example 1)

<br>


:::{.dapr2callout}

**Step 1:** Substitute the estimated coefficients into the linear expression.

$$
\text{w} = 87.92 + (-10.94 \cdot \text{outdoor_time}) +
(3.15 \cdot \text{hrs_sun}) +
(3.25 \cdot \text{outdoor_time} \cdot \text{hrs_sun}) +
\epsilon
$$ 

:::

<br>

:::{.dapr2callout .fragment}


**Step 2:** Decide what specific value of `hrs_sun` we want to find the slope over `outdoor_time` for.
Substitute that value in for `hrs_sun`.

**Let's start with `hrs_sun = 0`.**

$$
\text{w}_{\text{hrs_sun} = 0} = 87.92 + (-10.94 \cdot \text{outdoor_time}) + (3.15 \cdot 0) + (3.25 \cdot \text{outdoor_time} \cdot 0) + \epsilon
$$ 
:::

<br>

:::{.dapr2callout .fragment}

**Step 3:** Simplify this expression by working out the multiplication and addition step by step.

$$
\begin{align}
\text{w}_{\text{hrs_sun} = 0}  &= 87.92 + (-10.94 \cdot \text{outdoor_time}) + (3.15 \cdot 0) + (3.25 \cdot \text{outdoor_time} \cdot 0) + \epsilon \\
\text{w}_{\text{hrs_sun} = 0} &= 87.92 + (-10.94 \cdot \text{outdoor_time}) + \epsilon \\
\end{align}
$$ 

So the line that associates `outdoor_time` with `wellbeing`, when `hrs_sun = 0`, has an intercept of 87.92 and a slope of –10.94. **–10.94 is the simple slope.**

:::


## Calculating simple slopes by hand (Example 2)

<br>

:::{.dapr2callout}

**Step 1:** Substitute the estimated coefficients into the linear expression.

$$
\text{w} = 87.92 + (-10.94 \cdot \text{outdoor_time}) +
(3.15 \cdot \text{hrs_sun}) +
(3.25 \cdot \text{outdoor_time} \cdot \text{hrs_sun}) +
\epsilon
$$ 

:::

<br>

:::{.dapr2callout .fragment}


**Step 2:** Decide what specific value of `hrs_sun` we want to find the slope over `outdoor_time` for.
Substitute that value in for `hrs_sun`.

**Let's do the mean value for `hrs_sun`, which is 3.8.**

$$
\text{w}_{\text{hrs_sun} = 3.8} = 87.92 + (-10.94 \cdot \text{outdoor_time}) + (3.15 \cdot 3.8) + (3.25 \cdot \text{outdoor_time} \cdot 3.8) + \epsilon
$$ 
:::

<br>

:::{.dapr2callout .fragment}

**Step 3:** Simplify this expression by working out the multiplication and addition step by step.

Breakdown of steps on next slide.

:::

## Step 3 breakdown

<br>

**The starting expression that we want to simplify:**

$$
\text{w}_{\text{hrs_sun} = 3.8}  = 87.92 + (-10.94 \cdot \text{outdoor_time}) + (3.15 \cdot 3.8) + (3.25 \cdot \text{outdoor_time} \cdot 3.8) + \epsilon
$$

:::{.fragment}

**Multiply the 3.8s together with the numbers in the same brackets.**

$$
\text{w}_{\text{hrs_sun} = 3.8}  = 87.92 + (-10.94 \cdot \text{outdoor_time}) + 11.97 + (12.35 \cdot \text{outdoor_time}) + \epsilon
$$

:::

:::{.fragment}

**Add together the freestanding numbers.**

$$
\text{w}_{\text{hrs_sun} = 3.8}  = 99.89 + (-10.94 \cdot \text{outdoor_time}) + (12.35 \cdot \text{outdoor_time}) + \epsilon
$$

:::

:::{.fragment}

**Combine the numbers that are multiplied with $\text{outdoor_time}$. (In math terms, we're factoring out the variable $\text{outdoor_time}$ from both terms that contain it.)**

$$
\text{w}_{\text{hrs_sun} = 3.8}  = 99.89 + ((-10.94 + 12.35) \cdot \text{outdoor_time}) + \epsilon
$$

:::

:::{.fragment}

**Add up those combined numbers, and we're done!**

$$
\text{w}_{\text{hrs_sun} = 3.8}  = 99.89 + (1.41 \cdot \text{outdoor_time}) + \epsilon
$$

:::{.dapr2callout}
So the line that associates `outdoor_time` with `wellbeing`, when `hrs_sun` is at its mean of 3.8, has an intercept of about 99.89 and a slope of about 1.41. **1.41 is the simple slope.**
:::

:::


```{r include=F}
coef(m1)[['(Intercept)']] + (coef(m1)[['hrs_sun']] * 3.8)

coef(m1)[['outdoor_time']] + (coef(m1)[['outdoor_time:hrs_sun']] * 3.8)
```


## Plotting simple slopes in R

```{r eval=F}
library(interactions)

probe_interaction(
  m1,
  pred = outdoor_time,
  modx = hrs_sun,
  interval = T
)$interactplot
```

```{r echo=F, fig.dim = c(10, 8), fig.align='center'}

probe_interaction(
  m1,
  pred = outdoor_time,
  modx = hrs_sun,
  interval = T
)$interactplot +
  theme(text = element_text(size = 28))

```



## Computing simple slopes in R 

`probe_interaction()` can compute simple slopes _and_ test if they're significantly different from zero.

<br>

:::: {.columns}
::: {.column width="40%"}
```{r eval=F}
probe_interaction(
  m1,
  pred = outdoor_time,
  modx = hrs_sun,
)$simslopes
```
:::
::: {.column width="60%" style = "font-size:80%"}
```{r echo=F}
m1_simslopes <- probe_interaction(
  m1,
  pred = outdoor_time,
  modx = hrs_sun,
)$simslopes

m1_simslopes
```
:::
::::


## The Johnson-Neyman interval

The JN interval tells us **the values for one predictor when the simple slope of the other predictor is significantly different from zero.**
(This is also called a **region of significance analysis.**)

```{r echo=F}
cat(paste0(capture.output(m1_simslopes), '\n')[1:7])
```

<!-- <br> -->

**To plot the JN interval:**

:::: {.columns}

::: {.column width="50%"}

```{r echo=F, fig.dim = c(8, 6), fig.align = 'center'}
m1_jnp <- probe_interaction(
  m1,
  pred = outdoor_time,
  modx = hrs_sun,
  jnplot = T
)$simslopes$jnplot
m1_jnp +
  theme(text = element_text(size = 18))
```


:::

::: {.column width="50%"}

```{r eval=F}
probe_interaction(
  m1,
  pred = outdoor_time,
  modx = hrs_sun,
  jnplot = T
)$simslopes$jnplot
```

- x: `hrs_sun`
- y: Slope of `outdoor_time`
- Red area: Slope of `outdoor_time` not significantly diff. from zero
- Blue area: Slope of `outdoor_time` **is** significantly diff. from zero

:::

::::


# Numeric/numeric interactions, Round 2: With mean-centering

## <img style="vertical-align: text-bottom; width: 1.5em;" src="figs/icon-park-twotone--brain.svg"> Retrieval practice: Mean-centering

<br>

:::{.hcenter style="font-size: 125%;"}
`wooclap.com`, enter code `BIAHTI`
:::



## What's mean-centering again?

To mean-centre a variable means to **transform it so that the mean of the centered version is zero.**

Specifically, this involves **subtracting the mean** of a variable from every observation of that variable.


```{r}
outdoors <- outdoors |>
  mutate(
    outdoor_time_c = outdoor_time - mean(outdoor_time),
    hrs_sun_c      = hrs_sun - mean(hrs_sun),
  )

head(outdoors)
```

<br>

:::: {.columns}
::: {.column width="50%"}
```{r}
mean(outdoors$outdoor_time) |> round(2)
mean(outdoors$hrs_sun) |> round(2)
```
:::
::: {.column width="50%"}
```{r}
mean(outdoors$outdoor_time_c) |> round(2)
mean(outdoors$hrs_sun_c) |> round(2)
```
:::
::::





<!-- ## Before and after mean-centering (1) -->

<!-- :::: {.columns} -->
<!-- ::: {.column width="50%"} -->

<!-- **Before:** -->

<!-- ```{r echo=F, fig.align = 'center', fig.dim = c(8, 11)} -->
<!-- outdoors |> -->
<!--   mutate() |> -->
<!--   ggplot(aes(x = outdoor_time, y = wellbeing, colour = hrs_sun, size = hrs_sun)) + -->
<!--   geom_point() + -->
<!--   scale_colour_viridis_c(guide = "legend") + -->
<!--   scale_size_continuous(range = c(3, 15), transform = "exp") + -->
<!--   theme( -->
<!--     legend.position = 'bottom', -->
<!--     legend.direction="vertical", -->
<!--     text = element_text(size = 40) -->
<!--   ) -->
<!-- ``` -->
<!-- ::: -->
<!-- ::: {.column width="50%"} -->

<!-- **After:** -->

<!-- ```{r echo=F, fig.align = 'center', fig.dim = c(8, 10.5)} -->
<!-- outdoors |> -->
<!--   mutate() |> -->
<!--   ggplot(aes(x = outdoor_time_c, y = wellbeing, colour = hrs_sun_c, size = hrs_sun_c)) + -->
<!--   geom_point() + -->
<!--   scale_colour_viridis_c(guide = "legend") + -->
<!--   scale_size_continuous(range = c(3, 15), transform = "exp") + -->
<!--   theme( -->
<!--     legend.position = 'bottom', -->
<!--     legend.direction="vertical", -->
<!--     text = element_text(size = 40), -->
<!--     panel.grid.minor.x = element_blank() -->
<!--   ) -->
<!-- ``` -->
<!-- ::: -->
<!-- :::: -->


## Before and after mean-centering

**Before** (each panel is one value of `hrs_sun`):

```{r echo=F, fig.align = 'center', fig.dim = c(16, 5), warning = F}
p_sun_panel +
  facet_wrap(~ hrs_sun, nrow = 1) +
  theme(
    text = element_text(size = 40),
  )
```


**After** (each panel is one value of `hrs_sun_c`, which aren't round numbers because the original mean of 3.8 isn't a round number):

```{r echo=F, fig.align = 'center', fig.dim = c(16, 5), warning = F}
p_sun_panel_c <- outdoors |>
  ggplot(aes(x = outdoor_time_c, y = wellbeing, colour = hrs_sun_c)) +
  geom_point(aes(size = hrs_sun_c))+#, alpha = .5) +
  facet_wrap(~ hrs_sun_c, nrow = 1) +
  geom_smooth(se = F, method = 'lm', colour = 'black', show.legend = F) +
  scale_colour_viridis_c(guide = "legend") +
  scale_size_continuous(range = c(3, 15), transform = "exp") +
  theme(
    legend.position = 'none',
    panel.grid.minor = element_blank(),
    text = element_text(size = 40),
  ) +
  scale_x_continuous(breaks = c(-2, 0, 2)) 
p_sun_panel_c
```



## Think–Pair–Share: Mean-centered interactions

<br>

The interaction model &nbsp; `wellbeing ~ outdoor_time_c * hrs_sun_c` &nbsp; will have four coefficients:

- `Intercept`
- `outdoor_time_c`
- `hrs_sun_c`
- `outdoor_time_c:hrs_sun_c`

**What will each coefficient represent?**


<br>

:::{.dapr2callout style="font-size:100%"}

- **Think** to yourself about each coefficient's meaning. / **Pair** up with your neighbour and think together.

![](figs/streamline-plump--hourglass-remix.svg){fig-align="center"}

- Then **share** on `wooclap.com`, enter code `BIAHTI`

:::


## Fit the model

$$
\text{wellbeing} = \beta_0 + (\beta_1 \cdot \text{outdoor_time_c}) +
(\beta_2 \cdot \text{hrs_sun_c}) +
(\beta_3 \cdot \text{outdoor_time_c} \cdot \text{hrs_sun_c}) +
\epsilon
$$

```{r}
m2 <- lm(wellbeing ~ outdoor_time_c * hrs_sun_c, data = outdoors)
```

:::{.fragment}
```{r}
summary(m2)
```
:::


## Interpreting the mean-centered model (1)

:::: {.columns}
::: {.column width="60%"}
```{r echo=F, fig.align='center', fig.dim=c(10, 8)}
p_sun_panel_c
```

::::{style="font-size:80%;"}
```{r echo=F}
# cat(paste0(capture.output(summary(m2)), '\n')[10:14])
summary(m2)$coefficients |> round(2)
```
::::

:::

::: {.column width="40%"}

:::{.fragment}

**`Intercept`**

- When `outdoor_time = 0` (mean hrs outdoors) and `hrs_sun = 0` (mean sunlight hours), the estimated average `wellbeing` is 104.9.

:::

:::{.fragment}

**`outdoor_time_c`**

- Specifically when `hrs_sun = 0` (at the mean value for sunlight hours), spending an additional hour outdoors is associated with an increase in wellbeing of 1.4 points.

:::

:::{.fragment}

**`hrs_sun_c`**

- Specifically when `outdoor_time = 0` (at the mean number of hours spent outdoors), the sun shining for an extra hour is associated with an increase in wellbeing of 14.5 points.

:::

:::
::::

## Interpreting the mean-centered model (2)

:::: {.columns}
::: {.column width="60%"}
```{r echo=F, fig.align='center', fig.dim=c(10, 8)}
p_sun_panel_c
```

::::{style="font-size:80%;"}
```{r echo=F}
# cat(paste0(capture.output(summary(m2)), '\n')[10:14])
summary(m2)$coefficients |> round(2)
```
::::


:::

::: {.column width="40%"}

<!-- ::::{style="font-size:90%"} -->

**`outdoor_time_c:hrs_sun_c`**

- Increasing centered sunlight hours by 1 changes the association of `outdoor_time_c` with `wellbeing` by 3.3.

- So, the association of `outdoor_time_c` with `wellbeing` when ...
  - `hrs_sun_c = 0` is 1.4
  - `hrs_sun_c = 1` is 1.4 + 3.3 = 4.7
  - `hrs_sun_c = 2` is 1.4 + 3.3 + 3.3 = 8.0
  - ...
  
:::{.fragment}

- **Equivalently:** Increasing centered outdoor time by 1 changes the association of `hrs_sun_c` with `wellbeing` by 3.3.

- So, the association of `hrs_sun_c` with `wellbeing` when ...
  - `out_t_c = 0` is 14.5
  - `out_t_c = 1` is 14.5 + 3.3 = 17.8
  - `out_t_c = 2` is 14.5 + 3.3 + 3.3 = 21.1
  - ...

:::

<!-- :::: -->

:::
::::




# Probing the interaction

## Simple slopes

```{r fig.align = "center"}
probe_interaction(
  m2,
  pred = outdoor_time_c,
  modx = hrs_sun_c,
  interval = T,
)$interactplot
```

Compare to the old plot of simple slopes: the shape is the same!
Mean-centering doesn't change the relationship between simple slopes.


## Region of significance analysis

```{r fig.align="center"}
probe_interaction(
  m2,
  pred = outdoor_time_c,
  modx = hrs_sun_c,
  jnplot = T
)$simslopes$jnplot
```

Compare to the old plot: the shape is the same!
Mean-centering doesn't change the regions of (non)significance in how the predictors interact.



# The big picture: Interactions, now with numeric predictors

## Interactions, now with numeric predictors

<br>

![](figs/depends-on-12.svg){fig-align="center"}




# Back matter


## Revisiting this week's learning objectives

<br>

::: {.dapr2callout}
**How do we specify an interaction between two numeric predictors?**

- Exactly the same as we would for two categorical predictors!
- Mathematically: Interactions are always the product of the two interacting predictors.
- In R: If we have two interacting predictors A and B, we can write `A*B` (which stands for the individual predictors _and_ their interaction) or `A:B` (which stands for just the interaction).
:::

::: {.dapr2callout}
**What does it mean when we say "interactions are symmetrical"?**

- Imagine we have two interacting predictors, A and B.
- We can see the symmetry of this interaction because both of these "mirrored" interpretations are true:
	- The association between A and the outcome is different for different values of B.
	- The association between B and the outcome is different for different values of A.
:::

## Revisiting this week's learning objectives

<br>


::: {.dapr2callout}
**What is a simple slope?**

- The slope of the association between one predictor and the outcome, at a specific value of another predictor.
- If we have two interacting predictors, A and B, then we could look at (for example) 
  - the simple slope of A, when B = 0,
  - or the simple slope of B, when A = 100,
  - or the simple slope of A, when B = –5,
  - or ...
:::

::: {.dapr2callout}
**When we have an interaction between two numeric predictors, what values do we typically use to compute simple slopes?**

- We typically look at the simple slope of one predictor at three specific values of the other one: its mean, its mean + 1 SD, its mean – 1 SD.
- If we have two interacting predictors, A and B, then we might look at the simple slope of A
  - when B is at its mean minus one SD (i.e., `mean(B) - sd(B)`),
  - when B is at its mean (i.e., `mean(B)`), and
  - when B is at its mean plus one SD (i.e., `mean(B) + sd(B)`).
:::




## This week

<br>

:::: {.columns}
::: {.column width="50%"}

**Tasks:**

<br>

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/labs.svg')
```

**Attend your lab and work together on the exercises**

:::
::: {.column width="50%"}

**Support:**

<br>

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/forum.svg')
```

**Help each other on the Piazza forum**

:::
::::

<br>

:::: {.columns}
::: {.column width="50%"}

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/exam.svg')
```

**Complete the weekly quiz**

:::
::: {.column width="50%"}

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/oh.png')
```

**Attend office hours (see Learn page for details)**

:::
::::



# Appendix {.appendix} 



## Compare the coefficients

<!-- - Why is the intercept larger in the mean-centered model than in the non-centered model? -->
<!-- - Why is outdoor_time_c so much closer to zero in the mean-centered model? -->
<!-- - Why is hrs_sun_c so much larger in the mean-centered model? -->
<!-- - Why are the interaction terms the same in both models? -->

<!-- <br> -->

**The old coefficients in the non-centered model, `m1`:**

::::{.columns}
::: {.column width="30%"}

```{r echo=F}
round(coef(m1)[1], 1)
round(coef(m1)[2], 1)
round(coef(m1)[3], 1)
round(coef(m1)[4], 1)
```

:::

::: {.column width="70%"}


```{r echo=F, fig.align = 'center', fig.dim = c(12, 4), warning = F}
p_sun_panel +
  facet_wrap(~ hrs_sun, nrow = 1)
```

:::

::::



**The new coefficients in the mean-centered model, `m2`:**

::::{.columns}

::: {.column width="30%"}

```{r echo=F}
round(coef(m2)[1], 1)
round(coef(m2)[2], 1)
round(coef(m2)[3], 1)
round(coef(m2)[4], 1)
```

:::

::: {.column width="70%"}

```{r echo=F, fig.align = 'center', fig.dim = c(12, 4), warning = F}
p_sun_panel_c
```

:::

::::



<!-- :::: {.columns} -->
<!-- ::: {.column width="50%"} -->
<!-- a -->
<!-- ::: -->
<!-- ::: {.column width="50%"} -->
<!-- b -->
<!-- ::: -->
<!-- :::: -->
