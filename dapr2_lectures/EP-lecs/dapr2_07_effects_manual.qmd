---
title: "Effect coding and manual post-hoc contrasts"
editor_options: 
  chunk_output_type: console
format:
  revealjs:
    smaller: true
---

```{r setup, include = F}
library(tidyverse)
library(patchwork)
library(emmeans)
library(simglm)
source('_theme/theme_quarto.R')

theme_set(theme_quarto(title_font_size=42))
theme_update(
  text = element_text(family = 'Source Sans 3'),
  axis.title.y = element_text(angle=0, 
                              vjust=0.5, 
                              hjust = 0,
                              margin = margin(t = 0, r = 10, b = 0, l = 0)
  ),
  
)

dapr2red <- "#BF1932" 
pal <- c("#3173c9", "#ff94b0", "#51b375")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(3119) 

sim_arguments <- list(
  formula = y ~ 1 + hours + motivation + study + method,
  fixed = list(hours = list(var_type = 'ordinal', levels = 0:15),
               motivation = list(var_type = 'continuous', mean = 0, sd = 1),
               study = list(var_type = 'factor', 
                            levels = c('alone', 'others'),
                            prob = c(0.53, 0.47)),
               method = list(var_type = 'factor', 
                            levels = c('read', 'summarise', 'self-test'),
                            prob = c(0.3, 0.4, 0.3))),
  error = list(variance = 20),
  sample_size = 250,
  reg_weights = c(0.6, 1.4, 1.5, 6, 6, 2)
)

df3 <- simulate_fixed(data = NULL, sim_arguments) %>%
  simulate_error(sim_arguments) %>%
  generate_response(sim_arguments)

score_data <- df3 %>%
  dplyr::select(y, hours, motivation, study, method) %>%
  mutate(
    ID = paste("ID", 101:350, sep = ""),
    score = round(y+abs(min(y))),
    motivation = round(motivation, 2),
    study = factor(study),
    method = factor(method)
  ) %>%
  dplyr::select(ID, score, hours, motivation, study, method)

score_data <- score_data |>
  mutate(
    study_dum = ifelse(study == 'alone', 0, 1),
    study_sum = ifelse(study == 'alone', 1, -1),
    )

# get group means
mean_alone <- filter(score_data, study == 'alone')$score |> mean()
sd_alone <- filter(score_data, study == 'alone')$score |> sd()
mean_others <- filter(score_data, study == 'others')$score |> mean()
sd_others <- filter(score_data, study == 'others')$score |> sd()

mean_read <- filter(score_data, method == 'read')$score |> mean()
sd_read <- filter(score_data, method == 'read')$score |> sd()
mean_self <- filter(score_data, method == 'self-test')$score |> mean()
sd_self <- filter(score_data, method == 'self-test')$score |> sd()
mean_summ <- filter(score_data, method == 'summarise')$score |> mean()
sd_summ <- filter(score_data, method == 'summarise')$score |> sd()
```


# Course Overview

<br>

:::: {.columns}

::: {.column width="50%"}

```{r echo = FALSE, results='asis', warning = FALSE}
block1_name = "Introduction to Linear Models"
block1_lecs = c("Intro to Linear Regression",
                "Interpreting Linear Models",
                "Testing Individual Predictors",
                "Model Testing & Comparison",
                "Linear Model Analysis")
block2_name = "Analysing Experimental Studies"
block2_lecs = c("Categorical Predictors & Dummy Coding",
                "	Effects Coding & Coding Specific Contrasts",
                "Assumptions & Diagnostics",
                "Bootstrapping",
                "	Categorical Predictor Analysis")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")

course_table(block1_name,block2_name,block1_lecs,block2_lecs,week = 7)
```

:::

::: {.column width="50%"}

```{r echo = FALSE, results='asis', warning = FALSE}
block3_name = "Interactions"
block3_lecs = c("Interactions I",
                "Interactions II",
                "Interactions III",
                "Analysing Experiments",
                "Interaction Analysis")
block4_name = "Advanced Topics"
block4_lecs = c("Power Analysis",
                "Binary Logistic Regression I",
                "Binary Logistic Regression II",
                "Logistic Regression Analysis",
                "	Exam Prep and Course Q&A")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")

course_table(block3_name,block4_name,block3_lecs,block4_lecs,week = 0)
```

:::

::::


## <img style="vertical-align: text-bottom; width: 1.5em;" src="figs/icon-park-twotone--brain.svg"> Retrieval practice: Coefficients and <br> null hypotheses (H0s) in dummy coding

<br>

Answer the questions in this table as thoroughly as you can **FROM MEMORY.**

(It's extremely OK and normal to not remember everything.)

<br>

|  | Intercept $\beta_0$ |  | Slope $\beta_j$ |  |
|---|---|---|---|---|
|  | **Meaning** | **H0** | **Meaning** | **H0** |
| Dummy coding /<br> Treatment coding | *What does the intercept mean?* | *What null hypothesis is tested for the intercept?* | *What does the slope coefficient mean?* | *What hypothesis is tested for the slope coefficient?* |
|  |  |  |  |  |
<!-- | Dummy coding / Treatment coding | Mean outcome of reference level | Mean outcome of ref. level = 0 | Difference between non-ref. level and ref. level | This difference = 0 | -->
<!-- | Effects coding / Sum to zero coding | Mean of all group means (aka grand mean) | Grand mean = 0 | Difference between grand mean and the mean of group j | Diff = 0 | -->

Once you've written down everything you can remember, look at your notes and fill in the gaps.

<br>

:::{.dapr2callout}
Retrieving information from memory is a good study strategy too. According to [Brown et al. (2014)](https://www.hup.harvard.edu/file/feeds/PDF/9780674729018_sample.pdf), if you test your memory first and only afterward look up the information, you'll end up remembering things much better than if you look up the information without testing yourself first.
:::




## This week's learning objectives

<br>


::: {style="font-size: 125%;"}

::: {.fragment}
::: {.dapr2callout}
Dummy coding is one common scheme for *a priori* contrast coding. What's another common scheme, and how is it different?
:::
:::

::: {.fragment}
::: {.dapr2callout}
When we code predictors using this other coding scheme, how do we interpret the linear model's coefficients?
:::
:::

::: {.fragment}
::: {.dapr2callout}
In this other coding scheme, what hypotheses are tested for each coefficient?
:::
:::

::: {.fragment}
::: {.dapr2callout}
How can we test hypotheses other than the ones tested by *a priori* coding schemes?
:::
:::

:::

<!-- ======================================== -->






## Coefficients and null hypotheses (H0s)

<br>

|  | Intercept $\beta_0$ |  | Slope $\beta_j$ |  |
|---|---|---|---|---|
|  | **Meaning** | **H0** | **Meaning** | **H0** |
| Dummy coding / <br> Treatment coding | Mean outcome of reference level | Mean outcome of ref. level = 0 | Difference between non-ref. level and ref. level | Difference between non-ref. level and ref. level = 0 |
| Effect(s) coding / sum(-to-zero) coding |  |  |  |  |
|  |  |  |  |  |

<!-- | Effects coding / Sum to zero coding | Mean of all group means (aka grand mean) | Grand mean = 0 | Difference between grand mean and the mean of group j | Diff = 0 | -->

<br>

::: {.hcenter .fragment style="font-size:125%;"}
<img style="vertical-align: text-bottom; width: 2em;" src="figs/mdi--frequently-asked-questions.svg">
:::

# Effect coding


## Effect coding: Another way of representing categorical predictors as numbers

<br>

:::: {.columns}
::: {.column width="50%" .fragment}
**Dummy coding/treatment coding:**

![](figs/trtmt.svg){fig-align="center" height="300"}

- Studying `alone` is coded as 0.
- Studying with `others` is coded as 1.

:::
::: {.column width="50%" .fragment}

**Effect(s) coding / sum-to-zero coding:**

![](figs/sum.svg){fig-align="center" height="300"}

- Studying `alone` is coded as 1.
- Studying with `others` is coded as –1.

:::
::::

## Same data as last week: Two study patterns

```{r echo=F, fig.width = 10, fig.align = 'center'}
set.seed(1)
score_data |>
  ggplot(aes(x = study, y = score, fill = study, colour = study)) +
  geom_violin(alpha = 0.5) +
  geom_jitter(alpha = 0.5, width = 0.2, size = 5) +
  theme(legend.position = 'none') +
  scale_fill_manual(values = pal) +
  scale_colour_manual(values = pal) +
  stat_summary(fun = mean, geom = 'point', colour = 'black', size = 5) +
  NULL
```


## Same data represented as different numbers

:::: {.columns}
::: {.column width="50%" .fragment}

Dummy coding (from last week) uses 0 and 1.

```{r plot xy study dummy, echo=F, fig.width = 7.5, fig.asp=.9, fig.align='center'}
xlim_lower <- -2.2
xlim_upper <-  2.2
ylim_lower <- -15
ylim_upper <-  55

set.seed(1)  # seed for constant jitter
p_xy_study_dummy <- score_data |>
  ggplot(aes(x = study_dum, y = score)) +
  geom_jitter(aes(colour = study), alpha = 0.25, width = 0.1, size = 5) +
  scale_x_continuous(limits = c(xlim_lower, xlim_upper), expand = c(0, 0)) +
  scale_y_continuous(limits = c(ylim_lower, ylim_upper), expand = c(0, 0)) +
  geom_segment(x = xlim_lower, xend = xlim_upper, y = 0, yend = 0,
               arrow = arrow(ends = 'both', length = unit(12, 'pt')), colour = 'black') +
  geom_segment(x = 0, xend = 0, y = ylim_lower, yend = ylim_upper, 
               arrow = arrow(ends = 'both', length = unit(12, 'pt')), colour = 'black') +
  stat_summary(fun = mean, geom = 'point', colour = 'black', size = 8, show.legend = FALSE) +

  scale_colour_manual(values = pal) +
  theme(
    panel.grid.minor = element_blank(),
    legend.position = 'bottom'
  ) +
  labs(
    x = 'study (in numeric space,\ndummy coded)'
  ) +
 guides(colour = guide_legend(override.aes = list(alpha = 1))) + 
  NULL

p_xy_study_dummy
```

:::
::: {.column width="50%" .fragment}

Effect coding (this week) uses 1 and –1.

```{r plot xy study effect, echo=F, fig.width = 7.5, fig.asp=.9, fig.align='center'}
set.seed(1)  # seed for constant jitter
p_xy_study_eff <- score_data |>
  ggplot(aes(x = study_sum, y = score)) +
  geom_jitter(aes(colour = study), alpha = 0.25, width = 0.1, size = 5) +
  scale_x_continuous(limits = c(xlim_lower, xlim_upper), expand = c(0, 0)) +
  scale_y_continuous(limits = c(ylim_lower, ylim_upper), expand = c(0, 0)) +
  geom_segment(x = xlim_lower, xend = xlim_upper, y = 0, yend = 0,
               arrow = arrow(ends = 'both', length = unit(12, 'pt')), colour = 'black') +
  geom_segment(x = 0, xend = 0, y = ylim_lower, yend = ylim_upper, 
               arrow = arrow(ends = 'both', length = unit(12, 'pt')), colour = 'black') +
  stat_summary(fun = mean, geom = 'point', colour = 'black', size = 8, show.legend = FALSE) +

  scale_colour_manual(values = pal) +
  theme(
    panel.grid.minor = element_blank(),
    legend.position = 'bottom'
  ) +
  labs(
    x = 'study (in numeric space,\neffect coded)'
  ) +
 guides(colour = guide_legend(override.aes = list(alpha = 1))) + 
  NULL

p_xy_study_eff
```


:::
::::

:::{.fragment}
:::{.dapr2callout}
Effect coding still fits a line through both group means.

- What will this line's **intercept** represent?
- What will this line's **slope** represent?
:::

**Predict with your neighbours:**
What are your guesses for each question?
Why do you think your guesses are likely to be correct?
:::


## Defining effect coding in R

<br>

:::{.fragment}

R uses dummy coding by default.

```{r}
contrasts(score_data$study)
```

:::

<br>

:::{.fragment}
To make sure that our predictor is effect-coded, we use the function `contr.sum()`.

```{r}
contrasts(score_data$study) <- contr.sum(2)  # 2 because there are 2 levels
contrasts(score_data$study)
```

:::




## Model `score ~ study`

$$
\text{score}_i = \beta_0 + (\beta_1 \cdot \text{study}) + \epsilon_i
$$

```{r}
m1 <- lm(score ~ study, data = score_data)
```

:::{.fragment}
```{r}
summary(m1)
```
:::

```{r include = F}
m1_int <- summary(m1)$coefficients['(Intercept)', 'Estimate']
m1_slp <- summary(m1)$coefficients['study1', 'Estimate']
```


:::{.dapr2callout .fragment}
- Does your prediction about the **intercept** make sense, given the estimate of `r m1_int`?

- Does your prediction about the **slope** make sense, given the estimate of `r m1_slp`?
:::


## What does each coefficient represent?

:::: {.columns}
::: {.column width="50%"}
```{r echo=F, fig.align = 'center', fig.asp = 1}
set.seed(1)
p_xy_study_eff
```
:::
::: {.column width="50%" style='font-size:85%;'}
```{r echo=F}
# cat(paste0(capture.output(summary(m1)), '\n')[10:12])
summary(m1)$coefficients
```

:::
::::


## What does each coefficient represent?

:::: {.columns}
::: {.column width="50%"}
```{r echo=F, fig.align = 'center', fig.asp = 1}
set.seed(1)
p_xy_study_eff +
  geom_abline(intercept = m1_int, slope = m1_slp, linewidth = 2)
```
:::
::: {.column width="50%" style='font-size:85%;'}
```{r echo=F}
# cat(paste0(capture.output(summary(m1)), '\n')[10:12])
summary(m1)$coefficients
```

<br>

:::
::::



## What does each coefficient represent?

:::: {.columns}
::: {.column width="50%"}
```{r echo=F, fig.align = 'center', fig.asp = 1}
set.seed(1)
library(latex2exp)

gm <- m1_int

p_xy_study_eff +
  geom_abline(intercept = m1_int, slope = m1_slp, linewidth = 2) +
  # right triangle
  geom_segment(x = 0, xend = 1, y = gm, yend = gm,
               colour = dapr2red, linewidth = 2, linetype = 'dotted') +
  geom_segment(x = 1, xend = 1, y = gm, yend = mean_alone,
               colour = dapr2red, linewidth = 2) +
  # arrows
  geom_segment(x = -.5, xend = -.1, y = gm+13, yend = gm+2, arrow = arrow(), colour = dapr2red) +
  geom_segment(x = 1.7, xend = 1.1, y = gm-1, yend = gm-1, arrow = arrow(), colour = dapr2red) +
  # betas
  geom_label(x = -.5, 
             y = gm+13, 
             label = '(Intercept)',
             size = 10, 
             col = dapr2red) +
  geom_label(x = 1.8, 
             y = gm-1, 
             label = 'study1',
             size = 10, 
             col = dapr2red) +
  NULL
```

:::{.dapr2callout .fragment data-fragment-index="3"}

**Observe and explain**: Did your guesses match the results? Why are the results the way they are?

:::


:::
::: {.column width="50%"}
:::{style='font-size:85%;'}
```{r echo=F}
# cat(paste0(capture.output(summary(m1)), '\n')[10:12])
summary(m1)$coefficients
```
:::

<br>

:::{.fragment  data-fragment-index="1"}
**`(Intercept)` aka $\hat{\beta_0}$:**

- `r round(m1_int, 2)` is the **grand mean**: the mean of the group means.

```{r}
(m1_grand_mean <- mean(
  c(mean_others, mean_alone))
 )
```

:::


<br>

:::{.fragment  data-fragment-index="2"}
**`study1` aka $\hat{\beta_1}$:**

- `r round(m1_slp, 2)` is the difference between the level coded as 1, `alone`, and the grand mean.

```{r}
mean_alone - m1_grand_mean
```
:::


:::
::::





## Coefficients and null hypotheses (H0s)

<br>

|  | Intercept $\beta_0$ |  | Slope $\beta_j$ |  |
|---|---|---|---|---|
|  | **Meaning** | **H0** | **Meaning** | **H0** |
| Dummy coding / <br> Treatment coding | Mean outcome of reference level | Mean outcome of ref. level = 0 | Difference between non-ref. level and ref. level | Difference between non-ref. level and ref. level = 0 |
| Effect(s) coding / sum(-to-zero) coding | Grand mean (mean of all group mean outcomes) |  | Difference between mean of level coded as 1 and grand mean |  |
|  |  |  |  |  |

<!-- | Effects coding / Sum to zero coding | Mean of all group means (aka grand mean) | Grand mean = 0 | Difference between grand mean and mean of level coded as 1 | Diff = 0 | -->


<br>

::: {.hcenter .fragment style="font-size:125%;"}
<img style="vertical-align: text-bottom; width: 2em;" src="figs/mdi--frequently-asked-questions.svg">
:::


## What hypotheses does effect coding test?

<br>

```{r echo=F}
cat(paste0(capture.output(summary(m1)), '\n')[10:12])
```


<br>

:::{.fragment}
**`(Intercept)`:**

- Null hypothesis: The grand mean is equal to zero.
- $p$-value: the probability of observing a grand mean of `r m1_int` (or a value more extreme), assuming that the true grand mean is zero.

**Can we reject this null hypothesis?**   <img style="vertical-align: text-bottom; width: 1em;" src="figs/codicon--thumbsup-filled.svg"> <img style="vertical-align: text-bottom; width: 1em;" src="figs/codicon--thumbsdown-filled.svg">
:::

<br> 

:::{.fragment}
**`study1`:**

- Null hypothesis: The difference between the mean score of `alone` and the grand mean is equal to zero.
- $p$-value: the probability of observing a difference of `r m1_slp` (or a value more extreme), assuming that the true difference is zero.

**Can we reject this null hypothesis?**   <img style="vertical-align: text-bottom; width: 1em;" src="figs/codicon--thumbsup-filled.svg"> <img style="vertical-align: text-bottom; width: 1em;" src="figs/codicon--thumbsdown-filled.svg">
:::

## Coefficients and null hypotheses (H0s)

<br>

|  | Intercept $\beta_0$ |  | Slope $\beta_j$ |  |
|---|---|---|---|---|
|  | **Meaning** | **H0** | **Meaning** | **H0** |
| Dummy coding / <br> Treatment coding | Mean outcome of reference level | Mean outcome of ref. level = 0 | Difference between non-ref. level and ref. level | Difference between non-ref. level and ref. level = 0 |
| Effect(s) coding / sum(-to-zero) coding | Grand mean (mean of all group mean outcomes) | Grand mean = 0 | Difference between  mean of level coded as 1 and grand mean | Difference between mean of level coded as 1 and grand mean = 0 |
|  |  |  |  |  |

<br>

:::{.fragment}
**In general, the H0 being tested for a given parameter is always "this parameter is equal to 0".**
:::



::: {.hcenter .fragment style="font-size:125%;"}
<br>

<img style="vertical-align: text-bottom; width: 2em;" src="figs/mdi--frequently-asked-questions.svg">
:::


<!-- ======================================== -->

# Effect coding for >2 levels

## Same data as last week: Three study methods

```{r echo=F, fig.width = 10, fig.align = 'center'}
set.seed(1)
score_data |>
  ggplot(aes(x = method, y = score, fill = method, colour = method)) +
  geom_violin(alpha = 0.5) +
  geom_jitter(alpha = 0.5, width = 0.2, size = 5) +
  theme(legend.position = 'none') +
  scale_fill_manual(values = pal) +
  scale_colour_manual(values = pal) +
  stat_summary(fun = mean, geom = 'point', colour = 'black', size = 5) +
  NULL
```

## <img style="vertical-align: text-bottom; width: 1.5em;" src="figs/icon-park-outline--muscle.svg"> Challenge: Guess the coefficient values

:::{.dapr2callout .fragment}
Here's what the coefficients mean in effect coding:

- Intercept = Grand mean (mean of all group mean outcomes)
- Slope = Difference between mean of level coded as 1 and grand mean (i.e., group mean – grand mean) 
:::


:::: {.columns}

::: {.column width="30%"}
:::{.dapr2callout .fragment}
Mean of `read`:

```{r}
mean_read
```


Mean of `self-test`:

```{r}
mean_self
```


Mean of `summarise`:

```{r}
mean_summ
```
:::
:::
::: {.column width="70%"}

:::{.dapr2callout .fragment}
```{r}
contrasts(score_data$method) <- contr.sum(3)
contrasts(score_data$method)
```

:::

::: {.dapr2callout  .fragment style="background: #FDEDEF;"}
**Imagine fitting a model `score ~ method`. This slide has all the information you need to guess the coefficient values.**

Work individually or with your neighbour(s).

- What's the value of the intercept?
- There'll be a predictor called `method1`. What is its value?
- There'll also be a predictor called `method2`. What is its value?
:::
:::
::::

## <img style="vertical-align: text-bottom; width: 1.5em;" src="figs/icon-park-outline--muscle.svg">  Challenge: Guess the coefficient values

:::{.dapr2callout}
Here's what the coefficients mean in effect coding:

- Intercept = Grand mean (mean of all group mean outcomes)
- Slope = Difference between mean of level coded as 1 and grand mean (i.e., group mean – grand mean) 
:::


:::: {.columns}

::: {.column width="30%"}
:::{.dapr2callout}
Mean of `read`:

```{r}
mean_read
```


Mean of `self-test`:

```{r}
mean_self
```


Mean of `summarise`:

```{r}
mean_summ
```
:::
:::
::: {.column width="70%"}

:::{.dapr2callout}
```{r}
contrasts(score_data$method) <- contr.sum(3)
contrasts(score_data$method)
```

:::

::: {.dapr2callout style="background: #FDEDEF;"}
- Intercept: grand mean, so

```{r}
(m2_grand_mean <- (mean_read + mean_self + mean_summ)/3)
```

- `method1`: in column 1 of contrast matrix, `read` = 1, so

```{r}
mean_read - m2_grand_mean
```


- `method2`: in column 2 of contrast matrix, `self-test` = 1, so

```{r}
mean_self - m2_grand_mean
```

:::
:::
::::


## Model `score ~ method`

```{r}
m2 <- lm(score ~ method, data = score_data)
summary(m2)
```




## What hypotheses are being tested?

<br>

|  | Intercept $\beta_0$ |  | Slope $\beta_j$ |  |
|---|---|---|---|---|
|  | **Meaning** | **H0** | **Meaning** | **H0** |
| Dummy coding / <br> Treatment coding | Mean outcome of reference level | Mean outcome of ref. level = 0 | Difference between non-ref. level and ref. level | Difference between non-ref. level and ref. level = 0 |
| Effect(s) coding / sum(-to-zero) coding | Grand mean (mean of all group mean outcomes) | Grand mean = 0 | Difference between  mean of level coded as 1 and grand mean | Difference between mean of level coded as 1 and grand mean = 0 |
|  |  |  |  |  |

<br>

```{r echo=F}
cat(paste0(capture.output(summary(m2)), '\n')[10:13])
```


::: {.hcenter .fragment style="font-size:125%;"}
<br>

<img style="vertical-align: text-bottom; width: 2em;" src="figs/mdi--frequently-asked-questions.svg">
:::



<!-- ======================================== -->

# Creating your own post-hoc contrasts


## A note on terminology: *A priori* contrasts? <br> Post-hoc contrasts?


:::: {.columns}
::: {.column width="45%" .fragment}

***A priori* contrasts** are chosen *prior* to (before) fitting the model.

Every categorical variable must be coded with some kind of *a priori* contrast.

Your toolkit now includes:

1. **dummy coding** = treatment coding (uses 0 and 1)
2. **effect coding** = effects coding = sum-to-zero coding = sum coding (uses 1 and –1)

:::
::: {.column width="10%"}
:::
::: {.column width="45%" .fragment}

**Post-hoc contrasts** are tested *post* (after) fitting the model.

We can optionally use estimated marginal means to test hypotheses beyond the ones from our *a priori* contrasts.

We tested our first post-hoc contrasts last week, when we looked at the difference between the two non-reference levels of `method`.

**This session, we'll learn how to define any contrasts we want.**

:::
::::



## The data: Subjective well-being and partnership

```{r include=F}
n <- round(500*(c(.55, .2, .1, .05, .1)),0)
set.seed(7284)
wb_data <- tibble(
  swb = c(rnorm(n[1], 11, 3.6),
          rnorm(n[2], 12, 4.2),
          rnorm(n[3], 8, 2.2),
          rnorm(n[4], 6, 1.1),
          rnorm(n[5], 9.5, 2.5)),
  status = factor(c(rep("Married/CP", n[1]),
                    rep("Cohab", n[2]),
                    rep("Single", n[3]),
                    rep("Widowed", n[4]),
                    rep("Divorced", n[5]))
  )
)

mean_married <- filter(wb_data, status == "Married/CP")$swb |> mean()
mean_cohab <- filter(wb_data, status == "Cohab")$swb |> mean()
mean_single <- filter(wb_data, status == "Single")$swb |> mean()
mean_widowed <- filter(wb_data, status == "Widowed")$swb |> mean()
mean_divorced <- filter(wb_data, status == "Divorced")$swb |> mean()
m3_grand_mean <- mean(c(mean_cohab, mean_divorced, mean_married, mean_single, mean_widowed))
```

```{r echo=F, fig.width=11, fig.asp = .6, fig.align='center'}
p_swb_viol <- wb_data |>
  ggplot(aes(x = status, y = swb, fill = status, colour = status)) +
  geom_violin(alpha = 0.5) +
  geom_jitter(alpha = 0.2, width = 0.2, size = 5) +
  theme(
    legend.position = 'none'
  ) +
  NULL
p_swb_viol
```



## Two research questions

:::{.fragment style="font-size:120%;"}
<br>

1. **Is there a difference in subjective well-being between (1) people who are currently married or in a civil partnership and (2) people who were previously married or in a civil partnership?**

$\rightarrow$ We'll create the contrasts to address this question together.
:::

<br>


:::{.fragment style="font-size:120%;"}
2. **Is there a difference in subjective well-being between (1) people who are currently OR were previously married or in a civil partnership and (2) people who were never married or in a civil partnership?**

$\rightarrow$ You'll create the contrasts for this question with your neighbours.
:::



## Visualising the data these contrasts will analyse (1)

Currently partnered vs. previously partnered:

```{r echo=F, fig.align='center'}
wb_data |>
  mutate(
    current = case_when(
      status == 'Cohab' ~ NA,
      status == 'Divorced' ~ 'previous',
      status == 'Married/CP' ~ 'current',
      status == 'Single' ~ NA,
      status == 'Widowed' ~ 'previous',
    )
  ) |>
  filter(!is.na(current)) |>
  ggplot(aes(x = current, y = swb)) + 
  geom_violin(fill = 'grey', alpha = 0.2) +
  geom_jitter(aes(colour = status), size = 3, alpha = 0.5) +
  NULL
```


## Visualising the data these contrasts will analyse (2)

Has been married vs. never married:

```{r echo=F, fig.align='center'}
wb_data |>
  mutate(
    current = case_when(
      status == 'Cohab' ~ 'never',
      status == 'Divorced' ~ 'has been',
      status == 'Married/CP' ~ 'has been',
      status == 'Single' ~ 'never',
      status == 'Widowed' ~ 'has been',
    )
  ) |>
  filter(!is.na(current)) |>
  ggplot(aes(x = current, y = swb)) + 
  geom_violin(fill = 'grey', alpha = 0.2) +
  geom_jitter(aes(colour = status), size = 3, alpha = 0.5) +
  NULL
```



## Fit model

<br>

```{r}
m3 <- lm(swb ~ status, wb_data)
```

<br>

:::{.fragment}

If we don't specify a coding scheme *a priori*, the model will by default use treatment coding.

The reference level will be the level of the factor that comes first in the alphabet.

<br>

To see the dummy variables the model will use, try `contrasts()`.

```{r}
contrasts(wb_data$status)
```

:::


## Fit model

```{r}
summary(m3)
```

<br>

:::{.fragment .hcenter}
**These hypothesis tests don't address our research questions! We'll need to define our own contrasts.**
:::

::: {.hcenter .fragment style="font-size:125%;"}
<img style="vertical-align: text-bottom; width: 2em;" src="figs/mdi--frequently-asked-questions.svg">
:::


# Defining manual contrasts step by step

## Defining manual contrasts step by step

:::{.fragment}
**Is there a difference in subjective well-being between (1) people who are currently married or in a civil partnership and (2) people who were previously married or in a civil partnership?**
:::

:::: {.columns}
::: {.column width="30%" .fragment}
:::{.hcenter}

| `group`      | `current` |
| ------------ | --------- |
| `Cohab`      |           |
| `Divorced`   |           |
| `Married/CP` |           |
| `Single`     |           |
| `Widowed`    |           |
|||

:::
:::
::: {.column width="70%"}

:::{.dapr2callout .fragment}
**Step 1:** "Chunk" together the two group(s) that the research question is comparing.

- Chunk 1: People who are currently married or in a civil partnership: `Married/CP`.
- Chunk 2: People who were previously married or in a civil partnership: `Divorced`, `Widowed`.
:::

:::
::::

## Defining manual contrasts step by step

**Is there a difference in subjective well-being between (1) people who are currently married or in a civil partnership and (2) people who were previously married or in a civil partnership?**

:::: {.columns}
::: {.column width="30%"}
:::{.hcenter}

| `group`      | `current` |
| ------------ | --------: |
| `Cohab`      | 0         |
| `Divorced`   |           |
| `Married/CP` |           |
| `Single`     | 0         |
| `Widowed`    |           |
|||

:::
:::
::: {.column width="70%"}

:::{.dapr2callout}
**Step 1:** "Chunk" together the two group(s) that the research question is comparing.

- Chunk 1: People who are currently married or in a civil partnership: `Married/CP`.
- Chunk 2: People who were previously married or in a civil partnership: `Divorced`, `Widowed`.
:::

:::{.dapr2callout}
**Step 2:** Assign a 0 to any group(s) that aren't in one of the chunks from Step 1.

- `Cohab`, `Single`
:::

:::
::::


## Defining manual contrasts step by step

**Is there a difference in subjective well-being between (1) people who are currently married or in a civil partnership and (2) people who were previously married or in a civil partnership?**

:::: {.columns}
::: {.column width="30%"}
:::{.hcenter}

| `group`      | `current` |
| ------------ | --------: |
| `Cohab`      | 0         |
| `Divorced`   | –         |
| `Married/CP` | +         |
| `Single`     | 0         |
| `Widowed`    | –         |
|||

:::
:::
::: {.column width="70%"}


:::{.dapr2callout}
**Step 1:** "Chunk" together the two group(s) that the research question is comparing.

- Chunk 1: People who are currently married or in a civil partnership: `Married/CP`.
- Chunk 2: People who were previously married or in a civil partnership: `Divorced`, `Widowed`.
:::


:::{.dapr2callout}
**Step 2:** Assign a 0 to any group(s) that aren't in one of the chunks from Step 1.

- `Cohab`, `Single`
:::


:::{.dapr2callout}
**Step 3:** Assign a plus sign to every group in Chunk 1, and a minus sign to every group in Chunk 2.
:::


:::
::::



## Defining manual contrasts step by step

**Is there a difference in subjective well-being between (1) people who are currently married or in a civil partnership and (2) people who were previously married or in a civil partnership?**

:::: {.columns}
::: {.column width="30%"}
:::{.hcenter}

| `group`      | `current` |
| ------------ | --------: |
| `Cohab`      | 0         |
| `Divorced`   | –         |
| `Married/CP` | +         |
| `Single`     | 0         |
| `Widowed`    | –         |
|||

:::
:::
::: {.column width="70%"}

:::{.dapr2callout}
**Step 4:** Count the plus signs and minus signs.

- Plus: $n_{plus}$ = 1
- Minus: $n_{minus}$ = 2
:::

:::{.dapr2callout .fragment}
**Step 5:** To figure out the actual values for each cell, start with 1 and –1.
Divide 1 by $n_{plus}$, and divide –1 by $n_{minus}$.

- Plus: 1 divided by 1 = 1
- Minus: –1 divided by 2 = –1/2
:::

:::
::::



## Defining manual contrasts step by step

**Is there a difference in subjective well-being between (1) people who are currently married or in a civil partnership and (2) people who were previously married or in a civil partnership?**

:::: {.columns}
::: {.column width="30%"}
:::{.hcenter}

| `group`      | `current` |
| ------------ | --------: |
| `Cohab`      | 0         |
| `Divorced`   | –1/2      |
| `Married/CP` | 1         |
| `Single`     | 0         |
| `Widowed`    | –1/2      |
|||

:::
:::
::: {.column width="70%"}

:::{.dapr2callout}
**Step 4:** Count the plus signs and minus signs.

- Plus: $n_{plus}$ = 1
- Minus: $n_{minus}$ = 2
:::

:::{.dapr2callout}
**Step 5:** To figure out the actual values for each cell, start with 1 and –1.
Divide 1 by $n_{plus}$, and divide –1 by $n_{minus}$.

- Plus: 1 divided by 1 = 1
- Minus: –1 divided by 2 = –1/2
:::

:::{.dapr2callout}
**Step 6:** In the coding matrix, replace the plus signs with the positive coding value from Step 5, and replace the minus signs with the negative coding value from Step 5. **Done!**
:::

:::
::::


## Manual contrasts FAQ

<br>

:::{.incremental}
- <img style="vertical-align: text-bottom; width: 1.2em;" src="figs/twemoji--thinking-face.svg"> **Does it matter which chunk is positive and which chunk is negative?** Not really. It'll change whether the difference that emmeans estimates and tests is positive or negative, but the absolute value of the number should be the same.

- <img style="vertical-align: text-bottom; width: 1.2em;" src="figs/twemoji--thinking-face.svg"> **Can I compare more than two chunks in a single contrast?** No. This is because we're dealing with the slope of a line between two groups. If you want to compare more than two things, then you need more than one contrast.

- <img style="vertical-align: text-bottom; width: 1.2em;" src="figs/twemoji--thinking-face.svg"> **Can I use the exact same chunk in more than one contrast?** No. Using the exact same chunk in more than one contrast is the categorical predictor equivalent of collinearity/non-independence of predictors.

- <img style="vertical-align: text-bottom; width: 1.2em;" src="figs/twemoji--thinking-face.svg"> **How many contrasts can I have?** If you have $k$ groups, you can have up to $k-1$ contrasts. So since we have five groups, we can have up to four contrasts.
:::



::: {.hcenter .fragment style="font-size:125%;"}
<br>

<img style="vertical-align: text-bottom; width: 1.2em;" src="figs/twemoji--thinking-face.svg">  **Any other questions about manual contrasts?** <img style="vertical-align: text-bottom; width: 1.2em;" src="figs/twemoji--thinking-face.svg">
:::



## Testing manual contrasts

Compute `m3`'s estimated marginal means for each level of `status`.

```{r}
m3_emm <- emmeans(m3, ~status)
```

<!-- Like before, we'll use `emmeans`' `contrast()` function to test our manual contrasts. -->

<br>

:::{.fragment}

Next, check the order of levels with `levels()`.

```{r}
levels(wb_data$status)
```

:::

<br>

:::: {.columns .fragment}
::: {.column width="30%"}
:::{.hcenter}

| `group`      | `current` |
| ------------ | --------: |
| `Cohab`      | 0         |
| `Divorced`   | –1/2      |
| `Married/CP` | 1         |
| `Single`     | 0         |
| `Widowed`    | –1/2      |
|||

:::
:::
::: {.column width="70%"}


Then make sure the order of coding values matches the order of levels.

```{r}
m3_comparison1 <- list(
  "current" = c(
       0,  # Cohab
    -1/2,  # Divorced
       1,  # Married/CP 
       0,  # Single
    -1/2   # Widowed
  )
)
```


:::
::::

:::{.fragment}
The estimate we get will be the grand mean of the positive chunk, minus the grand mean of the negative chunk.
:::


## Testing manual contrasts

Using this comparisons list, test the contrast (i.e., test the H0 that the difference between chunks is equal to 0):

```{r}
(m3_contrast1 <- contrast(m3_emm, m3_comparison1))
```

<br>

:::{.fragment}
Get the associated 95% CIs:

```{r}
(m3_confint1 <- confint(m3_contrast1))
```
:::

<br>

:::{.fragment}
Where does this number for `estimate` come from?

It's the grand mean of the positive chunk, minus the grand mean of the negative chunk.

```{r}
mean_married - mean(c(mean_divorced, mean_widowed))
```
:::

<br>

:::{.fragment}
**Can we reject the null hypothesis that there's no difference in subjective well-being between people who are currently married and people who were previously married?**   <img style="vertical-align: text-bottom; width: 1em;" src="figs/codicon--thumbsup-filled.svg"> <img style="vertical-align: text-bottom; width: 1em;" src="figs/codicon--thumbsdown-filled.svg">
:::

# Your turn

## <img style="vertical-align: text-bottom; width: 1.5em;" src="figs/material-symbols--group-outline-rounded.svg"> Your turn: Research question 2

**Is there a difference in subjective well-being between (1) people who are currently OR were previously married or in a civil partnership and (2) people who were never married or in a civil partnership?**

:::: {.columns}
::: {.column width="35%"}
:::{.hcenter}

| `group`      | `evermarried` |
| ------------ | ------------- |
| `Cohab`      |               |
| `Divorced`   |               |
| `Married/CP` |               |
| `Single`     |               |
| `Widowed`    |               |
|||

:::
:::
::: {.column width="65%"}

:::{.dapr2callout}
**Step 1:** "Chunk" together the two group(s) that the research question is comparing.

- Chunk 1: `Divorced`, `Married/CP`, `Widowed`.
- Chunk 2: `Cohab`, `Single`.
:::

:::{.dapr2callout}
**Step 2:** Assign a 0 to any group(s) that aren't in one of the chunks from Step 1.
:::


:::{.dapr2callout}
**Step 3:** Assign a plus sign to every group in Chunk 1, and a minus sign to every group in Chunk 2.
:::

:::{.dapr2callout}
**Step 4:** Count the plus signs and minus signs.
:::

:::{.dapr2callout}
**Step 5:** To figure out the actual values for each cell, start with 1 and –1.
Divide 1 by $n_{plus}$, and divide –1 by $n_{minus}$.
:::

:::{.dapr2callout}
**Step 6:** In the coding matrix, replace the plus signs with the positive coding value from Step 5, and replace the minus signs with the negative coding value from Step 5. **Done!**
:::

:::

::::

## <img style="vertical-align: text-bottom; width: 1.5em;" src="figs/icon-park-outline--muscle.svg"> If you finish early

<br>

- Can you figure out what `emmeans`' estimate for the `evermarried` comparison will be?
- Can you code up your contrast in `emmeans` and test whether the difference between chunks is significantly different from zero?

<br>

```{r echo=F, fig.align='center'}
# # Save EMMs in tibble format, 
# # with compatible column names
# m3_emm_df <- m3_emm |>
#   as_tibble() |>
#   rename(swb = emmean)
# 
# # Plot the data like before, 
# # and now overlay EMMs
# p_swb_viol +
#   geom_errorbar(
#     data = m3_emm_df, 
#     aes(ymin = lower.CL, ymax = upper.CL), 
#     colour = 'black', 
#     width = 0.2,
#     linewidth = 2
#   ) +
#   geom_point(
#     data = m3_emm_df, 
#     colour = 'black', 
#     size = 5
#   )
```


```{r}
levels(wb_data$status)
```

<br>

```{r eval = F}
m3_comparison2 <- list(
  "evermarried" = c(
    ?,  # Cohab
    ?,  # Divorced
    ?,  # Married/CP 
    ?,  # Single
    ?   # Widowed
  )
)
```

<!-- - let someone come up to the computer and type in what they've got? -->
<!-- - run analysis live? that's kinda fun -->

## The results we should expect

```{r include=F}
m3_comparison2 <- list(
  "evermarried" = c(
    -1/2,  # Cohab
     1/3,  # Divorced
     1/3,  # Married/CP 
    -1/2,  # Single
     1/3   # Widowed
  )
)
```


Test the contrast (i.e., test the H0 that the estimate is different from 0):

```{r}
(m3_contrast2 <- contrast(m3_emm, m3_comparison2))
```


:::{.fragment}
Get the associated 95% CIs:

```{r}
(m3_confint2 <- confint(m3_contrast2))
```
:::

:::{.fragment}
Sense check: The `estimate` is the grand mean of the positive chunk, minus the grand mean of the negative chunk.

```{r}
pos_chunk_mean <- mean(c( mean_divorced, mean_married, mean_widowed ))
neg_chunk_mean <- mean(c( mean_cohab, mean_single ))

pos_chunk_mean - neg_chunk_mean
```
:::

:::{.fragment}
**Can we reject the null hypothesis that there's no difference in subjective well-being between people who've ever been married and people who've never been married?** <img style="vertical-align: text-bottom; width: 1em;" src="figs/codicon--thumbsup-filled.svg"> <img style="vertical-align: text-bottom; width: 1em;" src="figs/codicon--thumbsdown-filled.svg">
:::

::: {.hcenter .fragment style="font-size:125%;"}
<img style="vertical-align: text-bottom; width: 2em;" src="figs/mdi--frequently-asked-questions.svg">
:::


# Are the contrasts orthogonal?

## What's "orthogonal"?

<br>

**"Orthogonal"** is a word that makes you sound smart when you really just mean **"perpendicular" = <br> "at a 90 degree angle" = "at a right angle".**

<br>

:::: {.columns}
::: {.column width="50%" .hcenter}

Two orthogonal dimensions:

![](figs/orthogonal-2d-angle.svg){fig-align="center"}

:::
::: {.column width="50%" .hcenter}

Three orthogonal dimensions:

![](figs/orthogonal-3d-angle.svg){fig-align="center"}
:::
::::


## Why is it nice for contrasts to be orthogonal?

If you change the value on one dimension, you don't change the values on orthogonal dimension(s) at all.

:::: {.columns}
::: {.column width="50%" .fragment}

Moving on the y dimension doesn't affect x:

![](figs/orthogonal-2d-points.svg){height="600"}

:::
::: {.column width="50%" .fragment}

Moving on the z dimension doesn't affect x or y:

![](figs/orthogonal-3d-points.svg){height="600"}
:::
::::


:::{.fragment}
In other words, **if you know about y, you know nothing about x.**
This means that orthogonal dimensions, and orthogonal contrasts, contain completely different information.

**Statistical models really like that!**
:::


## Figuring out if contrasts are orthogonal

<br>

:::: {.columns}
::: {.column width="55%"}

:::{.r-stack}

| `group`      | `current` | `evermarried` | product |
| ------------ | --------: | ------------: | ------: |
| `Cohab`      | 0         |  –1/2         |         |
| `Divorced`   | –1/2      |   1/3         |         |
| `Married/CP` | 1         |   1/3         |         |
| `Single`     | 0         |  –1/2         |         |
| `Widowed`    | –1/2      |   1/3         |         |
||||

:::{.fragment data-fragment-index="2"}
| `group`      | `current` | `evermarried` | product |
| ------------ | --------: | ------------: | ------: |
| `Cohab`      | 0         |  –1/2         | 0       |
| `Divorced`   | –1/2      |   1/3         |         |
| `Married/CP` | 1         |   1/3         |         |
| `Single`     | 0         |  –1/2         |         |
| `Widowed`    | –1/2      |   1/3         |         |
||||
:::

:::{.fragment data-fragment-index="3"}
| `group`      | `current` | `evermarried` | product |
| ------------ | --------: | ------------: | ------: |
| `Cohab`      | 0         |  –1/2         |    0    |
| `Divorced`   | –1/2      |   1/3         | –1/6    |
| `Married/CP` | 1         |   1/3         |         |
| `Single`     | 0         |  –1/2         |         |
| `Widowed`    | –1/2      |   1/3         |         |
||||
:::

:::{.fragment data-fragment-index="4"}
| `group`      | `current` | `evermarried` | product |
| ------------ | --------: | ------------: | ------: |
| `Cohab`      | 0         |  –1/2         |    0    |
| `Divorced`   | –1/2      |   1/3         | –1/6    |
| `Married/CP` | 1         |   1/3         |  1/3    |
| `Single`     | 0         |  –1/2         |         |
| `Widowed`    | –1/2      |   1/3         |         |
||||
:::

:::{.fragment data-fragment-index="5"}
| `group`      | `current` | `evermarried` | product |
| ------------ | --------: | ------------: | ------: | 
| `Cohab`      | 0         |  –1/2         |    0    |
| `Divorced`   | –1/2      |   1/3         | –1/6    |
| `Married/CP` | 1         |   1/3         |  1/3    |
| `Single`     | 0         |  –1/2         |    0    |
| `Widowed`    | –1/2      |   1/3         |         |
||||
:::

:::{.fragment data-fragment-index="6"}
| `group`      | `current` | `evermarried` | product |
| ------------ | --------: | ------------: | ------: |
| `Cohab`      | 0         |  –1/2         |    0    |
| `Divorced`   | –1/2      |   1/3         | –1/6    |
| `Married/CP` | 1         |   1/3         |  1/3    |
| `Single`     | 0         |  –1/2         |    0    |
| `Widowed`    | –1/2      |   1/3         | –1/6    |
||||
:::


:::



:::
::: {.column width="45%"}
:::{.fragment data-fragment-index="1"}

1. Multiply the weights for each level together.

:::

:::{.fragment data-fragment-index="7"}
2. Add all of those products together.

  - If this sum = 0, then the contrasts are orthogonal.
  - If this sum $\neq$ 0, then the contrasts are non-orthogonal.
:::

:::

::::


:::{.fragment .hcenter data-fragment-index="8"}
<br>

**0 &nbsp;&nbsp;&nbsp; +&nbsp;&nbsp;&nbsp; –1/6 &nbsp;&nbsp;&nbsp;+ &nbsp;&nbsp;&nbsp;1/3 &nbsp;&nbsp;&nbsp;+ &nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;+ &nbsp;&nbsp;&nbsp; –1/6 &nbsp;&nbsp;&nbsp;**
:::
:::{.fragment .hcenter data-fragment-index="9"}
**= &nbsp;&nbsp;&nbsp; 0**
:::
:::{.fragment .hcenter data-fragment-index="10"}
<br>
Orthogonal!
:::

## Why does it matter if contrasts are orthogonal?

<br>

It affects how we interpret the contrasts.

<br>

:::{.fragment}

**If contrasts are orthogonal:**

- They are independent from one another.
- They test mutually independent hypotheses about the data.
- "Orthogonal" is the categorical version of "uncorrelated".

:::

<br>

:::{.fragment}

**If they're not orthogonal: **

- "Not orthogonal" is the categorical version of "correlated".
- Contrasts contain some of the same information. (this idea will come up again next week).
- It's not obvious which contrast is contributing what information to the outcome, so estimates are harder to interpret.

:::

<br>

:::{.fragment}

**If at all possible, create orthogonal contrasts. Your life will be easier.**

:::

::: {.hcenter .fragment style="font-size:125%;"}

<br>

<img style="vertical-align: text-bottom; width: 2em;" src="figs/mdi--frequently-asked-questions.svg">
:::


<!-- ======================================== -->

## Building an analysis workflow

<br> 

::: {.r-stack}
![](figs/block2-flowchart-07-0.svg){.fragment height="550" }

![](figs/block2-flowchart-07-1.svg){.fragment height="550" }

:::





## Revisiting this week's learning objectives

::: {style="font-size: 125%;"}

:::{}
::: {.dapr2callout .fragment}
**Dummy coding is one common scheme for *a priori* contrast coding. What's another common scheme, and how is it different?**

::: {style="font-size: 80%;"}
- Effects coding, also called sum-to-zero coding (or just "sum coding").
- Dummy coding uses 0/1, and one level of the predictor (the one coded as 0) is the reference level.
- Effects coding uses –1/1, and there is no reference level.
:::

:::
:::

::: {}
::: {.dapr2callout .fragment}
**When we code predictors using this other coding scheme, how do we interpret the linear model's coefficients?**

::: {style="font-size: 80%;"}
- Intercept (also written as $\beta_0$): The grand mean of the outcome (grand mean = the mean of every group's mean).
- Slope (also written as $\beta_1$, $\beta_2$, etc., or for short, $\beta_j$): The difference between (1) the mean of a group and (2) the grand mean, when all other predictors are at zero.
:::

:::
:::

:::

## Revisiting this week's learning objectives


::: {style="font-size: 125%;"}

::: {}
::: {.dapr2callout}
**In this other coding scheme, what hypotheses are tested for each coefficient?**

::: {style="font-size: 80%;"}
- The intercept's hypothesis test: The grand mean of the outcome is different from zero.
- The slopes' hypothesis tests: The difference between (1) the mean of each individual group and (2) the grand mean is different from zero.
:::

:::
:::

::: {}
::: {.dapr2callout .fragment}
**How can we test hypotheses other than the ones tested by *a priori* coding schemes?**

::: {style="font-size: 80%;"}
- Use a linear model to generate the expected outcome values for every level of our predictors (= the expected marginal means).
- We can compare expected marginal means of any combination of groups we want by manually creating our own contrasts.
- There is a step-by-step process we can follow to create any contrasts we want.
:::

:::
:::

:::




## This week {}

<br>

:::: {.columns}
::: {.column width="50%"}

### Tasks

<br>

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/labs.svg')
```

**Attend your lab and work together on the exercises** 

:::
::: {.column width="50%"}

### Support

<br>

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/forum.svg')
```

**Help each other on the Piazza forum**

:::
::::

<br>

:::: {.columns}
::: {.column width="50%"}

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/exam.svg')
```

**Complete the weekly quiz**

:::
::: {.column width="50%"}

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/oh.png')
```

**Attend office hours (see Learn page for details)**

:::
::::


# Appendix {.appendix}


## Prediction equations: Effect coding, three levels

The linear expression telling us model predictions:

$$
\widehat{\text{outcome}}= \hat{\beta_0} + (\hat{\beta_1} \cdot \text{Predictor1}) + (\hat{\beta_2} \cdot \text{Predictor2})
$$
<br>

We can combine the estimated betas to compute the means of each level.
To do this, we plug in the values for `Predictor1` and `Predictor2` that correspond to each level of the three-level variable.
We get these values from the rows of our our coding matrix.

<br>

:::: {.columns}
::: {.column width="20%"}

```{r}
contr.sum(3)
```

:::
::: {.column width="5%"}
:::
::: {.column width="75%"}

**Level 1** is represented as `Predictor1 = 1`, `Predictor2 = 0` <br> (first row of contrast matrix). 

$$
\begin{align}
\widehat{\text{outcome}}_{\text{level 1}} &= \hat{\beta_0} + (\hat{\beta_1} \cdot \text{Predictor1}) + (\hat{\beta_2} \cdot \text{Predictor2})\\
&= \hat{\beta_0} + (\hat{\beta_1} \cdot 1) + (\hat{\beta_2} \cdot 0)\\
&= \hat{\beta_0} + \hat{\beta_1}\\
\end{align}
$$

:::
::::


## Prediction equations: Effect coding, three levels

:::: {.columns}
::: {.column width="20%"}

```{r}
contr.sum(3)
```

:::
::: {.column width="5%"}
:::
::: {.column width="75%"}

**Level 2** is represented as `Predictor1 = 0`, `Predictor2 = 1` <br> (second row of contrast matrix). 

$$
\begin{align}
\widehat{\text{outcome}}_{\text{level 2}} &= \hat{\beta_0} + (\hat{\beta_1} \cdot \text{Predictor1}) + (\hat{\beta_2} \cdot \text{Predictor2})\\
&= \hat{\beta_0} + (\hat{\beta_1} \cdot 0) + (\hat{\beta_2} \cdot 1)\\
&= \hat{\beta_0} + \hat{\beta_2}\\
\end{align}
$$


<br>

**Level 3** is represented as `Predictor1 = -1`, `Predictor2 = -1` <br> (third row of contrast matrix). 

$$
\begin{align}
\widehat{\text{outcome}}_{\text{level 3}} &= \hat{\beta_0} + (\hat{\beta_1} \cdot \text{Predictor1}) + (\hat{\beta_2} \cdot \text{Predictor2})\\
&= \hat{\beta_0} + (\hat{\beta_1} \cdot -1) + (\hat{\beta_2} \cdot -1)\\
&= \hat{\beta_0} - \hat{\beta_1} - \hat{\beta_2}\\
&= \hat{\beta_0} - (\hat{\beta_1} + \hat{\beta_2})\\
\end{align}
$$

:::
::::



## Grand mean vs. overall mean of the data

The grand mean is the mean of the group means.

**The grand mean is sometimes, but not always, the overall mean of the observed data.**

- When the groups are all exactly the same size, then the grand mean = the overall mean of observed data.
- But when the groups are different sizes (like with the subjective well-being data), then the grand mean $\neq$ the overall mean.

```{r}
wb_data |>
  group_by(status) |>
  count()
```

<br>

:::: {.columns}
::: {.column width="50%"}
The mean of all `swb` values (*not* the grand mean):

```{r}
wb_data$swb |> mean()
```

:::
::: {.column width="50%"}

The grand mean (*not* the mean of all `swb` values):

```{r}
mean(c(mean_cohab, mean_divorced, mean_married, mean_single, mean_widowed))
```
:::
::::






## Visualise effect coding with >2 levels

```{r}
contrasts(score_data$method)
```

```{r echo=F, fig.asp = .5, fig.width = 18}
xlim_lower <- -2.2
xlim_upper <-  2.2
ylim_lower <- -25
ylim_upper <-  55

p1 <- score_data |> 
  filter(method %in% c('summarise', 'read')) |>
  mutate(method_num = ifelse(method == 'summarise', -1, 1)) |>
  ggplot(aes(x = method_num, y = score, fill = method, colour = method)) +
  geom_jitter(alpha = 0.2, width = 0.1, size = 5) +
  scale_x_continuous(limits = c(xlim_lower, xlim_upper), expand = c(0, 0)) +
  scale_y_continuous(limits = c(ylim_lower, ylim_upper), expand = c(0, 0)) +
  # xy vectors
  geom_segment(aes(x = xlim_lower, xend = xlim_upper, y = 0, yend = 0), arrow = arrow(ends = 'both', length = unit(12, 'pt')), colour = 'black') +
  geom_segment(aes(x = 0, xend = 0, y = ylim_lower, yend = ylim_upper), arrow = arrow(ends = 'both', length = unit(12, 'pt')), colour = 'black') +
  # group means
  stat_summary(fun = mean, geom = 'point', colour = 'black', size = 5, show.legend = FALSE) +
  # line between group means
  geom_segment(aes(x = -1, xend = 1, y = mean_summ, yend = mean_read), colour = 'black', linetype = 'dotted') +
  # slope lines
  geom_segment(aes(x = 0, xend = 1, y = m2_grand_mean, yend = m2_grand_mean), colour = dapr2red, linewidth = 2) +
  geom_segment(aes(x = 1, xend = 1, y = m2_grand_mean, yend = mean_read), colour = dapr2red, linewidth = 2) +
  # grand mean
  geom_point(x = 0, y = m2_grand_mean, colour = 'black', size = 8, show.legend = F, shape = 4) +
  labs(
    x = 'method (in numeric space,\n first predictor)'
  ) +
  theme(legend.position = 'bottom') +
  scale_colour_manual(values = c(pal[1], pal[3])) +
  guides(colour = guide_legend(override.aes = list(alpha = 1), nrow = 2, byrow = TRUE)) +
  NULL

p2 <- score_data |> 
  filter(method %in% c('summarise', 'self-test')) |>
  mutate(method_num = ifelse(method == 'summarise', -1, 1)) |>
  ggplot(aes(x = method_num, y = score, fill = method, colour = method)) +
  geom_jitter(alpha = 0.2, width = 0.1, size = 5) +
  scale_x_continuous(limits = c(xlim_lower, xlim_upper), expand = c(0, 0)) +
  scale_y_continuous(limits = c(ylim_lower, ylim_upper), expand = c(0, 0)) +
  # xy vectors
  geom_segment(aes(x = xlim_lower, xend = xlim_upper, y = 0, yend = 0), arrow = arrow(ends = 'both', length = unit(12, 'pt')), colour = 'black') +
  geom_segment(aes(x = 0, xend = 0, y = ylim_lower, yend = ylim_upper), arrow = arrow(ends = 'both', length = unit(12, 'pt')), colour = 'black') +
  # group means
  stat_summary(fun = mean, geom = 'point', colour = 'black', size = 5, show.legend = FALSE) +
  # line between group means
  geom_segment(aes(x = -1, xend = 1, y = mean_summ, yend = mean_self), colour = 'black', linetype = 'dotted') +
  # slope lines
  geom_segment(aes(x = 0, xend = 1, y = m2_grand_mean, yend = m2_grand_mean), colour = dapr2red, linewidth = 2) +
  geom_segment(aes(x = 1, xend = 1, y = m2_grand_mean, yend = mean_self), colour = dapr2red, linewidth = 2) +
  # grand mean
  geom_point(x = 0, y = m2_grand_mean, colour = 'black', size = 8, show.legend = F, shape = 4) +
  labs(
    x = 'method (in numeric space,\nsecond predictor)'
  ) +
  theme(legend.position = 'bottom') +
  scale_colour_manual(values = c(pal[2], pal[3])) +
  guides(colour = guide_legend(override.aes = list(alpha = 1), nrow = 2, byrow = TRUE)) +
  NULL

p1 + p2
```

The $\times$ shows the grand mean = the model's intercept.

**Once effect coding uses >2 levels, the line between group means does not give us the correct intercept or slope.**



## `evermarried`

<br>

:::: {.columns}
::: {.column width="50%"}
| `group`      | `evermarried` |
| ------------ | ------------: |
| `Cohab`      | –1/2          |
| `Divorced`   |  1/3          |
| `Married/CP` |  1/3          |
| `Single`     | –1/2          |
| `Widowed`    |  1/3          |
|||
:::
::: {.column width="50%"}
```{r eval=F}
m3_comparison2 <- list(
  "evermarried" = c(
    -1/2,  # Cohab
     1/3,  # Divorced
     1/3,  # Married/CP 
    -1/2,  # Single
     1/3   # Widowed
  )
)
```
:::
::::




<!-- :::: {.columns} -->
<!-- ::: {.column width="50%"} -->
<!-- a -->
<!-- ::: -->
<!-- ::: {.column width="50%"} -->
<!-- b -->
<!-- ::: -->
<!-- :::: -->

<!-- style="font-size: 125%;" -->

<!-- <img style="vertical-align: text-bottom; width: 1.2em;" src="figs/twemoji--thinking-face.svg"> -->