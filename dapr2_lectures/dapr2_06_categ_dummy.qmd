---
title: "Categorical predictors and dummy coding"
author: "Elizabeth Pankratz (elizabeth.pankratz@ed.ac.uk)"
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
library(tidyverse)
library(patchwork)
source('_theme/theme_quarto.R')
```


## Course Overview {.smaller}

<br>

:::: {.columns}

::: {.column width="50%"}

```{r echo = FALSE, results='asis', warning = FALSE}
block1_name = "Introduction to Linear Models"
block1_lecs = c("Intro to Linear Regression",
                "Interpreting Linear Models",
                "Testing Individual Predictors",
                "Model Testing & Comparison",
                "Linear Model Analysis")
block2_name = "Analysing Experimental Studies"
block2_lecs = c("Categorical Predictors & Dummy Coding",
                "	Effects Coding & Coding Specific Contrasts",
                "Assumptions & Diagnostics",
                "Bootstrapping",
                "	Categorical Predictor Analysis")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")

course_table(block1_name,block2_name,block1_lecs,block2_lecs,week = 6)
```

:::

::: {.column width="50%"}

```{r echo = FALSE, results='asis', warning = FALSE}
block3_name = "Interactions"
block3_lecs = c("Interactions I",
                "Interactions II",
                "Interactions III",
                "Analysing Experiments",
                "Interaction Analysis")
block4_name = "Advanced Topics"
block4_lecs = c("Power Analysis",
                "Binary Logistic Regression I",
                "Binary Logistic Regression II",
                "Logistic Regression Analysis",
                "	Exam Prep and Course Q&A")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")

course_table(block3_name,block4_name,block3_lecs,block4_lecs,week = 0)
```

:::

::::

## This week's learning objectives

<br>

::: {.fragment}
::: {.dapr2callout}
How can we include categorical variables as predictors in a linear model?
:::
:::

::: {.fragment}
::: {.dapr2callout}
When we use a categorical predictor, how do we interpret the linear model’s coefficients?
:::
:::

::: {.fragment}
::: {.dapr2callout}
What hypotheses are tested by the default way that R represents categorical predictors?
:::
:::

::: {.fragment}
::: {.dapr2callout}
If we wanted to test different hypotheses, how would we do that?
:::
:::



## Building an analysis workflow – Lecture 6

<br> 

::: {.r-stack}
![](figs/block2-flowchart-06-0.svg){.fragment height="550" }

![](figs/block2-flowchart-06-1.svg){.fragment height="550" }

![](figs/block2-flowchart-06-2.svg){.fragment height="550" }
:::





## Revisiting this week's learning objectives

::: {.fragment}
::: {.dapr2callout}
**How can we include categorical variables as predictors in a linear model?**

::: {style="font-size: 80%;" .incremental}
- Represent the variable numerically, for example using dummy coding (also called treatment coding).
- In dummy coding, the reference level (also called baseline level) is represented ("coded") as 0, and the non-reference level is coded as 1.
- For categorical predictors with >2 levels, dummy coding uses "dummy variables" to individually compare each non-reference level to the same reference level.
:::

:::
:::

::: {.fragment}
::: {.dapr2callout}
**When we use a categorical predictor, how do we interpret the linear model's coefficients?**

::: {style="font-size: 80%;" .incremental}
- Intercept (also written as $\beta_0$): The mean outcome for the reference level.
- Slope (also written as $\beta_1$, $\beta_2$, etc., or for short, $\beta_j$): The difference between (1) the mean outcome for the non-reference level and (2) the mean outcome for the reference level.
:::
:::
:::

## Revisiting this week's learning objectives

::: {.fragment}
::: {.dapr2callout}
**What hypotheses are tested by the default way that R represents categorical predictors?**

::: {style="font-size: 80%;" .incremental}
- By default, R uses dummy coding/treatment coding. And by default, the reference level is the level that comes first in the alphabet.
- The intercept's hypothesis test: The mean outcome for the reference level is different from zero.
- The slope's hypothesis test: The difference between the (1) mean outcome for the non-reference level and (2) the mean outcome for the reference level is different from zero.
:::
:::
:::

::: {.fragment}
::: {.dapr2callout}
**If we wanted to test different hypotheses, how would we do that?**

::: {style="font-size: 80%;" .incremental}
- We can use a linear model not just to estimate intercept and slope parameters, but also to estimate what we'd expect our outcome variable to be for every value of our predictor(s).
- These expected outcome values are called "expected marginal means".
- By comparing expected marginal means, we can test basically any hypotheses we want.

:::
:::
:::



## This Week 

<br>

:::: {.columns}
::: {.column width="50%"}

### Tasks

<br>

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/labs.svg')
```

**Attend your lab and work together on the exercises** 

:::
::: {.column width="50%"}

### Support

<br>

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/forum.svg')
```

**Help each other on the Piazza forum**

:::
::::

<br>

:::: {.columns}
::: {.column width="50%"}

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/exam.svg')
```

**Complete the weekly quiz**

:::
::: {.column width="50%"}

```{r, echo = F, out.width='15%'}
knitr::include_graphics('figs/oh.png')
```

**Attend office hours (see Learn page for details)**

:::
::::







