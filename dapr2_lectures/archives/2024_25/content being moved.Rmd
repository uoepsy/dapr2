---
title: "<b> Content needing new home </b>"
subtitle: "Data Analysis for Psychology in R 2<br><br> "
author: "dapR2 Team"
institute: "Department of Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
library(kableExtra)
library(simglm)

knitr::opts_chunk$set(out.width = '80%')

theme_set(theme_gray(base_size = 15))

baseColour <- "#BF1932"
```


```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #base_color = "#0F4C81", # DAPR1
   base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```


---
# A little more to say on residuals

$$y_i = \beta_0 + \beta_1 x_{i} + \epsilon_i$$

+ Recall last lecture we said that $\epsilon_i \sim N(0, \sigma)$ independently.

+ This means $\epsilon_i$ ...
  + are distributed ( $\sim$ )
    + a normal distribution ( $N$ )
      + with a mean of 0 ( $N(0,$ )
        + and a standard deviation of $\sigma$
  
+ $\sigma$ = standard deviation (spread) of the errors
  + $\sigma$, is constant, meaning that at any point along the x-axis, the spread of the residuals should be the same.
  
---
# Visualizing $sigma$

```{r echo = FALSE, message = FALSE, warning = FALSE}

n = 300
df1 <- tibble(
  x = runif(n, 1, 6),
  y = 3 + 2 * x + rnorm(n, 0, 0.4)
)

p1 <- ggplot(df1, aes(x, y)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  ylim(4, 20)


n = 300
df2 <- tibble(
  x = runif(n, 1, 6),
  y = 3 + 2 * x + rnorm(n, 0, 2.5)
)

p2 <- ggplot(df2, aes(x, y)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  ylim(4, 20)
```

.pull-left[
<center>**Small $\sigma$**</center>
```{r echo = FALSE, message = FALSE, warning = FALSE, out.width = '90%', fig.align='center'}
p1
```
]

.pull-right[
<center>**Large $\sigma$**</center>
```{r echo = FALSE, message = FALSE, warning = FALSE, out.width = '90%', fig.align='center'}
p2
```
]

???
+ The less scatter around the line, 
  + the smaller the standard deviation of the errors
  + the stronger the relationship between $y$ and $x$. 

---
# What is $\sigma$?

+ We estimate $\sigma$ using the residuals from our model

+ The estimated standard deviation of the errors is:
$$\hat \sigma = \sqrt{\frac{SS_{Residual}}{n - k - 1}} = \sqrt{\frac{\sum_{i=1}^n(y_i - \hat y_i)^2}{n - k - 1}}$$

+ In simple linear regression we only have one $x$, so $k = 1$ and the denominator becomes $n - 2$.

+ $\sigma$ and its properties will turn up a few times in this course.

     
      
      