---
title: "<b> Class Feedback: Group Report </b>"
subtitle: "Data Analysis for Psychology in R 2<br><br> "
author: "DAPR2 Team"
institute: "Department of Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #base_color = "#0F4C81", # DAPR1
   base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(car)
library(patchwork)
library(kableExtra)
```

# Overview
+ Brief overview of correct models for RQ1 & RQ2
+ Outline some of the most common mistakes across reports
  + Some of the points discussed  are fundamental, in that it is not possible to correctly and fully answer the questions if this was done. Others are less fundamental, but are the things that differentiate a passing grade from a high grade. 
  + Non-exhaustive list - look at your individual feedback comments

---
# Correct Models
+ The most concise way to answer both questions, was to:
  + fit a model which included aggressive behaviour and dark triad personality trait variables as covariates, both categorical variables (i.e., condition and character), and their interaction for RQ1
  + from this model, a specific contrast could then be coded to answer RQ2

---
# Correct Model

To address RQ1: **do differences in game-induced-stress between player character conditions depend on the playing condition**

```{r, eval = FALSE}
m1 <- lm(dcortisol~AGQ+M+N+P+condition*character, data = df)
```

---

# Correct Contrast

To address RQ2: **whether the difference in game-induced-stress between player character conditions differs between those playing in non-immersive conditions and immersive conditions**

```{r, eval = FALSE}
# compare those who played in non-immersive to immersive conditions
condition_coef  <- c('tablet' = -.5, 'console' = -.5, 'vr' = 1)

#compare person and cartoon player character conditions
character_coef  <- c('person' = 1, 'cartoon' = -1)

#combine individual weights into the interaction
contr = condition_coef %o% character_coef  
contr

# call emmeans to check ordering of coefficients 
emm <- emmeans(m1,~condition*character)
emm

# insert the coefficients following the order specified by the rows of emm above
comp <- contrast(emm, method = list('player character, non-immersive vs immersive' = c(-0.5, -0.5, 1, 0.5, 0.5, -1)))
summary(comp, infer=T)
```

---
class: center, middle

# Common Errors

---

# Covariates: None Included
+ The questions specifically asked: "The researchers want to know whether, **after accounting for aggressive behaviour and dark triad personality traits**:

  a. do differences in game-induced-stress between player character conditions depend on the playing condition.
  
  b. whether the difference in game-induced-stress between player character conditions differs between those playing in non-immersive conditions and immersive conditions."

+ This means that the three personality variables and the aggressive behaviour variable need to be in all models. If these were not included, the questions could not be answered

---
# Covariates: Inclusion Based on Significance

Selecting only a small number of the covariates (i.e., personality and agression) based on their relation to the DV

+ Lacked rationale given RQs. Why?
  + If we have covariates we want to control for, we want them in a model whether their effect is significant or not. This is because although the effects may not be large enough to meet our $\alpha$ threshold, it is unlikely their effect is 0. 
  + By wrongfully excluding some covariates, our resulting estimates of player character & playing conditions may differ in part be due to differences in those covariates

+ When would this have been appropriate?
  + If a covariate had very high multicollinearity
  + If we believed that there were many model influential cases based on responses to the covariate
  + If we had a small sample size and lots of covariates to control for  
+ Very few students provided any sort of rationale based on the above for only including a subset of covariates, most focused on significance

---
# Covariates: Combining All Dark Triad Traits

+ A number of reports included the creation of a new variable, where scores for Machiavellianism, Narcissism, and Psychopathy were combined into a single measure. 

+ Lacked rationale.
  + These traits are distinct - they each measure a different trait of the Dark Triad
  + Not appropriate to combine 

---
# Covariates: Model Comparison with and without Covariates

+ A number of reports fit a model without the covariates, and interpreted this for questions Q1 and Q2, then fit a model with covariates and compared this based on $F$-tests to the model without
+ This was a redundant analysis - we need to control for covariates in all models, not interested in whether their inclusion improved model fit
    
---
# Interaction: Not Specified

+ Both RQ1 and RQ2 both required looking at an interaction 
  + RQ1: Interaction concerned playing condition and player character
  + RQ2: Same variables but the interaction of the specific contrasts (see the creation of 'contr' in the code on slide 5). 
+ If these were not included, the questions could not be answered

---
# Contrast: Not Specified

**Combining levels**
+ No contrast given for RQ2, instead a second interaction model used where a new binary variable was created where observation condition now contained only 2 levels - 'immersive' and 'non-immersive' 
  + Not optimal or efficient

**Simple effects / pairwise tests**
+ The particular combination of averaging across levels of playing conditions conditions could not be achieved through either simple or pairwise effects
  + Unable to answer RQ2 using this approach

---
# Specification: Models

+ The model should have contained 10 $\beta$ coefficients (including the intercept):
  + 1 for intercept
  + 3 for personality (1 for each of the dark triad traits)
  + 1 for aggressive behaviour
  + 2 for playing condition $(k-1 = 3-1 = 2)$
  + 1 for player character condition $(r-1 = 2-1 = 1)$
  + 2 for interaction $((r-1)(k-1) = (3-1)(2-1) = (2)(1) = 2)$

+ Common for reports to contain model in the form of R code (i.e., included 8 $\beta$ coefficients (including the intercept) where there was:
  + 1 for playing condition
  + 1 for player character condition
  + 1 for interaction
  
+ Less common: Dark Triad traits to be 'combined' and represented by one $\beta$ coefficient instead of three
  + Not appropriate or correct
  
---
# Specification: Null & Alternative Hypotheses

+ Errors mostly followed from previous mis-specification of model, where many reports then suggested that RQ1 could be answered by evaluating a single $\beta$ coefficient (e.g., $H_0: \beta_{8} = 0$)

+ Some suggested that both interaction $\beta$ coefficients had to $\neq$ 0 in alternative hypothesis

+ In some cases, no hypotheses formally stated or described in text - unclear what models were being used to test

---
# Assumptions: Details

**Analysis Strategy**
+ In many cases there was insufficient information given concerning assumption checks. What needs to be included:
  + the assumption being evaluated
  + the plot used to evaluate this assumption
  + how you would determine whether the assumption was met
  + what you will do if there is a violation
  
**Results**
+ Linearity of model assumed, but the covariates were continuous - needed to check this   
+ Many just referred to appendix with no comment on how the assumptions were met. What needs to be included:
  + reference to all assumptions mentioned in analysis strategy
  + evaluation of plot - how we know the assumption was met
  + any action taken if assumption violated (e.g., removed $n$ outliers since [insert criteria to justify])

---
# Assumptions: Plagarism

+ Most obvious area where copying and pasting from labs occurred, with very minor or no changes to wording
+ Message contained in labs and write-up labs:

.pull-left[

**Labs**

```{r echo=FALSE, out.width = '100%'}
knitr::include_graphics('figs/lab_plagarism2324_lbs.png')
```

]

.pull-right[

**Write-Up & Recap Labs**

```{r echo=FALSE, out.width = '100%'}
knitr::include_graphics('figs/lab_plagarism2324.png')
```

]
---
# Analysis Strategy: Unable to Replicate

+ Report instructions: "A reader of your compiled report should be able to more or less replicate your analyses without referring to your R code"
  + Data checks not mentioned (e.g., were scores in range? Were there NA values?)
  + No statement of alpha 
  + Not clear which coding scheme was used (or why)
  + Not stated what reference levels were used or why certain levels were chosen (i.e., lacking rationale)
  + Models and/or hypotheses not formally presented or described in words (or there was a mis-match)
  + Weights for contrast not provided
  + Specifying a hypothesis for contrast analysis, but not stating what values represented 
  + No mention or limited discussion of assumptions (what criteria was used?)
  
---

# Interpretation: Errors or Issues with Detail

**Errors**
+ Mis-interpretation of results (e.g., estimates and/or significance), especially of interaction coefficents
+ Incorrect contrast estimate
  + Failed to check that the ordering of the weights matched the order of the levels within `emmeans`. This resulted in the incorrect value for the contrast
  + How/why did this happen? Typically when factors were re-ordered or re-labelled incorrectly
  
**Missing / Lacking Detail**
+ Level of interpretation in the reports was very low, largely focusing on statistical significance
+ Tables / figures presented, but not interpreted (e.g., only stating that descriptive statistics are presented in Table 1)

**Too Much Detail**
+ Reporting every single coefficient contained in the model output. Important in the results to focus on what is relevant to the RQs
+ Repetition of findings - e.g., repeated across tables/figures/in-text

---

# Interpretation: What we Wanted to See

**Results**  
+ All key model results presented  
+ A focus on the coefficients of interest - a full interpretation of *key* results 
+ Interpretation of the direction and magnitude of effects that were relevant  

**Discussion**
+ Summary of findings for *both* RQs framed in relation to the questions not specific results
+ Results summarised into concise and accurate take-home messages that provided a clear answer to the study RQs   

---

# Instructions: Structure

+ Report instructions: "Your report should include three sections: 1. Analysis Strategy 2. Results 3. Discussion (very brief)"
  + Many reports did not follow the above structure - some included no sections, others included many more sections

+ Report instructions: "Your analysis strategy should not contain any results."
  + Some reports included descriptive statistics in this section and/or results from assumption checks

+ Report instructions: "The Discussion section should contain very brief (1-2 sentence) summary statements linking the formal results to each of the research questions. The marking of this section will be based on the coherence and accuracy of these statements. This should not introduce any new statistical results, nor repeat detailed statistical results, but should refer to those presented in the analysis"
  + Discussion sections were often too long
  + Some included reporting of statistical results (either repeated from results section or new)
  + Lack of linking to RQs, especially RQ2 (e.g., no statement of direction of difference)

---

# Instructions: R Code/Output

+ Report instructions: "**Code chunks should be hidden** in the pdf produced by your rmd file. To tell RMarkdown to not show your code when knitting to HTML, add `echo=FALSE` next to the `r` that [appears after the backticks](https://uoepsy.github.io//rmd-bootcamp/05-echoeval.html). There should be no visible R code or direct output in your report. For a guide on writing and formatting in RMarkdown, you may find these resources helpful:

  + [UoEPsy Rmd-Bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/)  
  + [RMarkdown CheatSheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)  
  + [Writing Math in Rmd](https://rpruim.github.io/s341/S19/from-class/MathinRmd.html#:~:text=Math%20inside%20RMarkdown,10n%3D1n2)"   

+ Common issues:
  
  + Many reports included R code and/or direct R output -- make sure to check your PDF files before submission
  + Not creating own tables (e.g., printing contrast weights R object instead of creating table)
  + Not checking chunk options
  + Writing in R chunks as comments (i.e., using #) instead of as normal text
  
---
# Instructions: Key Tables/Figures in Appendix

Report instructions: 
+ "The assumption appendix is only for assumption and diagnostic figures and results. Any results from your main models including in the appendix will not be marked"
+ "All key model results should be presented (tables very useful) in the main body of the report"

+ These should have been in the main text if they contain the results for models you set out in your analysis strategy.

---
# Instructions: Formatting

+ Report instructions: "Reporting should be clear and consistent. If in doubt, follow APA 7th Edition guidelines."
  + Often numbers rounded to varying decimal points
  
+ Report instructions: "Figures and tables should be numbered and captioned, and referred to in the text; important statistical outcomes should be summarised in the text"
  + Figures and/or tables often not numbered or captioned
  + Often figure/table presented, but not commented on or referred to at all
  
+ Report instructions: "If you cannot knit to pdf, then try the following steps:
1) Knit to html file 2) Open your html in a web-browser (e.g. Chrome, Firefox) 3) Print to pdf (Ctrl+P, then choose to save to pdf) 4) Submit the pdf you just saved"
  + A number of students submitted 1 page PDF docs which were very difficult to read due to size issues

+ Presentation issues with model equations - often cut-off and full equation not shown on page. Need to knit regularly while you are writing to check that models, tables, plots, etc. are displaying as you intended and correctly

---
class: center, middle

# **Any Questions?**
