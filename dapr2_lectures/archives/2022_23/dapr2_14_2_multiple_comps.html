<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title> Multiple Comparisons </title>
    <meta charset="utf-8" />
    <meta name="author" content="dapR2 Team" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <b> Multiple Comparisons </b>
]
.subtitle[
## Data Analysis for Psychology in R 2<br><br>
]
.author[
### dapR2 Team
]
.institute[
### Department of Psychology<br>The University of Edinburgh
]

---









# Lecture Objectives
1. Understand post-hoc pairwise comparisons and when they are useful 
2. Apply pairwise testing with `emmeans`
3. Understand the multiple testing problem
4. Be able to apply and interpret results with adjustments for multiple comparisons


---
# Models for today

```r
m1 &lt;- lm(SWB ~ Treatment + Hospital + Treatment*Hospital, data = hosp_tbl,
         contrasts = list(Treatment = contr.sum, 
                          Hospital = contr.sum)) # you can code contrasts within lm

m1_emm &lt;- emmeans(m1, ~Treatment*Hospital)
```


---
# Pairwise comparisons
+ So far we have been discussing tests which move from the very general to the specific:
  + Overall model F
  + Incremental F/ F per condition
  + Contrasts and codes
  + Simple effects
  
+ But we have one more layer that more closely aligns to looking at the `\(\beta\)` coefficients, namely a fully exploratory pairwise analysis.

---
# Pairwise comparisons
+ As the name suggests, pairwise comparisons compare all levels of a given predictor variable with all levels of the other.


```r
pairs_res &lt;- pairs(m1_emm, adjust = "none")
```

---
# Pairwise comparisons


```
##  contrast                    estimate    SE  df t.ratio p.value
##  TreatA Hosp1 - TreatB Hosp1    1.370 0.523 174   2.619  0.0096
##  TreatA Hosp1 - TreatC Hosp1    0.697 0.523 174   1.332  0.1847
##  TreatA Hosp1 - TreatA Hosp2    2.947 0.523 174   5.632  &lt;.0001
##  TreatA Hosp1 - TreatB Hosp2   -2.317 0.523 174  -4.428  &lt;.0001
##  TreatA Hosp1 - TreatC Hosp2    2.820 0.523 174   5.390  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp1   -0.673 0.523 174  -1.287  0.1998
##  TreatB Hosp1 - TreatA Hosp2    1.577 0.523 174   3.014  0.0030
##  TreatB Hosp1 - TreatB Hosp2   -3.687 0.523 174  -7.047  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp2    1.450 0.523 174   2.772  0.0062
##  TreatC Hosp1 - TreatA Hosp2    2.250 0.523 174   4.301  &lt;.0001
##  TreatC Hosp1 - TreatB Hosp2   -3.013 0.523 174  -5.760  &lt;.0001
##  TreatC Hosp1 - TreatC Hosp2    2.123 0.523 174   4.059  0.0001
##  TreatA Hosp2 - TreatB Hosp2   -5.263 0.523 174 -10.061  &lt;.0001
##  TreatA Hosp2 - TreatC Hosp2   -0.127 0.523 174  -0.242  0.8090
##  TreatB Hosp2 - TreatC Hosp2    5.137 0.523 174   9.819  &lt;.0001
```

---
# Why do pairwise comparisons?

+ Sometimes we do not have a concrete hypothesis to test.

+ Sometimes we do, but the exploratory analysis is still useful information for the field.

+ Pairwise comparisons throws up a statistical issue, namely the problem of multiple comparisons.
  + When we do lots and lots of tests, the chances of Type I error (false-positives) increase.

+ We will move on to how we can adjust our inferences to deal with this next week, along with a quick revisit of assumption checks.

---
# Types of errors

+ Type I error = False Positive
  + Reject the null when the null is true. 
  + `\(\alpha = P(\text{Type I Error})\)`

+ Type II error = False negative
  + Fail to reject the null when the null is false. 
  + `\(\beta = P(\text{Type II Error})\)`
  
---
# A single test
+ If we perform a single test, our Type I error rate is `\(\alpha\)`.
  + So if we set `\(\alpha = 0.05\)`, the probability of a false positive is 0.05

+ However, what if we do multiple tests ( `\(m\)` ) each with the same `\(\alpha\)` level?

+ What is the probability of a false positive among `\(m\)` tests?

---
# Multiple tests

`$$P(\text{Type I error}) = \alpha$$`
`$$P(\text{not making a Type I error}) = 1 - \alpha$$`

`$$P(\text{Not making a Type I error in m tests}) = (1 - \alpha)^m$$`

`$$P(\text{Making a Type I error in m tests}) = 1 - (1-\alpha)^m$$`

---
# P(Making a Type I error in m tests)

+ Suppose `\(m=2\)` and `\(\alpha = 0.05\)`


```r
1 - ((1-0.05)^2)
```

```
## [1] 0.0975
```

+ Suppose `\(m=5\)` and `\(\alpha = 0.05\)`


```r
1 - ((1-0.05)^5)
```

```
## [1] 0.2262191
```

+ Suppose `\(m=10\)` and `\(\alpha = 0.05\)`


```r
1 - ((1-0.05)^10)
```

```
## [1] 0.4012631
```

---
# Why does this matter?

+ The `\(P(\text{Making a Type I error in m tests}) = 1 - (1-\alpha)^m\)` is referred to as the family-wise error rate. 

+ A "family" is a set of related tests. 

+ When we analyse an experimental design, and we look at lots of specific comparisons, we can think of all these tests as a "family". 

+ The larger the family, the more likely we are to find a false positive (see previous slide). 

---
# Corrections
+ There are various methods designed to control for the number of tests.
  + Here control means to keep the Type I Error rate at an intended `\(\alpha\)`. 

+ Many options. Some of most common:
  + Bonferroni
  + Sidak
  + Tukey
  + Scheffe

+ Others you may see:
  + Holm's step-down
  + Hochberg's step-up


---
# Bonferroni &amp; Sidak
+ Both are considered "conservative" adjustments.

+ Each treats individual tests within the family as if they are independent.
  + Consider an `\(\alpha = 0.05\)` and `\(m=\text{number of tests}=15\)`

+ **Bonferroni**: `\(\alpha_{Bonferroni} = \frac{\alpha}{m}\)`


```r
0.05/15
```

```
## [1] 0.003333333
```


+ **Sidak**: `\(\alpha_{Sidak} = 1 - (1- \alpha)^{\frac{1}{m}}\)`


```r
1-((1-0.05)^(1/15))
```

```
## [1] 0.003413713
```

---
# Adjusting `\(p\)` not `\(\alpha\)` 
+ On the previous slide, we adjusted the `\(\alpha\)` level.
  + To use this value, we would compare the exact `\(p\)`-value of a particular test to the adjusted `\(\alpha\)`

+ Alternatively, we can adjust the `\(p\)`-value itself, and then compare the adjusted `\(p\)`-value to the original `\(\alpha\)`
  + This is what `emmeans` does.
  
+ **Bonferroni**: `\(p_{Bonferroni} = p*m\)`


---
# No adjustments


```r
pairs(m1_emm, adjust="none")
```

```
##  contrast                    estimate    SE  df t.ratio p.value
##  TreatA Hosp1 - TreatB Hosp1    1.370 0.523 174   2.619  0.0096
##  TreatA Hosp1 - TreatC Hosp1    0.697 0.523 174   1.332  0.1847
##  TreatA Hosp1 - TreatA Hosp2    2.947 0.523 174   5.632  &lt;.0001
##  TreatA Hosp1 - TreatB Hosp2   -2.317 0.523 174  -4.428  &lt;.0001
##  TreatA Hosp1 - TreatC Hosp2    2.820 0.523 174   5.390  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp1   -0.673 0.523 174  -1.287  0.1998
##  TreatB Hosp1 - TreatA Hosp2    1.577 0.523 174   3.014  0.0030
##  TreatB Hosp1 - TreatB Hosp2   -3.687 0.523 174  -7.047  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp2    1.450 0.523 174   2.772  0.0062
##  TreatC Hosp1 - TreatA Hosp2    2.250 0.523 174   4.301  &lt;.0001
##  TreatC Hosp1 - TreatB Hosp2   -3.013 0.523 174  -5.760  &lt;.0001
##  TreatC Hosp1 - TreatC Hosp2    2.123 0.523 174   4.059  0.0001
##  TreatA Hosp2 - TreatB Hosp2   -5.263 0.523 174 -10.061  &lt;.0001
##  TreatA Hosp2 - TreatC Hosp2   -0.127 0.523 174  -0.242  0.8090
##  TreatB Hosp2 - TreatC Hosp2    5.137 0.523 174   9.819  &lt;.0001
```

---
# Bonferroni in action: `emmeans`


```r
pairs(m1_emm, adjust="bonferroni")
```

```
##  contrast                    estimate    SE  df t.ratio p.value
##  TreatA Hosp1 - TreatB Hosp1    1.370 0.523 174   2.619  0.1441
##  TreatA Hosp1 - TreatC Hosp1    0.697 0.523 174   1.332  1.0000
##  TreatA Hosp1 - TreatA Hosp2    2.947 0.523 174   5.632  &lt;.0001
##  TreatA Hosp1 - TreatB Hosp2   -2.317 0.523 174  -4.428  0.0003
##  TreatA Hosp1 - TreatC Hosp2    2.820 0.523 174   5.390  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp1   -0.673 0.523 174  -1.287  1.0000
##  TreatB Hosp1 - TreatA Hosp2    1.577 0.523 174   3.014  0.0445
##  TreatB Hosp1 - TreatB Hosp2   -3.687 0.523 174  -7.047  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp2    1.450 0.523 174   2.772  0.0928
##  TreatC Hosp1 - TreatA Hosp2    2.250 0.523 174   4.301  0.0004
##  TreatC Hosp1 - TreatB Hosp2   -3.013 0.523 174  -5.760  &lt;.0001
##  TreatC Hosp1 - TreatC Hosp2    2.123 0.523 174   4.059  0.0011
##  TreatA Hosp2 - TreatB Hosp2   -5.263 0.523 174 -10.061  &lt;.0001
##  TreatA Hosp2 - TreatC Hosp2   -0.127 0.523 174  -0.242  1.0000
##  TreatB Hosp2 - TreatC Hosp2    5.137 0.523 174   9.819  &lt;.0001
## 
## P value adjustment: bonferroni method for 15 tests
```

---
# Sidak with `emmeans`


```r
pairs(m1_emm, adjust = "sidak")
```

```
##  contrast                    estimate    SE  df t.ratio p.value
##  TreatA Hosp1 - TreatB Hosp1    1.370 0.523 174   2.619  0.1348
##  TreatA Hosp1 - TreatC Hosp1    0.697 0.523 174   1.332  0.9533
##  TreatA Hosp1 - TreatA Hosp2    2.947 0.523 174   5.632  &lt;.0001
##  TreatA Hosp1 - TreatB Hosp2   -2.317 0.523 174  -4.428  0.0003
##  TreatA Hosp1 - TreatC Hosp2    2.820 0.523 174   5.390  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp1   -0.673 0.523 174  -1.287  0.9647
##  TreatB Hosp1 - TreatA Hosp2    1.577 0.523 174   3.014  0.0436
##  TreatB Hosp1 - TreatB Hosp2   -3.687 0.523 174  -7.047  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp2    1.450 0.523 174   2.772  0.0889
##  TreatC Hosp1 - TreatA Hosp2    2.250 0.523 174   4.301  0.0004
##  TreatC Hosp1 - TreatB Hosp2   -3.013 0.523 174  -5.760  &lt;.0001
##  TreatC Hosp1 - TreatC Hosp2    2.123 0.523 174   4.059  0.0011
##  TreatA Hosp2 - TreatB Hosp2   -5.263 0.523 174 -10.061  &lt;.0001
##  TreatA Hosp2 - TreatC Hosp2   -0.127 0.523 174  -0.242  1.0000
##  TreatB Hosp2 - TreatC Hosp2    5.137 0.523 174   9.819  &lt;.0001
## 
## P value adjustment: sidak method for 15 tests
```

---
# What about if there were less tests?


```r
pairs(m1_emm, simple="Treatment", adjust="bonferroni")
```

```
## Hospital = Hosp1:
##  contrast        estimate    SE  df t.ratio p.value
##  TreatA - TreatB    1.370 0.523 174   2.619  0.0288
##  TreatA - TreatC    0.697 0.523 174   1.332  0.5541
##  TreatB - TreatC   -0.673 0.523 174  -1.287  0.5993
## 
## Hospital = Hosp2:
##  contrast        estimate    SE  df t.ratio p.value
##  TreatA - TreatB   -5.263 0.523 174 -10.061  &lt;.0001
##  TreatA - TreatC   -0.127 0.523 174  -0.242  1.0000
##  TreatB - TreatC    5.137 0.523 174   9.819  &lt;.0001
## 
## P value adjustment: bonferroni method for 3 tests
```


---
# Scheffe
+ **Scheffe procedure** calculates `\(p\)` value from the `\(F\)` distribution.

+ The Scheffe critical values is calculated as:

$$ \sqrt{rF(\alpha; r; d)}$$
+ Where 
  + `\(r\)` = number of tests (levels - 1)
  + `\(d\)` = residual degrees of freedom
  + `\(F\)` = unadjusted `\(F\)` critical value

+ Essentially makes the critical value of `\(F\)` larger for a fixed `\(\alpha\)`, dependent on the number of tests. 

+ The square-root of the adjusted F provides and adjusted `\(t\)`. 

---
# Tukey Honest Significant Differences
+ **Tukey's HSD**
  + Compares all pairwise group means. 
  + Each difference is divided by the `\(SE\)` of the sum of means. 
  + This produces a `\(q\)` statistic for each comparison. 
  + And is compared against a studentized range distribution. 


---
# With `emmeans`


```r
pairs(m1_emm, adjust = "tukey")
```

```
##  contrast                    estimate    SE  df t.ratio p.value
##  TreatA Hosp1 - TreatB Hosp1    1.370 0.523 174   2.619  0.0982
##  TreatA Hosp1 - TreatC Hosp1    0.697 0.523 174   1.332  0.7670
##  TreatA Hosp1 - TreatA Hosp2    2.947 0.523 174   5.632  &lt;.0001
##  TreatA Hosp1 - TreatB Hosp2   -2.317 0.523 174  -4.428  0.0002
##  TreatA Hosp1 - TreatC Hosp2    2.820 0.523 174   5.390  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp1   -0.673 0.523 174  -1.287  0.7918
##  TreatB Hosp1 - TreatA Hosp2    1.577 0.523 174   3.014  0.0346
##  TreatB Hosp1 - TreatB Hosp2   -3.687 0.523 174  -7.047  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp2    1.450 0.523 174   2.772  0.0670
##  TreatC Hosp1 - TreatA Hosp2    2.250 0.523 174   4.301  0.0004
##  TreatC Hosp1 - TreatB Hosp2   -3.013 0.523 174  -5.760  &lt;.0001
##  TreatC Hosp1 - TreatC Hosp2    2.123 0.523 174   4.059  0.0010
##  TreatA Hosp2 - TreatB Hosp2   -5.263 0.523 174 -10.061  &lt;.0001
##  TreatA Hosp2 - TreatC Hosp2   -0.127 0.523 174  -0.242  0.9999
##  TreatB Hosp2 - TreatC Hosp2    5.137 0.523 174   9.819  &lt;.0001
## 
## P value adjustment: tukey method for comparing a family of 6 estimates
```


---
# With `emmeans`


```r
pairs(m1_emm, adjust = "scheffe")
```

```
##  contrast                    estimate    SE  df t.ratio p.value
##  TreatA Hosp1 - TreatB Hosp1    1.370 0.523 174   2.619  0.2372
##  TreatA Hosp1 - TreatC Hosp1    0.697 0.523 174   1.332  0.8787
##  TreatA Hosp1 - TreatA Hosp2    2.947 0.523 174   5.632  &lt;.0001
##  TreatA Hosp1 - TreatB Hosp2   -2.317 0.523 174  -4.428  0.0021
##  TreatA Hosp1 - TreatC Hosp2    2.820 0.523 174   5.390  0.0001
##  TreatB Hosp1 - TreatC Hosp1   -0.673 0.523 174  -1.287  0.8935
##  TreatB Hosp1 - TreatA Hosp2    1.577 0.523 174   3.014  0.1119
##  TreatB Hosp1 - TreatB Hosp2   -3.687 0.523 174  -7.047  &lt;.0001
##  TreatB Hosp1 - TreatC Hosp2    1.450 0.523 174   2.772  0.1809
##  TreatC Hosp1 - TreatA Hosp2    2.250 0.523 174   4.301  0.0033
##  TreatC Hosp1 - TreatB Hosp2   -3.013 0.523 174  -5.760  &lt;.0001
##  TreatC Hosp1 - TreatC Hosp2    2.123 0.523 174   4.059  0.0072
##  TreatA Hosp2 - TreatB Hosp2   -5.263 0.523 174 -10.061  &lt;.0001
##  TreatA Hosp2 - TreatC Hosp2   -0.127 0.523 174  -0.242  1.0000
##  TreatB Hosp2 - TreatC Hosp2    5.137 0.523 174   9.819  &lt;.0001
## 
## P value adjustment: scheffe method with rank 5
```


---
# Summary
+ We are know finished with discussing testing effects within `lm`.

+ This week we have looked at ways we can code categorical data to test experimental effects.

+ In the next block, we will consider:
  + Non-continuous **dependent** variables
  + Approaches to modelling and modelling issues
  + Power

+ Last week of the course will be all Q&amp;A and discussing exam.


---
class: center, middle
# Thanks for listening!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
