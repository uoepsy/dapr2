---
title: "<b> Testing Contrasts and One-way Analyses </b>"
subtitle: "Data Analysis for Psychology in R 2<br><br> "
author: "dapR2 Team"
institute: "Department of Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #base_color = "#0F4C81", # DAPR1
   base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
library(emmeans)
library(matrixStats)

hosp_tbl <- read_csv("./hospital.csv", col_types = "dff")

```

# Week's Learning Objectives
1. Introduce rules for constructing contrasts
2. Introduce `emmeans` as a tool for testing different effects in models with categorical predictors.
3. Brief refresher on experimental design
4. Distinguish between main effects, simple effects and contrasts
5. Be able to estimate main effects via use of $F$-tests

---
# Manual contrast testing
+ We can structure a wide variety of contrasts so long as they can be written:

  1. A as a linear combination of population means.
  2. The associated coefficients (weights) sum to zero.

+ So

$$H_0: c_1\mu_1 + c_2\mu_2 + c_3\mu_3 $$

+ With

$$c_1 + c_2 + c_3 = 0$$

---
# Rules for assigning weights

+ **Rule 1**: Weights range between -1 and 1
+ **Rule 2**: The group(s) in one chunk are given negative weights, the group(s) in the other get positive weights
+ **Rule 3**: The sum of the weights of the comparison must be 0
+ **Rule 4**: If a group is not involved in the comparison, weight is 0
+ **Rule 5**: For a given comparison, weights assigned to group(s) are equal to 1 divided by the number of groups in that chunk.
+ **Rule 6**: Restrict yourself to running $k$ - 1 comparisons (where $k$ = number of groups)
+ **Rule 7**: Each contrast can only compare 2 chunks of variance
+ **Rule 8**: Once a group singled out, it can not enter other contrasts 

---
# New example
+ Suppose we were interested in the effect of various relationship statuses on an individuals subjective well-being (`swb`)
  + Keeping with a theme on our outcome.

+ Our predictor is `status` which has 5 levels:
  + Married or Civil Partnership
  + Cohabiting relationship
  + Single
  + Widowed
  + Divorced

+ Let's say we have data on 500 people.

---
# Data
```{r, echo=FALSE}
n <- round(500*(c(.55, .2, .1, .05, .1)),0)
set.seed(7284)
wb_tib <- tibble(
  swb = c(rnorm(n[1], 11, 3.6),
          rnorm(n[2], 12, 4.2),
          rnorm(n[3], 8, 2.2),
          rnorm(n[4], 6, 1.1),
          rnorm(n[5], 9.5, 2.5)),
  status = factor(c(rep("Married/CP", n[1]),
             rep("Cohab", n[2]),
             rep("Single", n[3]),
             rep("Widowed", n[4]),
             rep("Divorced", n[5]))
             )
)

wb_tib %>%
  group_by(status) %>%
  summarise(
    n = n(),
    mean = round(mean(swb),2),
    sd = round(sd(swb),2)
  ) %>%
  kable(.)%>%
  kable_styling(., full_width = F)
```


---
# Applying rules
+ Let's say we want to make two contrasts

1. Those who are currently or previously married or in a civil partnership vs not.
2. Those who are currently married or in a civil partnership vs those who have previously been.

```{r, echo=FALSE}
contrasts <- tibble(
  group = c("Cohab", "Divorced", "Married/CP", "Single", "Widowed"),
  contrast1 = round(c(-0.5, 1/3, 1/3, -0.5, 1/3),2),
  contrast2 = round(c(0, -0.5, 1, 0, -0.5),2)
  )
contrasts %>% 
  kable(.) %>%
  kable_styling(., full_width = F)
```


---
# Orthogonal vs. Non-orthogonal Contrasts
+ Orthogonal contrasts test independent sources of variation.
  + If we follow the rules above, we will have orthogonal contrasts.

+ Non-orthogonal contrasts test non-independent sources of variation.
  + This presents some further statistical challenges in terms of making inferences. 
  + We will come back to this discussion later in the course.

---
# Rule 10: Checking if contrasts are orthogonal
+ The sum of the products of the weights will = 0 for any pair of orthogonal comparisons

$$\sum{c_{1j}c_{2j}} = 0$$

---
# From our example

```{r, echo=FALSE}
contrasts %>% 
  kable(.) %>%
  kable_styling(., full_width = F)
```

+ Below we can see the product of $c_1c_2$ for each level, and the row-wise sums for each contrast and the products.
  + The 0 for contrast 1 and 2 show we have set correct weights.
  + The 0 for the product shows the contrasts are orthogonal

```{r, echo=FALSE}
tibble(
  Contrast = c("Contrast1", "Contrast2", "Product"),
  Cohab = c(-0.5, 0, 0),
  Divorced = c(0.33, -0.5, -0.165),
  Married_CP = c(0.33, 1, 0.33),
  Single = c(-0.5, 0, 0),
  Widowed = c(0.33, -0.5, -.165),
  Sum = c(0,0,0)
  ) %>%
  kable(.) %>%
  kable_styling(., full_width = F)
```


---
class: center, middle
# Questions....


---
# Using `emmeans` to test contrasts

+ We will use the package `emmeans` to test our contrasts
  + We will also be using this in the next few weeks to look at analysing experimental designs.

+ **E**stimated
+ **M**arginal
+ **Means**

+ Essentially this package provides us with a lot of tools to help us model contrasts and linear functions.

---
# Working with `emmeans`
+ First we run our model:

```{r}
status_res <- lm(swb ~ status, wb_tib)
```

+ wNext we use the `emmeans` to get the estimated means of our groups.

```{r}

status_mean <- emmeans(status_res, ~status)
status_mean
```


---
# Visualise estimated means

.pull-left[
```{r, eval=FALSE}
plot(status_mean)
```

+ We then use these means to test contrasts

]

.pull-right[
```{r, echo=FALSE}
plot(status_mean)
```

]

---
# Defining the contrast

+ **KEY POINT**: The order of your categorical variable matters as `emmeans` uses this order. 


```{r, echo=FALSE}
contrasts %>% 
  kable(.) %>%
  kable_styling(., full_width = F)
```


```{r}
levels(wb_tib$status)
```

```{r}
status_comp <- list("Married or CP vs not" = c(-1/2, 1/3, 1/3, -1/2, 1/3),
                    "Current vs Not current" = c(0, -1/2, 1, 0, -1/2))

```


---
# Requesting the test
+ In order to test our effects, we use the `contrast` function from `emmeans`

```{r}
status_comp_test <- contrast(status_mean, status_comp)
status_comp_test
```
+ We can see we have p-values, but we can also request confidence intervals

```{r}
confint(status_comp_test)
```


---
# Interpreting the results
+ The estimate is the difference between the average of the group means within each chunk.


```{r}
confint(status_comp_test)
```
+ So for `Married or CP vs not` :

```{r}
((10.63 + 6.00 + 9.37)/3) - ((11.44 + 8.06)/2)
```
+ So those who are not currently or previously married or in a civial partnership have higher SWB.
  + And this is significant.


---
class: center, middle
# Questions....


---
# Experimental Design: manipulation
+ A key feature of experimental designs is that we actively manipulate our predictor (IV).

+ The intention is that changing the predictor will result in changes in the outcome (DV).

+ That is our manipulation will lead to variation in the outcome.

+ Our experiments can fail because we design these manipulations poorly.

+ The predictors in an experiment are (primarily) experimental conditions.


---
# Conditions/Factors & levels
+ **Conditions**: 
  + Are part of our experimental designs.
  + They are what is manipulated.
  
+ **Factors**
  + The resultant variables in our data set that code the experimental conditions are typically called factors.
  + Generally the terms conditions and factors are used interchangeably.
  + But it is useful to differentiate the design (conditions) and the data that represents aspects of the design (factors)

+ Factors can have **levels**
  + These are the number of ways we vary or manipulate the condition

---
# Example
+ So for our now very familiar example:

+ **Condition 1**: `Treatment` (Levels: TreatA, TreatB, TreatC).
  
+ **Condition 2**: `Hosp` (Levels: Hosp1, Hosp2). 
  
+ **Outcome**: Subjective well-being (SWB)


---
# Models and Experiments
+ Our linear model can be simply stated as:

$$outcome = model + error$$ 

+ When we have an experiment:

$$outcome = design + error$$ 

+ The design is simply sets of categorical variables.

$$y = b_0 + \underbrace{(b_1E_1 + b_2E_2)}_{\text{Conditin1}} + \underbrace{b_3E_3}_{\text{Condition2}} + \underbrace{b_4E_{13} + b_5E_{23}}_{\text{Interactions}} + \underbrace{\epsilon_{i}}_{\text{error}}$$

+ So to analyse an experiment, we are simply analysing a linear model with categorical predictors.




---
# Hypotheses we test in experimental studies
+ In a one-way design we only have one condition that is manipulated:

$$y = b_0 + \underbrace{(b_1E_1 + b_2E_2)}_{\text{Treatment}} +  \underbrace{\epsilon_{i}}_{\text{error}}$$

+ One-way designs:
  + **Main effect**: Tests overall effect of a condition  ( $F$-tests)
  + **Contrasts**: Tests differences between specific group means (based on coding schemes and associated $\beta$ )

---
# Hypotheses we test in experimental studies
+ In a two-way (or 2+ way) design we manipulate multiple conditions:

$$y_{ijk} = b_0 + \underbrace{(b_1E_1 + b_2E_2)}_{\text{Treatment}} + \underbrace{b_3E_3}_{\text{Hospital}} + \underbrace{b_4E_{13} + b_5E_{23}}_{\text{Interactions}} + \epsilon_{i}$$

+ Factorial designs:
  + Main effects & Contrasts
  + **Interactions**: Categorical*categorical and usually based on effects (sum to zero) coding ( $F$-tests & $\beta$ )
  + **Simple contrasts/effects**: Effects of one level in one condition, across levels of another condition. 


---
# Hypotheses we test 
+ Main effects
  + An overall, or average, effect of a condition.
  + Is there an effect of `Treatment` averaged over `Hospital`? 
  + Is there an effect of `Hospital` averaged over `Treatment`? 

+ Interactions (categorical*categorical)
  + A change in the effect of some condition as a function of another.
  + Does the effect of `Treatment` differ by `Hospital`? 
  
+ Simple contrasts/effects
  + An effect of one condition at a specific level of another.
  + Is there an effect of `Hospital` for those receiving `Treatment A`? (...and so on for all combinations.)


---
# One way main effects

+ As we have an experiment, we typically use effects coding:
```{r}
contrasts(hosp_tbl$Treatment) <- contr.sum
```

+ Run the model:
```{r}
m1 <- lm(SWB ~ Treatment, data = hosp_tbl)
anova(m1)
```

---
# One way main effects
```{r}
summary(m1)
```

---
class: center, middle
# All good?
**So lets look at main effects for factorial designs**

---
# Using model comparisons
+ In order to tests main effects, we need to compare sets of models that differ by the variable of interest.

+ To do all effects in our two-way design, we need 4 models:

```{r}
comp1 <- lm(SWB ~ Treatment, data = hosp_tbl)
comp2 <- lm(SWB ~ Hospital, data = hosp_tbl)
comp3 <- lm(SWB ~ Treatment + Hospital, data = hosp_tbl)
comp4 <- lm(SWB ~ Treatment + Hospital + Treatment*Hospital, data = hosp_tbl)
```


---
# Testing the overall effects

+ For the effect of `Treatment`:

```{r}
comp2 <- lm(SWB ~ Hospital, data = hosp_tbl)
comp3 <- lm(SWB ~ Treatment + Hospital, data = hosp_tbl)

anova(comp2,comp3)
```

+ An effect of Treatment

---
# Testing the overall effects

+ For the effect of `Hospital`:

```{r}
comp1 <- lm(SWB ~ Treatment, data = hosp_tbl)
comp3 <- lm(SWB ~ Treatment + Hospital, data = hosp_tbl)

anova(comp1, comp3)
```

+ No effect of hospital

---
# Testing the overall effects

+ For the effect of interaction:

```{r}
comp3 <- lm(SWB ~ Treatment + Hospital, data = hosp_tbl)
comp4 <- lm(SWB ~ Treatment + Hospital + Treatment*Hospital, data = hosp_tbl)

anova(comp3, comp4)
```

+ An interaction


---
# Using `anova` on a single model

```{r}
anova(comp4)
```

---
# Testing the overall effects
+ You may have noted using `anova()` for a single model, and for the model comparison approach yield slightly different results.
  + Sums of squares difference is the same
  + Degrees of freedom are the same
  + $F$ is slightly different for `Treatment` and `Hospital` (and therefore so is $p$-value)

+ Note the main conclusions do not change.

+ This difference relates to differences in the degrees of freedom associated with the $F$-test.



---
# Summary
+ This week we have looked at the use of `emmeans` to test specific contrasts.
  + Run the model
  + Estimate the means
  + Define the contrast
  + Test the contrast

+ We recapped experimental designs

+ And we began to explore testing them.
  + Next week we will continue this to recap interactions, look at interacting contrasts, simple and pairwise tests

---
class: center, middle
# Thanks for listening!
