---
title: "<b> Model Comparisons </b>"
subtitle: "Data Analysis for Psychology in R 2<br><br> "
author: "dapR2 Team"
institute: "Department of Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #base_color = "#0F4C81", # DAPR1
   base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(car)
library(patchwork)
library(kableExtra)
```

# Week's Learning Objectives

+ Understand how to use model comparisons to test different types of question.
+ Understand the calculation of the incremental $F$-test.
+ Understand the difference between nested and non-nested models, and the appropriate statistics to use for comparison in each case.

---
# Topics for today
+ Discuss some motivating examples:
  + Categorical variables with 2+ levels 
  + Interactions with categorical variables with 2+ levels
  + Controlling for covariates

+ Statistical tools for selection/comparison
  + Incremental $F$-test
  + Nested vs. non-nested models
  + AIC & BIC


---
# Some data
+ We have previously looked at this example. 

+ A researcher was interested in whether the subjective well-being of patients differed dependent on the post-operation treatment schedule they were given, and the hospital in which they were staying. 

+ **Condition 1**: `Treatment` (Levels: TreatA, TreatB, TreatC).
  
+ **Condition 2**: `Hospital` (Levels: Hosp1, Hosp2). 
  
+ Total sample n = 180 (30 patients in each of 6 groups).
  + Between person design. 

+ **Outcome**: Subjective well-being (`SWB`)
  + An average of multiple raters (the patient, a member of their family, and a friend). 
  + SWB score ranged from 0 to 20.

---
# The data
```{r}
hosp_tbl <- read_csv("hospital.csv", col_types = "dff")
hosp_tbl %>%
  slice(1:10)
```


---
# Example 1: Categorical Variables with 2+ levels

+ What if the researcher wanted to ask a general question; Is there an overall effect of `Treatment`?

+ How might we do this with the skills we have learned already?

```{r, eval=FALSE}
summary(lm(SWB ~ Treatment, data = hosp_tbl))
```

---
# Results

```{r, echo=FALSE}
summary(lm(SWB ~ Treatment, data = hosp_tbl))
```

---
# Example 2: Categorical Interactions with 2+ levels

+ If we stay with the same example, what if we asked the question:

+ Is there an interaction between `Hospital` and `Treatement`?


```{r eval=FALSE}
summary(lm(SWB ~ Treatment*Hospital, data = hosp_tbl))
```

---
# Results

```{r echo=FALSE}
summary(lm(SWB ~ Treatment*Hospital, data = hosp_tbl))
```

---
# Some more data
+ How about this example based on data from the Midlife In United States (MIDUS2) study.

+ Outcome: self-rated health

+ Covariates: Age, sex

+ Predictors: Big Five traits and Purpose in Life.

---
# The data
```{r, warning=FALSE, message=FALSE}
midus <- read_csv("MIDUS2.csv")
midus2 <- midus %>%
  select(1:4, 31:42) %>%
  mutate(
    PIL = rowMeans(.[grep("PIL", names(.))],na.rm=T)
  ) %>%
  select(1:4, 12:17) %>%
  drop_na(.)
slice(midus2, 1:3)

```


---
# Example 3: Controlling for covariates
+ Suppose our question was....

+ Does personality significantly predict self-rated health over and above the effects of age and sex?

```{r, eval=FALSE}
summary(lm(health ~ age + sex + O + C + E + A + N, data = midus2))
```

---

```{r, echo=FALSE}
summary(lm(health ~ age + sex + O + C + E + A + N, data = midus2))
```

---
# What do these questions have in common?
+ A key feature of these questions is that they require us to evaluate whether multiple variables (think more than one beta coefficient) are significant.

+ Another - potentially more useful - way to think are "are significant" is to say "do they improve my model"?

+ Up to this point, we have only discussed ways to explore this:
  + In a very limited case (i.e. the single categorical predictor with 2+ levels) like example 1
  + Descriptively
  
+ What we will look at next is how we can formally test such questions.

---
class: center, middle
# Questions on the general concept...


---
# Recall the $F$-test
+ $F$-ratio is a ratio of the explained to unexplained variance:

$$F = \frac{MS_{Model}}{MS_{Residual}}$$

+ Where the mean squares (MS) are the sums of squares divided by the degrees of freedom. So we can also write:

$$F = \frac{SS_{Model}/df_{Model}}{SS_{Residual}/df_{residual}}$$

---
# F-ratio
+ Bigger $F$-ratios indicate better models.
  + It means the model variance is big compared to the residual variance.

+ The null hypothesis for the model says that the best guess of any individuals $y$ value is the mean of $y$ plus error.
	+ Or, that the $x$ variables carry no information collectively about $y$.
	+ Or, a test that all $\beta$ = 0

+ $F$-ratio will be close to 1 when the null hypothesis is true
  + If there is equivalent residual to model variation, $F$=1
	+ If there is more model than residual $F$ > 1

+ $F$-ratio is then evaluated against an $F$-distribution with $df_{Model}$ and $df_{Residual}$ and a pre-defined $\alpha$

+ Testing the $F$-ratio evaluates statistical significance of the overall model


---
# $F$-test as an incremental test

+ One important way we can think about the $F$-test and the $F$-ratio is as an incremental test against an "empty" or null model.

+ A null or empty model is a linear model with only the intercept.
  + In this model, our predicted value of the outcome for every case in our data set, is the mean of the outcome.
  + That is, with no predictors, we have no information that may help us predict the outcome.
  + So we will be "least wrong" by guessing the mean of the outcome.

+ An empty model is the same as saying all $\beta$ = 0.

+ So in this way, the $F$-test we have already seen **is comparing two models**.

+ We can extend this idea, and use the $F$-test to compare two models that contain different sets of predictors.
  + This is the **incremental $F$-test**

---
# Incremental $F$-test
.pull-left[
+ The incremental $F$-test evaluates the statistical significance of the improvement in variance explained in an outcome with the addition of further predictor(s)

+ It is based on the difference in $F$-values between two models.
  + We call the model with the additional predictor(s) model 1 or full model
  + We call the model without model 0 or restricted model

]

.pull-right[
$$F_{(df_R-df_F),df_F} = \frac{(SSR_R-SSR_F)/(df_R-df_F)}{SSR_F / df_F}$$



$$
\begin{align}
& \text{Where:} \\
& SSR_R = \text{residual sums of squares for the restricted model} \\
& SSR_F = \text{residual sums of squares for the full model} \\
& df_R = \text{residual degrees of freedom from the restricted model} \\
& df_F = \text{residual degrees of freedom from the full model} \\
\end{align}
$$
]


---
# Incremental $F$-test in R

+ In order to apply the $F$-test for model comparison in R, we use the `anova()` function.

+ `anova()` takes as its arguments models that we wish to compare
  + Here we will show examples with 2 models, but we can use more.

---
# Application to example 1

+ Is there an overall effect of `Treatment`?

```{r}
ex1_r <- lm(SWB ~ 1, data = hosp_tbl)
ex1_f <- lm(SWB ~ Treatment, data = hosp_tbl)

anova(ex1_r, ex1_f)
```

---
# Application to example 1

```{r}
summary(ex1_f)
```


---
# Application to example 2
+ Is there an interaction between `Hospital` and `Treatment`?

```{r}
ex2_r <- lm(SWB ~ Treatment + Hospital, data = hosp_tbl)
ex2_f <- lm(SWB ~ Treatment*Hospital, data = hosp_tbl)

anova(ex2_r, ex2_f)
```

---
# Application to example 3
+ Does personality significantly predict self-rated health over and above the effects of age and sex?

```{r}
ex3_r <- lm(health ~ age + sex, data = midus2)
ex3_f <- lm(health ~ age + sex + O + C + E + A + N, data = midus2)

anova(ex3_r, ex3_f)
```



---
class: center, middle
# Questions....

---
# Nested vs non-nested models
+ The $F$-ratio depends on the models being compared being nested

+ Nested means that the predictors in one model are a subset of the predictors in the other

+ We also require the models to be computed on the same data


---
# Nested vs non-nested models

.pull-left[
**Nested**

```{r, eval=FALSE}

m0 <- lm(outcome ~ x1 + x2 , data = data)

m1 <- lm(outcome ~ x1 + x2 + x3, data = data)

```

+ These models are nested.

+ `x1` and `x2` appear in both models
]


.pull-right[
**Non-nested**

```{r, eval=FALSE}

m0 <- lm(outcome ~ x1 + x2 + x4, data = data)

m1 <- lm(outcome ~ x1 + x2 + x3, data = data)

```

+ These models are non-nested

+ There are unique variables in both models
  + `x4` in `m0`
  + `x3` in `m1`

]


---
# Model comparison for non-nested models
+ So what happens when we have non-nested models?

+ There are two commonly used alternatives
  + AIC
  + BIC

+ Unlike the incremental $F$-test AIC and BIC do not require two models to be nested

+ Smaller (more negative) values indicate better fitting models.
  + So we compare values and choose the model with the smaller AIC or BIC value
  
---
# AIC & BIC

.pull-left[
$$AIC = n\,\text{ln}\left( \frac{SS_{residual}}{n} \right) + 2k$$

$$
\begin{align}
& \text{Where:} \\
& SS_{residual} = \text{sum of squares residuals} \\
& n = \text{sample size} \\
& k = \text{number of explanatory variables} \\
& \text{ln} = \text{natural log function} 
\end{align}
$$
]

.pull-right[

$$BIC = n\,\text{ln}\left( \frac{SS_{residual}}{n} \right) + k\,\text{ln}(n)$$

$$
\begin{align}
& \text{Where:} \\
& SS_{residual} = \text{sum of squares residuals} \\
& n = \text{sample size} \\
& k = \text{number of explanatory variables} \\
& \text{ln} = \text{natural log function} 
\end{align}
$$


]


---
# Parsimony corrections

+ Both AIC and BIC contain something called a parsimony correction
  + In essence, they penalise models for being complex
  + This is to help us avoid overfitting (adding predictors arbitarily to improve fit)
  
$$AIC = n\,\text{ln}\left( \frac{SS_{residual}}{n} \right) + 2k$$

$$BIC = n\,\text{ln}\left( \frac{SS_{residual}}{n} \right) + k\,\text{ln}(n)$$

+ BIC has a harsher parsimony penalty for typical sample sizes when applying linear models than AIC
  + When $\text{ln}(n) > 2$ BIC will have a more severe parsimony penalty (i.e. essentially all the time!)


---
# In R

```{r}
AIC(ex3_r, ex3_f)
```

---
# Applied to non-nested models

```{r}
ex3_nn1 <- lm(health ~ O + C + E + A + N, data=midus2)
ex3_nn2 <- lm(health ~ age + sex + PIL, data = midus2)
AIC(ex3_nn1, ex3_nn2)
```



---
# In R

```{r}
BIC(ex3_r, ex3_f)
```


```{r}
BIC(ex3_nn1, ex3_nn2)
```


---
# Considerations for use of AIC and BIC
+ The AIC and BIC for a single model are not meaningful
  + They only make sense for model comparisons

+ AIC and BIC can be used for both nested and non-nested models.

+ For AIC, there are no cut-offs to suggest how big a difference in two models is needed to conclude that one is substantively better than the other

+ For BIC, a difference of 10 can be used as a rule of thumb to suggest that one model is substantively better than another


---
# Summary of today
+ We have set out the types of question that may require us to use model comparison methods.

+ We have introduced the incremental $F$-test and linked it to the $F$-test from semester 1.

+ We also introduced the concepts of nested and non-neste tests, and the use of AIC and BIC for model comparison of non-nested models.

---
class: center, middle
# Thanks for listening!
