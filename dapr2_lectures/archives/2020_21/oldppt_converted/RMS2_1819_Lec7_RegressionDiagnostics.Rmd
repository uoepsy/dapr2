---
title: ' Lecture 7: Regression Case Diagnostics '
subtitle: 'Research Methods & Statistics 2  Aja Murray: aja.murray@ed.ac.uk, F16, 7 George Square Tom Booth: tom.booth@ed.ac.uk, F17, 7 George Square '
author: Tom Booth
date: 2020-06-23
output:
  xaringan::moon_reader:
  lib_dir: libs
  nature:
    highlightStyle: github
    highlightLines: true
    countIncrementalSlides: false
---
#  Overview 

+ Regression Outliers
+ Leverage
+ Influence
+ Dealing with ‘problematic’ cases

---
#  Regression Diagnostics 

+ In previous lectures we have discussed evaluating regression models:
	+ Evaluating model fit (R^2 and F-ratio)
	+ Evaluating individual predictors
+ Another important aspect of evaluating regression models pertains to the cases (individuals):
	+ Does the regression model fit poorly for some individuals?
	+ Do some individuals have a lot of influence on the results?
+ Regression diagnostics allow us to explore individual cases in the context of a regression model

---
#  Three important features 

+ Regression outliers
	+ Cases for which there is a large discrepancy between their predicted y-value and their observed y-value
+ High leverage cases
	+ Cases with an unusual combination of predictor values
+ High influence cases
	+ Cases who are having a large influence on the regression results

---
#  Regression Outliers 



---
#  Regression Outliers 

+ Regression outliers are cases that have unusual DV values given their IV values
	+ They will show a large difference between its predicted and its observed value
	+ i.e. they will show a large *residuals*

X

Y

---
#  Why are we interested in regression outliers? 

+ They can (but do not necessarily) have a strong influence on the model
	+ We’ll get to this…
+ It may be informative to follow-up and investigate outliers
	+ Is it a data entry error?
	+ Does the case somehow not belong with the rest of the data?
		+ E.g., a male in a sample of females
.pull-left[![](assets/img/image3.png)]

.pull-right[![](assets/img/image2.png)]

---
#  How do we determine if a case is an outlier? 

+ We judge regression outlying-ness of a case on the basis of the size of its residual
+ Unstandardised residuals are )
	+ They are in the same units as the DV
	+ Fine for comparison across cases within the same regression model
	+ Difficult to compare across models where the DVs will have different units

---
#  Standardised residuals 

+ Standardised residuals
	+ Divide the unstandardised residuals by an estimate of their standard deviation
	+ Converts the residuals to z-score units
	+ However, their calculation includes the potential outlier
+ Studentised residuals
	+ Provide a version of the standardised residual excluding the case
	+ Values **>+2 or <-2** indicate potential outlyingness

---
#  Studentised residuals in R 

+ Let’s imagine we have collected data on n=95 adolescents
+ We’re interested in whether we can predict violence from gender, alcohol use, and low self-control
+ We have fit our model using lm( ) and now want to look for regression outliers
![](assets/img/image4.jpeg)

---
#  studres( ) function 


After fitting our model...

…we can extract the studentised residuals using the studres ( ) function from the MASS package
.pull-left[![](assets/img/image6.emf)]

.pull-right[![](assets/img/image5.emf)]

---
#  Identifying studentised residuals >2 

#    

+ The ‘ stdz ’ object we created stores the studentised residual values for every case in the dataset, e.g., for the first 20 cases:
![](assets/img/image7.emf)

---
#  Identifying studentised residuals >2 

#    

+ We can check which cases have studentised residuals > , using:
+ Specifies absolute value to capture both >+2 and <-2
+ Used to identify cases for which a specified statement is true
+ Row numbers where the value of stdz is greater than
![](assets/img/image8.emf)

---
#  Leverage 



---
#  Leverage 

+ High leverage cases are those with an unusual IV or combination of IV values
	+ In simple regression: an X value far from the mean of X
	+ In multiple regression: a set of X values far from the centroid of X
		+ Centroid= generalisation of the mean to multivariate space

X

Y

---
#  Why are we interested in leverage? 

+ High leverage cases have considerable potential to influence the regression model
	+ i.e., change the estimates of the intercept and regression slopes
+ High leverage cases, when they are also regression outliers, will have high **influence**
![](assets/img/image9.jpeg)

---
#  How do we determine if a case has high leverage? 

+ ‘hat values’ are used to assess leverage in regression
+ For simple regression the hat value for a case would be:
+ n  is the sample size
+ is the squared deviation of an X value from the mean X
+ is the sum of squared deviations of each X value from the mean
![](assets/img/image13.png)

---
#  Hat values 

+ Hat values range between 1/n and n
+ The average hat value for a regression is :
+ k is the number of predictors
+ n is the sample size
+ As a rough heuristic, values more than 2x are considered high leverage
![](assets/img/image14.jpeg)

---
#  hatvalues ( ) function 


After fitting our model...

…we can extract the hat values using the hatvalues ( ) function
.pull-left[![](assets/img/image15.emf)]

.pull-right[![](assets/img/image5.emf)]

---
#  Identifying leverage values >2x the average 

+ The hats object stores all our hat values, e.g., for the first 20 cases:
+ We can check which cases have hat values >2x the average value:
.pull-left[![](assets/img/image17.emf)]

.pull-right[![](assets/img/image16.emf)]

---
#  Influence 



---
#  Influence 

+ Cases with high influence, have a strong effect on the coefficients
	+ Occurs when a case has both high leverage and is a regression outlier
+ If we deleted such a case, the regression coefficients would change substantially
+ If a handful of influential cases are responsible for the regression results, the conclusions might not generalise very well

Y

---
#  How do we identify influential cases? 

+ We can look at the effect of deleting a case:
	+ DFFit
		+ The difference between the predicted DV value for a case with versus without a case included
	+ DFbeta
		+ For each regression coefficient, the difference between that coefficient with and without a case included
	+ DFbetas
		+ A standardised version of DFbeta , obtained by dividing by an estimate of the standard error of the regression coefficient with the case removed
	+ Cook’s distance
		+ A single summary index of the influence of a case
		+ Most commonly used measure of influence

---
#  Cook’s Distance 


So;

---
#  Cook’s Distance 

+ We look for Cook’s distance values where:
+ The cut-off for our violence example with n=95, k=3 would, therefore, be 4/(95-3-1)=0.044.

---
#  Cook’s distance in R 


After fitting our model...

…we can extract the Cook’s distance values using the cooks.distance ( ) function
.pull-left[![](assets/img/image19.emf)]

.pull-right[![](assets/img/image5.emf)]

---
#  Influence on standard errors 

+ As well as having a strong influence on the regression coefficients, a case might be influential with respect to the standard errors of regression coefficients
+ Recall, the standard error for a regression slope in simple regression is:
+ Where:
	+ SSE is the sum of squared error (i.e., )
	+ N is the sample size
	+ k is the number of predictors (=1 for simple regression)

---
#  Influence on standard errors 

+ is the sum of squared deviations from each X value from the mean of X
+ This term implies that increasing the variance in X will decrease the standard error of
+ High leverage cases (which are far from the mean of X) can affect by increasing X variance
	+ If the case has high leverage but is not a regression outlier they can affect without necessarily affecting the regression coefficients

---
#  COVRATIO 

+ Influence on standard errors can be measured using the COVRATIO statistic
	+ COVRATIO value <1 show that precision is decreased (SE increased)  by a case
	+ COVRATIO value >1 show that precision is increased (SE decreased) by a case
+ Cases with COVRATIOS >1+[3( k +1)/ n ] or < 1-[3( k +1)/ n ] can be considered to have a strong influence on the standard errors
	+ For our violence example with n=95 , k=3 would, cases with a strong influence on the standard errors would have values :

>1+3(4)/95=1.27

OR

<1-3(4)/95=0.87

---
#  COVRATIO in R 


After fitting our model…

…COVRATIO values can be extracted using the covratio ( ) function
.pull-left[![](assets/img/image5.emf)]

.pull-right[![](assets/img/image20.emf)]

---
#  Solutions to outlying, high leverage and influential cases? 



---
#  What should be done about outliers, high leverage and high influence values? 

+ Easier to identify unusual cases than it is to decide what to do about them …
+ In general, not a good idea to delete cases just because they exceed a threshold on a measure of outlyingness , leverage, or influence
	+ Especially if they don’t show large influence
+ Instead, try to investigate why a case is unusual
+ Think of regression diagnostics more as a way of learning about the limitations of the model
	+ Which cases can’t it explain very well?
	+ Do results depend quite strongly on certain cases ?
+ … rather than as a justification for deleting cases
![](assets/img/image21.jpeg)

---
#  Investigating  and dealing with unusual cases 

+ Is there a data entry error?
	+ Is the value within the plausible range of values for a variable?
	+ Can it be corrected? If not, the incorrect value should be deleted
+ Is the data legit but extreme?
	+ Consider *winsorisation* ** over deletion to reduce its influence
		+ Replacing the extreme value with the next largest value for that variable
		+ Avoids missingness/ preserves information
	+ Note that deleting or winsorising values can change the model, therefore, different cases might then show up as outlying, high leverage, or influential
		+ Iterative approach to removing/ winsorising cases is needed
![](assets/img/image22.jpeg)

---
#  Investigating and dealing with unusual cases 

+ Is the data legit but extreme?
	+ Might there be unexplained variance that could be explained by predictors missing from your model?
		+ Or an interaction between predictors (see lecture 11 and 12)
	+ Is there something about a case that suggests it does not belong with the rest of the sample?
		+ Does a case come from a different population that would be expected to have substantively different IV-DV relations?
		+ E.g., do you have clinical cases in a non-clinical sample, children in a largely adult sample etc.
![](assets/img/image23.png)

---
#  Investigating and dealing with unusual cases 

+ Are there ‘unusual’ values as a result of skewness?
	+ Unusual values can sometimes result from skewed distributions
	+ Look at a histogram and skewness values to identify problems
	+ Consider transforming skewed variables to normality  (see lecture tomorrow)

```{r tbl34, echo = FALSE}
tbl34 <- tibble::tribble(
~`Positive skew`, ~`No skew`, ~`Negative skew`,
"Long tail to the right","Symmetrical","Long tail to the left",
"Lots of small values"," ","Lots of big values"
)

kableExtra::kable_styling(knitr::kable(tbl34), font_size = 18)
```
![](assets/img/image24.png)

---
#  Sensitivity Analyses 

+ Sensitivity analysis refers to the idea of checking whether you get similar results irrespective of the methodological decisions you make
+ Sensitivity analysis can be used to check whether you get the same pattern of results:
	+ With versus without including certain unusual cases
	+ With versus without transforming a variable
	+ Etc.
+ If results are highly similar, you have more confidence that the results aren’t very dependent on those decisions
+ If they differ a lot, this should be reported as a limitation

---
#  Summary 

+ Regression case diagnostics allow us to learn about:
	+ Cases that are poorly described by the model (regression outliers)
	+ Cases that have unusual combinations of predictor values (leverage)
	+ Cases that strongly affect the regression results (influence)
+ Typically we are most concerned about influential cases
	+ They can undermine the generalisability of the conclusions
+ Cases flagged by regression diagnostics should not necessarily be deleted, but followed-up to see if the reasons can be identified

---
#  Things to do… 

+ **Problem set & Lab** **:**
	+ Lab: Continue with the big lab from last week. This week should be running and checking your models.
	+ Problem Set: Some more practice with assumptions and diagnostics. Answers to the problem set will be posted after Thursday final lab.
+ **Reading** **:** On LEARN. No additional readings
+ **Homework** **:** Categorical variables and model selection.
	+ Open now, closes 17:00 Sunday.
