---
title: ' Lecture 20:Validity '
subtitle: 'Research Methods & Statistics 3  Alex Weiss: alex.weiss@ed.ac.uk, F17 7 George Square '
author: Tom Booth
date: 2020-06-23
output:
  xaringan::moon_reader:
  lib_dir: libs
  nature:
    highlightStyle: github
    highlightLines: true
    countIncrementalSlides: false
---
#  Todays lecture 

+ Defining validity
+ Relation of reliability and validity
+ Debate on the concept of validity
+ Types of validity and what it can tell us about a measure

---
#  Global reference 

+ Much of the source material from this lecture comes from:

Hughes, D.J. (In press). Psychometric Validity: Establishing the Accuracy and Appropriateness of Psychometric Measures. In Irwing , Booth & Hughes (Eds.). *Wiley Handbook of Psychometric Testing.*

---
#  Validity of measurement 

+ Before we continue it is worth noting that this lecture largely concerns ***validity of measurement.***
+ Other concepts in validity are relevant to study design.
	+ E.g. Ecological validity
	+ That is we could talk about whether survey methodology is an ecologically valid way to study X, in the same way as we could an experimental paradigm.

---
#  Validity 

+ Standard for Educational and Psychological Testing:

“Validity refers to the degree to which evidence and theory support the interpretations of test scores for proposed uses of tests. Validity is, therefore, the most fundamental consideration in developing tests and evaluating tests. The process of validation involves accumulating relevant evidence to provide a sound scientific basis for the proposed score interpretations. It is the interpretations of the test scores for the proposed uses that are valuated, not the test itself.”

---
#  Much debate about validity 

![](assets/img/image1.emf)

---
#  Evidence for Validity 

+ The debate around the definition of validity brings to prominence discussion of exactly what constitutes evidence for validity.
+ The sources of evidence align to what may be viewed as “classical” concepts of validity reported in many textbooks, studies and test manuals.

---
#  Evidence related to content 

+ Content validity:
	+ A test should contain only content relevant to the intended construct.
	+ It should measure what it was intended to measure.
+ Face validity:
	+ Does the test appear to measure what it was designed to measure to those taking the test.

---
#  Evidence from within the scale 

+ Factorial validity:
	+ Do the items measure a single intended construct.
	+ This is a tricky concept.
		+ As we have discussed, factor models provide very limited information towards this.
		+ And how else would we assess it?

---
#  Relations with other constructs 

+ Construct validity, or…
+ Convergent and discriminant validity (Cronbach and Meehl , 1955).
	+ **Convergent:** A measure should have high correlations with other measures of the same construct.
	+ **Discriminant:** A measure should have low correlations with measures of different constructs.
	+ **Nomological** **net:** Broadly defined, a measure should have expected patterns of correlations with different sets of constructs.

---
#  Nomological nets 

![](assets/img/image2.tiff)

---
#  Relations with other constructs 

+ We may also think about these relations in terms of there temporal sequence.
+ Concurrent validity:
	+ Correlations with contemporaneous measures.
+ Predictive validity:
	+ Does my measure predict an expected set of outcomes at a future point in time.

---
#  Evidence related to response process 

+ Figure from Karabenick et al. (2007). Cognitive Processing of Self-Report Items in Educational Research: Do they think what we mean? *Educational Psychologist, 42,* 139-151.
+ Area of validity evidence which is not commonly considered in design.
+ We will talk more about this next lecture.
![](assets/img/image3.emf)


---
#  Evidence concerning consequences 

+ Perhaps the most controversial and debated aspect of current validity discussions.
+ Should the potential consequences of test use be considered part of evidence for its validity as an instrument?
+ Very important questions for the **use** of tests.
	+ Is my measure fair for all groups of test takers?
	+ Put another way, is it systematically biased?
	+ Does this bias have social ramifications in its application?

---
#  So what is validity? 

+ Hughes (in press):
	+ *Validity* is a word with myriad meanings, some which are markedly different.
	+ When using term ‘validity’, be critical and examine which evidence has been used to ‘determine validity’.
	+ Validation is an on-going process.
	+ It concerns
		+ Accuracy
		+ Appropriateness
![](assets/img/image4.png)

---
#  Establishing Accuracy and Appropriateness 

+ Accuracy
	+ Content
	+ Response process
	+ Structural (within and across groups)
	+ Convergent (two measures of the same construct)
+ Appropriateness
	+ Predictive, concurrent, incremental
	+ Know groups
	+ Consequences (fairness, bias)
	+ Feasibility (cost, length etc.)
![](assets/img/image4.png)

---
#  Reliability and Validity 

+ Last lecture we defined reliability as the relation of the true score with the observed score.
+ In the previous slides, we defined validity in a number of ways, but correlations with other measures plays a key role.
+ Logically, a score or measure can not correlate with anything more than it correlates with itself.
+ And so reliability becomes the limit on validity.

---
#  Why do reliability and validity matter? 

+ Fundamental first step in science is measurement.
	+ If we can not measure well the variables of interest, we can not study them.
+ This is a large and tricky problem in psychology where many variables/constructs are not directly accessible.
	+ I know, I know, I say this A LOT.

---
#  Why do reliability and validity matter? 

+ Poor reliability and validity may lead to erroneous conclusions due to measurement problems.
+ If we know the reliability of the test, we can sometimes make adjustments to results.
	+ Correction for attenuation.
+ And they can be interesting subjects of investigation in and of themselves.

---
#  Validity studies 

+ From the preceding discussion, it is clear validity studies can take many forms. 
	+ New measure given as part of a large battery and concurrent validity (convergent and discriminant) considered.
		+ This will usually also contain factorial validity.
	+ Samples may be followed up for predictive validity.

---
#  Where do I find this information? 

+ Test manuals for established tests.
+ Original published papers for new tests.
+ Papers investigating the quality of measures in different groups, languages, contexts etc.

---
#  Where do I find this information? 

+ Some useful journals:
	+ *Assessment*
	+ *Psychological Assessment*
	+ *European Journal of Psychological Assessment*
	+ *Organisational Research Methods*
+ More advanced discussions appear in:
	+ *Methodology*
	+ *Psychometrika*

---
#  Tasks for this week… 

+ **Problem** **set:** Glossary and begin exam note preparations.
+ **Lab:** Weeks 3 to 5 you will be doing a large EFA analysis.
	+ This week you will be looking at the reproducibility of a section of your solution and on reliability estimates.
+ **Reading:** Reading list on LEARN.
+ **Homework:** Factor analysis 2.
	+ Live now, closes Sunday at 17:00
