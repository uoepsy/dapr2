---
title: "<b> Sum-to-zero (Effects) coding & Manual Contrasts </b>"
subtitle: "Data Analysis for Psychology in R 2<br><br> "
author: "dapR2 Team"
institute: "Department of Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #base_color = "#0F4C81", # DAPR1
   base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(car)
library(patchwork)
library(kableExtra)
library(effsize)
library(simglm)
library(emmeans)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(3119) 

sim_arguments <- list(
  formula = y ~ 1 + hours + motivation + study + method,
  fixed = list(hours = list(var_type = 'ordinal', levels = 0:15),
               motivation = list(var_type = 'continuous', mean = 0, sd = 1),
               study = list(var_type = 'factor', 
                            levels = c('alone', 'others'),
                            prob = c(0.53, 0.47)),
               method = list(var_type = 'factor', 
                            levels = c('read', 'summarise', 'self-test'),
                            prob = c(0.3, 0.4, 0.3))),
  error = list(variance = 20),
  sample_size = 250,
  reg_weights = c(0.6, 1.4, 1.5, 6, 6, 2)
)

df3 <- simulate_fixed(data = NULL, sim_arguments) %>%
  simulate_error(sim_arguments) %>%
  generate_response(sim_arguments)

test_study3 <- df3 %>%
  dplyr::select(y, hours, motivation, study, method) %>%
  mutate(
    ID = paste("ID", 101:350, sep = ""),
    score = round(y+abs(min(y))),
    motivation = round(motivation, 2),
    study = factor(study),
    method = factor(method)
  ) %>%
  dplyr::select(ID, score, hours, motivation, study, method)

```


# Weeks Learning Objectives
1. Understand the difference between dummy and sum-to-zero coding.

2. Understand the core principle of different coding schemes.

3. Interpret the output from a model using sum-to-zero coding.

4. Introduce rules for constructing contrasts

5. Use `emmeans` to investigate manual contrasts.


---
class: inverse, center, middle

# Part 1: Why can't we always use dummy coding?

---
# Why not always use dummy coding?
+ Last week we discussed dummy coding.

+ We saw how it:
  + Creates a set of $k$-1, dummy variables (coded 0-1).
  + Each variable codes the difference between the group coded 1, and the reference group (coded 0 for all dummy variables)
  + As such, we say it uses a reference group constraint to estimate our group means

+ This is a neat and (comparatively) straight-forward way to deal with categorical variables.

+ But it doesn't always give us the exact test we need. We might want to compare to:
  + The overall or grand mean
  + Group 1 vs groups 2, 3, 4 combined
  + and on we could go!


---
# Why not always use dummy coding?
+ The link last week has many different examples of coding schemes that answer different questions.

+ This week we will consider the two examples on the previous slide:

1. Comparing a specific group to the overall mean in your sample (grand mean). This is **sum-to-zero or effects coding**
2. Comparing specific combinations of groups. This is **manual contrasts**

+ Let's start with the grand mean with our class study example.

---
# Effects coding (sum to zero coding)

.pull-left[
```{r, echo=FALSE, message=FALSE}
set.seed(1)
gpM <- test_study3 %>%
  group_by(method) %>%
  summarise(
    score = round(mean(score))
  ) %>%
  mutate(
    GM = c(rep(mean(score),3))
  )

test_study3 %>%
  ggplot(., aes(x=method, y=score, colour = method, shape = method)) +
  geom_jitter(width = 0.1, size = 2) + 
  geom_hline(yintercept = mean(test_study3$score), lty = 2, colour = "darkgrey") +
  theme_classic() +
  geom_errorbar(data = gpM, width=0.8,aes(ymax= after_stat(y),ymin= after_stat(y)))
```
]

.pull-right[

+ To interpret the plot:
  + The coloured points represent the individual test scores for the students in each group.
  + The solid coloured lines are the group means.
  + The dashed grey line is the grand mean (the mean of all the observations)

+ We can see already a key difference
  + Rather than all groups being compared to reading, all will not be compared to the grey line.

+ **looking at this plot, if our coefficients will compare each group (solid colour line), to the grand mean (grey dashed line), what direction of coefficients would we expect for each group? Where is the biggest absolute difference?**

]


---
# Model with the grand mean
+ If we write our model including the grand mean, we get:

$$y_{ij} = \mu + \beta_j + \epsilon_{ij}$$
+ where
  + $y_{ij}$ is the score for a given individual ( $i$ ) in a given group ( $j$ )
  + $\mu$ is the grand mean
  + $\beta_j$ is a group specific effect
  + $\epsilon_{ij}$ is the individual deviation from the group mean
  
+ Let's breifly consider the constraints we apply, before looking at how we do this in R.

---
# Model with the grand mean
+ This means that each group mean is:

$$\mu_{read} = \mu + \beta_{read}$$

$$\mu_{self-test} = \mu + \beta_{self-test}$$

$$\mu_{summarise} = \mu + \beta_{summarise}$$

+ And as with dummy coding, this means we have 4 things to estimate ( $\mu$ , $\beta_{read}$ , $\beta_{self-test}$ , $\beta_{summarise}$ ), but only 3 group means.

---
# Sum to zero constraint

+ In sum to zero coding, we fix this with the following constraint:

$$\sum_{j=1}^m \beta_j = 0$$

+ Or alternatively written for the 3 group case:

$$\beta_1 + \beta_2 + \beta_3 = 0$$


---
# Sum to zero constraint
+ This constraints leads to the following interpretations:

+ $\beta_0$ is the grand mean (mean of all observations) or $\mu$

+ $\beta_j$ are the differences between the coded group and the grand mean:

$$\beta_j = \mu_j - \mu$$

---
# Why the grand mean?

$$\beta_1 + \beta_2 + \beta_3 = 0$$

+ Substitute $\beta_0$ :

$$(\mu_1 - \beta_0) + (\mu_2 - \beta_0) + (\mu_3 - \beta_0) = 0$$

$$\mu_1 + \mu_2 + \mu_3 = 3\beta_0$$

$$\beta_0 = \frac{\mu_1 + \mu_2 + \mu_3}{3} $$
$$\beta_0 = \mu$$

---
# Sum to zero constraint

+ Finally, we can get back to our group means from the coefficients as follows: 

$$\mu_1 = \beta_0 + \beta_1$$

$$\mu_2 = \beta_0 + \beta_2$$

$$\mu_3 = \beta_0 - (\beta_1 + \beta_2)$$

---
class: inverse, center, middle

# Part 2: Calculating coefficients with sum-to-zero coding



---
# Group Means

```{r}
test_study3 %>%
  select(1,2,6) %>%
  group_by(method) %>%
  summarise(
    mean = round(mean(score),3),
    sd = round(sd(score),1),
    N = n()
  )
```


---
# Effects (sum to zero) model

+ We need to change the contrast scheme from default.

```{r}
contrasts(test_study3$method) <- contr.sum 
contrasts(test_study3$method)
```

---
# Effects (sum to zero) model
```{r}
summary(lm(score ~ method, data = test_study3))
```


---
# Effects (sum to zero) model

.pull-left[
```{r, echo=FALSE}
Eres <- summary(lm(score ~ method, data = test_study3))
round(Eres$coefficients[,1],3)
```

+ Coefficients from group means


$$\beta_0 = \frac{\mu_1 + \mu_2 + \mu_3}{3}$$ 

$$\beta_1 = \mu_1 - \mu$$

$$\beta_2 = \mu_2 - \mu$$

]


.pull-right[

```{r, echo=FALSE}
test_study3 %>%
  select(1,2,6) %>%
  group_by(method) %>%
  summarise(
    mean = round(mean(score),3)
  ) %>%
  mutate(
    Gmean = round(mean(mean),3),
    Coefficients = mean - Gmean
  ) %>%
  kable(.) %>%
  kable_styling(., full_width = F)
```

]


---
# Effects (sum to zero) model

.pull-left[
```{r, echo=FALSE}
Eres <- summary(lm(score ~ method, data = test_study3))
round(Eres$coefficients[,1],3)
```

+ Group means from coefficients:

$$\mu_1 = \beta_0 + \beta_1$$

$$\mu_2 = \beta_0 + \beta_2$$

$$\mu_3 = \beta_0 - (\beta_1 + \beta_2)$$
]


.pull-right[

```{r, echo=FALSE}
test_study3 %>%
  select(1,2,6) %>%
  group_by(method) %>%
  summarise(
    mean = round(mean(score),3)
  ) %>%
  mutate(
    Gmean = round(mean(mean),3),
    Coefficients = mean - Gmean
  ) %>%
  kable(.) %>%
  kable_styling(., full_width = F)
```

```{r}
25.062 + -1.648
```

```{r}
25.062 + 2.514
```

```{r}
25.062 - (-1.648 + 2.514)
```


]


---
# The wide world of contrasts 
+ We have now seen two examples of coding schemes (dummy and effect).

+ There are **lots** of different coding schemes we can use for categorical variables to make different comparisons.
  + If you are interested, see the excellent resource on [UCLA website](https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/)

+ But always remember...

**The data is the same, the tested contrast differs**

---
class: inverse, center, middle

# Part 3: The data doesn't change, what we compare does

---
# The data is the same, the tested contrasts differ

+ We can run our model for `method` using both dummy and sum-to-zero coding schemes

```{r}
contrasts(test_study3$method) <- contr.treatment
m_dummy <- lm(score ~ method, data = test_study3)

# Change the contrasts and run again
contrasts(test_study3$method) <- contr.sum
m_zero <- lm(score ~ method, data = test_study3)

```

+ Create a small data set:

```{r}
treat <- tibble(method = c("read", "self-test", "summarise"))
```

---
# The data is the same, the tested contrasts differ

+ Add the predicted values from our models

```{r}
treat %>%
  mutate(
    pred_dummy = predict(m_dummy, newdata = .),
    pred_zero = predict(m_zero, newdata = .)
  )
```

+ No matter what coding or contrasts we use, we are still modelling the group means!



---
class: inverse, center, middle

# Part 4: Setting up our own specific tests


---
# Why do we need manual contrasts?
+ We have looked now at dummy and sum-to-zero coding. 

+ These provide us with coefficients which test the significance of the difference between means of groups and some other mean (either reference group or grandmean)
  + The other coding schemes we linked to do exactly the same thing.

+ ***Sometimes*** we have a research question that requires the test of the difference between particular combinations of groups for which there is no *"off the shelf"* test. 

+ For such situations, we can apply a set of rules and test what are referred to as manual contrasts.


---
# Manual contrast testing
+ We can structure a wide variety of contrasts so long as they can be written:

  1. A as a linear combination of population means.
  2. The associated coefficients (weights $c_1$ etc below) sum to zero.

+ So

$$H_0: c_1\mu_1 + c_2\mu_2 + c_3\mu_3 $$

+ With

$$c_1 + c_2 + c_3 = 0$$

---
# New example
+ Suppose we were interested in the effect of various relationship statuses on an individuals subjective well-being (`swb`)

+ Our predictor is `status` which has 5 levels:
  + Married or Civil Partnership
  + Cohabiting relationship
  + Single
  + Widowed
  + Divorced

+ Let's say we have data on 500 people.

---
# Data
```{r, echo=FALSE}
n <- round(500*(c(.55, .2, .1, .05, .1)),0)
set.seed(7284)
wb_tib <- tibble(
  swb = c(rnorm(n[1], 11, 3.6),
          rnorm(n[2], 12, 4.2),
          rnorm(n[3], 8, 2.2),
          rnorm(n[4], 6, 1.1),
          rnorm(n[5], 9.5, 2.5)),
  status = factor(c(rep("Married/CP", n[1]),
             rep("Cohab", n[2]),
             rep("Single", n[3]),
             rep("Widowed", n[4]),
             rep("Divorced", n[5]))
             )
)

wb_tib %>%
  group_by(status) %>%
  summarise(
    n = n(),
    mean = round(mean(swb),2),
    sd = round(sd(swb),2)
  ) %>%
  kable(.)%>%
  kable_styling(., full_width = F)
```


---
# Our questions
+ Suppose we want to know if there are `swb` differences between:

1. Those who are currently or previously married or in a civil partnership vs not.
2. Those who are currently married or in a civil partnership vs those who have previously been.

+ To not test this, we need to:
  + group levels of our factor `status`
  + calculate a mean of these new sub-groups making sure all groups contribute equally to the respective groups
  + then test the difference between these means

+ Manual contrasts can do this for us, if we follow some rules.

---
# Rules manual contrasts

+ **Rule 1**: Weights (e.g. $c_1$ etc from previous slide) range between -1 and 1
+ **Rule 2**: The group(s) in one chunk are given negative weights, the group(s) in the other get positive weights
+ **Rule 3**: The sum of the weights of the comparison must be 0
+ **Rule 4**: If a group is not involved in the comparison, weight is 0
+ **Rule 5**: For a given comparison, weights assigned to group(s) are equal to 1 divided by the number of groups in that chunk.
+ **Rule 6**: Restrict yourself to running $k$ - 1 comparisons (where $k$ = number of groups)
+ **Rule 7**: Each contrast can only compare 2 chunks
+ **Rule 8**: Once a group singled out, it can not enter other contrasts 

---
# Applying rules
+ Let's construct two contrasts to answer questions 1 and 2:

1. Those who are currently or previously married or in a civil partnership vs not.
2. Those who are currently married or in a civil partnership vs those who have previously been.

```{r, echo=FALSE}
contrasts <- tibble(
  group = c("Cohab", "Divorced", "Married/CP", "Single", "Widowed"),
  contrast1 = round(c(-0.5, 1/3, 1/3, -0.5, 1/3),2),
  contrast2 = round(c(0, -0.5, 1, 0, -0.5),2)
  )
contrasts %>% 
  kable(.) %>%
  kable_styling(., full_width = F)
```


---
# Orthogonal vs. Non-orthogonal Contrasts
+ Orthogonal contrasts test independent sources of variation.
  + If we follow the rules above, we will have orthogonal contrasts.

+ Non-orthogonal contrasts test non-independent sources of variation.
  + This presents some further statistical challenges in terms of making inferences. 
  + We will come back to this discussion later in the course.

---
# Checking if contrasts are orthogonal
+ The sum of the products of the weights will = 0 for any pair of orthogonal comparisons

$$\sum{c_{1j}c_{2j}} = 0$$

---
# From our example

```{r, echo=FALSE}
contrasts %>% 
  kable(.) %>%
  kable_styling(., full_width = F)
```

+ Below we can see the product of $c_1c_2$ for each level, and the row-wise sums for each contrast and the products.
  + The 0 for contrast 1 and 2 show we have set correct weights.
  + The 0 for the product shows the contrasts are orthogonal

```{r, echo=FALSE}
tibble(
  Contrast = c("Contrast1", "Contrast2", "Product"),
  Cohab = c(-0.5, 0, 0),
  Divorced = c(0.33, -0.5, -0.165),
  Married_CP = c(0.33, 1, 0.33),
  Single = c(-0.5, 0, 0),
  Widowed = c(0.33, -0.5, -.165),
  Sum = c(0,0,0)
  ) %>%
  kable(.) %>%
  kable_styling(., full_width = F)
```


---
class: inverse, center, middle

# Part 5: Testing manual contrasts using emmeans


---
# Using `emmeans` to test contrasts

+ We will use the package `emmeans` to test our contrasts
  + We will also be using this in the next few weeks to look at analysing experimental designs.

+ **E**stimated
+ **M**arginal
+ **Means**

+ Essentially this package provides us with a lot of tools to help us model contrasts and linear functions.

---
# Working with `emmeans`
+ First we run our model:

```{r}
status_res <- lm(swb ~ status, wb_tib)
```

+ Next we use the `emmeans` to get the estimated means of our groups.

```{r}

status_mean <- emmeans(status_res, ~status)
status_mean
```


---
# Visualise estimated means

.pull-left[
```{r, eval=FALSE}
plot(status_mean)
```

+ We then use these means to test contrasts

]

.pull-right[
```{r, echo=FALSE}
plot(status_mean)
```

]

---
# Defining the contrast

+ **KEY POINT**: The order of your categorical variable matters as `emmeans` uses this order. 


```{r, echo=FALSE}
contrasts %>% 
  kable(.) %>%
  kable_styling(., full_width = F)
```


```{r}
levels(wb_tib$status)
```

```{r}
status_comp <- list("Married or CP vs not" = c(-1/2, 1/3, 1/3, -1/2, 1/3),
                    "Current vs Not current" = c(0, -1/2, 1, 0, -1/2))

```


---
# Requesting the test
+ In order to test our effects, we use the `contrast` function from `emmeans`

```{r}
status_comp_test <- contrast(status_mean, status_comp)
status_comp_test
```
+ We can see we have p-values, but we can also request confidence intervals

```{r}
confint(status_comp_test)
```


---
# Interpreting the results
+ The estimate is the difference between the average of the group means within each chunk.


```{r}
confint(status_comp_test)
```
+ So for `Married or CP vs not` :

```{r}
((10.63 + 6.00 + 9.37)/3) - ((11.44 + 8.06)/2)
```
+ So those who are not currently or previously married or in a civial partnership have higher SWB.
  + And this is significant.


---
# Summary of today

+ We have considered different ways in which we can code categorical predictors.

+ Take home:
  + Use of coding schemes allows us to compare groups (or levels) in lots of ways.
  + Our $\beta$'s will represent differences in group means.
  + The scheme we use determines which group or combination of groups we are comparing.
  + **In all cases the underlying data is unchanged.**

+ We also looked at the use of `emmeans` in testing manual contrasts.
  + Run the model
  + Estimate the means
  + Define the contrast
  + Test the contrast

+ Though I am sure tricky at points, I hope this shows how coding schemes are a very flexible tool for testing hypotheses.


---
class: inverse, center, middle

# Thanks for listening
