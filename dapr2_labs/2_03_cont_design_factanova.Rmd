---
title: "Contrasts, Study Design, & Factorial ANOVA"
bibliography: references.bib
biblio-style: apalike
link-citations: yes
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---

```{r setup, include=FALSE}
source('assets/setup.R')

set.seed(953)
```


:::lo
**LEARNING OBJECTIVES**

1. Understand how to specify contracts to test specific effects.  
2. Understand different types of study design.
3. Interpret interactions with effects coding.

:::

# Case Study - Contrasts

In the first section of this lab, you will be presented with a research question, and will need to go through the steps of describing, visualising, modelling, and interpreting the results. 

> **Research Question:** 
> Does WPM differ by caffeine treatment condition?  

To investigate if the number of words typed per minute (WPM) differs among caffeine treatment conditions, the researchers conducted an experiment where participants were randomly allocated to one of four treatment conditions. Two of these conditions included non-caffeinated drinks - control (water) and mint tea, and the other two caffeinated drinks - coffee and red bull. 

| Drink           | Caffeine | Temp  | 
|:---------------:|:--------:|:-----:|
| Control (Water) | No       | Cold  | 
| Red Bull        | Yes      | Cold  | 
| Coffee          | Yes      | Hot   |
| Mint Tea        | No       | Hot   |

The researchers were specifically interested in the following comparisons:

- Whether having some kind of caffeine (i.e., red bull / coffee), rather than no caffeine (i.e., control - water / mint tea), resulted in a difference in average WPM
- Whether there was a difference in average WPM between those with hot drinks (i.e., mint tea / coffee) in comparison to those with cold drinks (control - water / red bull)

`r optbegin("Caffeine data codebook.", olabel=FALSE, toggle=params$TOGGLE)`  

__Download link__

The data is available at https://uoepsy.github.io/data/caffeinedrink.csv.  
__Preview__

The first six rows of the data are:

```{r echo=FALSE}
library(tidyverse)
read_csv('https://uoepsy.github.io/data/caffeinedrink.csv') %>% 
    head() %>% 
    gt::gt()
```
  
`r optend()`

`r qbegin(1)`

(1) Load the `tidyverse` package.
(2) Read the data into R using the function `read_csv()` and name the data `caffeine`.
(3) Check for the correct coding of all variables (i.e., categorical variables should be factors and numeric variables should be numeric).

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
library(tidyverse)
caffeine <- read_csv("https://uoepsy.github.io/data/caffeinedrink.csv")
```

Treatment is a categorical variable but it is coded as a character (`<chr>`), so we need to correct this: 

```{r}
caffeine <- caffeine %>%
  mutate(treatment = as.factor(treatment))
```

`r solend()`

`r qbegin(2)`

Numerically and visually summarise the `caffeine` dataset. Comment on any observed differences among treatment groups. 

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
caffeine%>%
  group_by(treatment) %>%
  summarise(n = n(), 
            M = mean(wpm), 
            SD = sd(wpm))
```

We have a continuous outcome and a categorical predictor - a boxplot would be most appropriate for visualisations:

```{r}
ggplot(data = caffeine, aes(x = treatment, y = wpm, color = treatment)) +
  geom_boxplot() +
  labs(x = 'Treatment Condition', y = 'WPM') + 
    theme_classic()
```

:::int

From the boxplots, it seems that those in the Red Bull condition, on average, typed the most WPM, whilst those in the Mint Tea condition the fewest. 

Overall, the average WPM appears to be lower for those in the non-caffeine conditions (i.e., control - water / mint tea) in comparison to those in the caffeine drinks condition (red bull / coffee).

:::

`r solend()`

`r qbegin(3)`

Set an appropriate reference group based on the research question. 

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

It would make most sense to have the 'Control' caffeine treatment condition as our reference group. 

```{r}
caffeine$treatment <- fct_relevel(caffeine$treatment, "control")
```

`r solend()`

`r qbegin(4)`

Fit the following model, and assign it the name "caf_mdl1". 

Examine and describe the coefficients in the output of `summary()` before interpreting the F-test results from `anova()` in the context of the ANOVA null hypothesis.

$\text{WPM} = \beta_0 + \beta_1 \cdot \text{Treatment (Category)} + \epsilon$  

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
caf_mdl1 <- lm(wpm ~ treatment, data=caffeine)
summary(caf_mdl1)
anova(caf_mdl1)
```


:::int

The estimate corresponding to (Intercept) contains $\hat \beta_0 = \hat \mu_1 = 112.1460$. The estimated average WPM for those in the control condition (water) is approximately 112.15.

The next estimate corresponds to `treatmentcoffee` and is $\hat \beta_2 = 2.3350$. The difference in mean WPM between `Control` and `Coffee` is estimated to be $2.3350$. In other words, people who have had a coffee type approximately 2.3 words per minute more than those who have had water.

The estimate corresponding to `treatmentmint_tea` is $\hat \beta_3 = -1.0550$. This is the estimated difference in mean WPM between `Control` and `Mint Tea` is estimated to be $-1.0550$. In other words, people who have had a mint tea type approximately 1.1 words per minute less than those who have had water.

The estimate corresponding to `treatmentred_bull` is $\hat \beta_4 = 4.5060$. This is the estimated difference in mean WPM between `Control` and `Red Bull` is estimated to be $4.5060$. In other words, people who have had a red bull type approximately 4.5 words per minute more than those who have had water.

We performed an analysis of variance against the null hypothesis of equal population mean spending across four types of treatment condition. At the 5% significance level, we reject the null hypothesis as there is strong evidence that at least three population means differ $F(3, 36) = 15.05$, $p < .001$.

:::

`r solend()`

`r qbegin(5)`

The two planned comparisons that the researchers were interested in can be translated into the following research hypotheses:


\begin{aligned}
1. \quad H_0 &: \mu_\text{No Caffeine} = \mu_\text{Caffeine} \\

    \quad H_0 &: \frac{1}{2} (\mu_\text{Control} + \mu_\text{Mint Tea}) = \frac{1}{2} (\mu_\text{Coffee} + \mu_\text{Red Bull}) \\



2. \quad H_0 &: \mu_\text{Hot Drink} = \mu_\text{Cold Drink} \\
    \quad H_0 &: \frac{1}{2} (\mu_\text{Coffee} + \mu_\text{Mint Tea}) = \frac{1}{2} (\mu_\text{Control} + \mu_\text{Red Bull})

\end{aligned}


After checking the levels of the factor `treatment`, use `emmeans` to obtain the estimated treatment means and uncertainties for your factor. *Hint* use plot() to visualise this.

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
levels(caffeine$treatment)
```

```{r}
library(emmeans)
emm <- emmeans(caf_mdl1, ~ treatment)
emm
plot(emm)
```

`r solend()`

`r qbegin(6)`

Specify the coefficients of the comparisons and run the contrast analysis. Obtain 95% confidence intervals, and then interpret your results in relation to the researchers hypotheses. 

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
comp <- list("No Caffeine - Caffeine" = c(1/2, -1/2, 1/2, -1/2),
             "Hot Drink - Cold Drink" = c(-1/2, 1/2, 1/2, -1/2)
             )
```


```{r}
comp_res <- contrast(emm, method = comp)
comp_res
confint(comp_res)
```

The hypothesis test for the first contrast could be reported as follows:

:::int
We performed a test against $H_0: \frac{1}{2}(\mu_1 + \mu_3) - \frac{1}{2}(\mu_2 + \mu_4) = 0$. At the 5\% significance level, there was evidence that the mean WPM for those who were in the no caffeine condition was significantly different from those in a caffeine condition $t(36) = -6.62, p = < .001$ (two-sided). We are 95\% confident that those who consumed no caffeine typed, on average, between 2.7 and 5.3 words less per minute than those who consumed some form of caffeine $CI_{95}[-5.25, -2.65]$.
:::

The hypothesis test for the second contrast could be reported as follows:

:::int

We performed a test against $H_0: \frac{1}{2}(\mu_2 + \mu_3) - \frac{1}{2}(\mu_1 + \mu_4) = 0$. At the 5\% significance level, there was evidence that the average WPM for those in the hot drink condition significantly differed from those in the cold drink condition $t(36) = -2.52, p = .02$ (two-sided). We are 95\% confident that those who consumed a hot drink typed, on average, between 0.3 and 2.9 words less per minute than those who consumed a cold drink $CI_{95}[-2.91, -0.32]$.
:::

`r solend()`

## Study Design

For each of the below experiment descriptions, note (1) the design, (2) number of variables of interest, (3) levels of categorical variables, (4) what you think the reference group should be and why.

`r qbegin(1)`

A group of researchers were interested in whether sleep deprivation influenced reaction time. They hypothesised that sleep deprived individuals would have slower reaction times than non-sleep deprived individuals. 

To test this, they recruited 60 participants who were matched on a number of demographic variables including age and sex. One member of each pair (e.g., female aged 18) was placed into a different sleep condition - 'Sleep Deprived' (4 hours per night) or 'Non-Sleep Deprived' (8 hours per night).

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

1. Design = Between-person: Matched pairs
2. No of variables of interest = 2 - Sleep Condition and Reaction Time
3. Levels of variables = Sleep Condition has 2 levels - Sleep Deprived and Non-Sleep Deprived; Reaction Time is a continuous measure, so has no associated levels
4. Reference Groups = Sleep Condition - Non-Sleep Deprived because the RQ stated that the researchers were interested in how the sleep deprived group *differed from* the non-sleep deprived group. 

`r solend()`

`r qbegin(2)`

A group of researchers were interested in replicating an experiment testing the Stroop Effect. 

They recruited 50 participants who took part in Task A (word colour and meaning are congruent) and Task B (word colour and meaning are incongruent) where they were asked to name the color of the ink instead of reading the word. The order of presentation was counterbalanced across participants. The researchers hypothesised that participants would take significantly more time ('response time' measured in seconds) to complete Task B than Task A.

You can test yourself here for fun: [Stroop Task](https://www.psytoolkit.org/lessons/experiment_stroop.html)

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

1. Design = Within-person: repeated measures
2. No of variables of interest = 2 - Task and Response Time 
3. Levels of variables = Task has 2 levels - A and B; Response Time is a continuous measure, so has no associated levels
4. Reference Groups = Task - A because the RQ stated that the researchers were interested in how response time in Task B *differed from* the response time in Task A. 

`r solend()`

`r qbegin(3)`

A group of researchers wanted to test a hypothesised theory according to which patients with amnesia will have a deficit in explicit memory but not implicit memory. Huntingtons patients, on the other hand, will display the opposite: they will have no deficit in explicit memory, but will have a deficit in implicit memory.

To test this, researchers designed a study that included two variables: 'Diagnosis' (Amnesic, Huntingtons, Control) and 'Task' (Grammar, Classification, Recognition) where participants were randomly assigned to a Task condition. The first two tasks (Grammar and Classification) are known to reflect implicit memory processes, whereas the Recognition task is known to reflect explicit memory processes.

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

1. Design = Between-person: 3Ã—3 factorial design 
2. No of variables of interest = 2 - Diagnosis and Task
3. Levels of variables = Diagnosis has 3 levels - Amnesic, Huntingtons, and Control; Task has 3 levels - Grammar, Classification, and Recognition
4. Reference Groups = Diagnosis - Control; Task - Recognition. We have chosen Control since the other two groups have some form of cognitive impairment; and the Recognition task since it measures explicit memory whilst the other two task types implicit. 

`r solend()`

## Factorial ANOVA

Next week, the lab will focus on Experiment 3 described above. You have already worked with this data before - see [semester 1 week 8 lab](https://uoepsy.github.io/dapr2/labs/1_08_int_cc.html). We have data from the 45 participants (15 amnesiacs, 15 Huntington individuals, and 15 controls). Recall that study involves two factors with three levels each. For each combination of factor levels we have 5 observations:

```{r echo=FALSE}
df <- read_csv('https://uoepsy.github.io/data/cognitive_experiment.csv')
# head(df)

df$Diagnosis <- factor(df$Diagnosis, 
                       labels = c("amnesic", "huntingtons", "control"),
                       ordered = FALSE)

df$Task <- factor(df$Task, 
                  labels = c("grammar", "classification", "recognition"), 
                  ordered = FALSE)

library(kableExtra)

df %>% 
    pivot_wider(names_from = 'Task', values_from = 'Y') %>% 
    kable() %>%
    kable_styling(full_width = FALSE) %>%
    add_header_above(c(" " = 1, "Task" = 3))
```


The five observations are assumed to come from a population having a specific mean. The population means corresponding to each combination of factor levels can be schematically written as:


$$
\begin{matrix}
                   &         &         & \textbf{Task} & \\
                   &         & (j=1)\text{ grammar} & (j=2)\text{ classification} & (j=3)\text{ recognition} \\
                   & (i=1)\text{ control} & \mu_{1,1} & \mu_{1,2} & \mu_{1,3} \\
\textbf{Diagnosis} & (i=2)\text{ amnesic} & \mu_{2,1} & \mu_{2,2} & \mu_{2,3} \\
                   & (i=3)\text{ huntingtons} & \mu_{3,1} & \mu_{3,2} & \mu_{3,3}
\end{matrix}
$$


`r qbegin(1)`
Repeat the steps outlined in the Semester 1 Week 8 lab:

- Read the cognitive experiment data into R. 
- Convert categorical variables into factors, and assign more informative labels to the factor levels according to the data description provided above.
- Relevel the `Diagnosis` factor to have 'Control' as the reference group.
- Relevel the `Task` factor to have 'Recognition' as the reference group. 
- Rename the response variable from `Y` to `Score`.
- Describe the data.
- Visualise the interaction between Diagnosis and Task.

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Load the tidyverse library and read the data into R:

```{r}
cog <- read_csv('https://uoepsy.github.io/data/cognitive_experiment.csv')
head(cog)
```

We will now convert `Diagnosis` and `Task` into factors, making the labels of each factor level more meaningful. 

According to the data description, the encoding of the factor `Diagnosis` is: 1 = amnesic patients, 2 = Huntingtons patients, and 3 are control patients.The encoding for the factor `Task` is: 1 = grammar task, 2 = classification task, and 3 = recognition task.

```{r}
cog$Diagnosis <- factor(cog$Diagnosis, 
                        labels = c("amnesic", "huntingtons", "control"), 
                        ordered = FALSE)
cog$Task <- factor(cog$Task, 
                   labels = c("grammar", "classification", "recognition"), 
                   ordered = FALSE)
```

Relevel the `Diagnosis` factor so that the reference group is "Control":

```{r}
cog$Diagnosis <- fct_relevel(cog$Diagnosis, "control")
cog$Task <- fct_relevel(cog$Task, "recognition")
```

Rename the response:

```{r}
cog <- cog %>%
    rename(Score = Y)
```

Look at the data:

```{r}
head(cog)
```

Describe data:
```{r}
cog_stats <- cog %>% 
    group_by(Diagnosis, Task) %>%
    summarise(
        Avg_Score = mean(Score), 
        SD = sd(Score),
        SE = sd(Score) / sqrt(n())
        )

cog_stats
```

Since we have not yet fitted our model, we cannot use the `emmip` function from `emmeans` or `plot_model` from `sjPlot`. We can however use a simple `ggplot` and use our summary scores from above:

```{r}
ggplot(data = cog_stats, aes(x = Task, y = Avg_Score, color = Diagnosis)) +
    geom_point(size = 3) +
    geom_line(aes(x = as.numeric(Task)))
```

:::int

Control patients consistently perform best across all tasks. They don't seem to differ substantially in their scores between grammar and classification tasks, but they clearly perform better in the recognition task than the grammar and classification ones.

Amnesic patients appear to perform better than Huntingtons patients in grammar an classification tasks (reflecting intrinsic memory processes) and perform worse than Huntingtons patients in the recognition task (reflecting extrinsic memory processes).

:::

`r solend()`

`r qbegin(2)`

The model with interaction is:


\begin{aligned}
Score &= \beta_0 \\
      &+ \beta_1 D_\text{Control} + \beta_2 D_\text{Amnesic}   \\
      &+ \beta_3 T_\text{Recognition}  + \beta_4 D_\text{Grammar} \\
      &+ \beta_5 (D_\text{Control} * T_\text{Recognition}) + \beta_6 (D_\text{Amnesic} * T_\text{Recognition})  \\
      &+ \beta_7 (D_\text{Control} * T_\text{Grammar}) + \beta_8 (D_\text{Amnesic} * T_\text{Grammar})  \\
      &+ \epsilon 
\end{aligned}


Fit the above model, and set the the sum to zero constraint for `Diagnosis` of 'Control' and `Task` of 'Recognition'.

Applying the sum to zero constraint, we would have:

\begin{aligned}
\text{Intercept (global mean)} &= \beta_0 \frac{\mu_{1,1} + \mu_{1,2} + \cdots + \mu_{3,3}}{9} \\
\beta_{Huntingtons} &= -(\beta_1 + \beta_2) \\
\beta_{Classification} &= -(\beta_3 + \beta_4) \\
\beta_{Huntingtons:Classification} &= -(\beta_5 + \beta_6 + \beta_7 + \beta_8)
\end{aligned}

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

The fitted model should be:

```{r}
contrasts(cog$Diagnosis) <- "contr.sum"
contrasts(cog$Task) <- "contr.sum"
mdl_int1 <- lm(Score ~ Diagnosis * Task, data = cog)
summary(mdl_int1)
anova(mdl_int1)
```

Next week, we will explore the `summary()` and `anova()` output in detail. If you have time, note down what you think these estimates might be telling us. Remember, the interpretation of the estimates is now *different* from what you had in Semester 1 Week 8 - now each beta coefficient is the difference between a group mean and the **overall** mean. 

`r solend()`

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>